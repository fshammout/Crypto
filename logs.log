2023-02-03 14:46:41,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 14:46:41,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 14:46:41,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 14:46:41,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 14:46:42,898:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-03 15:11:05,142:INFO:PyCaret RegressionExperiment
2023-02-03 15:11:05,143:INFO:Logging name: reg-default-name
2023-02-03 15:11:05,143:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-03 15:11:05,143:INFO:version 3.0.0.rc8
2023-02-03 15:11:05,143:INFO:Initializing setup()
2023-02-03 15:11:05,144:INFO:self.USI: b860
2023-02-03 15:11:05,144:INFO:self._variable_keys: {'_available_plots', 'n_jobs_param', '_ml_usecase', 'exp_id', 'logging_param', 'fold_generator', 'html_param', 'USI', 'gpu_param', 'fold_groups_param', 'exp_name_log', 'idx', 'memory', 'fold_shuffle_param', 'seed', 'gpu_n_jobs_param', 'y', 'y_train', 'X_train', 'X', 'X_test', 'pipeline', 'log_plots_param', 'data', 'transform_target_param', 'y_test', 'target_param'}
2023-02-03 15:11:05,145:INFO:Checking environment
2023-02-03 15:11:05,145:INFO:python_version: 3.10.9
2023-02-03 15:11:05,145:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-02-03 15:11:05,145:INFO:machine: AMD64
2023-02-03 15:11:05,145:INFO:platform: Windows-10-10.0.19045-SP0
2023-02-03 15:11:05,146:INFO:Memory: svmem(total=17090879488, available=6431473664, percent=62.4, used=10659405824, free=6431473664)
2023-02-03 15:11:05,146:INFO:Physical Core: 4
2023-02-03 15:11:05,146:INFO:Logical Core: 8
2023-02-03 15:11:05,147:INFO:Checking libraries
2023-02-03 15:11:05,147:INFO:System:
2023-02-03 15:11:05,147:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-02-03 15:11:05,147:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-02-03 15:11:05,147:INFO:   machine: Windows-10-10.0.19045-SP0
2023-02-03 15:11:05,147:INFO:PyCaret required dependencies:
2023-02-03 15:11:05,147:INFO:                 pip: 23.0
2023-02-03 15:11:05,147:INFO:          setuptools: 67.1.0
2023-02-03 15:11:05,147:INFO:             pycaret: 3.0.0rc8
2023-02-03 15:11:05,148:INFO:             IPython: 8.8.0
2023-02-03 15:11:05,148:INFO:          ipywidgets: 8.0.4
2023-02-03 15:11:05,148:INFO:                tqdm: 4.64.1
2023-02-03 15:11:05,148:INFO:               numpy: 1.23.5
2023-02-03 15:11:05,148:INFO:              pandas: 1.5.3
2023-02-03 15:11:05,148:INFO:              jinja2: 3.1.2
2023-02-03 15:11:05,148:INFO:               scipy: 1.10.0
2023-02-03 15:11:05,148:INFO:              joblib: 1.2.0
2023-02-03 15:11:05,148:INFO:             sklearn: 1.1.3
2023-02-03 15:11:05,148:INFO:                pyod: 1.0.7
2023-02-03 15:11:05,148:INFO:            imblearn: 0.10.1
2023-02-03 15:11:05,148:INFO:   category_encoders: 2.6.0
2023-02-03 15:11:05,148:INFO:            lightgbm: 3.3.5
2023-02-03 15:11:05,148:INFO:               numba: 0.56.4
2023-02-03 15:11:05,149:INFO:            requests: 2.28.2
2023-02-03 15:11:05,149:INFO:          matplotlib: 3.6.3
2023-02-03 15:11:05,149:INFO:          scikitplot: 0.3.7
2023-02-03 15:11:05,149:INFO:         yellowbrick: 1.5
2023-02-03 15:11:05,149:INFO:              plotly: 5.13.0
2023-02-03 15:11:05,149:INFO:             kaleido: 0.2.1
2023-02-03 15:11:05,149:INFO:         statsmodels: 0.13.5
2023-02-03 15:11:05,149:INFO:              sktime: 0.16.0
2023-02-03 15:11:05,149:INFO:               tbats: 1.1.2
2023-02-03 15:11:05,150:INFO:            pmdarima: 2.0.2
2023-02-03 15:11:05,150:INFO:              psutil: 5.9.0
2023-02-03 15:11:05,150:INFO:PyCaret optional dependencies:
2023-02-03 15:11:05,189:INFO:                shap: Not installed
2023-02-03 15:11:05,189:INFO:           interpret: Not installed
2023-02-03 15:11:05,190:INFO:                umap: Not installed
2023-02-03 15:11:05,190:INFO:    pandas_profiling: Not installed
2023-02-03 15:11:05,190:INFO:  explainerdashboard: Not installed
2023-02-03 15:11:05,190:INFO:             autoviz: Not installed
2023-02-03 15:11:05,190:INFO:           fairlearn: Not installed
2023-02-03 15:11:05,190:INFO:             xgboost: Not installed
2023-02-03 15:11:05,190:INFO:            catboost: Not installed
2023-02-03 15:11:05,191:INFO:              kmodes: Not installed
2023-02-03 15:11:05,191:INFO:             mlxtend: Not installed
2023-02-03 15:11:05,191:INFO:       statsforecast: Not installed
2023-02-03 15:11:05,191:INFO:        tune_sklearn: Not installed
2023-02-03 15:11:05,192:INFO:                 ray: Not installed
2023-02-03 15:11:05,192:INFO:            hyperopt: Not installed
2023-02-03 15:11:05,192:INFO:              optuna: Not installed
2023-02-03 15:11:05,193:INFO:               skopt: Not installed
2023-02-03 15:11:05,193:INFO:              mlflow: Not installed
2023-02-03 15:11:05,193:INFO:              gradio: Not installed
2023-02-03 15:11:05,193:INFO:             fastapi: Not installed
2023-02-03 15:11:05,193:INFO:             uvicorn: Not installed
2023-02-03 15:11:05,194:INFO:              m2cgen: Not installed
2023-02-03 15:11:05,194:INFO:           evidently: Not installed
2023-02-03 15:11:05,194:INFO:                nltk: Not installed
2023-02-03 15:11:05,194:INFO:            pyLDAvis: Not installed
2023-02-03 15:11:05,194:INFO:              gensim: Not installed
2023-02-03 15:11:05,194:INFO:               spacy: Not installed
2023-02-03 15:11:05,194:INFO:           wordcloud: Not installed
2023-02-03 15:11:05,194:INFO:            textblob: Not installed
2023-02-03 15:11:05,194:INFO:               fugue: Not installed
2023-02-03 15:11:05,195:INFO:           streamlit: Not installed
2023-02-03 15:11:05,195:INFO:             prophet: Not installed
2023-02-03 15:11:05,195:INFO:None
2023-02-03 15:11:05,195:INFO:Set up GPU usage.
2023-02-03 15:11:05,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:05,195:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-02-03 15:11:05,195:INFO:Set up data.
2023-02-03 15:11:05,205:INFO:Set up train/test split.
2023-02-03 15:11:05,209:INFO:Set up index.
2023-02-03 15:11:05,210:INFO:Set up folding strategy.
2023-02-03 15:11:05,210:INFO:Assigning column types.
2023-02-03 15:11:05,215:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-03 15:11:05,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:05,216:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-03 15:11:05,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:05,221:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-03 15:11:05,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:05,228:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:11:05,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:05,323:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:05,323:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:05,402:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:11:05,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:05,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:05,404:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:13,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:13,645:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:13,645:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-03 15:11:13,646:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:13,660:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-03 15:11:13,660:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:13,675:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:11:13,675:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:13,788:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:13,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:13,848:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:11:13,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:13,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:13,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:14,210:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:14,211:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-03 15:11:14,211:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,211:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,228:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-03 15:11:14,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,246:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:11:14,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,383:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:14,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,452:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:11:14,452:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,453:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:14,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:14,611:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,611:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,625:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-03 15:11:14,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,639:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:11:14,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,757:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:14,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,819:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:11:14,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,820:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:14,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:14,995:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-03 15:11:14,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,023:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:11:15,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,142:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:15,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,212:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:11:15,212:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,212:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,213:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:15,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:15,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,393:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,407:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:11:15,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,524:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:15,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,581:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:11:15,582:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,582:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:15,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:15,756:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-03 15:11:15,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,771:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,911:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:15,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,977:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:11:15,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:16,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:16,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,155:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,286:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:16,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,347:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:11:16,347:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,347:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,348:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:16,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:16,524:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-03 15:11:16,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,676:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:16,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,740:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,740:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:16,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:16,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,115:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:17,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,193:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:17,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:17,370:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-03 15:11:17,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,388:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,532:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:17,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:17,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,791:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:18,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:18,146:INFO:Preparing preprocessing pipeline...
2023-02-03 15:11:18,148:INFO:Set up simple imputation.
2023-02-03 15:11:18,208:INFO:Finished creating preprocessing pipeline.
2023-02-03 15:11:18,219:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-02-03 15:11:18,219:INFO:Creating final display dataframe.
2023-02-03 15:11:18,402:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape          (648, 2)
4        Transformed data shape          (648, 2)
5   Transformed train set shape          (453, 2)
6    Transformed test set shape          (195, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              b860
2023-02-03 15:11:18,412:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,423:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,428:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,522:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,586:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,587:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:18,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:18,755:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,783:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:19,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:19,116:INFO:setup() successfully completed in 13.98s...............
2023-02-03 15:12:03,091:INFO:PyCaret RegressionExperiment
2023-02-03 15:12:03,091:INFO:Logging name: reg-default-name
2023-02-03 15:12:03,091:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-03 15:12:03,091:INFO:version 3.0.0.rc8
2023-02-03 15:12:03,091:INFO:Initializing setup()
2023-02-03 15:12:03,092:INFO:self.USI: 42b7
2023-02-03 15:12:03,092:INFO:self._variable_keys: {'_available_plots', 'n_jobs_param', '_ml_usecase', 'exp_id', 'logging_param', 'fold_generator', 'html_param', 'USI', 'gpu_param', 'fold_groups_param', 'exp_name_log', 'idx', 'memory', 'fold_shuffle_param', 'seed', 'gpu_n_jobs_param', 'y', 'y_train', 'X_train', 'X', 'X_test', 'pipeline', 'log_plots_param', 'data', 'transform_target_param', 'y_test', 'target_param'}
2023-02-03 15:12:03,092:INFO:Checking environment
2023-02-03 15:12:03,092:INFO:python_version: 3.10.9
2023-02-03 15:12:03,092:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-02-03 15:12:03,092:INFO:machine: AMD64
2023-02-03 15:12:03,092:INFO:platform: Windows-10-10.0.19045-SP0
2023-02-03 15:12:03,092:INFO:Memory: svmem(total=17090879488, available=5927350272, percent=65.3, used=11163529216, free=5927350272)
2023-02-03 15:12:03,093:INFO:Physical Core: 4
2023-02-03 15:12:03,093:INFO:Logical Core: 8
2023-02-03 15:12:03,093:INFO:Checking libraries
2023-02-03 15:12:03,093:INFO:System:
2023-02-03 15:12:03,093:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-02-03 15:12:03,093:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-02-03 15:12:03,093:INFO:   machine: Windows-10-10.0.19045-SP0
2023-02-03 15:12:03,093:INFO:PyCaret required dependencies:
2023-02-03 15:12:03,094:INFO:                 pip: 23.0
2023-02-03 15:12:03,094:INFO:          setuptools: 67.1.0
2023-02-03 15:12:03,094:INFO:             pycaret: 3.0.0rc8
2023-02-03 15:12:03,094:INFO:             IPython: 8.8.0
2023-02-03 15:12:03,094:INFO:          ipywidgets: 8.0.4
2023-02-03 15:12:03,094:INFO:                tqdm: 4.64.1
2023-02-03 15:12:03,094:INFO:               numpy: 1.23.5
2023-02-03 15:12:03,094:INFO:              pandas: 1.5.3
2023-02-03 15:12:03,094:INFO:              jinja2: 3.1.2
2023-02-03 15:12:03,094:INFO:               scipy: 1.10.0
2023-02-03 15:12:03,095:INFO:              joblib: 1.2.0
2023-02-03 15:12:03,095:INFO:             sklearn: 1.1.3
2023-02-03 15:12:03,095:INFO:                pyod: 1.0.7
2023-02-03 15:12:03,095:INFO:            imblearn: 0.10.1
2023-02-03 15:12:03,095:INFO:   category_encoders: 2.6.0
2023-02-03 15:12:03,095:INFO:            lightgbm: 3.3.5
2023-02-03 15:12:03,095:INFO:               numba: 0.56.4
2023-02-03 15:12:03,095:INFO:            requests: 2.28.2
2023-02-03 15:12:03,095:INFO:          matplotlib: 3.6.3
2023-02-03 15:12:03,095:INFO:          scikitplot: 0.3.7
2023-02-03 15:12:03,096:INFO:         yellowbrick: 1.5
2023-02-03 15:12:03,096:INFO:              plotly: 5.13.0
2023-02-03 15:12:03,096:INFO:             kaleido: 0.2.1
2023-02-03 15:12:03,096:INFO:         statsmodels: 0.13.5
2023-02-03 15:12:03,096:INFO:              sktime: 0.16.0
2023-02-03 15:12:03,096:INFO:               tbats: 1.1.2
2023-02-03 15:12:03,096:INFO:            pmdarima: 2.0.2
2023-02-03 15:12:03,096:INFO:              psutil: 5.9.0
2023-02-03 15:12:03,096:INFO:PyCaret optional dependencies:
2023-02-03 15:12:03,096:INFO:                shap: Not installed
2023-02-03 15:12:03,096:INFO:           interpret: Not installed
2023-02-03 15:12:03,096:INFO:                umap: Not installed
2023-02-03 15:12:03,096:INFO:    pandas_profiling: Not installed
2023-02-03 15:12:03,097:INFO:  explainerdashboard: Not installed
2023-02-03 15:12:03,097:INFO:             autoviz: Not installed
2023-02-03 15:12:03,097:INFO:           fairlearn: Not installed
2023-02-03 15:12:03,097:INFO:             xgboost: Not installed
2023-02-03 15:12:03,097:INFO:            catboost: Not installed
2023-02-03 15:12:03,097:INFO:              kmodes: Not installed
2023-02-03 15:12:03,097:INFO:             mlxtend: Not installed
2023-02-03 15:12:03,097:INFO:       statsforecast: Not installed
2023-02-03 15:12:03,097:INFO:        tune_sklearn: Not installed
2023-02-03 15:12:03,098:INFO:                 ray: Not installed
2023-02-03 15:12:03,098:INFO:            hyperopt: Not installed
2023-02-03 15:12:03,098:INFO:              optuna: Not installed
2023-02-03 15:12:03,098:INFO:               skopt: Not installed
2023-02-03 15:12:03,098:INFO:              mlflow: Not installed
2023-02-03 15:12:03,098:INFO:              gradio: Not installed
2023-02-03 15:12:03,098:INFO:             fastapi: Not installed
2023-02-03 15:12:03,098:INFO:             uvicorn: Not installed
2023-02-03 15:12:03,098:INFO:              m2cgen: Not installed
2023-02-03 15:12:03,098:INFO:           evidently: Not installed
2023-02-03 15:12:03,099:INFO:                nltk: Not installed
2023-02-03 15:12:03,099:INFO:            pyLDAvis: Not installed
2023-02-03 15:12:03,099:INFO:              gensim: Not installed
2023-02-03 15:12:03,099:INFO:               spacy: Not installed
2023-02-03 15:12:03,099:INFO:           wordcloud: Not installed
2023-02-03 15:12:03,099:INFO:            textblob: Not installed
2023-02-03 15:12:03,100:INFO:               fugue: Not installed
2023-02-03 15:12:03,100:INFO:           streamlit: Not installed
2023-02-03 15:12:03,100:INFO:             prophet: Not installed
2023-02-03 15:12:03,100:INFO:None
2023-02-03 15:12:03,100:INFO:Set up GPU usage.
2023-02-03 15:12:03,100:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,100:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-02-03 15:12:03,100:INFO:Set up data.
2023-02-03 15:12:03,105:INFO:Set up train/test split.
2023-02-03 15:12:03,109:INFO:Set up index.
2023-02-03 15:12:03,109:INFO:Set up folding strategy.
2023-02-03 15:12:03,109:INFO:Assigning column types.
2023-02-03 15:12:03,113:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-03 15:12:03,114:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,114:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,114:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,120:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,120:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,129:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,214:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,277:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,278:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:03,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:03,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,455:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,468:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,483:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,603:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,669:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,669:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,669:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,670:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:03,836:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:03,837:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-03 15:12:03,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,851:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,861:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,969:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,026:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,027:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:04,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:04,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,216:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,229:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,343:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,343:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,409:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,409:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:04,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:04,563:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-03 15:12:04,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,577:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,591:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,702:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,702:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,759:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,759:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,759:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,760:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:04,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:04,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,931:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,941:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,941:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,055:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:05,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:12:05,121:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,121:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:05,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:05,273:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-03 15:12:05,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,299:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,420:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:05,420:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,485:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:12:05,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:05,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:05,650:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,651:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,665:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,795:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:05,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,862:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:12:05,862:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,862:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,863:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:06,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:06,031:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-03 15:12:06,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,059:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,175:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:06,175:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,239:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:06,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:06,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,411:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,425:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,546:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:06,546:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,609:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,609:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:06,763:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:06,764:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-03 15:12:06,764:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,764:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,792:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,909:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,971:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,972:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:07,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:07,134:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,134:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,279:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:07,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:07,499:INFO:Preparing preprocessing pipeline...
2023-02-03 15:12:07,500:INFO:Set up simple imputation.
2023-02-03 15:12:07,549:INFO:Finished creating preprocessing pipeline.
2023-02-03 15:12:07,556:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-02-03 15:12:07,556:INFO:Creating final display dataframe.
2023-02-03 15:12:07,760:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape          (959, 2)
4        Transformed data shape          (959, 2)
5   Transformed train set shape          (671, 2)
6    Transformed test set shape          (288, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              42b7
2023-02-03 15:12:07,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,783:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,925:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:08,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:08,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:08,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:08,154:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:08,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:08,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:08,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:08,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:08,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:08,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:08,497:INFO:setup() successfully completed in 5.41s...............
2023-02-03 15:14:56,207:INFO:Initializing compare_models()
2023-02-03 15:14:56,207:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, include=None, fold=None, round=4, cross_validation=True, sort=r2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'r2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-03 15:14:56,207:INFO:Checking exceptions
2023-02-03 15:14:56,214:INFO:Preparing display monitor
2023-02-03 15:14:56,263:INFO:Initializing Linear Regression
2023-02-03 15:14:56,263:INFO:Total runtime is 0.0 minutes
2023-02-03 15:14:56,273:INFO:SubProcess create_model() called ==================================
2023-02-03 15:14:56,274:INFO:Initializing create_model()
2023-02-03 15:14:56,274:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:14:56,275:INFO:Checking exceptions
2023-02-03 15:14:56,275:INFO:Importing libraries
2023-02-03 15:14:56,275:INFO:Copying training dataset
2023-02-03 15:14:56,282:INFO:Defining folds
2023-02-03 15:14:56,282:INFO:Declaring metric variables
2023-02-03 15:14:56,292:INFO:Importing untrained model
2023-02-03 15:14:56,298:INFO:Linear Regression Imported successfully
2023-02-03 15:14:56,313:INFO:Starting cross validation
2023-02-03 15:14:56,339:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:14:57,776:INFO:Calculating mean and std
2023-02-03 15:14:57,777:INFO:Creating metrics dataframe
2023-02-03 15:14:57,785:INFO:Uploading results into container
2023-02-03 15:14:57,786:INFO:Uploading model into container now
2023-02-03 15:14:57,787:INFO:_master_model_container: 1
2023-02-03 15:14:57,787:INFO:_display_container: 2
2023-02-03 15:14:57,787:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:14:57,787:INFO:create_model() successfully completed......................................
2023-02-03 15:14:57,913:INFO:SubProcess create_model() end ==================================
2023-02-03 15:14:57,913:INFO:Creating metrics dataframe
2023-02-03 15:14:57,923:INFO:Initializing Lasso Regression
2023-02-03 15:14:57,924:INFO:Total runtime is 0.0276871124903361 minutes
2023-02-03 15:14:57,932:INFO:SubProcess create_model() called ==================================
2023-02-03 15:14:57,933:INFO:Initializing create_model()
2023-02-03 15:14:57,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:14:57,934:INFO:Checking exceptions
2023-02-03 15:14:57,934:INFO:Importing libraries
2023-02-03 15:14:57,935:INFO:Copying training dataset
2023-02-03 15:14:57,942:INFO:Defining folds
2023-02-03 15:14:57,943:INFO:Declaring metric variables
2023-02-03 15:14:57,949:INFO:Importing untrained model
2023-02-03 15:14:57,954:INFO:Lasso Regression Imported successfully
2023-02-03 15:14:57,969:INFO:Starting cross validation
2023-02-03 15:14:57,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:14:58,035:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.653e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,091:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.713e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,208:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.832e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,270:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,324:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.826e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,370:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,425:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,480:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,541:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,589:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.356e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,609:INFO:Calculating mean and std
2023-02-03 15:14:58,611:INFO:Creating metrics dataframe
2023-02-03 15:14:58,617:INFO:Uploading results into container
2023-02-03 15:14:58,618:INFO:Uploading model into container now
2023-02-03 15:14:58,618:INFO:_master_model_container: 2
2023-02-03 15:14:58,619:INFO:_display_container: 2
2023-02-03 15:14:58,619:INFO:Lasso(random_state=123)
2023-02-03 15:14:58,619:INFO:create_model() successfully completed......................................
2023-02-03 15:14:58,723:INFO:SubProcess create_model() end ==================================
2023-02-03 15:14:58,725:INFO:Creating metrics dataframe
2023-02-03 15:14:58,738:INFO:Initializing Ridge Regression
2023-02-03 15:14:58,739:INFO:Total runtime is 0.04126158555348714 minutes
2023-02-03 15:14:58,747:INFO:SubProcess create_model() called ==================================
2023-02-03 15:14:58,748:INFO:Initializing create_model()
2023-02-03 15:14:58,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:14:58,749:INFO:Checking exceptions
2023-02-03 15:14:58,750:INFO:Importing libraries
2023-02-03 15:14:58,751:INFO:Copying training dataset
2023-02-03 15:14:58,761:INFO:Defining folds
2023-02-03 15:14:58,761:INFO:Declaring metric variables
2023-02-03 15:14:58,768:INFO:Importing untrained model
2023-02-03 15:14:58,775:INFO:Ridge Regression Imported successfully
2023-02-03 15:14:58,788:INFO:Starting cross validation
2023-02-03 15:14:58,790:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:14:59,025:INFO:Calculating mean and std
2023-02-03 15:14:59,026:INFO:Creating metrics dataframe
2023-02-03 15:14:59,030:INFO:Uploading results into container
2023-02-03 15:14:59,030:INFO:Uploading model into container now
2023-02-03 15:14:59,031:INFO:_master_model_container: 3
2023-02-03 15:14:59,031:INFO:_display_container: 2
2023-02-03 15:14:59,032:INFO:Ridge(random_state=123)
2023-02-03 15:14:59,032:INFO:create_model() successfully completed......................................
2023-02-03 15:14:59,115:INFO:SubProcess create_model() end ==================================
2023-02-03 15:14:59,115:INFO:Creating metrics dataframe
2023-02-03 15:14:59,129:INFO:Initializing Elastic Net
2023-02-03 15:14:59,130:INFO:Total runtime is 0.04778089920679728 minutes
2023-02-03 15:14:59,135:INFO:SubProcess create_model() called ==================================
2023-02-03 15:14:59,135:INFO:Initializing create_model()
2023-02-03 15:14:59,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:14:59,136:INFO:Checking exceptions
2023-02-03 15:14:59,136:INFO:Importing libraries
2023-02-03 15:14:59,136:INFO:Copying training dataset
2023-02-03 15:14:59,140:INFO:Defining folds
2023-02-03 15:14:59,140:INFO:Declaring metric variables
2023-02-03 15:14:59,147:INFO:Importing untrained model
2023-02-03 15:14:59,152:INFO:Elastic Net Imported successfully
2023-02-03 15:14:59,165:INFO:Starting cross validation
2023-02-03 15:14:59,166:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:14:59,188:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,213:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.982e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,234:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,256:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,278:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.646e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,300:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.039e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,322:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.999e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,342:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,364:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.979e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,388:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,398:INFO:Calculating mean and std
2023-02-03 15:14:59,399:INFO:Creating metrics dataframe
2023-02-03 15:14:59,403:INFO:Uploading results into container
2023-02-03 15:14:59,404:INFO:Uploading model into container now
2023-02-03 15:14:59,405:INFO:_master_model_container: 4
2023-02-03 15:14:59,405:INFO:_display_container: 2
2023-02-03 15:14:59,405:INFO:ElasticNet(random_state=123)
2023-02-03 15:14:59,405:INFO:create_model() successfully completed......................................
2023-02-03 15:14:59,490:INFO:SubProcess create_model() end ==================================
2023-02-03 15:14:59,490:INFO:Creating metrics dataframe
2023-02-03 15:14:59,502:INFO:Initializing Least Angle Regression
2023-02-03 15:14:59,503:INFO:Total runtime is 0.05399715503056844 minutes
2023-02-03 15:14:59,508:INFO:SubProcess create_model() called ==================================
2023-02-03 15:14:59,509:INFO:Initializing create_model()
2023-02-03 15:14:59,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:14:59,509:INFO:Checking exceptions
2023-02-03 15:14:59,510:INFO:Importing libraries
2023-02-03 15:14:59,510:INFO:Copying training dataset
2023-02-03 15:14:59,515:INFO:Defining folds
2023-02-03 15:14:59,515:INFO:Declaring metric variables
2023-02-03 15:14:59,520:INFO:Importing untrained model
2023-02-03 15:14:59,527:INFO:Least Angle Regression Imported successfully
2023-02-03 15:14:59,539:INFO:Starting cross validation
2023-02-03 15:14:59,541:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:14:59,568:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,597:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,618:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,642:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,662:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,684:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,708:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,730:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,750:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,771:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,782:INFO:Calculating mean and std
2023-02-03 15:14:59,783:INFO:Creating metrics dataframe
2023-02-03 15:14:59,787:INFO:Uploading results into container
2023-02-03 15:14:59,788:INFO:Uploading model into container now
2023-02-03 15:14:59,788:INFO:_master_model_container: 5
2023-02-03 15:14:59,788:INFO:_display_container: 2
2023-02-03 15:14:59,789:INFO:Lars(random_state=123)
2023-02-03 15:14:59,789:INFO:create_model() successfully completed......................................
2023-02-03 15:14:59,871:INFO:SubProcess create_model() end ==================================
2023-02-03 15:14:59,871:INFO:Creating metrics dataframe
2023-02-03 15:14:59,887:INFO:Initializing Lasso Least Angle Regression
2023-02-03 15:14:59,888:INFO:Total runtime is 0.06040764252344767 minutes
2023-02-03 15:14:59,893:INFO:SubProcess create_model() called ==================================
2023-02-03 15:14:59,894:INFO:Initializing create_model()
2023-02-03 15:14:59,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:14:59,894:INFO:Checking exceptions
2023-02-03 15:14:59,895:INFO:Importing libraries
2023-02-03 15:14:59,895:INFO:Copying training dataset
2023-02-03 15:14:59,900:INFO:Defining folds
2023-02-03 15:14:59,901:INFO:Declaring metric variables
2023-02-03 15:14:59,907:INFO:Importing untrained model
2023-02-03 15:14:59,914:INFO:Lasso Least Angle Regression Imported successfully
2023-02-03 15:14:59,926:INFO:Starting cross validation
2023-02-03 15:14:59,928:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:14:59,954:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:14:59,978:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,002:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,029:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,050:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,071:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,092:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,113:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,133:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,152:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,161:INFO:Calculating mean and std
2023-02-03 15:15:00,162:INFO:Creating metrics dataframe
2023-02-03 15:15:00,166:INFO:Uploading results into container
2023-02-03 15:15:00,167:INFO:Uploading model into container now
2023-02-03 15:15:00,168:INFO:_master_model_container: 6
2023-02-03 15:15:00,168:INFO:_display_container: 2
2023-02-03 15:15:00,168:INFO:LassoLars(random_state=123)
2023-02-03 15:15:00,168:INFO:create_model() successfully completed......................................
2023-02-03 15:15:00,250:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:00,250:INFO:Creating metrics dataframe
2023-02-03 15:15:00,266:INFO:Initializing Orthogonal Matching Pursuit
2023-02-03 15:15:00,266:INFO:Total runtime is 0.066716468334198 minutes
2023-02-03 15:15:00,272:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:00,272:INFO:Initializing create_model()
2023-02-03 15:15:00,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:00,272:INFO:Checking exceptions
2023-02-03 15:15:00,272:INFO:Importing libraries
2023-02-03 15:15:00,273:INFO:Copying training dataset
2023-02-03 15:15:00,278:INFO:Defining folds
2023-02-03 15:15:00,278:INFO:Declaring metric variables
2023-02-03 15:15:00,286:INFO:Importing untrained model
2023-02-03 15:15:00,293:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-03 15:15:00,306:INFO:Starting cross validation
2023-02-03 15:15:00,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:00,328:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,352:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,376:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,396:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,417:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,437:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,458:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,479:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,500:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,520:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,532:INFO:Calculating mean and std
2023-02-03 15:15:00,533:INFO:Creating metrics dataframe
2023-02-03 15:15:00,537:INFO:Uploading results into container
2023-02-03 15:15:00,538:INFO:Uploading model into container now
2023-02-03 15:15:00,539:INFO:_master_model_container: 7
2023-02-03 15:15:00,539:INFO:_display_container: 2
2023-02-03 15:15:00,540:INFO:OrthogonalMatchingPursuit()
2023-02-03 15:15:00,541:INFO:create_model() successfully completed......................................
2023-02-03 15:15:00,623:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:00,623:INFO:Creating metrics dataframe
2023-02-03 15:15:00,639:INFO:Initializing Bayesian Ridge
2023-02-03 15:15:00,639:INFO:Total runtime is 0.07292533318201701 minutes
2023-02-03 15:15:00,645:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:00,646:INFO:Initializing create_model()
2023-02-03 15:15:00,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:00,646:INFO:Checking exceptions
2023-02-03 15:15:00,646:INFO:Importing libraries
2023-02-03 15:15:00,646:INFO:Copying training dataset
2023-02-03 15:15:00,651:INFO:Defining folds
2023-02-03 15:15:00,651:INFO:Declaring metric variables
2023-02-03 15:15:00,656:INFO:Importing untrained model
2023-02-03 15:15:00,664:INFO:Bayesian Ridge Imported successfully
2023-02-03 15:15:00,680:INFO:Starting cross validation
2023-02-03 15:15:00,682:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:00,945:INFO:Calculating mean and std
2023-02-03 15:15:00,945:INFO:Creating metrics dataframe
2023-02-03 15:15:00,949:INFO:Uploading results into container
2023-02-03 15:15:00,950:INFO:Uploading model into container now
2023-02-03 15:15:00,951:INFO:_master_model_container: 8
2023-02-03 15:15:00,951:INFO:_display_container: 2
2023-02-03 15:15:00,952:INFO:BayesianRidge()
2023-02-03 15:15:00,952:INFO:create_model() successfully completed......................................
2023-02-03 15:15:01,039:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:01,039:INFO:Creating metrics dataframe
2023-02-03 15:15:01,053:INFO:Initializing Passive Aggressive Regressor
2023-02-03 15:15:01,053:INFO:Total runtime is 0.07983566919962565 minutes
2023-02-03 15:15:01,058:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:01,058:INFO:Initializing create_model()
2023-02-03 15:15:01,059:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:01,059:INFO:Checking exceptions
2023-02-03 15:15:01,059:INFO:Importing libraries
2023-02-03 15:15:01,059:INFO:Copying training dataset
2023-02-03 15:15:01,063:INFO:Defining folds
2023-02-03 15:15:01,063:INFO:Declaring metric variables
2023-02-03 15:15:01,070:INFO:Importing untrained model
2023-02-03 15:15:01,075:INFO:Passive Aggressive Regressor Imported successfully
2023-02-03 15:15:01,086:INFO:Starting cross validation
2023-02-03 15:15:01,087:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:01,308:INFO:Calculating mean and std
2023-02-03 15:15:01,310:INFO:Creating metrics dataframe
2023-02-03 15:15:01,314:INFO:Uploading results into container
2023-02-03 15:15:01,315:INFO:Uploading model into container now
2023-02-03 15:15:01,316:INFO:_master_model_container: 9
2023-02-03 15:15:01,316:INFO:_display_container: 2
2023-02-03 15:15:01,316:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-03 15:15:01,316:INFO:create_model() successfully completed......................................
2023-02-03 15:15:01,400:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:01,401:INFO:Creating metrics dataframe
2023-02-03 15:15:01,415:INFO:Initializing Huber Regressor
2023-02-03 15:15:01,415:INFO:Total runtime is 0.08587079842885335 minutes
2023-02-03 15:15:01,420:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:01,421:INFO:Initializing create_model()
2023-02-03 15:15:01,421:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:01,421:INFO:Checking exceptions
2023-02-03 15:15:01,421:INFO:Importing libraries
2023-02-03 15:15:01,421:INFO:Copying training dataset
2023-02-03 15:15:01,425:INFO:Defining folds
2023-02-03 15:15:01,425:INFO:Declaring metric variables
2023-02-03 15:15:01,431:INFO:Importing untrained model
2023-02-03 15:15:01,437:INFO:Huber Regressor Imported successfully
2023-02-03 15:15:01,451:INFO:Starting cross validation
2023-02-03 15:15:01,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:01,765:INFO:Calculating mean and std
2023-02-03 15:15:01,766:INFO:Creating metrics dataframe
2023-02-03 15:15:01,771:INFO:Uploading results into container
2023-02-03 15:15:01,772:INFO:Uploading model into container now
2023-02-03 15:15:01,773:INFO:_master_model_container: 10
2023-02-03 15:15:01,773:INFO:_display_container: 2
2023-02-03 15:15:01,774:INFO:HuberRegressor()
2023-02-03 15:15:01,774:INFO:create_model() successfully completed......................................
2023-02-03 15:15:01,857:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:01,857:INFO:Creating metrics dataframe
2023-02-03 15:15:01,874:INFO:Initializing K Neighbors Regressor
2023-02-03 15:15:01,874:INFO:Total runtime is 0.09351608753204346 minutes
2023-02-03 15:15:01,880:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:01,880:INFO:Initializing create_model()
2023-02-03 15:15:01,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:01,880:INFO:Checking exceptions
2023-02-03 15:15:01,880:INFO:Importing libraries
2023-02-03 15:15:01,880:INFO:Copying training dataset
2023-02-03 15:15:01,885:INFO:Defining folds
2023-02-03 15:15:01,885:INFO:Declaring metric variables
2023-02-03 15:15:01,890:INFO:Importing untrained model
2023-02-03 15:15:01,898:INFO:K Neighbors Regressor Imported successfully
2023-02-03 15:15:01,917:INFO:Starting cross validation
2023-02-03 15:15:01,919:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:07,209:INFO:Calculating mean and std
2023-02-03 15:15:07,210:INFO:Creating metrics dataframe
2023-02-03 15:15:07,214:INFO:Uploading results into container
2023-02-03 15:15:07,216:INFO:Uploading model into container now
2023-02-03 15:15:07,217:INFO:_master_model_container: 11
2023-02-03 15:15:07,217:INFO:_display_container: 2
2023-02-03 15:15:07,218:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-03 15:15:07,218:INFO:create_model() successfully completed......................................
2023-02-03 15:15:07,309:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:07,309:INFO:Creating metrics dataframe
2023-02-03 15:15:07,327:INFO:Initializing Decision Tree Regressor
2023-02-03 15:15:07,328:INFO:Total runtime is 0.18439719676971436 minutes
2023-02-03 15:15:07,332:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:07,333:INFO:Initializing create_model()
2023-02-03 15:15:07,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:07,335:INFO:Checking exceptions
2023-02-03 15:15:07,335:INFO:Importing libraries
2023-02-03 15:15:07,335:INFO:Copying training dataset
2023-02-03 15:15:07,340:INFO:Defining folds
2023-02-03 15:15:07,341:INFO:Declaring metric variables
2023-02-03 15:15:07,346:INFO:Importing untrained model
2023-02-03 15:15:07,355:INFO:Decision Tree Regressor Imported successfully
2023-02-03 15:15:07,371:INFO:Starting cross validation
2023-02-03 15:15:07,372:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:07,612:INFO:Calculating mean and std
2023-02-03 15:15:07,614:INFO:Creating metrics dataframe
2023-02-03 15:15:07,620:INFO:Uploading results into container
2023-02-03 15:15:07,620:INFO:Uploading model into container now
2023-02-03 15:15:07,621:INFO:_master_model_container: 12
2023-02-03 15:15:07,621:INFO:_display_container: 2
2023-02-03 15:15:07,622:INFO:DecisionTreeRegressor(random_state=123)
2023-02-03 15:15:07,624:INFO:create_model() successfully completed......................................
2023-02-03 15:15:07,708:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:07,708:INFO:Creating metrics dataframe
2023-02-03 15:15:07,724:INFO:Initializing Random Forest Regressor
2023-02-03 15:15:07,724:INFO:Total runtime is 0.19100876649220785 minutes
2023-02-03 15:15:07,729:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:07,729:INFO:Initializing create_model()
2023-02-03 15:15:07,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:07,730:INFO:Checking exceptions
2023-02-03 15:15:07,730:INFO:Importing libraries
2023-02-03 15:15:07,730:INFO:Copying training dataset
2023-02-03 15:15:07,735:INFO:Defining folds
2023-02-03 15:15:07,735:INFO:Declaring metric variables
2023-02-03 15:15:07,742:INFO:Importing untrained model
2023-02-03 15:15:07,747:INFO:Random Forest Regressor Imported successfully
2023-02-03 15:15:07,760:INFO:Starting cross validation
2023-02-03 15:15:07,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:10,341:INFO:Calculating mean and std
2023-02-03 15:15:10,343:INFO:Creating metrics dataframe
2023-02-03 15:15:10,347:INFO:Uploading results into container
2023-02-03 15:15:10,347:INFO:Uploading model into container now
2023-02-03 15:15:10,348:INFO:_master_model_container: 13
2023-02-03 15:15:10,348:INFO:_display_container: 2
2023-02-03 15:15:10,348:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:15:10,349:INFO:create_model() successfully completed......................................
2023-02-03 15:15:10,440:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:10,440:INFO:Creating metrics dataframe
2023-02-03 15:15:10,459:INFO:Initializing Extra Trees Regressor
2023-02-03 15:15:10,459:INFO:Total runtime is 0.23660185337066653 minutes
2023-02-03 15:15:10,465:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:10,466:INFO:Initializing create_model()
2023-02-03 15:15:10,466:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:10,466:INFO:Checking exceptions
2023-02-03 15:15:10,466:INFO:Importing libraries
2023-02-03 15:15:10,467:INFO:Copying training dataset
2023-02-03 15:15:10,472:INFO:Defining folds
2023-02-03 15:15:10,473:INFO:Declaring metric variables
2023-02-03 15:15:10,477:INFO:Importing untrained model
2023-02-03 15:15:10,486:INFO:Extra Trees Regressor Imported successfully
2023-02-03 15:15:10,501:INFO:Starting cross validation
2023-02-03 15:15:10,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:12,813:INFO:Calculating mean and std
2023-02-03 15:15:12,815:INFO:Creating metrics dataframe
2023-02-03 15:15:12,821:INFO:Uploading results into container
2023-02-03 15:15:12,823:INFO:Uploading model into container now
2023-02-03 15:15:12,824:INFO:_master_model_container: 14
2023-02-03 15:15:12,824:INFO:_display_container: 2
2023-02-03 15:15:12,825:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:15:12,825:INFO:create_model() successfully completed......................................
2023-02-03 15:15:12,925:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:12,926:INFO:Creating metrics dataframe
2023-02-03 15:15:12,946:INFO:Initializing AdaBoost Regressor
2023-02-03 15:15:12,946:INFO:Total runtime is 0.2780460238456726 minutes
2023-02-03 15:15:12,951:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:12,951:INFO:Initializing create_model()
2023-02-03 15:15:12,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:12,952:INFO:Checking exceptions
2023-02-03 15:15:12,952:INFO:Importing libraries
2023-02-03 15:15:12,952:INFO:Copying training dataset
2023-02-03 15:15:12,959:INFO:Defining folds
2023-02-03 15:15:12,959:INFO:Declaring metric variables
2023-02-03 15:15:12,966:INFO:Importing untrained model
2023-02-03 15:15:12,973:INFO:AdaBoost Regressor Imported successfully
2023-02-03 15:15:12,985:INFO:Starting cross validation
2023-02-03 15:15:12,987:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:13,658:INFO:Calculating mean and std
2023-02-03 15:15:13,660:INFO:Creating metrics dataframe
2023-02-03 15:15:13,666:INFO:Uploading results into container
2023-02-03 15:15:13,667:INFO:Uploading model into container now
2023-02-03 15:15:13,667:INFO:_master_model_container: 15
2023-02-03 15:15:13,668:INFO:_display_container: 2
2023-02-03 15:15:13,668:INFO:AdaBoostRegressor(random_state=123)
2023-02-03 15:15:13,668:INFO:create_model() successfully completed......................................
2023-02-03 15:15:13,763:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:13,763:INFO:Creating metrics dataframe
2023-02-03 15:15:13,783:INFO:Initializing Gradient Boosting Regressor
2023-02-03 15:15:13,784:INFO:Total runtime is 0.29201157887776696 minutes
2023-02-03 15:15:13,789:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:13,790:INFO:Initializing create_model()
2023-02-03 15:15:13,790:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:13,791:INFO:Checking exceptions
2023-02-03 15:15:13,791:INFO:Importing libraries
2023-02-03 15:15:13,792:INFO:Copying training dataset
2023-02-03 15:15:13,796:INFO:Defining folds
2023-02-03 15:15:13,797:INFO:Declaring metric variables
2023-02-03 15:15:13,805:INFO:Importing untrained model
2023-02-03 15:15:13,813:INFO:Gradient Boosting Regressor Imported successfully
2023-02-03 15:15:13,829:INFO:Starting cross validation
2023-02-03 15:15:13,830:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:14,571:INFO:Calculating mean and std
2023-02-03 15:15:14,572:INFO:Creating metrics dataframe
2023-02-03 15:15:14,580:INFO:Uploading results into container
2023-02-03 15:15:14,580:INFO:Uploading model into container now
2023-02-03 15:15:14,581:INFO:_master_model_container: 16
2023-02-03 15:15:14,581:INFO:_display_container: 2
2023-02-03 15:15:14,582:INFO:GradientBoostingRegressor(random_state=123)
2023-02-03 15:15:14,582:INFO:create_model() successfully completed......................................
2023-02-03 15:15:14,695:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:14,695:INFO:Creating metrics dataframe
2023-02-03 15:15:14,719:INFO:Initializing Light Gradient Boosting Machine
2023-02-03 15:15:14,719:INFO:Total runtime is 0.30760041475296024 minutes
2023-02-03 15:15:14,729:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:14,729:INFO:Initializing create_model()
2023-02-03 15:15:14,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:14,730:INFO:Checking exceptions
2023-02-03 15:15:14,730:INFO:Importing libraries
2023-02-03 15:15:14,730:INFO:Copying training dataset
2023-02-03 15:15:14,736:INFO:Defining folds
2023-02-03 15:15:14,736:INFO:Declaring metric variables
2023-02-03 15:15:14,747:INFO:Importing untrained model
2023-02-03 15:15:14,754:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-03 15:15:14,777:INFO:Starting cross validation
2023-02-03 15:15:14,779:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:29,715:INFO:Calculating mean and std
2023-02-03 15:15:29,717:INFO:Creating metrics dataframe
2023-02-03 15:15:29,726:INFO:Uploading results into container
2023-02-03 15:15:29,727:INFO:Uploading model into container now
2023-02-03 15:15:29,729:INFO:_master_model_container: 17
2023-02-03 15:15:29,729:INFO:_display_container: 2
2023-02-03 15:15:29,730:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-02-03 15:15:29,730:INFO:create_model() successfully completed......................................
2023-02-03 15:15:29,855:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:29,856:INFO:Creating metrics dataframe
2023-02-03 15:15:29,873:INFO:Initializing Dummy Regressor
2023-02-03 15:15:29,874:INFO:Total runtime is 0.5601612011591593 minutes
2023-02-03 15:15:29,879:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:29,879:INFO:Initializing create_model()
2023-02-03 15:15:29,879:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:29,880:INFO:Checking exceptions
2023-02-03 15:15:29,880:INFO:Importing libraries
2023-02-03 15:15:29,880:INFO:Copying training dataset
2023-02-03 15:15:29,884:INFO:Defining folds
2023-02-03 15:15:29,884:INFO:Declaring metric variables
2023-02-03 15:15:29,890:INFO:Importing untrained model
2023-02-03 15:15:29,896:INFO:Dummy Regressor Imported successfully
2023-02-03 15:15:29,906:INFO:Starting cross validation
2023-02-03 15:15:29,908:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:30,144:INFO:Calculating mean and std
2023-02-03 15:15:30,145:INFO:Creating metrics dataframe
2023-02-03 15:15:30,149:INFO:Uploading results into container
2023-02-03 15:15:30,149:INFO:Uploading model into container now
2023-02-03 15:15:30,151:INFO:_master_model_container: 18
2023-02-03 15:15:30,151:INFO:_display_container: 2
2023-02-03 15:15:30,152:INFO:DummyRegressor()
2023-02-03 15:15:30,152:INFO:create_model() successfully completed......................................
2023-02-03 15:15:30,236:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:30,237:INFO:Creating metrics dataframe
2023-02-03 15:15:30,273:INFO:Initializing create_model()
2023-02-03 15:15:30,273:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:30,273:INFO:Checking exceptions
2023-02-03 15:15:30,277:INFO:Importing libraries
2023-02-03 15:15:30,277:INFO:Copying training dataset
2023-02-03 15:15:30,280:INFO:Defining folds
2023-02-03 15:15:30,280:INFO:Declaring metric variables
2023-02-03 15:15:30,280:INFO:Importing untrained model
2023-02-03 15:15:30,280:INFO:Declaring custom model
2023-02-03 15:15:30,281:INFO:Linear Regression Imported successfully
2023-02-03 15:15:30,281:INFO:Cross validation set to False
2023-02-03 15:15:30,281:INFO:Fitting Model
2023-02-03 15:15:30,317:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:15:30,317:INFO:create_model() successfully completed......................................
2023-02-03 15:15:30,463:INFO:_master_model_container: 18
2023-02-03 15:15:30,464:INFO:_display_container: 2
2023-02-03 15:15:30,464:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:15:30,465:INFO:compare_models() successfully completed......................................
2023-02-03 15:16:47,655:INFO:Initializing compare_models()
2023-02-03 15:16:47,656:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, include=None, fold=None, round=4, cross_validation=True, sort=r2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'r2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-03 15:16:47,656:INFO:Checking exceptions
2023-02-03 15:16:47,661:INFO:Preparing display monitor
2023-02-03 15:16:47,712:INFO:Initializing Linear Regression
2023-02-03 15:16:47,713:INFO:Total runtime is 1.6661485036214194e-05 minutes
2023-02-03 15:16:47,722:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:47,723:INFO:Initializing create_model()
2023-02-03 15:16:47,723:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:47,724:INFO:Checking exceptions
2023-02-03 15:16:47,724:INFO:Importing libraries
2023-02-03 15:16:47,724:INFO:Copying training dataset
2023-02-03 15:16:47,736:INFO:Defining folds
2023-02-03 15:16:47,737:INFO:Declaring metric variables
2023-02-03 15:16:47,748:INFO:Importing untrained model
2023-02-03 15:16:47,755:INFO:Linear Regression Imported successfully
2023-02-03 15:16:47,770:INFO:Starting cross validation
2023-02-03 15:16:47,773:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:48,167:INFO:Calculating mean and std
2023-02-03 15:16:48,168:INFO:Creating metrics dataframe
2023-02-03 15:16:48,174:INFO:Uploading results into container
2023-02-03 15:16:48,174:INFO:Uploading model into container now
2023-02-03 15:16:48,175:INFO:_master_model_container: 19
2023-02-03 15:16:48,175:INFO:_display_container: 3
2023-02-03 15:16:48,176:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:16:48,176:INFO:create_model() successfully completed......................................
2023-02-03 15:16:48,266:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:48,266:INFO:Creating metrics dataframe
2023-02-03 15:16:48,284:INFO:Initializing Lasso Regression
2023-02-03 15:16:48,284:INFO:Total runtime is 0.009527858098347981 minutes
2023-02-03 15:16:48,290:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:48,291:INFO:Initializing create_model()
2023-02-03 15:16:48,291:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:48,291:INFO:Checking exceptions
2023-02-03 15:16:48,291:INFO:Importing libraries
2023-02-03 15:16:48,291:INFO:Copying training dataset
2023-02-03 15:16:48,294:INFO:Defining folds
2023-02-03 15:16:48,294:INFO:Declaring metric variables
2023-02-03 15:16:48,299:INFO:Importing untrained model
2023-02-03 15:16:48,304:INFO:Lasso Regression Imported successfully
2023-02-03 15:16:48,320:INFO:Starting cross validation
2023-02-03 15:16:48,321:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:48,346:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.653e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,379:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.713e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,406:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.832e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,431:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,456:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.826e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,478:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,502:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,527:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,556:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,577:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.356e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,587:INFO:Calculating mean and std
2023-02-03 15:16:48,588:INFO:Creating metrics dataframe
2023-02-03 15:16:48,591:INFO:Uploading results into container
2023-02-03 15:16:48,592:INFO:Uploading model into container now
2023-02-03 15:16:48,593:INFO:_master_model_container: 20
2023-02-03 15:16:48,593:INFO:_display_container: 3
2023-02-03 15:16:48,594:INFO:Lasso(random_state=123)
2023-02-03 15:16:48,594:INFO:create_model() successfully completed......................................
2023-02-03 15:16:48,695:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:48,695:INFO:Creating metrics dataframe
2023-02-03 15:16:48,710:INFO:Initializing Ridge Regression
2023-02-03 15:16:48,710:INFO:Total runtime is 0.016623783111572265 minutes
2023-02-03 15:16:48,715:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:48,716:INFO:Initializing create_model()
2023-02-03 15:16:48,716:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:48,716:INFO:Checking exceptions
2023-02-03 15:16:48,716:INFO:Importing libraries
2023-02-03 15:16:48,717:INFO:Copying training dataset
2023-02-03 15:16:48,722:INFO:Defining folds
2023-02-03 15:16:48,722:INFO:Declaring metric variables
2023-02-03 15:16:48,728:INFO:Importing untrained model
2023-02-03 15:16:48,735:INFO:Ridge Regression Imported successfully
2023-02-03 15:16:48,748:INFO:Starting cross validation
2023-02-03 15:16:48,750:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:48,996:INFO:Calculating mean and std
2023-02-03 15:16:48,997:INFO:Creating metrics dataframe
2023-02-03 15:16:49,002:INFO:Uploading results into container
2023-02-03 15:16:49,003:INFO:Uploading model into container now
2023-02-03 15:16:49,003:INFO:_master_model_container: 21
2023-02-03 15:16:49,004:INFO:_display_container: 3
2023-02-03 15:16:49,004:INFO:Ridge(random_state=123)
2023-02-03 15:16:49,004:INFO:create_model() successfully completed......................................
2023-02-03 15:16:49,095:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:49,095:INFO:Creating metrics dataframe
2023-02-03 15:16:49,109:INFO:Initializing Elastic Net
2023-02-03 15:16:49,109:INFO:Total runtime is 0.023270229498545326 minutes
2023-02-03 15:16:49,114:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:49,114:INFO:Initializing create_model()
2023-02-03 15:16:49,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:49,115:INFO:Checking exceptions
2023-02-03 15:16:49,115:INFO:Importing libraries
2023-02-03 15:16:49,115:INFO:Copying training dataset
2023-02-03 15:16:49,120:INFO:Defining folds
2023-02-03 15:16:49,120:INFO:Declaring metric variables
2023-02-03 15:16:49,125:INFO:Importing untrained model
2023-02-03 15:16:49,132:INFO:Elastic Net Imported successfully
2023-02-03 15:16:49,147:INFO:Starting cross validation
2023-02-03 15:16:49,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:49,171:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,195:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.982e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,219:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,240:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,262:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.646e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,287:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.039e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,312:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.999e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,333:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,358:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.979e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,383:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,392:INFO:Calculating mean and std
2023-02-03 15:16:49,393:INFO:Creating metrics dataframe
2023-02-03 15:16:49,397:INFO:Uploading results into container
2023-02-03 15:16:49,397:INFO:Uploading model into container now
2023-02-03 15:16:49,399:INFO:_master_model_container: 22
2023-02-03 15:16:49,399:INFO:_display_container: 3
2023-02-03 15:16:49,400:INFO:ElasticNet(random_state=123)
2023-02-03 15:16:49,400:INFO:create_model() successfully completed......................................
2023-02-03 15:16:49,488:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:49,488:INFO:Creating metrics dataframe
2023-02-03 15:16:49,502:INFO:Initializing Least Angle Regression
2023-02-03 15:16:49,502:INFO:Total runtime is 0.029832891623179116 minutes
2023-02-03 15:16:49,508:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:49,508:INFO:Initializing create_model()
2023-02-03 15:16:49,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:49,508:INFO:Checking exceptions
2023-02-03 15:16:49,509:INFO:Importing libraries
2023-02-03 15:16:49,509:INFO:Copying training dataset
2023-02-03 15:16:49,513:INFO:Defining folds
2023-02-03 15:16:49,513:INFO:Declaring metric variables
2023-02-03 15:16:49,520:INFO:Importing untrained model
2023-02-03 15:16:49,528:INFO:Least Angle Regression Imported successfully
2023-02-03 15:16:49,543:INFO:Starting cross validation
2023-02-03 15:16:49,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:49,567:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,592:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,614:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,635:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,658:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,678:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,698:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,719:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,739:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,759:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,769:INFO:Calculating mean and std
2023-02-03 15:16:49,771:INFO:Creating metrics dataframe
2023-02-03 15:16:49,777:INFO:Uploading results into container
2023-02-03 15:16:49,778:INFO:Uploading model into container now
2023-02-03 15:16:49,778:INFO:_master_model_container: 23
2023-02-03 15:16:49,779:INFO:_display_container: 3
2023-02-03 15:16:49,779:INFO:Lars(random_state=123)
2023-02-03 15:16:49,780:INFO:create_model() successfully completed......................................
2023-02-03 15:16:49,860:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:49,861:INFO:Creating metrics dataframe
2023-02-03 15:16:49,873:INFO:Initializing Lasso Least Angle Regression
2023-02-03 15:16:49,874:INFO:Total runtime is 0.03602958520253499 minutes
2023-02-03 15:16:49,879:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:49,880:INFO:Initializing create_model()
2023-02-03 15:16:49,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:49,880:INFO:Checking exceptions
2023-02-03 15:16:49,880:INFO:Importing libraries
2023-02-03 15:16:49,880:INFO:Copying training dataset
2023-02-03 15:16:49,885:INFO:Defining folds
2023-02-03 15:16:49,885:INFO:Declaring metric variables
2023-02-03 15:16:49,891:INFO:Importing untrained model
2023-02-03 15:16:49,895:INFO:Lasso Least Angle Regression Imported successfully
2023-02-03 15:16:49,911:INFO:Starting cross validation
2023-02-03 15:16:49,913:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:49,930:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:49,961:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,004:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,033:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,073:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,102:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,133:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,163:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,247:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,282:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,296:INFO:Calculating mean and std
2023-02-03 15:16:50,298:INFO:Creating metrics dataframe
2023-02-03 15:16:50,306:INFO:Uploading results into container
2023-02-03 15:16:50,307:INFO:Uploading model into container now
2023-02-03 15:16:50,307:INFO:_master_model_container: 24
2023-02-03 15:16:50,307:INFO:_display_container: 3
2023-02-03 15:16:50,308:INFO:LassoLars(random_state=123)
2023-02-03 15:16:50,308:INFO:create_model() successfully completed......................................
2023-02-03 15:16:50,398:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:50,398:INFO:Creating metrics dataframe
2023-02-03 15:16:50,412:INFO:Initializing Orthogonal Matching Pursuit
2023-02-03 15:16:50,412:INFO:Total runtime is 0.044984956582387284 minutes
2023-02-03 15:16:50,416:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:50,417:INFO:Initializing create_model()
2023-02-03 15:16:50,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:50,418:INFO:Checking exceptions
2023-02-03 15:16:50,418:INFO:Importing libraries
2023-02-03 15:16:50,418:INFO:Copying training dataset
2023-02-03 15:16:50,424:INFO:Defining folds
2023-02-03 15:16:50,425:INFO:Declaring metric variables
2023-02-03 15:16:50,429:INFO:Importing untrained model
2023-02-03 15:16:50,434:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-03 15:16:50,447:INFO:Starting cross validation
2023-02-03 15:16:50,448:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:50,464:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,496:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,517:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,539:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,561:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,582:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,605:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,626:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,647:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,671:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,681:INFO:Calculating mean and std
2023-02-03 15:16:50,683:INFO:Creating metrics dataframe
2023-02-03 15:16:50,689:INFO:Uploading results into container
2023-02-03 15:16:50,690:INFO:Uploading model into container now
2023-02-03 15:16:50,691:INFO:_master_model_container: 25
2023-02-03 15:16:50,691:INFO:_display_container: 3
2023-02-03 15:16:50,692:INFO:OrthogonalMatchingPursuit()
2023-02-03 15:16:50,693:INFO:create_model() successfully completed......................................
2023-02-03 15:16:50,783:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:50,783:INFO:Creating metrics dataframe
2023-02-03 15:16:50,799:INFO:Initializing Bayesian Ridge
2023-02-03 15:16:50,799:INFO:Total runtime is 0.05144790808359782 minutes
2023-02-03 15:16:50,806:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:50,806:INFO:Initializing create_model()
2023-02-03 15:16:50,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:50,806:INFO:Checking exceptions
2023-02-03 15:16:50,806:INFO:Importing libraries
2023-02-03 15:16:50,807:INFO:Copying training dataset
2023-02-03 15:16:50,811:INFO:Defining folds
2023-02-03 15:16:50,812:INFO:Declaring metric variables
2023-02-03 15:16:50,817:INFO:Importing untrained model
2023-02-03 15:16:50,825:INFO:Bayesian Ridge Imported successfully
2023-02-03 15:16:50,838:INFO:Starting cross validation
2023-02-03 15:16:50,841:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:51,084:INFO:Calculating mean and std
2023-02-03 15:16:51,089:INFO:Creating metrics dataframe
2023-02-03 15:16:51,094:INFO:Uploading results into container
2023-02-03 15:16:51,095:INFO:Uploading model into container now
2023-02-03 15:16:51,096:INFO:_master_model_container: 26
2023-02-03 15:16:51,096:INFO:_display_container: 3
2023-02-03 15:16:51,097:INFO:BayesianRidge()
2023-02-03 15:16:51,097:INFO:create_model() successfully completed......................................
2023-02-03 15:16:51,189:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:51,189:INFO:Creating metrics dataframe
2023-02-03 15:16:51,206:INFO:Initializing Passive Aggressive Regressor
2023-02-03 15:16:51,207:INFO:Total runtime is 0.05824400981267293 minutes
2023-02-03 15:16:51,211:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:51,212:INFO:Initializing create_model()
2023-02-03 15:16:51,212:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:51,212:INFO:Checking exceptions
2023-02-03 15:16:51,212:INFO:Importing libraries
2023-02-03 15:16:51,213:INFO:Copying training dataset
2023-02-03 15:16:51,217:INFO:Defining folds
2023-02-03 15:16:51,217:INFO:Declaring metric variables
2023-02-03 15:16:51,225:INFO:Importing untrained model
2023-02-03 15:16:51,234:INFO:Passive Aggressive Regressor Imported successfully
2023-02-03 15:16:51,273:INFO:Starting cross validation
2023-02-03 15:16:51,277:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:51,515:INFO:Calculating mean and std
2023-02-03 15:16:51,516:INFO:Creating metrics dataframe
2023-02-03 15:16:51,521:INFO:Uploading results into container
2023-02-03 15:16:51,523:INFO:Uploading model into container now
2023-02-03 15:16:51,523:INFO:_master_model_container: 27
2023-02-03 15:16:51,523:INFO:_display_container: 3
2023-02-03 15:16:51,524:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-03 15:16:51,524:INFO:create_model() successfully completed......................................
2023-02-03 15:16:51,610:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:51,610:INFO:Creating metrics dataframe
2023-02-03 15:16:51,629:INFO:Initializing Huber Regressor
2023-02-03 15:16:51,629:INFO:Total runtime is 0.0652733047803243 minutes
2023-02-03 15:16:51,634:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:51,635:INFO:Initializing create_model()
2023-02-03 15:16:51,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:51,635:INFO:Checking exceptions
2023-02-03 15:16:51,635:INFO:Importing libraries
2023-02-03 15:16:51,635:INFO:Copying training dataset
2023-02-03 15:16:51,642:INFO:Defining folds
2023-02-03 15:16:51,642:INFO:Declaring metric variables
2023-02-03 15:16:51,647:INFO:Importing untrained model
2023-02-03 15:16:51,654:INFO:Huber Regressor Imported successfully
2023-02-03 15:16:51,666:INFO:Starting cross validation
2023-02-03 15:16:51,667:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:51,945:INFO:Calculating mean and std
2023-02-03 15:16:51,946:INFO:Creating metrics dataframe
2023-02-03 15:16:51,950:INFO:Uploading results into container
2023-02-03 15:16:51,951:INFO:Uploading model into container now
2023-02-03 15:16:51,952:INFO:_master_model_container: 28
2023-02-03 15:16:51,952:INFO:_display_container: 3
2023-02-03 15:16:51,953:INFO:HuberRegressor()
2023-02-03 15:16:51,953:INFO:create_model() successfully completed......................................
2023-02-03 15:16:52,047:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:52,047:INFO:Creating metrics dataframe
2023-02-03 15:16:52,065:INFO:Initializing K Neighbors Regressor
2023-02-03 15:16:52,065:INFO:Total runtime is 0.07253581285476685 minutes
2023-02-03 15:16:52,073:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:52,074:INFO:Initializing create_model()
2023-02-03 15:16:52,074:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:52,075:INFO:Checking exceptions
2023-02-03 15:16:52,075:INFO:Importing libraries
2023-02-03 15:16:52,075:INFO:Copying training dataset
2023-02-03 15:16:52,079:INFO:Defining folds
2023-02-03 15:16:52,079:INFO:Declaring metric variables
2023-02-03 15:16:52,085:INFO:Importing untrained model
2023-02-03 15:16:52,094:INFO:K Neighbors Regressor Imported successfully
2023-02-03 15:16:52,112:INFO:Starting cross validation
2023-02-03 15:16:52,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:52,481:INFO:Calculating mean and std
2023-02-03 15:16:52,482:INFO:Creating metrics dataframe
2023-02-03 15:16:52,486:INFO:Uploading results into container
2023-02-03 15:16:52,488:INFO:Uploading model into container now
2023-02-03 15:16:52,488:INFO:_master_model_container: 29
2023-02-03 15:16:52,488:INFO:_display_container: 3
2023-02-03 15:16:52,489:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-03 15:16:52,489:INFO:create_model() successfully completed......................................
2023-02-03 15:16:52,569:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:52,570:INFO:Creating metrics dataframe
2023-02-03 15:16:52,588:INFO:Initializing Decision Tree Regressor
2023-02-03 15:16:52,589:INFO:Total runtime is 0.08128010034561158 minutes
2023-02-03 15:16:52,594:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:52,595:INFO:Initializing create_model()
2023-02-03 15:16:52,595:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:52,595:INFO:Checking exceptions
2023-02-03 15:16:52,595:INFO:Importing libraries
2023-02-03 15:16:52,596:INFO:Copying training dataset
2023-02-03 15:16:52,601:INFO:Defining folds
2023-02-03 15:16:52,601:INFO:Declaring metric variables
2023-02-03 15:16:52,609:INFO:Importing untrained model
2023-02-03 15:16:52,614:INFO:Decision Tree Regressor Imported successfully
2023-02-03 15:16:52,626:INFO:Starting cross validation
2023-02-03 15:16:52,627:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:52,861:INFO:Calculating mean and std
2023-02-03 15:16:52,862:INFO:Creating metrics dataframe
2023-02-03 15:16:52,866:INFO:Uploading results into container
2023-02-03 15:16:52,867:INFO:Uploading model into container now
2023-02-03 15:16:52,868:INFO:_master_model_container: 30
2023-02-03 15:16:52,868:INFO:_display_container: 3
2023-02-03 15:16:52,868:INFO:DecisionTreeRegressor(random_state=123)
2023-02-03 15:16:52,868:INFO:create_model() successfully completed......................................
2023-02-03 15:16:52,951:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:52,952:INFO:Creating metrics dataframe
2023-02-03 15:16:52,967:INFO:Initializing Random Forest Regressor
2023-02-03 15:16:52,968:INFO:Total runtime is 0.08757672707239787 minutes
2023-02-03 15:16:52,974:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:52,975:INFO:Initializing create_model()
2023-02-03 15:16:52,975:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:52,975:INFO:Checking exceptions
2023-02-03 15:16:52,975:INFO:Importing libraries
2023-02-03 15:16:52,975:INFO:Copying training dataset
2023-02-03 15:16:52,981:INFO:Defining folds
2023-02-03 15:16:52,981:INFO:Declaring metric variables
2023-02-03 15:16:52,988:INFO:Importing untrained model
2023-02-03 15:16:52,996:INFO:Random Forest Regressor Imported successfully
2023-02-03 15:16:53,012:INFO:Starting cross validation
2023-02-03 15:16:53,013:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:54,900:INFO:Calculating mean and std
2023-02-03 15:16:54,901:INFO:Creating metrics dataframe
2023-02-03 15:16:54,907:INFO:Uploading results into container
2023-02-03 15:16:54,908:INFO:Uploading model into container now
2023-02-03 15:16:54,909:INFO:_master_model_container: 31
2023-02-03 15:16:54,909:INFO:_display_container: 3
2023-02-03 15:16:54,910:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:16:54,910:INFO:create_model() successfully completed......................................
2023-02-03 15:16:55,004:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:55,004:INFO:Creating metrics dataframe
2023-02-03 15:16:55,021:INFO:Initializing Extra Trees Regressor
2023-02-03 15:16:55,022:INFO:Total runtime is 0.12183132568995159 minutes
2023-02-03 15:16:55,028:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:55,029:INFO:Initializing create_model()
2023-02-03 15:16:55,029:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:55,030:INFO:Checking exceptions
2023-02-03 15:16:55,030:INFO:Importing libraries
2023-02-03 15:16:55,030:INFO:Copying training dataset
2023-02-03 15:16:55,034:INFO:Defining folds
2023-02-03 15:16:55,034:INFO:Declaring metric variables
2023-02-03 15:16:55,039:INFO:Importing untrained model
2023-02-03 15:16:55,048:INFO:Extra Trees Regressor Imported successfully
2023-02-03 15:16:55,062:INFO:Starting cross validation
2023-02-03 15:16:55,063:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:57,056:INFO:Calculating mean and std
2023-02-03 15:16:57,058:INFO:Creating metrics dataframe
2023-02-03 15:16:57,063:INFO:Uploading results into container
2023-02-03 15:16:57,063:INFO:Uploading model into container now
2023-02-03 15:16:57,064:INFO:_master_model_container: 32
2023-02-03 15:16:57,064:INFO:_display_container: 3
2023-02-03 15:16:57,065:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:16:57,065:INFO:create_model() successfully completed......................................
2023-02-03 15:16:57,155:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:57,155:INFO:Creating metrics dataframe
2023-02-03 15:16:57,171:INFO:Initializing AdaBoost Regressor
2023-02-03 15:16:57,171:INFO:Total runtime is 0.15764414469401042 minutes
2023-02-03 15:16:57,179:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:57,180:INFO:Initializing create_model()
2023-02-03 15:16:57,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:57,180:INFO:Checking exceptions
2023-02-03 15:16:57,180:INFO:Importing libraries
2023-02-03 15:16:57,180:INFO:Copying training dataset
2023-02-03 15:16:57,184:INFO:Defining folds
2023-02-03 15:16:57,185:INFO:Declaring metric variables
2023-02-03 15:16:57,191:INFO:Importing untrained model
2023-02-03 15:16:57,196:INFO:AdaBoost Regressor Imported successfully
2023-02-03 15:16:57,212:INFO:Starting cross validation
2023-02-03 15:16:57,213:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:57,817:INFO:Calculating mean and std
2023-02-03 15:16:57,819:INFO:Creating metrics dataframe
2023-02-03 15:16:57,823:INFO:Uploading results into container
2023-02-03 15:16:57,824:INFO:Uploading model into container now
2023-02-03 15:16:57,824:INFO:_master_model_container: 33
2023-02-03 15:16:57,824:INFO:_display_container: 3
2023-02-03 15:16:57,825:INFO:AdaBoostRegressor(random_state=123)
2023-02-03 15:16:57,825:INFO:create_model() successfully completed......................................
2023-02-03 15:16:57,911:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:57,911:INFO:Creating metrics dataframe
2023-02-03 15:16:57,932:INFO:Initializing Gradient Boosting Regressor
2023-02-03 15:16:57,933:INFO:Total runtime is 0.1703368385632833 minutes
2023-02-03 15:16:57,939:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:57,940:INFO:Initializing create_model()
2023-02-03 15:16:57,940:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:57,940:INFO:Checking exceptions
2023-02-03 15:16:57,940:INFO:Importing libraries
2023-02-03 15:16:57,940:INFO:Copying training dataset
2023-02-03 15:16:57,945:INFO:Defining folds
2023-02-03 15:16:57,945:INFO:Declaring metric variables
2023-02-03 15:16:57,951:INFO:Importing untrained model
2023-02-03 15:16:57,956:INFO:Gradient Boosting Regressor Imported successfully
2023-02-03 15:16:57,970:INFO:Starting cross validation
2023-02-03 15:16:57,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:58,725:INFO:Calculating mean and std
2023-02-03 15:16:58,729:INFO:Creating metrics dataframe
2023-02-03 15:16:58,733:INFO:Uploading results into container
2023-02-03 15:16:58,734:INFO:Uploading model into container now
2023-02-03 15:16:58,735:INFO:_master_model_container: 34
2023-02-03 15:16:58,735:INFO:_display_container: 3
2023-02-03 15:16:58,736:INFO:GradientBoostingRegressor(random_state=123)
2023-02-03 15:16:58,736:INFO:create_model() successfully completed......................................
2023-02-03 15:16:58,823:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:58,823:INFO:Creating metrics dataframe
2023-02-03 15:16:58,842:INFO:Initializing Light Gradient Boosting Machine
2023-02-03 15:16:58,843:INFO:Total runtime is 0.18551145394643148 minutes
2023-02-03 15:16:58,849:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:58,849:INFO:Initializing create_model()
2023-02-03 15:16:58,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:58,850:INFO:Checking exceptions
2023-02-03 15:16:58,850:INFO:Importing libraries
2023-02-03 15:16:58,850:INFO:Copying training dataset
2023-02-03 15:16:58,854:INFO:Defining folds
2023-02-03 15:16:58,855:INFO:Declaring metric variables
2023-02-03 15:16:58,863:INFO:Importing untrained model
2023-02-03 15:16:58,868:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-03 15:16:58,881:INFO:Starting cross validation
2023-02-03 15:16:58,883:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:06,317:INFO:Calculating mean and std
2023-02-03 15:17:06,319:INFO:Creating metrics dataframe
2023-02-03 15:17:06,329:INFO:Uploading results into container
2023-02-03 15:17:06,330:INFO:Uploading model into container now
2023-02-03 15:17:06,331:INFO:_master_model_container: 35
2023-02-03 15:17:06,331:INFO:_display_container: 3
2023-02-03 15:17:06,332:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-02-03 15:17:06,332:INFO:create_model() successfully completed......................................
2023-02-03 15:17:06,455:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:06,455:INFO:Creating metrics dataframe
2023-02-03 15:17:06,477:INFO:Initializing Dummy Regressor
2023-02-03 15:17:06,477:INFO:Total runtime is 0.31273931662241616 minutes
2023-02-03 15:17:06,482:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:06,482:INFO:Initializing create_model()
2023-02-03 15:17:06,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:06,483:INFO:Checking exceptions
2023-02-03 15:17:06,483:INFO:Importing libraries
2023-02-03 15:17:06,484:INFO:Copying training dataset
2023-02-03 15:17:06,490:INFO:Defining folds
2023-02-03 15:17:06,490:INFO:Declaring metric variables
2023-02-03 15:17:06,495:INFO:Importing untrained model
2023-02-03 15:17:06,502:INFO:Dummy Regressor Imported successfully
2023-02-03 15:17:06,513:INFO:Starting cross validation
2023-02-03 15:17:06,516:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:06,720:INFO:Calculating mean and std
2023-02-03 15:17:06,722:INFO:Creating metrics dataframe
2023-02-03 15:17:06,726:INFO:Uploading results into container
2023-02-03 15:17:06,727:INFO:Uploading model into container now
2023-02-03 15:17:06,728:INFO:_master_model_container: 36
2023-02-03 15:17:06,728:INFO:_display_container: 3
2023-02-03 15:17:06,728:INFO:DummyRegressor()
2023-02-03 15:17:06,729:INFO:create_model() successfully completed......................................
2023-02-03 15:17:06,821:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:06,821:INFO:Creating metrics dataframe
2023-02-03 15:17:06,856:INFO:Initializing create_model()
2023-02-03 15:17:06,857:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:06,857:INFO:Checking exceptions
2023-02-03 15:17:06,859:INFO:Importing libraries
2023-02-03 15:17:06,859:INFO:Copying training dataset
2023-02-03 15:17:06,862:INFO:Defining folds
2023-02-03 15:17:06,862:INFO:Declaring metric variables
2023-02-03 15:17:06,862:INFO:Importing untrained model
2023-02-03 15:17:06,862:INFO:Declaring custom model
2023-02-03 15:17:06,863:INFO:Linear Regression Imported successfully
2023-02-03 15:17:06,864:INFO:Cross validation set to False
2023-02-03 15:17:06,864:INFO:Fitting Model
2023-02-03 15:17:06,883:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:17:06,883:INFO:create_model() successfully completed......................................
2023-02-03 15:17:07,040:INFO:_master_model_container: 36
2023-02-03 15:17:07,041:INFO:_display_container: 3
2023-02-03 15:17:07,041:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:17:07,041:INFO:compare_models() successfully completed......................................
2023-02-03 15:17:18,979:INFO:Initializing compare_models()
2023-02-03 15:17:18,979:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, include=None, fold=None, round=4, cross_validation=True, sort=r2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'r2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-03 15:17:18,980:INFO:Checking exceptions
2023-02-03 15:17:18,985:INFO:Preparing display monitor
2023-02-03 15:17:19,034:INFO:Initializing Linear Regression
2023-02-03 15:17:19,035:INFO:Total runtime is 1.660585403442383e-05 minutes
2023-02-03 15:17:19,043:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:19,043:INFO:Initializing create_model()
2023-02-03 15:17:19,044:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:19,044:INFO:Checking exceptions
2023-02-03 15:17:19,044:INFO:Importing libraries
2023-02-03 15:17:19,045:INFO:Copying training dataset
2023-02-03 15:17:19,053:INFO:Defining folds
2023-02-03 15:17:19,054:INFO:Declaring metric variables
2023-02-03 15:17:19,061:INFO:Importing untrained model
2023-02-03 15:17:19,069:INFO:Linear Regression Imported successfully
2023-02-03 15:17:19,084:INFO:Starting cross validation
2023-02-03 15:17:19,086:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:19,358:INFO:Calculating mean and std
2023-02-03 15:17:19,358:INFO:Creating metrics dataframe
2023-02-03 15:17:19,362:INFO:Uploading results into container
2023-02-03 15:17:19,362:INFO:Uploading model into container now
2023-02-03 15:17:19,363:INFO:_master_model_container: 37
2023-02-03 15:17:19,363:INFO:_display_container: 4
2023-02-03 15:17:19,363:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:17:19,363:INFO:create_model() successfully completed......................................
2023-02-03 15:17:19,454:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:19,454:INFO:Creating metrics dataframe
2023-02-03 15:17:19,466:INFO:Initializing Lasso Regression
2023-02-03 15:17:19,466:INFO:Total runtime is 0.007212615013122559 minutes
2023-02-03 15:17:19,471:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:19,472:INFO:Initializing create_model()
2023-02-03 15:17:19,472:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:19,472:INFO:Checking exceptions
2023-02-03 15:17:19,472:INFO:Importing libraries
2023-02-03 15:17:19,473:INFO:Copying training dataset
2023-02-03 15:17:19,477:INFO:Defining folds
2023-02-03 15:17:19,477:INFO:Declaring metric variables
2023-02-03 15:17:19,482:INFO:Importing untrained model
2023-02-03 15:17:19,487:INFO:Lasso Regression Imported successfully
2023-02-03 15:17:19,499:INFO:Starting cross validation
2023-02-03 15:17:19,500:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:19,523:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.653e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,553:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.713e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,575:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.832e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,599:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,625:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.826e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,651:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,675:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,699:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,722:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,745:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.356e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,755:INFO:Calculating mean and std
2023-02-03 15:17:19,755:INFO:Creating metrics dataframe
2023-02-03 15:17:19,759:INFO:Uploading results into container
2023-02-03 15:17:19,760:INFO:Uploading model into container now
2023-02-03 15:17:19,760:INFO:_master_model_container: 38
2023-02-03 15:17:19,760:INFO:_display_container: 4
2023-02-03 15:17:19,761:INFO:Lasso(random_state=123)
2023-02-03 15:17:19,761:INFO:create_model() successfully completed......................................
2023-02-03 15:17:19,842:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:19,842:INFO:Creating metrics dataframe
2023-02-03 15:17:19,857:INFO:Initializing Ridge Regression
2023-02-03 15:17:19,858:INFO:Total runtime is 0.013742069403330486 minutes
2023-02-03 15:17:19,862:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:19,863:INFO:Initializing create_model()
2023-02-03 15:17:19,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:19,863:INFO:Checking exceptions
2023-02-03 15:17:19,863:INFO:Importing libraries
2023-02-03 15:17:19,863:INFO:Copying training dataset
2023-02-03 15:17:19,868:INFO:Defining folds
2023-02-03 15:17:19,868:INFO:Declaring metric variables
2023-02-03 15:17:19,873:INFO:Importing untrained model
2023-02-03 15:17:19,892:INFO:Ridge Regression Imported successfully
2023-02-03 15:17:19,912:INFO:Starting cross validation
2023-02-03 15:17:19,913:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:20,162:INFO:Calculating mean and std
2023-02-03 15:17:20,163:INFO:Creating metrics dataframe
2023-02-03 15:17:20,170:INFO:Uploading results into container
2023-02-03 15:17:20,170:INFO:Uploading model into container now
2023-02-03 15:17:20,171:INFO:_master_model_container: 39
2023-02-03 15:17:20,171:INFO:_display_container: 4
2023-02-03 15:17:20,172:INFO:Ridge(random_state=123)
2023-02-03 15:17:20,172:INFO:create_model() successfully completed......................................
2023-02-03 15:17:20,272:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:20,272:INFO:Creating metrics dataframe
2023-02-03 15:17:20,288:INFO:Initializing Elastic Net
2023-02-03 15:17:20,288:INFO:Total runtime is 0.020902458826700845 minutes
2023-02-03 15:17:20,294:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:20,294:INFO:Initializing create_model()
2023-02-03 15:17:20,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:20,294:INFO:Checking exceptions
2023-02-03 15:17:20,295:INFO:Importing libraries
2023-02-03 15:17:20,295:INFO:Copying training dataset
2023-02-03 15:17:20,301:INFO:Defining folds
2023-02-03 15:17:20,301:INFO:Declaring metric variables
2023-02-03 15:17:20,307:INFO:Importing untrained model
2023-02-03 15:17:20,314:INFO:Elastic Net Imported successfully
2023-02-03 15:17:20,329:INFO:Starting cross validation
2023-02-03 15:17:20,331:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:20,357:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,384:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.982e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,408:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,429:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,452:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.646e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,474:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.039e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,495:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.999e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,517:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,538:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.979e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,563:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,573:INFO:Calculating mean and std
2023-02-03 15:17:20,575:INFO:Creating metrics dataframe
2023-02-03 15:17:20,579:INFO:Uploading results into container
2023-02-03 15:17:20,579:INFO:Uploading model into container now
2023-02-03 15:17:20,580:INFO:_master_model_container: 40
2023-02-03 15:17:20,580:INFO:_display_container: 4
2023-02-03 15:17:20,581:INFO:ElasticNet(random_state=123)
2023-02-03 15:17:20,581:INFO:create_model() successfully completed......................................
2023-02-03 15:17:20,663:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:20,663:INFO:Creating metrics dataframe
2023-02-03 15:17:20,677:INFO:Initializing Least Angle Regression
2023-02-03 15:17:20,677:INFO:Total runtime is 0.02738208770751953 minutes
2023-02-03 15:17:20,682:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:20,683:INFO:Initializing create_model()
2023-02-03 15:17:20,683:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:20,684:INFO:Checking exceptions
2023-02-03 15:17:20,684:INFO:Importing libraries
2023-02-03 15:17:20,684:INFO:Copying training dataset
2023-02-03 15:17:20,689:INFO:Defining folds
2023-02-03 15:17:20,689:INFO:Declaring metric variables
2023-02-03 15:17:20,695:INFO:Importing untrained model
2023-02-03 15:17:20,703:INFO:Least Angle Regression Imported successfully
2023-02-03 15:17:20,717:INFO:Starting cross validation
2023-02-03 15:17:20,719:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:20,741:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,762:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,785:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,805:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,826:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,848:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,873:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,894:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,915:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,936:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,950:INFO:Calculating mean and std
2023-02-03 15:17:20,951:INFO:Creating metrics dataframe
2023-02-03 15:17:20,956:INFO:Uploading results into container
2023-02-03 15:17:20,957:INFO:Uploading model into container now
2023-02-03 15:17:20,958:INFO:_master_model_container: 41
2023-02-03 15:17:20,958:INFO:_display_container: 4
2023-02-03 15:17:20,958:INFO:Lars(random_state=123)
2023-02-03 15:17:20,959:INFO:create_model() successfully completed......................................
2023-02-03 15:17:21,050:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:21,050:INFO:Creating metrics dataframe
2023-02-03 15:17:21,062:INFO:Initializing Lasso Least Angle Regression
2023-02-03 15:17:21,063:INFO:Total runtime is 0.03382838169733683 minutes
2023-02-03 15:17:21,069:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:21,070:INFO:Initializing create_model()
2023-02-03 15:17:21,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:21,070:INFO:Checking exceptions
2023-02-03 15:17:21,070:INFO:Importing libraries
2023-02-03 15:17:21,070:INFO:Copying training dataset
2023-02-03 15:17:21,074:INFO:Defining folds
2023-02-03 15:17:21,074:INFO:Declaring metric variables
2023-02-03 15:17:21,081:INFO:Importing untrained model
2023-02-03 15:17:21,087:INFO:Lasso Least Angle Regression Imported successfully
2023-02-03 15:17:21,099:INFO:Starting cross validation
2023-02-03 15:17:21,101:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:21,123:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,146:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,168:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,190:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,212:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,234:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,257:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,277:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,297:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,320:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,330:INFO:Calculating mean and std
2023-02-03 15:17:21,334:INFO:Creating metrics dataframe
2023-02-03 15:17:21,340:INFO:Uploading results into container
2023-02-03 15:17:21,341:INFO:Uploading model into container now
2023-02-03 15:17:21,341:INFO:_master_model_container: 42
2023-02-03 15:17:21,342:INFO:_display_container: 4
2023-02-03 15:17:21,342:INFO:LassoLars(random_state=123)
2023-02-03 15:17:21,342:INFO:create_model() successfully completed......................................
2023-02-03 15:17:21,428:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:21,428:INFO:Creating metrics dataframe
2023-02-03 15:17:21,443:INFO:Initializing Orthogonal Matching Pursuit
2023-02-03 15:17:21,443:INFO:Total runtime is 0.040146406491597494 minutes
2023-02-03 15:17:21,447:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:21,447:INFO:Initializing create_model()
2023-02-03 15:17:21,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:21,448:INFO:Checking exceptions
2023-02-03 15:17:21,448:INFO:Importing libraries
2023-02-03 15:17:21,449:INFO:Copying training dataset
2023-02-03 15:17:21,455:INFO:Defining folds
2023-02-03 15:17:21,456:INFO:Declaring metric variables
2023-02-03 15:17:21,461:INFO:Importing untrained model
2023-02-03 15:17:21,468:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-03 15:17:21,484:INFO:Starting cross validation
2023-02-03 15:17:21,487:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:21,504:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,530:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,552:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,572:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,592:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,613:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,636:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,658:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,680:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,702:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,712:INFO:Calculating mean and std
2023-02-03 15:17:21,714:INFO:Creating metrics dataframe
2023-02-03 15:17:21,719:INFO:Uploading results into container
2023-02-03 15:17:21,719:INFO:Uploading model into container now
2023-02-03 15:17:21,720:INFO:_master_model_container: 43
2023-02-03 15:17:21,721:INFO:_display_container: 4
2023-02-03 15:17:21,721:INFO:OrthogonalMatchingPursuit()
2023-02-03 15:17:21,722:INFO:create_model() successfully completed......................................
2023-02-03 15:17:21,809:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:21,809:INFO:Creating metrics dataframe
2023-02-03 15:17:21,823:INFO:Initializing Bayesian Ridge
2023-02-03 15:17:21,823:INFO:Total runtime is 0.046492513020833334 minutes
2023-02-03 15:17:21,829:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:21,829:INFO:Initializing create_model()
2023-02-03 15:17:21,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:21,830:INFO:Checking exceptions
2023-02-03 15:17:21,830:INFO:Importing libraries
2023-02-03 15:17:21,830:INFO:Copying training dataset
2023-02-03 15:17:21,836:INFO:Defining folds
2023-02-03 15:17:21,836:INFO:Declaring metric variables
2023-02-03 15:17:21,842:INFO:Importing untrained model
2023-02-03 15:17:21,848:INFO:Bayesian Ridge Imported successfully
2023-02-03 15:17:21,865:INFO:Starting cross validation
2023-02-03 15:17:21,866:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:22,106:INFO:Calculating mean and std
2023-02-03 15:17:22,107:INFO:Creating metrics dataframe
2023-02-03 15:17:22,111:INFO:Uploading results into container
2023-02-03 15:17:22,112:INFO:Uploading model into container now
2023-02-03 15:17:22,112:INFO:_master_model_container: 44
2023-02-03 15:17:22,113:INFO:_display_container: 4
2023-02-03 15:17:22,113:INFO:BayesianRidge()
2023-02-03 15:17:22,114:INFO:create_model() successfully completed......................................
2023-02-03 15:17:22,204:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:22,204:INFO:Creating metrics dataframe
2023-02-03 15:17:22,218:INFO:Initializing Passive Aggressive Regressor
2023-02-03 15:17:22,219:INFO:Total runtime is 0.053088982899983726 minutes
2023-02-03 15:17:22,223:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:22,223:INFO:Initializing create_model()
2023-02-03 15:17:22,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:22,224:INFO:Checking exceptions
2023-02-03 15:17:22,224:INFO:Importing libraries
2023-02-03 15:17:22,224:INFO:Copying training dataset
2023-02-03 15:17:22,228:INFO:Defining folds
2023-02-03 15:17:22,229:INFO:Declaring metric variables
2023-02-03 15:17:22,234:INFO:Importing untrained model
2023-02-03 15:17:22,244:INFO:Passive Aggressive Regressor Imported successfully
2023-02-03 15:17:22,262:INFO:Starting cross validation
2023-02-03 15:17:22,264:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:22,496:INFO:Calculating mean and std
2023-02-03 15:17:22,498:INFO:Creating metrics dataframe
2023-02-03 15:17:22,503:INFO:Uploading results into container
2023-02-03 15:17:22,504:INFO:Uploading model into container now
2023-02-03 15:17:22,504:INFO:_master_model_container: 45
2023-02-03 15:17:22,504:INFO:_display_container: 4
2023-02-03 15:17:22,505:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-03 15:17:22,505:INFO:create_model() successfully completed......................................
2023-02-03 15:17:22,590:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:22,591:INFO:Creating metrics dataframe
2023-02-03 15:17:22,607:INFO:Initializing Huber Regressor
2023-02-03 15:17:22,608:INFO:Total runtime is 0.059568393230438235 minutes
2023-02-03 15:17:22,614:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:22,615:INFO:Initializing create_model()
2023-02-03 15:17:22,615:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:22,615:INFO:Checking exceptions
2023-02-03 15:17:22,615:INFO:Importing libraries
2023-02-03 15:17:22,615:INFO:Copying training dataset
2023-02-03 15:17:22,622:INFO:Defining folds
2023-02-03 15:17:22,622:INFO:Declaring metric variables
2023-02-03 15:17:22,629:INFO:Importing untrained model
2023-02-03 15:17:22,635:INFO:Huber Regressor Imported successfully
2023-02-03 15:17:22,649:INFO:Starting cross validation
2023-02-03 15:17:22,651:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:22,925:INFO:Calculating mean and std
2023-02-03 15:17:22,928:INFO:Creating metrics dataframe
2023-02-03 15:17:22,940:INFO:Uploading results into container
2023-02-03 15:17:22,942:INFO:Uploading model into container now
2023-02-03 15:17:22,942:INFO:_master_model_container: 46
2023-02-03 15:17:22,943:INFO:_display_container: 4
2023-02-03 15:17:22,943:INFO:HuberRegressor()
2023-02-03 15:17:22,943:INFO:create_model() successfully completed......................................
2023-02-03 15:17:23,057:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:23,057:INFO:Creating metrics dataframe
2023-02-03 15:17:23,075:INFO:Initializing K Neighbors Regressor
2023-02-03 15:17:23,076:INFO:Total runtime is 0.06736389001210531 minutes
2023-02-03 15:17:23,081:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:23,082:INFO:Initializing create_model()
2023-02-03 15:17:23,082:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:23,082:INFO:Checking exceptions
2023-02-03 15:17:23,082:INFO:Importing libraries
2023-02-03 15:17:23,083:INFO:Copying training dataset
2023-02-03 15:17:23,090:INFO:Defining folds
2023-02-03 15:17:23,091:INFO:Declaring metric variables
2023-02-03 15:17:23,097:INFO:Importing untrained model
2023-02-03 15:17:23,104:INFO:K Neighbors Regressor Imported successfully
2023-02-03 15:17:23,120:INFO:Starting cross validation
2023-02-03 15:17:23,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:23,478:INFO:Calculating mean and std
2023-02-03 15:17:23,479:INFO:Creating metrics dataframe
2023-02-03 15:17:23,483:INFO:Uploading results into container
2023-02-03 15:17:23,485:INFO:Uploading model into container now
2023-02-03 15:17:23,486:INFO:_master_model_container: 47
2023-02-03 15:17:23,486:INFO:_display_container: 4
2023-02-03 15:17:23,487:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-03 15:17:23,487:INFO:create_model() successfully completed......................................
2023-02-03 15:17:23,573:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:23,574:INFO:Creating metrics dataframe
2023-02-03 15:17:23,591:INFO:Initializing Decision Tree Regressor
2023-02-03 15:17:23,591:INFO:Total runtime is 0.07595900297164918 minutes
2023-02-03 15:17:23,597:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:23,597:INFO:Initializing create_model()
2023-02-03 15:17:23,597:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:23,597:INFO:Checking exceptions
2023-02-03 15:17:23,598:INFO:Importing libraries
2023-02-03 15:17:23,598:INFO:Copying training dataset
2023-02-03 15:17:23,602:INFO:Defining folds
2023-02-03 15:17:23,603:INFO:Declaring metric variables
2023-02-03 15:17:23,611:INFO:Importing untrained model
2023-02-03 15:17:23,616:INFO:Decision Tree Regressor Imported successfully
2023-02-03 15:17:23,626:INFO:Starting cross validation
2023-02-03 15:17:23,628:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:23,864:INFO:Calculating mean and std
2023-02-03 15:17:23,865:INFO:Creating metrics dataframe
2023-02-03 15:17:23,870:INFO:Uploading results into container
2023-02-03 15:17:23,871:INFO:Uploading model into container now
2023-02-03 15:17:23,872:INFO:_master_model_container: 48
2023-02-03 15:17:23,872:INFO:_display_container: 4
2023-02-03 15:17:23,873:INFO:DecisionTreeRegressor(random_state=123)
2023-02-03 15:17:23,873:INFO:create_model() successfully completed......................................
2023-02-03 15:17:23,955:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:23,955:INFO:Creating metrics dataframe
2023-02-03 15:17:23,971:INFO:Initializing Random Forest Regressor
2023-02-03 15:17:23,971:INFO:Total runtime is 0.08228869438171388 minutes
2023-02-03 15:17:23,976:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:23,977:INFO:Initializing create_model()
2023-02-03 15:17:23,977:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:23,977:INFO:Checking exceptions
2023-02-03 15:17:23,977:INFO:Importing libraries
2023-02-03 15:17:23,978:INFO:Copying training dataset
2023-02-03 15:17:23,981:INFO:Defining folds
2023-02-03 15:17:23,982:INFO:Declaring metric variables
2023-02-03 15:17:23,988:INFO:Importing untrained model
2023-02-03 15:17:23,994:INFO:Random Forest Regressor Imported successfully
2023-02-03 15:17:24,009:INFO:Starting cross validation
2023-02-03 15:17:24,011:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:25,842:INFO:Calculating mean and std
2023-02-03 15:17:25,844:INFO:Creating metrics dataframe
2023-02-03 15:17:25,848:INFO:Uploading results into container
2023-02-03 15:17:25,849:INFO:Uploading model into container now
2023-02-03 15:17:25,850:INFO:_master_model_container: 49
2023-02-03 15:17:25,850:INFO:_display_container: 4
2023-02-03 15:17:25,851:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:17:25,851:INFO:create_model() successfully completed......................................
2023-02-03 15:17:25,944:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:25,944:INFO:Creating metrics dataframe
2023-02-03 15:17:25,961:INFO:Initializing Extra Trees Regressor
2023-02-03 15:17:25,961:INFO:Total runtime is 0.11545761028925579 minutes
2023-02-03 15:17:25,965:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:25,966:INFO:Initializing create_model()
2023-02-03 15:17:25,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:25,966:INFO:Checking exceptions
2023-02-03 15:17:25,967:INFO:Importing libraries
2023-02-03 15:17:25,967:INFO:Copying training dataset
2023-02-03 15:17:25,971:INFO:Defining folds
2023-02-03 15:17:25,971:INFO:Declaring metric variables
2023-02-03 15:17:25,977:INFO:Importing untrained model
2023-02-03 15:17:25,983:INFO:Extra Trees Regressor Imported successfully
2023-02-03 15:17:25,992:INFO:Starting cross validation
2023-02-03 15:17:25,994:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:27,928:INFO:Calculating mean and std
2023-02-03 15:17:27,930:INFO:Creating metrics dataframe
2023-02-03 15:17:27,935:INFO:Uploading results into container
2023-02-03 15:17:27,936:INFO:Uploading model into container now
2023-02-03 15:17:27,936:INFO:_master_model_container: 50
2023-02-03 15:17:27,936:INFO:_display_container: 4
2023-02-03 15:17:27,937:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:17:27,937:INFO:create_model() successfully completed......................................
2023-02-03 15:17:28,021:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:28,021:INFO:Creating metrics dataframe
2023-02-03 15:17:28,038:INFO:Initializing AdaBoost Regressor
2023-02-03 15:17:28,038:INFO:Total runtime is 0.15007108052571616 minutes
2023-02-03 15:17:28,044:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:28,044:INFO:Initializing create_model()
2023-02-03 15:17:28,044:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:28,044:INFO:Checking exceptions
2023-02-03 15:17:28,044:INFO:Importing libraries
2023-02-03 15:17:28,044:INFO:Copying training dataset
2023-02-03 15:17:28,049:INFO:Defining folds
2023-02-03 15:17:28,049:INFO:Declaring metric variables
2023-02-03 15:17:28,054:INFO:Importing untrained model
2023-02-03 15:17:28,062:INFO:AdaBoost Regressor Imported successfully
2023-02-03 15:17:28,074:INFO:Starting cross validation
2023-02-03 15:17:28,075:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:28,691:INFO:Calculating mean and std
2023-02-03 15:17:28,693:INFO:Creating metrics dataframe
2023-02-03 15:17:28,697:INFO:Uploading results into container
2023-02-03 15:17:28,698:INFO:Uploading model into container now
2023-02-03 15:17:28,699:INFO:_master_model_container: 51
2023-02-03 15:17:28,699:INFO:_display_container: 4
2023-02-03 15:17:28,700:INFO:AdaBoostRegressor(random_state=123)
2023-02-03 15:17:28,700:INFO:create_model() successfully completed......................................
2023-02-03 15:17:28,787:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:28,787:INFO:Creating metrics dataframe
2023-02-03 15:17:28,804:INFO:Initializing Gradient Boosting Regressor
2023-02-03 15:17:28,804:INFO:Total runtime is 0.16283047993977867 minutes
2023-02-03 15:17:28,810:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:28,810:INFO:Initializing create_model()
2023-02-03 15:17:28,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:28,811:INFO:Checking exceptions
2023-02-03 15:17:28,811:INFO:Importing libraries
2023-02-03 15:17:28,811:INFO:Copying training dataset
2023-02-03 15:17:28,815:INFO:Defining folds
2023-02-03 15:17:28,815:INFO:Declaring metric variables
2023-02-03 15:17:28,821:INFO:Importing untrained model
2023-02-03 15:17:28,830:INFO:Gradient Boosting Regressor Imported successfully
2023-02-03 15:17:28,845:INFO:Starting cross validation
2023-02-03 15:17:28,847:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:29,569:INFO:Calculating mean and std
2023-02-03 15:17:29,571:INFO:Creating metrics dataframe
2023-02-03 15:17:29,580:INFO:Uploading results into container
2023-02-03 15:17:29,581:INFO:Uploading model into container now
2023-02-03 15:17:29,582:INFO:_master_model_container: 52
2023-02-03 15:17:29,582:INFO:_display_container: 4
2023-02-03 15:17:29,583:INFO:GradientBoostingRegressor(random_state=123)
2023-02-03 15:17:29,583:INFO:create_model() successfully completed......................................
2023-02-03 15:17:29,684:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:29,684:INFO:Creating metrics dataframe
2023-02-03 15:17:29,704:INFO:Initializing Light Gradient Boosting Machine
2023-02-03 15:17:29,704:INFO:Total runtime is 0.1778382460276286 minutes
2023-02-03 15:17:29,713:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:29,713:INFO:Initializing create_model()
2023-02-03 15:17:29,714:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:29,714:INFO:Checking exceptions
2023-02-03 15:17:29,714:INFO:Importing libraries
2023-02-03 15:17:29,715:INFO:Copying training dataset
2023-02-03 15:17:29,721:INFO:Defining folds
2023-02-03 15:17:29,721:INFO:Declaring metric variables
2023-02-03 15:17:29,730:INFO:Importing untrained model
2023-02-03 15:17:29,736:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-03 15:17:29,758:INFO:Starting cross validation
2023-02-03 15:17:29,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:37,210:INFO:Calculating mean and std
2023-02-03 15:17:37,213:INFO:Creating metrics dataframe
2023-02-03 15:17:37,222:INFO:Uploading results into container
2023-02-03 15:17:37,224:INFO:Uploading model into container now
2023-02-03 15:17:37,225:INFO:_master_model_container: 53
2023-02-03 15:17:37,225:INFO:_display_container: 4
2023-02-03 15:17:37,226:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-02-03 15:17:37,226:INFO:create_model() successfully completed......................................
2023-02-03 15:17:37,349:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:37,350:INFO:Creating metrics dataframe
2023-02-03 15:17:37,368:INFO:Initializing Dummy Regressor
2023-02-03 15:17:37,369:INFO:Total runtime is 0.30558565457661946 minutes
2023-02-03 15:17:37,374:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:37,374:INFO:Initializing create_model()
2023-02-03 15:17:37,374:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:37,375:INFO:Checking exceptions
2023-02-03 15:17:37,375:INFO:Importing libraries
2023-02-03 15:17:37,375:INFO:Copying training dataset
2023-02-03 15:17:37,379:INFO:Defining folds
2023-02-03 15:17:37,379:INFO:Declaring metric variables
2023-02-03 15:17:37,385:INFO:Importing untrained model
2023-02-03 15:17:37,391:INFO:Dummy Regressor Imported successfully
2023-02-03 15:17:37,401:INFO:Starting cross validation
2023-02-03 15:17:37,403:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:37,606:INFO:Calculating mean and std
2023-02-03 15:17:37,607:INFO:Creating metrics dataframe
2023-02-03 15:17:37,612:INFO:Uploading results into container
2023-02-03 15:17:37,613:INFO:Uploading model into container now
2023-02-03 15:17:37,614:INFO:_master_model_container: 54
2023-02-03 15:17:37,614:INFO:_display_container: 4
2023-02-03 15:17:37,615:INFO:DummyRegressor()
2023-02-03 15:17:37,615:INFO:create_model() successfully completed......................................
2023-02-03 15:17:37,704:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:37,704:INFO:Creating metrics dataframe
2023-02-03 15:17:37,739:INFO:Initializing create_model()
2023-02-03 15:17:37,740:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:37,740:INFO:Checking exceptions
2023-02-03 15:17:37,742:INFO:Importing libraries
2023-02-03 15:17:37,742:INFO:Copying training dataset
2023-02-03 15:17:37,746:INFO:Defining folds
2023-02-03 15:17:37,746:INFO:Declaring metric variables
2023-02-03 15:17:37,746:INFO:Importing untrained model
2023-02-03 15:17:37,746:INFO:Declaring custom model
2023-02-03 15:17:37,747:INFO:Linear Regression Imported successfully
2023-02-03 15:17:37,747:INFO:Cross validation set to False
2023-02-03 15:17:37,747:INFO:Fitting Model
2023-02-03 15:17:37,758:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:17:37,758:INFO:create_model() successfully completed......................................
2023-02-03 15:17:37,902:INFO:_master_model_container: 54
2023-02-03 15:17:37,903:INFO:_display_container: 4
2023-02-03 15:17:37,903:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:17:37,903:INFO:compare_models() successfully completed......................................
2023-02-03 15:19:00,284:INFO:Initializing create_model()
2023-02-03 15:19:00,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:00,284:INFO:Checking exceptions
2023-02-03 15:19:00,326:INFO:Importing libraries
2023-02-03 15:19:00,327:INFO:Copying training dataset
2023-02-03 15:19:00,340:INFO:Defining folds
2023-02-03 15:19:00,340:INFO:Declaring metric variables
2023-02-03 15:19:00,352:INFO:Importing untrained model
2023-02-03 15:19:00,352:INFO:Declaring custom model
2023-02-03 15:19:00,360:INFO:Linear Regression Imported successfully
2023-02-03 15:19:00,377:INFO:Starting cross validation
2023-02-03 15:19:00,380:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:00,745:INFO:Calculating mean and std
2023-02-03 15:19:00,746:INFO:Creating metrics dataframe
2023-02-03 15:19:00,754:INFO:Finalizing model
2023-02-03 15:19:00,776:INFO:Uploading results into container
2023-02-03 15:19:00,778:INFO:Uploading model into container now
2023-02-03 15:19:00,804:INFO:_master_model_container: 55
2023-02-03 15:19:00,804:INFO:_display_container: 5
2023-02-03 15:19:00,804:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:19:00,805:INFO:create_model() successfully completed......................................
2023-02-03 15:19:20,909:INFO:Initializing compare_models()
2023-02-03 15:19:20,910:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-03 15:19:20,910:INFO:Checking exceptions
2023-02-03 15:19:20,913:INFO:Preparing display monitor
2023-02-03 15:19:20,966:INFO:Initializing Linear Regression
2023-02-03 15:19:20,967:INFO:Total runtime is 1.6669432322184246e-05 minutes
2023-02-03 15:19:20,977:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:20,978:INFO:Initializing create_model()
2023-02-03 15:19:20,978:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:20,978:INFO:Checking exceptions
2023-02-03 15:19:20,979:INFO:Importing libraries
2023-02-03 15:19:20,980:INFO:Copying training dataset
2023-02-03 15:19:20,992:INFO:Defining folds
2023-02-03 15:19:20,992:INFO:Declaring metric variables
2023-02-03 15:19:20,999:INFO:Importing untrained model
2023-02-03 15:19:21,010:INFO:Linear Regression Imported successfully
2023-02-03 15:19:21,024:INFO:Starting cross validation
2023-02-03 15:19:21,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:21,315:INFO:Calculating mean and std
2023-02-03 15:19:21,315:INFO:Creating metrics dataframe
2023-02-03 15:19:21,319:INFO:Uploading results into container
2023-02-03 15:19:21,320:INFO:Uploading model into container now
2023-02-03 15:19:21,320:INFO:_master_model_container: 56
2023-02-03 15:19:21,320:INFO:_display_container: 6
2023-02-03 15:19:21,320:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:19:21,321:INFO:create_model() successfully completed......................................
2023-02-03 15:19:21,404:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:21,404:INFO:Creating metrics dataframe
2023-02-03 15:19:21,416:INFO:Initializing Lasso Regression
2023-02-03 15:19:21,416:INFO:Total runtime is 0.007495677471160889 minutes
2023-02-03 15:19:21,423:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:21,423:INFO:Initializing create_model()
2023-02-03 15:19:21,424:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:21,424:INFO:Checking exceptions
2023-02-03 15:19:21,424:INFO:Importing libraries
2023-02-03 15:19:21,424:INFO:Copying training dataset
2023-02-03 15:19:21,427:INFO:Defining folds
2023-02-03 15:19:21,427:INFO:Declaring metric variables
2023-02-03 15:19:21,433:INFO:Importing untrained model
2023-02-03 15:19:21,440:INFO:Lasso Regression Imported successfully
2023-02-03 15:19:21,451:INFO:Starting cross validation
2023-02-03 15:19:21,452:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:21,471:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.653e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,501:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.713e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,525:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.832e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,545:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,566:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.826e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,587:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,612:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,633:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,655:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,676:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.356e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,685:INFO:Calculating mean and std
2023-02-03 15:19:21,686:INFO:Creating metrics dataframe
2023-02-03 15:19:21,691:INFO:Uploading results into container
2023-02-03 15:19:21,691:INFO:Uploading model into container now
2023-02-03 15:19:21,692:INFO:_master_model_container: 57
2023-02-03 15:19:21,692:INFO:_display_container: 6
2023-02-03 15:19:21,692:INFO:Lasso(random_state=123)
2023-02-03 15:19:21,692:INFO:create_model() successfully completed......................................
2023-02-03 15:19:21,776:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:21,776:INFO:Creating metrics dataframe
2023-02-03 15:19:21,788:INFO:Initializing Ridge Regression
2023-02-03 15:19:21,788:INFO:Total runtime is 0.013692132631937663 minutes
2023-02-03 15:19:21,794:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:21,794:INFO:Initializing create_model()
2023-02-03 15:19:21,794:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:21,794:INFO:Checking exceptions
2023-02-03 15:19:21,794:INFO:Importing libraries
2023-02-03 15:19:21,795:INFO:Copying training dataset
2023-02-03 15:19:21,798:INFO:Defining folds
2023-02-03 15:19:21,798:INFO:Declaring metric variables
2023-02-03 15:19:21,802:INFO:Importing untrained model
2023-02-03 15:19:21,808:INFO:Ridge Regression Imported successfully
2023-02-03 15:19:21,819:INFO:Starting cross validation
2023-02-03 15:19:21,822:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:22,054:INFO:Calculating mean and std
2023-02-03 15:19:22,055:INFO:Creating metrics dataframe
2023-02-03 15:19:22,060:INFO:Uploading results into container
2023-02-03 15:19:22,061:INFO:Uploading model into container now
2023-02-03 15:19:22,062:INFO:_master_model_container: 58
2023-02-03 15:19:22,062:INFO:_display_container: 6
2023-02-03 15:19:22,063:INFO:Ridge(random_state=123)
2023-02-03 15:19:22,063:INFO:create_model() successfully completed......................................
2023-02-03 15:19:22,145:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:22,145:INFO:Creating metrics dataframe
2023-02-03 15:19:22,157:INFO:Initializing Elastic Net
2023-02-03 15:19:22,158:INFO:Total runtime is 0.019855419794718426 minutes
2023-02-03 15:19:22,162:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:22,163:INFO:Initializing create_model()
2023-02-03 15:19:22,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:22,163:INFO:Checking exceptions
2023-02-03 15:19:22,163:INFO:Importing libraries
2023-02-03 15:19:22,163:INFO:Copying training dataset
2023-02-03 15:19:22,167:INFO:Defining folds
2023-02-03 15:19:22,167:INFO:Declaring metric variables
2023-02-03 15:19:22,174:INFO:Importing untrained model
2023-02-03 15:19:22,182:INFO:Elastic Net Imported successfully
2023-02-03 15:19:22,194:INFO:Starting cross validation
2023-02-03 15:19:22,195:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:22,218:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,245:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.982e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,266:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,286:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,307:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.646e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,329:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.039e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,350:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.999e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,372:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,394:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.979e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,413:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,422:INFO:Calculating mean and std
2023-02-03 15:19:22,423:INFO:Creating metrics dataframe
2023-02-03 15:19:22,427:INFO:Uploading results into container
2023-02-03 15:19:22,428:INFO:Uploading model into container now
2023-02-03 15:19:22,429:INFO:_master_model_container: 59
2023-02-03 15:19:22,430:INFO:_display_container: 6
2023-02-03 15:19:22,430:INFO:ElasticNet(random_state=123)
2023-02-03 15:19:22,430:INFO:create_model() successfully completed......................................
2023-02-03 15:19:22,526:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:22,526:INFO:Creating metrics dataframe
2023-02-03 15:19:22,541:INFO:Initializing Least Angle Regression
2023-02-03 15:19:22,541:INFO:Total runtime is 0.02625157435735067 minutes
2023-02-03 15:19:22,547:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:22,547:INFO:Initializing create_model()
2023-02-03 15:19:22,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:22,548:INFO:Checking exceptions
2023-02-03 15:19:22,548:INFO:Importing libraries
2023-02-03 15:19:22,548:INFO:Copying training dataset
2023-02-03 15:19:22,555:INFO:Defining folds
2023-02-03 15:19:22,555:INFO:Declaring metric variables
2023-02-03 15:19:22,560:INFO:Importing untrained model
2023-02-03 15:19:22,568:INFO:Least Angle Regression Imported successfully
2023-02-03 15:19:22,589:INFO:Starting cross validation
2023-02-03 15:19:22,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:22,624:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,650:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,673:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,695:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,719:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,746:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,767:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,790:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,810:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,833:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,845:INFO:Calculating mean and std
2023-02-03 15:19:22,846:INFO:Creating metrics dataframe
2023-02-03 15:19:22,851:INFO:Uploading results into container
2023-02-03 15:19:22,852:INFO:Uploading model into container now
2023-02-03 15:19:22,852:INFO:_master_model_container: 60
2023-02-03 15:19:22,852:INFO:_display_container: 6
2023-02-03 15:19:22,853:INFO:Lars(random_state=123)
2023-02-03 15:19:22,853:INFO:create_model() successfully completed......................................
2023-02-03 15:19:22,943:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:22,943:INFO:Creating metrics dataframe
2023-02-03 15:19:22,958:INFO:Initializing Lasso Least Angle Regression
2023-02-03 15:19:22,958:INFO:Total runtime is 0.03319758176803589 minutes
2023-02-03 15:19:22,963:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:22,963:INFO:Initializing create_model()
2023-02-03 15:19:22,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:22,964:INFO:Checking exceptions
2023-02-03 15:19:22,964:INFO:Importing libraries
2023-02-03 15:19:22,964:INFO:Copying training dataset
2023-02-03 15:19:22,968:INFO:Defining folds
2023-02-03 15:19:22,968:INFO:Declaring metric variables
2023-02-03 15:19:22,976:INFO:Importing untrained model
2023-02-03 15:19:22,983:INFO:Lasso Least Angle Regression Imported successfully
2023-02-03 15:19:22,998:INFO:Starting cross validation
2023-02-03 15:19:22,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:23,017:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,044:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,066:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,087:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,111:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,133:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,156:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,177:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,198:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,220:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,230:INFO:Calculating mean and std
2023-02-03 15:19:23,231:INFO:Creating metrics dataframe
2023-02-03 15:19:23,235:INFO:Uploading results into container
2023-02-03 15:19:23,236:INFO:Uploading model into container now
2023-02-03 15:19:23,237:INFO:_master_model_container: 61
2023-02-03 15:19:23,237:INFO:_display_container: 6
2023-02-03 15:19:23,239:INFO:LassoLars(random_state=123)
2023-02-03 15:19:23,239:INFO:create_model() successfully completed......................................
2023-02-03 15:19:23,330:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:23,330:INFO:Creating metrics dataframe
2023-02-03 15:19:23,346:INFO:Initializing Orthogonal Matching Pursuit
2023-02-03 15:19:23,347:INFO:Total runtime is 0.039677258332570395 minutes
2023-02-03 15:19:23,352:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:23,352:INFO:Initializing create_model()
2023-02-03 15:19:23,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:23,353:INFO:Checking exceptions
2023-02-03 15:19:23,353:INFO:Importing libraries
2023-02-03 15:19:23,354:INFO:Copying training dataset
2023-02-03 15:19:23,362:INFO:Defining folds
2023-02-03 15:19:23,362:INFO:Declaring metric variables
2023-02-03 15:19:23,370:INFO:Importing untrained model
2023-02-03 15:19:23,380:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-03 15:19:23,394:INFO:Starting cross validation
2023-02-03 15:19:23,396:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:23,414:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,441:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,464:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,488:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,509:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,530:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,551:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,575:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,596:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,616:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,627:INFO:Calculating mean and std
2023-02-03 15:19:23,628:INFO:Creating metrics dataframe
2023-02-03 15:19:23,632:INFO:Uploading results into container
2023-02-03 15:19:23,633:INFO:Uploading model into container now
2023-02-03 15:19:23,633:INFO:_master_model_container: 62
2023-02-03 15:19:23,633:INFO:_display_container: 6
2023-02-03 15:19:23,634:INFO:OrthogonalMatchingPursuit()
2023-02-03 15:19:23,634:INFO:create_model() successfully completed......................................
2023-02-03 15:19:23,729:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:23,730:INFO:Creating metrics dataframe
2023-02-03 15:19:23,745:INFO:Initializing Bayesian Ridge
2023-02-03 15:19:23,745:INFO:Total runtime is 0.04630675713221232 minutes
2023-02-03 15:19:23,751:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:23,751:INFO:Initializing create_model()
2023-02-03 15:19:23,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:23,752:INFO:Checking exceptions
2023-02-03 15:19:23,752:INFO:Importing libraries
2023-02-03 15:19:23,752:INFO:Copying training dataset
2023-02-03 15:19:23,758:INFO:Defining folds
2023-02-03 15:19:23,758:INFO:Declaring metric variables
2023-02-03 15:19:23,764:INFO:Importing untrained model
2023-02-03 15:19:23,770:INFO:Bayesian Ridge Imported successfully
2023-02-03 15:19:23,788:INFO:Starting cross validation
2023-02-03 15:19:23,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:24,026:INFO:Calculating mean and std
2023-02-03 15:19:24,027:INFO:Creating metrics dataframe
2023-02-03 15:19:24,032:INFO:Uploading results into container
2023-02-03 15:19:24,033:INFO:Uploading model into container now
2023-02-03 15:19:24,033:INFO:_master_model_container: 63
2023-02-03 15:19:24,034:INFO:_display_container: 6
2023-02-03 15:19:24,034:INFO:BayesianRidge()
2023-02-03 15:19:24,035:INFO:create_model() successfully completed......................................
2023-02-03 15:19:24,126:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:24,126:INFO:Creating metrics dataframe
2023-02-03 15:19:24,142:INFO:Initializing Passive Aggressive Regressor
2023-02-03 15:19:24,142:INFO:Total runtime is 0.05291986068089803 minutes
2023-02-03 15:19:24,146:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:24,148:INFO:Initializing create_model()
2023-02-03 15:19:24,148:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:24,148:INFO:Checking exceptions
2023-02-03 15:19:24,148:INFO:Importing libraries
2023-02-03 15:19:24,148:INFO:Copying training dataset
2023-02-03 15:19:24,151:INFO:Defining folds
2023-02-03 15:19:24,152:INFO:Declaring metric variables
2023-02-03 15:19:24,159:INFO:Importing untrained model
2023-02-03 15:19:24,167:INFO:Passive Aggressive Regressor Imported successfully
2023-02-03 15:19:24,182:INFO:Starting cross validation
2023-02-03 15:19:24,183:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:24,458:INFO:Calculating mean and std
2023-02-03 15:19:24,460:INFO:Creating metrics dataframe
2023-02-03 15:19:24,464:INFO:Uploading results into container
2023-02-03 15:19:24,465:INFO:Uploading model into container now
2023-02-03 15:19:24,465:INFO:_master_model_container: 64
2023-02-03 15:19:24,466:INFO:_display_container: 6
2023-02-03 15:19:24,466:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-03 15:19:24,467:INFO:create_model() successfully completed......................................
2023-02-03 15:19:24,559:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:24,559:INFO:Creating metrics dataframe
2023-02-03 15:19:24,576:INFO:Initializing Huber Regressor
2023-02-03 15:19:24,576:INFO:Total runtime is 0.06016546885172526 minutes
2023-02-03 15:19:24,581:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:24,581:INFO:Initializing create_model()
2023-02-03 15:19:24,582:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:24,582:INFO:Checking exceptions
2023-02-03 15:19:24,582:INFO:Importing libraries
2023-02-03 15:19:24,582:INFO:Copying training dataset
2023-02-03 15:19:24,586:INFO:Defining folds
2023-02-03 15:19:24,587:INFO:Declaring metric variables
2023-02-03 15:19:24,595:INFO:Importing untrained model
2023-02-03 15:19:24,600:INFO:Huber Regressor Imported successfully
2023-02-03 15:19:24,613:INFO:Starting cross validation
2023-02-03 15:19:24,615:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:24,899:INFO:Calculating mean and std
2023-02-03 15:19:24,900:INFO:Creating metrics dataframe
2023-02-03 15:19:24,904:INFO:Uploading results into container
2023-02-03 15:19:24,905:INFO:Uploading model into container now
2023-02-03 15:19:24,907:INFO:_master_model_container: 65
2023-02-03 15:19:24,907:INFO:_display_container: 6
2023-02-03 15:19:24,908:INFO:HuberRegressor()
2023-02-03 15:19:24,908:INFO:create_model() successfully completed......................................
2023-02-03 15:19:24,999:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:24,999:INFO:Creating metrics dataframe
2023-02-03 15:19:25,017:INFO:Initializing K Neighbors Regressor
2023-02-03 15:19:25,017:INFO:Total runtime is 0.06751126448313395 minutes
2023-02-03 15:19:25,022:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:25,023:INFO:Initializing create_model()
2023-02-03 15:19:25,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:25,024:INFO:Checking exceptions
2023-02-03 15:19:25,025:INFO:Importing libraries
2023-02-03 15:19:25,025:INFO:Copying training dataset
2023-02-03 15:19:25,030:INFO:Defining folds
2023-02-03 15:19:25,031:INFO:Declaring metric variables
2023-02-03 15:19:25,038:INFO:Importing untrained model
2023-02-03 15:19:25,045:INFO:K Neighbors Regressor Imported successfully
2023-02-03 15:19:25,064:INFO:Starting cross validation
2023-02-03 15:19:25,065:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:25,428:INFO:Calculating mean and std
2023-02-03 15:19:25,429:INFO:Creating metrics dataframe
2023-02-03 15:19:25,433:INFO:Uploading results into container
2023-02-03 15:19:25,434:INFO:Uploading model into container now
2023-02-03 15:19:25,435:INFO:_master_model_container: 66
2023-02-03 15:19:25,435:INFO:_display_container: 6
2023-02-03 15:19:25,436:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-03 15:19:25,436:INFO:create_model() successfully completed......................................
2023-02-03 15:19:25,524:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:25,524:INFO:Creating metrics dataframe
2023-02-03 15:19:25,542:INFO:Initializing Decision Tree Regressor
2023-02-03 15:19:25,542:INFO:Total runtime is 0.07626235882441203 minutes
2023-02-03 15:19:25,548:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:25,548:INFO:Initializing create_model()
2023-02-03 15:19:25,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:25,549:INFO:Checking exceptions
2023-02-03 15:19:25,549:INFO:Importing libraries
2023-02-03 15:19:25,549:INFO:Copying training dataset
2023-02-03 15:19:25,554:INFO:Defining folds
2023-02-03 15:19:25,554:INFO:Declaring metric variables
2023-02-03 15:19:25,564:INFO:Importing untrained model
2023-02-03 15:19:25,569:INFO:Decision Tree Regressor Imported successfully
2023-02-03 15:19:25,582:INFO:Starting cross validation
2023-02-03 15:19:25,584:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:25,819:INFO:Calculating mean and std
2023-02-03 15:19:25,821:INFO:Creating metrics dataframe
2023-02-03 15:19:25,830:INFO:Uploading results into container
2023-02-03 15:19:25,831:INFO:Uploading model into container now
2023-02-03 15:19:25,832:INFO:_master_model_container: 67
2023-02-03 15:19:25,832:INFO:_display_container: 6
2023-02-03 15:19:25,832:INFO:DecisionTreeRegressor(random_state=123)
2023-02-03 15:19:25,832:INFO:create_model() successfully completed......................................
2023-02-03 15:19:25,915:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:25,915:INFO:Creating metrics dataframe
2023-02-03 15:19:25,932:INFO:Initializing Random Forest Regressor
2023-02-03 15:19:25,932:INFO:Total runtime is 0.08275857766469319 minutes
2023-02-03 15:19:25,939:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:25,939:INFO:Initializing create_model()
2023-02-03 15:19:25,939:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:25,940:INFO:Checking exceptions
2023-02-03 15:19:25,940:INFO:Importing libraries
2023-02-03 15:19:25,940:INFO:Copying training dataset
2023-02-03 15:19:25,945:INFO:Defining folds
2023-02-03 15:19:25,945:INFO:Declaring metric variables
2023-02-03 15:19:25,951:INFO:Importing untrained model
2023-02-03 15:19:25,957:INFO:Random Forest Regressor Imported successfully
2023-02-03 15:19:25,968:INFO:Starting cross validation
2023-02-03 15:19:25,969:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:27,868:INFO:Calculating mean and std
2023-02-03 15:19:27,869:INFO:Creating metrics dataframe
2023-02-03 15:19:27,873:INFO:Uploading results into container
2023-02-03 15:19:27,874:INFO:Uploading model into container now
2023-02-03 15:19:27,874:INFO:_master_model_container: 68
2023-02-03 15:19:27,874:INFO:_display_container: 6
2023-02-03 15:19:27,875:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:19:27,876:INFO:create_model() successfully completed......................................
2023-02-03 15:19:27,980:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:27,980:INFO:Creating metrics dataframe
2023-02-03 15:19:28,003:INFO:Initializing Extra Trees Regressor
2023-02-03 15:19:28,003:INFO:Total runtime is 0.11727210680643717 minutes
2023-02-03 15:19:28,013:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:28,013:INFO:Initializing create_model()
2023-02-03 15:19:28,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:28,014:INFO:Checking exceptions
2023-02-03 15:19:28,014:INFO:Importing libraries
2023-02-03 15:19:28,014:INFO:Copying training dataset
2023-02-03 15:19:28,022:INFO:Defining folds
2023-02-03 15:19:28,022:INFO:Declaring metric variables
2023-02-03 15:19:28,031:INFO:Importing untrained model
2023-02-03 15:19:28,041:INFO:Extra Trees Regressor Imported successfully
2023-02-03 15:19:28,066:INFO:Starting cross validation
2023-02-03 15:19:28,068:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:29,967:INFO:Calculating mean and std
2023-02-03 15:19:29,968:INFO:Creating metrics dataframe
2023-02-03 15:19:29,972:INFO:Uploading results into container
2023-02-03 15:19:29,973:INFO:Uploading model into container now
2023-02-03 15:19:29,973:INFO:_master_model_container: 69
2023-02-03 15:19:29,974:INFO:_display_container: 6
2023-02-03 15:19:29,974:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:19:29,975:INFO:create_model() successfully completed......................................
2023-02-03 15:19:30,060:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:30,061:INFO:Creating metrics dataframe
2023-02-03 15:19:30,077:INFO:Initializing AdaBoost Regressor
2023-02-03 15:19:30,077:INFO:Total runtime is 0.15183955430984497 minutes
2023-02-03 15:19:30,084:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:30,084:INFO:Initializing create_model()
2023-02-03 15:19:30,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:30,085:INFO:Checking exceptions
2023-02-03 15:19:30,085:INFO:Importing libraries
2023-02-03 15:19:30,085:INFO:Copying training dataset
2023-02-03 15:19:30,089:INFO:Defining folds
2023-02-03 15:19:30,089:INFO:Declaring metric variables
2023-02-03 15:19:30,095:INFO:Importing untrained model
2023-02-03 15:19:30,102:INFO:AdaBoost Regressor Imported successfully
2023-02-03 15:19:30,112:INFO:Starting cross validation
2023-02-03 15:19:30,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:30,786:INFO:Calculating mean and std
2023-02-03 15:19:30,788:INFO:Creating metrics dataframe
2023-02-03 15:19:30,792:INFO:Uploading results into container
2023-02-03 15:19:30,793:INFO:Uploading model into container now
2023-02-03 15:19:30,793:INFO:_master_model_container: 70
2023-02-03 15:19:30,794:INFO:_display_container: 6
2023-02-03 15:19:30,795:INFO:AdaBoostRegressor(random_state=123)
2023-02-03 15:19:30,796:INFO:create_model() successfully completed......................................
2023-02-03 15:19:30,887:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:30,888:INFO:Creating metrics dataframe
2023-02-03 15:19:30,905:INFO:Initializing Gradient Boosting Regressor
2023-02-03 15:19:30,906:INFO:Total runtime is 0.16566501458485922 minutes
2023-02-03 15:19:30,913:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:30,913:INFO:Initializing create_model()
2023-02-03 15:19:30,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:30,914:INFO:Checking exceptions
2023-02-03 15:19:30,914:INFO:Importing libraries
2023-02-03 15:19:30,914:INFO:Copying training dataset
2023-02-03 15:19:30,919:INFO:Defining folds
2023-02-03 15:19:30,919:INFO:Declaring metric variables
2023-02-03 15:19:30,926:INFO:Importing untrained model
2023-02-03 15:19:30,932:INFO:Gradient Boosting Regressor Imported successfully
2023-02-03 15:19:30,945:INFO:Starting cross validation
2023-02-03 15:19:30,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:31,714:INFO:Calculating mean and std
2023-02-03 15:19:31,717:INFO:Creating metrics dataframe
2023-02-03 15:19:31,722:INFO:Uploading results into container
2023-02-03 15:19:31,724:INFO:Uploading model into container now
2023-02-03 15:19:31,725:INFO:_master_model_container: 71
2023-02-03 15:19:31,726:INFO:_display_container: 6
2023-02-03 15:19:31,727:INFO:GradientBoostingRegressor(random_state=123)
2023-02-03 15:19:31,727:INFO:create_model() successfully completed......................................
2023-02-03 15:19:31,842:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:31,842:INFO:Creating metrics dataframe
2023-02-03 15:19:31,874:INFO:Initializing Light Gradient Boosting Machine
2023-02-03 15:19:31,874:INFO:Total runtime is 0.18178909619649253 minutes
2023-02-03 15:19:31,884:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:31,885:INFO:Initializing create_model()
2023-02-03 15:19:31,885:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:31,885:INFO:Checking exceptions
2023-02-03 15:19:31,885:INFO:Importing libraries
2023-02-03 15:19:31,885:INFO:Copying training dataset
2023-02-03 15:19:31,899:INFO:Defining folds
2023-02-03 15:19:31,899:INFO:Declaring metric variables
2023-02-03 15:19:31,910:INFO:Importing untrained model
2023-02-03 15:19:31,923:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-03 15:19:31,944:INFO:Starting cross validation
2023-02-03 15:19:31,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:39,600:INFO:Calculating mean and std
2023-02-03 15:19:39,605:INFO:Creating metrics dataframe
2023-02-03 15:19:39,612:INFO:Uploading results into container
2023-02-03 15:19:39,613:INFO:Uploading model into container now
2023-02-03 15:19:39,613:INFO:_master_model_container: 72
2023-02-03 15:19:39,613:INFO:_display_container: 6
2023-02-03 15:19:39,614:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-02-03 15:19:39,615:INFO:create_model() successfully completed......................................
2023-02-03 15:19:39,726:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:39,726:INFO:Creating metrics dataframe
2023-02-03 15:19:39,746:INFO:Initializing Dummy Regressor
2023-02-03 15:19:39,747:INFO:Total runtime is 0.3130154967308044 minutes
2023-02-03 15:19:39,752:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:39,752:INFO:Initializing create_model()
2023-02-03 15:19:39,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:39,753:INFO:Checking exceptions
2023-02-03 15:19:39,753:INFO:Importing libraries
2023-02-03 15:19:39,754:INFO:Copying training dataset
2023-02-03 15:19:39,759:INFO:Defining folds
2023-02-03 15:19:39,760:INFO:Declaring metric variables
2023-02-03 15:19:39,766:INFO:Importing untrained model
2023-02-03 15:19:39,773:INFO:Dummy Regressor Imported successfully
2023-02-03 15:19:39,786:INFO:Starting cross validation
2023-02-03 15:19:39,787:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:40,024:INFO:Calculating mean and std
2023-02-03 15:19:40,025:INFO:Creating metrics dataframe
2023-02-03 15:19:40,029:INFO:Uploading results into container
2023-02-03 15:19:40,030:INFO:Uploading model into container now
2023-02-03 15:19:40,030:INFO:_master_model_container: 73
2023-02-03 15:19:40,031:INFO:_display_container: 6
2023-02-03 15:19:40,031:INFO:DummyRegressor()
2023-02-03 15:19:40,031:INFO:create_model() successfully completed......................................
2023-02-03 15:19:40,129:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:40,130:INFO:Creating metrics dataframe
2023-02-03 15:19:40,164:INFO:Initializing create_model()
2023-02-03 15:19:40,164:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:40,164:INFO:Checking exceptions
2023-02-03 15:19:40,167:INFO:Importing libraries
2023-02-03 15:19:40,167:INFO:Copying training dataset
2023-02-03 15:19:40,173:INFO:Defining folds
2023-02-03 15:19:40,173:INFO:Declaring metric variables
2023-02-03 15:19:40,174:INFO:Importing untrained model
2023-02-03 15:19:40,174:INFO:Declaring custom model
2023-02-03 15:19:40,174:INFO:Linear Regression Imported successfully
2023-02-03 15:19:40,175:INFO:Cross validation set to False
2023-02-03 15:19:40,175:INFO:Fitting Model
2023-02-03 15:19:40,187:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:19:40,187:INFO:create_model() successfully completed......................................
2023-02-03 15:19:40,362:INFO:_master_model_container: 73
2023-02-03 15:19:40,362:INFO:_display_container: 6
2023-02-03 15:19:40,363:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:19:40,363:INFO:compare_models() successfully completed......................................
2023-02-03 15:19:48,854:INFO:Initializing compare_models()
2023-02-03 15:19:48,855:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, include=None, fold=None, round=4, cross_validation=True, sort=r2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'r2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-03 15:19:48,855:INFO:Checking exceptions
2023-02-03 15:19:48,859:INFO:Preparing display monitor
2023-02-03 15:19:48,912:INFO:Initializing Linear Regression
2023-02-03 15:19:48,912:INFO:Total runtime is 0.0 minutes
2023-02-03 15:19:48,920:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:48,921:INFO:Initializing create_model()
2023-02-03 15:19:48,921:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:48,921:INFO:Checking exceptions
2023-02-03 15:19:48,922:INFO:Importing libraries
2023-02-03 15:19:48,922:INFO:Copying training dataset
2023-02-03 15:19:48,929:INFO:Defining folds
2023-02-03 15:19:48,930:INFO:Declaring metric variables
2023-02-03 15:19:48,939:INFO:Importing untrained model
2023-02-03 15:19:48,950:INFO:Linear Regression Imported successfully
2023-02-03 15:19:48,967:INFO:Starting cross validation
2023-02-03 15:19:48,969:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:49,359:INFO:Calculating mean and std
2023-02-03 15:19:49,359:INFO:Creating metrics dataframe
2023-02-03 15:19:49,364:INFO:Uploading results into container
2023-02-03 15:19:49,366:INFO:Uploading model into container now
2023-02-03 15:19:49,367:INFO:_master_model_container: 74
2023-02-03 15:19:49,367:INFO:_display_container: 7
2023-02-03 15:19:49,367:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:19:49,367:INFO:create_model() successfully completed......................................
2023-02-03 15:19:49,452:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:49,452:INFO:Creating metrics dataframe
2023-02-03 15:19:49,463:INFO:Initializing Lasso Regression
2023-02-03 15:19:49,463:INFO:Total runtime is 0.00917805035909017 minutes
2023-02-03 15:19:49,468:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:49,469:INFO:Initializing create_model()
2023-02-03 15:19:49,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:49,470:INFO:Checking exceptions
2023-02-03 15:19:49,470:INFO:Importing libraries
2023-02-03 15:19:49,470:INFO:Copying training dataset
2023-02-03 15:19:49,474:INFO:Defining folds
2023-02-03 15:19:49,474:INFO:Declaring metric variables
2023-02-03 15:19:49,479:INFO:Importing untrained model
2023-02-03 15:19:49,484:INFO:Lasso Regression Imported successfully
2023-02-03 15:19:49,495:INFO:Starting cross validation
2023-02-03 15:19:49,497:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:49,524:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.653e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,559:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.713e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,584:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.832e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,605:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,631:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.826e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,660:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,683:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,705:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,726:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,748:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.356e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,757:INFO:Calculating mean and std
2023-02-03 15:19:49,758:INFO:Creating metrics dataframe
2023-02-03 15:19:49,761:INFO:Uploading results into container
2023-02-03 15:19:49,762:INFO:Uploading model into container now
2023-02-03 15:19:49,763:INFO:_master_model_container: 75
2023-02-03 15:19:49,763:INFO:_display_container: 7
2023-02-03 15:19:49,763:INFO:Lasso(random_state=123)
2023-02-03 15:19:49,763:INFO:create_model() successfully completed......................................
2023-02-03 15:19:49,877:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:49,877:INFO:Creating metrics dataframe
2023-02-03 15:19:49,906:INFO:Initializing Ridge Regression
2023-02-03 15:19:49,907:INFO:Total runtime is 0.016573814551035564 minutes
2023-02-03 15:19:49,920:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:49,922:INFO:Initializing create_model()
2023-02-03 15:19:49,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:49,922:INFO:Checking exceptions
2023-02-03 15:19:49,922:INFO:Importing libraries
2023-02-03 15:19:49,922:INFO:Copying training dataset
2023-02-03 15:19:49,928:INFO:Defining folds
2023-02-03 15:19:49,928:INFO:Declaring metric variables
2023-02-03 15:19:49,941:INFO:Importing untrained model
2023-02-03 15:19:49,953:INFO:Ridge Regression Imported successfully
2023-02-03 15:19:49,988:INFO:Starting cross validation
2023-02-03 15:19:49,990:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:50,256:INFO:Calculating mean and std
2023-02-03 15:19:50,258:INFO:Creating metrics dataframe
2023-02-03 15:19:50,262:INFO:Uploading results into container
2023-02-03 15:19:50,263:INFO:Uploading model into container now
2023-02-03 15:19:50,265:INFO:_master_model_container: 76
2023-02-03 15:19:50,266:INFO:_display_container: 7
2023-02-03 15:19:50,267:INFO:Ridge(random_state=123)
2023-02-03 15:19:50,267:INFO:create_model() successfully completed......................................
2023-02-03 15:19:50,362:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:50,362:INFO:Creating metrics dataframe
2023-02-03 15:19:50,376:INFO:Initializing Elastic Net
2023-02-03 15:19:50,376:INFO:Total runtime is 0.02440266211827596 minutes
2023-02-03 15:19:50,384:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:50,384:INFO:Initializing create_model()
2023-02-03 15:19:50,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:50,385:INFO:Checking exceptions
2023-02-03 15:19:50,385:INFO:Importing libraries
2023-02-03 15:19:50,385:INFO:Copying training dataset
2023-02-03 15:19:50,390:INFO:Defining folds
2023-02-03 15:19:50,390:INFO:Declaring metric variables
2023-02-03 15:19:50,396:INFO:Importing untrained model
2023-02-03 15:19:50,403:INFO:Elastic Net Imported successfully
2023-02-03 15:19:50,417:INFO:Starting cross validation
2023-02-03 15:19:50,418:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:50,441:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,478:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.982e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,503:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,526:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,548:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.646e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,571:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.039e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,593:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.999e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,616:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,637:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.979e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,668:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,682:INFO:Calculating mean and std
2023-02-03 15:19:50,684:INFO:Creating metrics dataframe
2023-02-03 15:19:50,688:INFO:Uploading results into container
2023-02-03 15:19:50,689:INFO:Uploading model into container now
2023-02-03 15:19:50,690:INFO:_master_model_container: 77
2023-02-03 15:19:50,691:INFO:_display_container: 7
2023-02-03 15:19:50,691:INFO:ElasticNet(random_state=123)
2023-02-03 15:19:50,692:INFO:create_model() successfully completed......................................
2023-02-03 15:19:50,777:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:50,777:INFO:Creating metrics dataframe
2023-02-03 15:19:50,790:INFO:Initializing Least Angle Regression
2023-02-03 15:19:50,790:INFO:Total runtime is 0.03129870494206746 minutes
2023-02-03 15:19:50,794:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:50,795:INFO:Initializing create_model()
2023-02-03 15:19:50,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:50,795:INFO:Checking exceptions
2023-02-03 15:19:50,796:INFO:Importing libraries
2023-02-03 15:19:50,796:INFO:Copying training dataset
2023-02-03 15:19:50,801:INFO:Defining folds
2023-02-03 15:19:50,802:INFO:Declaring metric variables
2023-02-03 15:19:50,810:INFO:Importing untrained model
2023-02-03 15:19:50,822:INFO:Least Angle Regression Imported successfully
2023-02-03 15:19:50,833:INFO:Starting cross validation
2023-02-03 15:19:50,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:50,857:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:50,888:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:50,922:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:50,947:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:50,978:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,001:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,023:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,043:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,067:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,090:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,104:INFO:Calculating mean and std
2023-02-03 15:19:51,105:INFO:Creating metrics dataframe
2023-02-03 15:19:51,110:INFO:Uploading results into container
2023-02-03 15:19:51,110:INFO:Uploading model into container now
2023-02-03 15:19:51,111:INFO:_master_model_container: 78
2023-02-03 15:19:51,111:INFO:_display_container: 7
2023-02-03 15:19:51,112:INFO:Lars(random_state=123)
2023-02-03 15:19:51,112:INFO:create_model() successfully completed......................................
2023-02-03 15:19:51,196:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:51,196:INFO:Creating metrics dataframe
2023-02-03 15:19:51,211:INFO:Initializing Lasso Least Angle Regression
2023-02-03 15:19:51,211:INFO:Total runtime is 0.03831135829289754 minutes
2023-02-03 15:19:51,219:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:51,220:INFO:Initializing create_model()
2023-02-03 15:19:51,220:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:51,220:INFO:Checking exceptions
2023-02-03 15:19:51,220:INFO:Importing libraries
2023-02-03 15:19:51,220:INFO:Copying training dataset
2023-02-03 15:19:51,226:INFO:Defining folds
2023-02-03 15:19:51,226:INFO:Declaring metric variables
2023-02-03 15:19:51,235:INFO:Importing untrained model
2023-02-03 15:19:51,244:INFO:Lasso Least Angle Regression Imported successfully
2023-02-03 15:19:51,263:INFO:Starting cross validation
2023-02-03 15:19:51,264:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:51,289:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,320:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,345:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,371:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,407:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,429:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,455:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,478:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,502:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,526:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,538:INFO:Calculating mean and std
2023-02-03 15:19:51,539:INFO:Creating metrics dataframe
2023-02-03 15:19:51,545:INFO:Uploading results into container
2023-02-03 15:19:51,546:INFO:Uploading model into container now
2023-02-03 15:19:51,547:INFO:_master_model_container: 79
2023-02-03 15:19:51,547:INFO:_display_container: 7
2023-02-03 15:19:51,547:INFO:LassoLars(random_state=123)
2023-02-03 15:19:51,547:INFO:create_model() successfully completed......................................
2023-02-03 15:19:51,644:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:51,645:INFO:Creating metrics dataframe
2023-02-03 15:19:51,660:INFO:Initializing Orthogonal Matching Pursuit
2023-02-03 15:19:51,660:INFO:Total runtime is 0.045790394147237144 minutes
2023-02-03 15:19:51,665:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:51,665:INFO:Initializing create_model()
2023-02-03 15:19:51,666:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:51,666:INFO:Checking exceptions
2023-02-03 15:19:51,666:INFO:Importing libraries
2023-02-03 15:19:51,667:INFO:Copying training dataset
2023-02-03 15:19:51,673:INFO:Defining folds
2023-02-03 15:19:51,673:INFO:Declaring metric variables
2023-02-03 15:19:51,682:INFO:Importing untrained model
2023-02-03 15:19:51,690:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-03 15:19:51,709:INFO:Starting cross validation
2023-02-03 15:19:51,710:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:51,730:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,764:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,791:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,818:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,842:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,869:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,896:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,922:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,951:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,975:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,987:INFO:Calculating mean and std
2023-02-03 15:19:51,989:INFO:Creating metrics dataframe
2023-02-03 15:19:51,993:INFO:Uploading results into container
2023-02-03 15:19:51,994:INFO:Uploading model into container now
2023-02-03 15:19:51,994:INFO:_master_model_container: 80
2023-02-03 15:19:51,994:INFO:_display_container: 7
2023-02-03 15:19:51,995:INFO:OrthogonalMatchingPursuit()
2023-02-03 15:19:51,995:INFO:create_model() successfully completed......................................
2023-02-03 15:19:52,097:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:52,097:INFO:Creating metrics dataframe
2023-02-03 15:19:52,114:INFO:Initializing Bayesian Ridge
2023-02-03 15:19:52,114:INFO:Total runtime is 0.05336937904357911 minutes
2023-02-03 15:19:52,123:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:52,124:INFO:Initializing create_model()
2023-02-03 15:19:52,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:52,124:INFO:Checking exceptions
2023-02-03 15:19:52,125:INFO:Importing libraries
2023-02-03 15:19:52,125:INFO:Copying training dataset
2023-02-03 15:19:52,129:INFO:Defining folds
2023-02-03 15:19:52,130:INFO:Declaring metric variables
2023-02-03 15:19:52,137:INFO:Importing untrained model
2023-02-03 15:19:52,142:INFO:Bayesian Ridge Imported successfully
2023-02-03 15:19:52,158:INFO:Starting cross validation
2023-02-03 15:19:52,160:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:52,409:INFO:Calculating mean and std
2023-02-03 15:19:52,410:INFO:Creating metrics dataframe
2023-02-03 15:19:52,414:INFO:Uploading results into container
2023-02-03 15:19:52,415:INFO:Uploading model into container now
2023-02-03 15:19:52,415:INFO:_master_model_container: 81
2023-02-03 15:19:52,416:INFO:_display_container: 7
2023-02-03 15:19:52,417:INFO:BayesianRidge()
2023-02-03 15:19:52,417:INFO:create_model() successfully completed......................................
2023-02-03 15:19:52,508:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:52,508:INFO:Creating metrics dataframe
2023-02-03 15:19:52,527:INFO:Initializing Passive Aggressive Regressor
2023-02-03 15:19:52,527:INFO:Total runtime is 0.06024888753890992 minutes
2023-02-03 15:19:52,534:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:52,535:INFO:Initializing create_model()
2023-02-03 15:19:52,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:52,536:INFO:Checking exceptions
2023-02-03 15:19:52,536:INFO:Importing libraries
2023-02-03 15:19:52,536:INFO:Copying training dataset
2023-02-03 15:19:52,543:INFO:Defining folds
2023-02-03 15:19:52,543:INFO:Declaring metric variables
2023-02-03 15:19:52,554:INFO:Importing untrained model
2023-02-03 15:19:52,560:INFO:Passive Aggressive Regressor Imported successfully
2023-02-03 15:19:52,575:INFO:Starting cross validation
2023-02-03 15:19:52,576:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:52,910:INFO:Calculating mean and std
2023-02-03 15:19:52,912:INFO:Creating metrics dataframe
2023-02-03 15:19:52,916:INFO:Uploading results into container
2023-02-03 15:19:52,917:INFO:Uploading model into container now
2023-02-03 15:19:52,919:INFO:_master_model_container: 82
2023-02-03 15:19:52,919:INFO:_display_container: 7
2023-02-03 15:19:52,920:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-03 15:19:52,921:INFO:create_model() successfully completed......................................
2023-02-03 15:19:53,027:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:53,027:INFO:Creating metrics dataframe
2023-02-03 15:19:53,048:INFO:Initializing Huber Regressor
2023-02-03 15:19:53,048:INFO:Total runtime is 0.0689271132151286 minutes
2023-02-03 15:19:53,057:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:53,057:INFO:Initializing create_model()
2023-02-03 15:19:53,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:53,057:INFO:Checking exceptions
2023-02-03 15:19:53,057:INFO:Importing libraries
2023-02-03 15:19:53,057:INFO:Copying training dataset
2023-02-03 15:19:53,062:INFO:Defining folds
2023-02-03 15:19:53,062:INFO:Declaring metric variables
2023-02-03 15:19:53,070:INFO:Importing untrained model
2023-02-03 15:19:53,075:INFO:Huber Regressor Imported successfully
2023-02-03 15:19:53,092:INFO:Starting cross validation
2023-02-03 15:19:53,094:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:53,444:INFO:Calculating mean and std
2023-02-03 15:19:53,445:INFO:Creating metrics dataframe
2023-02-03 15:19:53,449:INFO:Uploading results into container
2023-02-03 15:19:53,450:INFO:Uploading model into container now
2023-02-03 15:19:53,450:INFO:_master_model_container: 83
2023-02-03 15:19:53,450:INFO:_display_container: 7
2023-02-03 15:19:53,454:INFO:HuberRegressor()
2023-02-03 15:19:53,455:INFO:create_model() successfully completed......................................
2023-02-03 15:19:53,566:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:53,566:INFO:Creating metrics dataframe
2023-02-03 15:19:53,588:INFO:Initializing K Neighbors Regressor
2023-02-03 15:19:53,588:INFO:Total runtime is 0.07793862422307334 minutes
2023-02-03 15:19:53,593:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:53,594:INFO:Initializing create_model()
2023-02-03 15:19:53,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:53,594:INFO:Checking exceptions
2023-02-03 15:19:53,594:INFO:Importing libraries
2023-02-03 15:19:53,595:INFO:Copying training dataset
2023-02-03 15:19:53,598:INFO:Defining folds
2023-02-03 15:19:53,598:INFO:Declaring metric variables
2023-02-03 15:19:53,607:INFO:Importing untrained model
2023-02-03 15:19:53,613:INFO:K Neighbors Regressor Imported successfully
2023-02-03 15:19:53,630:INFO:Starting cross validation
2023-02-03 15:19:53,632:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:54,042:INFO:Calculating mean and std
2023-02-03 15:19:54,044:INFO:Creating metrics dataframe
2023-02-03 15:19:54,048:INFO:Uploading results into container
2023-02-03 15:19:54,049:INFO:Uploading model into container now
2023-02-03 15:19:54,050:INFO:_master_model_container: 84
2023-02-03 15:19:54,050:INFO:_display_container: 7
2023-02-03 15:19:54,050:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-03 15:19:54,050:INFO:create_model() successfully completed......................................
2023-02-03 15:19:54,146:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:54,146:INFO:Creating metrics dataframe
2023-02-03 15:19:54,165:INFO:Initializing Decision Tree Regressor
2023-02-03 15:19:54,165:INFO:Total runtime is 0.08754975398381552 minutes
2023-02-03 15:19:54,175:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:54,175:INFO:Initializing create_model()
2023-02-03 15:19:54,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:54,176:INFO:Checking exceptions
2023-02-03 15:19:54,176:INFO:Importing libraries
2023-02-03 15:19:54,176:INFO:Copying training dataset
2023-02-03 15:19:54,180:INFO:Defining folds
2023-02-03 15:19:54,180:INFO:Declaring metric variables
2023-02-03 15:19:54,190:INFO:Importing untrained model
2023-02-03 15:19:54,198:INFO:Decision Tree Regressor Imported successfully
2023-02-03 15:19:54,213:INFO:Starting cross validation
2023-02-03 15:19:54,214:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:54,458:INFO:Calculating mean and std
2023-02-03 15:19:54,460:INFO:Creating metrics dataframe
2023-02-03 15:19:54,464:INFO:Uploading results into container
2023-02-03 15:19:54,465:INFO:Uploading model into container now
2023-02-03 15:19:54,466:INFO:_master_model_container: 85
2023-02-03 15:19:54,466:INFO:_display_container: 7
2023-02-03 15:19:54,467:INFO:DecisionTreeRegressor(random_state=123)
2023-02-03 15:19:54,467:INFO:create_model() successfully completed......................................
2023-02-03 15:19:54,548:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:54,548:INFO:Creating metrics dataframe
2023-02-03 15:19:54,567:INFO:Initializing Random Forest Regressor
2023-02-03 15:19:54,567:INFO:Total runtime is 0.09424591461817425 minutes
2023-02-03 15:19:54,573:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:54,574:INFO:Initializing create_model()
2023-02-03 15:19:54,574:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:54,574:INFO:Checking exceptions
2023-02-03 15:19:54,575:INFO:Importing libraries
2023-02-03 15:19:54,575:INFO:Copying training dataset
2023-02-03 15:19:54,578:INFO:Defining folds
2023-02-03 15:19:54,579:INFO:Declaring metric variables
2023-02-03 15:19:54,586:INFO:Importing untrained model
2023-02-03 15:19:54,591:INFO:Random Forest Regressor Imported successfully
2023-02-03 15:19:54,608:INFO:Starting cross validation
2023-02-03 15:19:54,610:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:56,918:INFO:Calculating mean and std
2023-02-03 15:19:56,920:INFO:Creating metrics dataframe
2023-02-03 15:19:56,927:INFO:Uploading results into container
2023-02-03 15:19:56,928:INFO:Uploading model into container now
2023-02-03 15:19:56,929:INFO:_master_model_container: 86
2023-02-03 15:19:56,929:INFO:_display_container: 7
2023-02-03 15:19:56,929:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:19:56,930:INFO:create_model() successfully completed......................................
2023-02-03 15:19:57,024:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:57,024:INFO:Creating metrics dataframe
2023-02-03 15:19:57,043:INFO:Initializing Extra Trees Regressor
2023-02-03 15:19:57,043:INFO:Total runtime is 0.13552223443984987 minutes
2023-02-03 15:19:57,048:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:57,048:INFO:Initializing create_model()
2023-02-03 15:19:57,049:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:57,049:INFO:Checking exceptions
2023-02-03 15:19:57,049:INFO:Importing libraries
2023-02-03 15:19:57,049:INFO:Copying training dataset
2023-02-03 15:19:57,053:INFO:Defining folds
2023-02-03 15:19:57,053:INFO:Declaring metric variables
2023-02-03 15:19:57,062:INFO:Importing untrained model
2023-02-03 15:19:57,067:INFO:Extra Trees Regressor Imported successfully
2023-02-03 15:19:57,081:INFO:Starting cross validation
2023-02-03 15:19:57,082:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:59,041:INFO:Calculating mean and std
2023-02-03 15:19:59,043:INFO:Creating metrics dataframe
2023-02-03 15:19:59,046:INFO:Uploading results into container
2023-02-03 15:19:59,047:INFO:Uploading model into container now
2023-02-03 15:19:59,047:INFO:_master_model_container: 87
2023-02-03 15:19:59,048:INFO:_display_container: 7
2023-02-03 15:19:59,048:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:19:59,048:INFO:create_model() successfully completed......................................
2023-02-03 15:19:59,132:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:59,132:INFO:Creating metrics dataframe
2023-02-03 15:19:59,150:INFO:Initializing AdaBoost Regressor
2023-02-03 15:19:59,150:INFO:Total runtime is 0.1706383268038432 minutes
2023-02-03 15:19:59,155:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:59,155:INFO:Initializing create_model()
2023-02-03 15:19:59,156:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:59,156:INFO:Checking exceptions
2023-02-03 15:19:59,157:INFO:Importing libraries
2023-02-03 15:19:59,157:INFO:Copying training dataset
2023-02-03 15:19:59,161:INFO:Defining folds
2023-02-03 15:19:59,161:INFO:Declaring metric variables
2023-02-03 15:19:59,166:INFO:Importing untrained model
2023-02-03 15:19:59,171:INFO:AdaBoost Regressor Imported successfully
2023-02-03 15:19:59,184:INFO:Starting cross validation
2023-02-03 15:19:59,185:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:59,852:INFO:Calculating mean and std
2023-02-03 15:19:59,853:INFO:Creating metrics dataframe
2023-02-03 15:19:59,860:INFO:Uploading results into container
2023-02-03 15:19:59,860:INFO:Uploading model into container now
2023-02-03 15:19:59,861:INFO:_master_model_container: 88
2023-02-03 15:19:59,862:INFO:_display_container: 7
2023-02-03 15:19:59,862:INFO:AdaBoostRegressor(random_state=123)
2023-02-03 15:19:59,862:INFO:create_model() successfully completed......................................
2023-02-03 15:19:59,955:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:59,955:INFO:Creating metrics dataframe
2023-02-03 15:19:59,972:INFO:Initializing Gradient Boosting Regressor
2023-02-03 15:19:59,973:INFO:Total runtime is 0.18434717257817587 minutes
2023-02-03 15:19:59,981:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:59,982:INFO:Initializing create_model()
2023-02-03 15:19:59,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:59,983:INFO:Checking exceptions
2023-02-03 15:19:59,983:INFO:Importing libraries
2023-02-03 15:19:59,983:INFO:Copying training dataset
2023-02-03 15:19:59,987:INFO:Defining folds
2023-02-03 15:19:59,987:INFO:Declaring metric variables
2023-02-03 15:19:59,994:INFO:Importing untrained model
2023-02-03 15:19:59,999:INFO:Gradient Boosting Regressor Imported successfully
2023-02-03 15:20:00,011:INFO:Starting cross validation
2023-02-03 15:20:00,014:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:20:00,806:INFO:Calculating mean and std
2023-02-03 15:20:00,810:INFO:Creating metrics dataframe
2023-02-03 15:20:00,816:INFO:Uploading results into container
2023-02-03 15:20:00,817:INFO:Uploading model into container now
2023-02-03 15:20:00,817:INFO:_master_model_container: 89
2023-02-03 15:20:00,817:INFO:_display_container: 7
2023-02-03 15:20:00,818:INFO:GradientBoostingRegressor(random_state=123)
2023-02-03 15:20:00,818:INFO:create_model() successfully completed......................................
2023-02-03 15:20:00,919:INFO:SubProcess create_model() end ==================================
2023-02-03 15:20:00,919:INFO:Creating metrics dataframe
2023-02-03 15:20:00,941:INFO:Initializing Light Gradient Boosting Machine
2023-02-03 15:20:00,942:INFO:Total runtime is 0.20050466060638428 minutes
2023-02-03 15:20:00,949:INFO:SubProcess create_model() called ==================================
2023-02-03 15:20:00,950:INFO:Initializing create_model()
2023-02-03 15:20:00,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:20:00,951:INFO:Checking exceptions
2023-02-03 15:20:00,951:INFO:Importing libraries
2023-02-03 15:20:00,951:INFO:Copying training dataset
2023-02-03 15:20:00,955:INFO:Defining folds
2023-02-03 15:20:00,955:INFO:Declaring metric variables
2023-02-03 15:20:00,965:INFO:Importing untrained model
2023-02-03 15:20:00,971:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-03 15:20:00,987:INFO:Starting cross validation
2023-02-03 15:20:00,988:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:20:08,856:INFO:Calculating mean and std
2023-02-03 15:20:08,857:INFO:Creating metrics dataframe
2023-02-03 15:20:08,868:INFO:Uploading results into container
2023-02-03 15:20:08,870:INFO:Uploading model into container now
2023-02-03 15:20:08,871:INFO:_master_model_container: 90
2023-02-03 15:20:08,871:INFO:_display_container: 7
2023-02-03 15:20:08,872:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-02-03 15:20:08,872:INFO:create_model() successfully completed......................................
2023-02-03 15:20:09,012:INFO:SubProcess create_model() end ==================================
2023-02-03 15:20:09,012:INFO:Creating metrics dataframe
2023-02-03 15:20:09,035:INFO:Initializing Dummy Regressor
2023-02-03 15:20:09,036:INFO:Total runtime is 0.33540481328964233 minutes
2023-02-03 15:20:09,041:INFO:SubProcess create_model() called ==================================
2023-02-03 15:20:09,041:INFO:Initializing create_model()
2023-02-03 15:20:09,041:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:20:09,041:INFO:Checking exceptions
2023-02-03 15:20:09,042:INFO:Importing libraries
2023-02-03 15:20:09,042:INFO:Copying training dataset
2023-02-03 15:20:09,047:INFO:Defining folds
2023-02-03 15:20:09,047:INFO:Declaring metric variables
2023-02-03 15:20:09,055:INFO:Importing untrained model
2023-02-03 15:20:09,061:INFO:Dummy Regressor Imported successfully
2023-02-03 15:20:09,075:INFO:Starting cross validation
2023-02-03 15:20:09,076:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:20:09,329:INFO:Calculating mean and std
2023-02-03 15:20:09,330:INFO:Creating metrics dataframe
2023-02-03 15:20:09,338:INFO:Uploading results into container
2023-02-03 15:20:09,339:INFO:Uploading model into container now
2023-02-03 15:20:09,340:INFO:_master_model_container: 91
2023-02-03 15:20:09,340:INFO:_display_container: 7
2023-02-03 15:20:09,340:INFO:DummyRegressor()
2023-02-03 15:20:09,341:INFO:create_model() successfully completed......................................
2023-02-03 15:20:09,430:INFO:SubProcess create_model() end ==================================
2023-02-03 15:20:09,430:INFO:Creating metrics dataframe
2023-02-03 15:20:09,464:INFO:Initializing create_model()
2023-02-03 15:20:09,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:20:09,465:INFO:Checking exceptions
2023-02-03 15:20:09,470:INFO:Importing libraries
2023-02-03 15:20:09,471:INFO:Copying training dataset
2023-02-03 15:20:09,474:INFO:Defining folds
2023-02-03 15:20:09,474:INFO:Declaring metric variables
2023-02-03 15:20:09,474:INFO:Importing untrained model
2023-02-03 15:20:09,474:INFO:Declaring custom model
2023-02-03 15:20:09,475:INFO:Linear Regression Imported successfully
2023-02-03 15:20:09,475:INFO:Cross validation set to False
2023-02-03 15:20:09,475:INFO:Fitting Model
2023-02-03 15:20:09,491:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:20:09,491:INFO:create_model() successfully completed......................................
2023-02-03 15:20:09,656:INFO:_master_model_container: 91
2023-02-03 15:20:09,656:INFO:_display_container: 7
2023-02-03 15:20:09,656:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:20:09,656:INFO:compare_models() successfully completed......................................
2023-02-03 15:20:26,315:INFO:Initializing create_model()
2023-02-03 15:20:26,316:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:20:26,316:INFO:Checking exceptions
2023-02-03 15:20:26,347:INFO:Importing libraries
2023-02-03 15:20:26,348:INFO:Copying training dataset
2023-02-03 15:20:26,357:INFO:Defining folds
2023-02-03 15:20:26,358:INFO:Declaring metric variables
2023-02-03 15:20:26,365:INFO:Importing untrained model
2023-02-03 15:20:26,365:INFO:Declaring custom model
2023-02-03 15:20:26,374:INFO:Linear Regression Imported successfully
2023-02-03 15:20:26,388:INFO:Starting cross validation
2023-02-03 15:20:26,390:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:20:26,678:INFO:Calculating mean and std
2023-02-03 15:20:26,679:INFO:Creating metrics dataframe
2023-02-03 15:20:26,685:INFO:Finalizing model
2023-02-03 15:20:26,709:INFO:Uploading results into container
2023-02-03 15:20:26,710:INFO:Uploading model into container now
2023-02-03 15:20:26,726:INFO:_master_model_container: 92
2023-02-03 15:20:26,726:INFO:_display_container: 8
2023-02-03 15:20:26,726:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:20:26,727:INFO:create_model() successfully completed......................................
2023-02-03 15:22:19,811:INFO:Initializing create_model()
2023-02-03 15:22:19,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:19,811:INFO:Checking exceptions
2023-02-03 15:22:19,849:INFO:Importing libraries
2023-02-03 15:22:19,850:INFO:Copying training dataset
2023-02-03 15:22:19,862:INFO:Defining folds
2023-02-03 15:22:19,863:INFO:Declaring metric variables
2023-02-03 15:22:19,871:INFO:Importing untrained model
2023-02-03 15:22:19,881:INFO:Huber Regressor Imported successfully
2023-02-03 15:22:19,898:INFO:Starting cross validation
2023-02-03 15:22:19,899:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:20,335:INFO:Calculating mean and std
2023-02-03 15:22:20,335:INFO:Creating metrics dataframe
2023-02-03 15:22:20,344:INFO:Finalizing model
2023-02-03 15:22:20,370:INFO:Uploading results into container
2023-02-03 15:22:20,372:INFO:Uploading model into container now
2023-02-03 15:22:20,390:INFO:_master_model_container: 93
2023-02-03 15:22:20,390:INFO:_display_container: 9
2023-02-03 15:22:20,391:INFO:HuberRegressor()
2023-02-03 15:22:20,391:INFO:create_model() successfully completed......................................
2023-02-03 15:22:38,501:INFO:Initializing compare_models()
2023-02-03 15:22:38,502:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-03 15:22:38,502:INFO:Checking exceptions
2023-02-03 15:22:38,506:INFO:Preparing display monitor
2023-02-03 15:22:38,560:INFO:Initializing Linear Regression
2023-02-03 15:22:38,560:INFO:Total runtime is 0.0 minutes
2023-02-03 15:22:38,569:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:38,570:INFO:Initializing create_model()
2023-02-03 15:22:38,571:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:38,571:INFO:Checking exceptions
2023-02-03 15:22:38,572:INFO:Importing libraries
2023-02-03 15:22:38,572:INFO:Copying training dataset
2023-02-03 15:22:38,579:INFO:Defining folds
2023-02-03 15:22:38,579:INFO:Declaring metric variables
2023-02-03 15:22:38,588:INFO:Importing untrained model
2023-02-03 15:22:38,597:INFO:Linear Regression Imported successfully
2023-02-03 15:22:38,613:INFO:Starting cross validation
2023-02-03 15:22:38,615:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:39,011:INFO:Calculating mean and std
2023-02-03 15:22:39,012:INFO:Creating metrics dataframe
2023-02-03 15:22:39,017:INFO:Uploading results into container
2023-02-03 15:22:39,018:INFO:Uploading model into container now
2023-02-03 15:22:39,019:INFO:_master_model_container: 94
2023-02-03 15:22:39,019:INFO:_display_container: 10
2023-02-03 15:22:39,019:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:22:39,019:INFO:create_model() successfully completed......................................
2023-02-03 15:22:39,135:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:39,135:INFO:Creating metrics dataframe
2023-02-03 15:22:39,154:INFO:Initializing Lasso Regression
2023-02-03 15:22:39,154:INFO:Total runtime is 0.009894271691640219 minutes
2023-02-03 15:22:39,161:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:39,162:INFO:Initializing create_model()
2023-02-03 15:22:39,162:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:39,162:INFO:Checking exceptions
2023-02-03 15:22:39,162:INFO:Importing libraries
2023-02-03 15:22:39,163:INFO:Copying training dataset
2023-02-03 15:22:39,169:INFO:Defining folds
2023-02-03 15:22:39,169:INFO:Declaring metric variables
2023-02-03 15:22:39,174:INFO:Importing untrained model
2023-02-03 15:22:39,180:INFO:Lasso Regression Imported successfully
2023-02-03 15:22:39,193:INFO:Starting cross validation
2023-02-03 15:22:39,195:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:39,219:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.653e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,260:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.713e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,285:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.832e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,307:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,330:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.826e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,360:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,386:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,421:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,454:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,487:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.356e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,499:INFO:Calculating mean and std
2023-02-03 15:22:39,499:INFO:Creating metrics dataframe
2023-02-03 15:22:39,505:INFO:Uploading results into container
2023-02-03 15:22:39,506:INFO:Uploading model into container now
2023-02-03 15:22:39,506:INFO:_master_model_container: 95
2023-02-03 15:22:39,506:INFO:_display_container: 10
2023-02-03 15:22:39,507:INFO:Lasso(random_state=123)
2023-02-03 15:22:39,507:INFO:create_model() successfully completed......................................
2023-02-03 15:22:39,620:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:39,620:INFO:Creating metrics dataframe
2023-02-03 15:22:39,636:INFO:Initializing Ridge Regression
2023-02-03 15:22:39,636:INFO:Total runtime is 0.017922989527384442 minutes
2023-02-03 15:22:39,642:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:39,642:INFO:Initializing create_model()
2023-02-03 15:22:39,643:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:39,643:INFO:Checking exceptions
2023-02-03 15:22:39,643:INFO:Importing libraries
2023-02-03 15:22:39,643:INFO:Copying training dataset
2023-02-03 15:22:39,648:INFO:Defining folds
2023-02-03 15:22:39,648:INFO:Declaring metric variables
2023-02-03 15:22:39,657:INFO:Importing untrained model
2023-02-03 15:22:39,665:INFO:Ridge Regression Imported successfully
2023-02-03 15:22:39,682:INFO:Starting cross validation
2023-02-03 15:22:39,685:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:39,959:INFO:Calculating mean and std
2023-02-03 15:22:39,961:INFO:Creating metrics dataframe
2023-02-03 15:22:39,966:INFO:Uploading results into container
2023-02-03 15:22:39,967:INFO:Uploading model into container now
2023-02-03 15:22:39,969:INFO:_master_model_container: 96
2023-02-03 15:22:39,969:INFO:_display_container: 10
2023-02-03 15:22:39,970:INFO:Ridge(random_state=123)
2023-02-03 15:22:39,970:INFO:create_model() successfully completed......................................
2023-02-03 15:22:40,067:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:40,068:INFO:Creating metrics dataframe
2023-02-03 15:22:40,088:INFO:Initializing Elastic Net
2023-02-03 15:22:40,088:INFO:Total runtime is 0.025468671321868898 minutes
2023-02-03 15:22:40,094:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:40,094:INFO:Initializing create_model()
2023-02-03 15:22:40,094:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:40,095:INFO:Checking exceptions
2023-02-03 15:22:40,095:INFO:Importing libraries
2023-02-03 15:22:40,095:INFO:Copying training dataset
2023-02-03 15:22:40,101:INFO:Defining folds
2023-02-03 15:22:40,102:INFO:Declaring metric variables
2023-02-03 15:22:40,109:INFO:Importing untrained model
2023-02-03 15:22:40,117:INFO:Elastic Net Imported successfully
2023-02-03 15:22:40,133:INFO:Starting cross validation
2023-02-03 15:22:40,135:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:40,163:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,194:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.982e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,221:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,247:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,280:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.646e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,307:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.039e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,339:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.999e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,373:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,406:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.979e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,442:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,454:INFO:Calculating mean and std
2023-02-03 15:22:40,456:INFO:Creating metrics dataframe
2023-02-03 15:22:40,461:INFO:Uploading results into container
2023-02-03 15:22:40,462:INFO:Uploading model into container now
2023-02-03 15:22:40,463:INFO:_master_model_container: 97
2023-02-03 15:22:40,463:INFO:_display_container: 10
2023-02-03 15:22:40,464:INFO:ElasticNet(random_state=123)
2023-02-03 15:22:40,464:INFO:create_model() successfully completed......................................
2023-02-03 15:22:40,567:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:40,567:INFO:Creating metrics dataframe
2023-02-03 15:22:40,583:INFO:Initializing Least Angle Regression
2023-02-03 15:22:40,584:INFO:Total runtime is 0.03373061815897624 minutes
2023-02-03 15:22:40,593:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:40,594:INFO:Initializing create_model()
2023-02-03 15:22:40,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:40,594:INFO:Checking exceptions
2023-02-03 15:22:40,594:INFO:Importing libraries
2023-02-03 15:22:40,594:INFO:Copying training dataset
2023-02-03 15:22:40,599:INFO:Defining folds
2023-02-03 15:22:40,599:INFO:Declaring metric variables
2023-02-03 15:22:40,606:INFO:Importing untrained model
2023-02-03 15:22:40,613:INFO:Least Angle Regression Imported successfully
2023-02-03 15:22:40,628:INFO:Starting cross validation
2023-02-03 15:22:40,630:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:40,652:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,690:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,721:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,747:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,781:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,808:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,833:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,857:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,881:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,903:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,914:INFO:Calculating mean and std
2023-02-03 15:22:40,915:INFO:Creating metrics dataframe
2023-02-03 15:22:40,923:INFO:Uploading results into container
2023-02-03 15:22:40,924:INFO:Uploading model into container now
2023-02-03 15:22:40,925:INFO:_master_model_container: 98
2023-02-03 15:22:40,925:INFO:_display_container: 10
2023-02-03 15:22:40,926:INFO:Lars(random_state=123)
2023-02-03 15:22:40,926:INFO:create_model() successfully completed......................................
2023-02-03 15:22:41,033:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:41,034:INFO:Creating metrics dataframe
2023-02-03 15:22:41,054:INFO:Initializing Lasso Least Angle Regression
2023-02-03 15:22:41,054:INFO:Total runtime is 0.04155953327814738 minutes
2023-02-03 15:22:41,059:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:41,060:INFO:Initializing create_model()
2023-02-03 15:22:41,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:41,060:INFO:Checking exceptions
2023-02-03 15:22:41,061:INFO:Importing libraries
2023-02-03 15:22:41,061:INFO:Copying training dataset
2023-02-03 15:22:41,065:INFO:Defining folds
2023-02-03 15:22:41,065:INFO:Declaring metric variables
2023-02-03 15:22:41,073:INFO:Importing untrained model
2023-02-03 15:22:41,082:INFO:Lasso Least Angle Regression Imported successfully
2023-02-03 15:22:41,095:INFO:Starting cross validation
2023-02-03 15:22:41,096:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:41,120:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,157:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,182:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,210:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,234:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,265:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,293:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,317:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,347:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,374:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,383:INFO:Calculating mean and std
2023-02-03 15:22:41,385:INFO:Creating metrics dataframe
2023-02-03 15:22:41,392:INFO:Uploading results into container
2023-02-03 15:22:41,393:INFO:Uploading model into container now
2023-02-03 15:22:41,393:INFO:_master_model_container: 99
2023-02-03 15:22:41,393:INFO:_display_container: 10
2023-02-03 15:22:41,394:INFO:LassoLars(random_state=123)
2023-02-03 15:22:41,394:INFO:create_model() successfully completed......................................
2023-02-03 15:22:41,506:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:41,506:INFO:Creating metrics dataframe
2023-02-03 15:22:41,522:INFO:Initializing Orthogonal Matching Pursuit
2023-02-03 15:22:41,522:INFO:Total runtime is 0.049355045954386396 minutes
2023-02-03 15:22:41,528:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:41,529:INFO:Initializing create_model()
2023-02-03 15:22:41,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:41,529:INFO:Checking exceptions
2023-02-03 15:22:41,529:INFO:Importing libraries
2023-02-03 15:22:41,529:INFO:Copying training dataset
2023-02-03 15:22:41,534:INFO:Defining folds
2023-02-03 15:22:41,535:INFO:Declaring metric variables
2023-02-03 15:22:41,545:INFO:Importing untrained model
2023-02-03 15:22:41,550:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-03 15:22:41,567:INFO:Starting cross validation
2023-02-03 15:22:41,569:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:41,594:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,626:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,650:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,676:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,701:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,726:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,757:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,781:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,805:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,828:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,840:INFO:Calculating mean and std
2023-02-03 15:22:41,842:INFO:Creating metrics dataframe
2023-02-03 15:22:41,848:INFO:Uploading results into container
2023-02-03 15:22:41,849:INFO:Uploading model into container now
2023-02-03 15:22:41,849:INFO:_master_model_container: 100
2023-02-03 15:22:41,850:INFO:_display_container: 10
2023-02-03 15:22:41,850:INFO:OrthogonalMatchingPursuit()
2023-02-03 15:22:41,851:INFO:create_model() successfully completed......................................
2023-02-03 15:22:41,956:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:41,956:INFO:Creating metrics dataframe
2023-02-03 15:22:41,979:INFO:Initializing Bayesian Ridge
2023-02-03 15:22:41,979:INFO:Total runtime is 0.056983943780263266 minutes
2023-02-03 15:22:41,984:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:41,985:INFO:Initializing create_model()
2023-02-03 15:22:41,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:41,987:INFO:Checking exceptions
2023-02-03 15:22:41,988:INFO:Importing libraries
2023-02-03 15:22:41,988:INFO:Copying training dataset
2023-02-03 15:22:41,993:INFO:Defining folds
2023-02-03 15:22:41,993:INFO:Declaring metric variables
2023-02-03 15:22:41,999:INFO:Importing untrained model
2023-02-03 15:22:42,005:INFO:Bayesian Ridge Imported successfully
2023-02-03 15:22:42,023:INFO:Starting cross validation
2023-02-03 15:22:42,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:42,304:INFO:Calculating mean and std
2023-02-03 15:22:42,306:INFO:Creating metrics dataframe
2023-02-03 15:22:42,310:INFO:Uploading results into container
2023-02-03 15:22:42,311:INFO:Uploading model into container now
2023-02-03 15:22:42,311:INFO:_master_model_container: 101
2023-02-03 15:22:42,311:INFO:_display_container: 10
2023-02-03 15:22:42,312:INFO:BayesianRidge()
2023-02-03 15:22:42,312:INFO:create_model() successfully completed......................................
2023-02-03 15:22:42,424:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:42,425:INFO:Creating metrics dataframe
2023-02-03 15:22:42,443:INFO:Initializing Passive Aggressive Regressor
2023-02-03 15:22:42,443:INFO:Total runtime is 0.06471283038457235 minutes
2023-02-03 15:22:42,449:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:42,450:INFO:Initializing create_model()
2023-02-03 15:22:42,450:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:42,450:INFO:Checking exceptions
2023-02-03 15:22:42,450:INFO:Importing libraries
2023-02-03 15:22:42,450:INFO:Copying training dataset
2023-02-03 15:22:42,457:INFO:Defining folds
2023-02-03 15:22:42,457:INFO:Declaring metric variables
2023-02-03 15:22:42,462:INFO:Importing untrained model
2023-02-03 15:22:42,469:INFO:Passive Aggressive Regressor Imported successfully
2023-02-03 15:22:42,488:INFO:Starting cross validation
2023-02-03 15:22:42,490:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:42,850:INFO:Calculating mean and std
2023-02-03 15:22:42,851:INFO:Creating metrics dataframe
2023-02-03 15:22:42,859:INFO:Uploading results into container
2023-02-03 15:22:42,860:INFO:Uploading model into container now
2023-02-03 15:22:42,861:INFO:_master_model_container: 102
2023-02-03 15:22:42,861:INFO:_display_container: 10
2023-02-03 15:22:42,862:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-03 15:22:42,862:INFO:create_model() successfully completed......................................
2023-02-03 15:22:42,967:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:42,968:INFO:Creating metrics dataframe
2023-02-03 15:22:42,994:INFO:Initializing Huber Regressor
2023-02-03 15:22:42,994:INFO:Total runtime is 0.07389095624287922 minutes
2023-02-03 15:22:43,000:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:43,000:INFO:Initializing create_model()
2023-02-03 15:22:43,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:43,001:INFO:Checking exceptions
2023-02-03 15:22:43,001:INFO:Importing libraries
2023-02-03 15:22:43,001:INFO:Copying training dataset
2023-02-03 15:22:43,007:INFO:Defining folds
2023-02-03 15:22:43,007:INFO:Declaring metric variables
2023-02-03 15:22:43,015:INFO:Importing untrained model
2023-02-03 15:22:43,022:INFO:Huber Regressor Imported successfully
2023-02-03 15:22:43,050:INFO:Starting cross validation
2023-02-03 15:22:43,051:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:43,390:INFO:Calculating mean and std
2023-02-03 15:22:43,392:INFO:Creating metrics dataframe
2023-02-03 15:22:43,400:INFO:Uploading results into container
2023-02-03 15:22:43,401:INFO:Uploading model into container now
2023-02-03 15:22:43,401:INFO:_master_model_container: 103
2023-02-03 15:22:43,401:INFO:_display_container: 10
2023-02-03 15:22:43,402:INFO:HuberRegressor()
2023-02-03 15:22:43,402:INFO:create_model() successfully completed......................................
2023-02-03 15:22:43,489:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:43,489:INFO:Creating metrics dataframe
2023-02-03 15:22:43,509:INFO:Initializing K Neighbors Regressor
2023-02-03 15:22:43,509:INFO:Total runtime is 0.08248596986134846 minutes
2023-02-03 15:22:43,514:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:43,514:INFO:Initializing create_model()
2023-02-03 15:22:43,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:43,515:INFO:Checking exceptions
2023-02-03 15:22:43,515:INFO:Importing libraries
2023-02-03 15:22:43,516:INFO:Copying training dataset
2023-02-03 15:22:43,522:INFO:Defining folds
2023-02-03 15:22:43,522:INFO:Declaring metric variables
2023-02-03 15:22:43,530:INFO:Importing untrained model
2023-02-03 15:22:43,536:INFO:K Neighbors Regressor Imported successfully
2023-02-03 15:22:43,550:INFO:Starting cross validation
2023-02-03 15:22:43,552:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:43,943:INFO:Calculating mean and std
2023-02-03 15:22:43,944:INFO:Creating metrics dataframe
2023-02-03 15:22:43,949:INFO:Uploading results into container
2023-02-03 15:22:43,950:INFO:Uploading model into container now
2023-02-03 15:22:43,951:INFO:_master_model_container: 104
2023-02-03 15:22:43,951:INFO:_display_container: 10
2023-02-03 15:22:43,952:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-03 15:22:43,952:INFO:create_model() successfully completed......................................
2023-02-03 15:22:44,061:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:44,061:INFO:Creating metrics dataframe
2023-02-03 15:22:44,083:INFO:Initializing Decision Tree Regressor
2023-02-03 15:22:44,084:INFO:Total runtime is 0.09206384420394896 minutes
2023-02-03 15:22:44,093:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:44,094:INFO:Initializing create_model()
2023-02-03 15:22:44,094:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:44,094:INFO:Checking exceptions
2023-02-03 15:22:44,094:INFO:Importing libraries
2023-02-03 15:22:44,095:INFO:Copying training dataset
2023-02-03 15:22:44,101:INFO:Defining folds
2023-02-03 15:22:44,101:INFO:Declaring metric variables
2023-02-03 15:22:44,112:INFO:Importing untrained model
2023-02-03 15:22:44,124:INFO:Decision Tree Regressor Imported successfully
2023-02-03 15:22:44,146:INFO:Starting cross validation
2023-02-03 15:22:44,148:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:44,502:INFO:Calculating mean and std
2023-02-03 15:22:44,504:INFO:Creating metrics dataframe
2023-02-03 15:22:44,512:INFO:Uploading results into container
2023-02-03 15:22:44,513:INFO:Uploading model into container now
2023-02-03 15:22:44,514:INFO:_master_model_container: 105
2023-02-03 15:22:44,514:INFO:_display_container: 10
2023-02-03 15:22:44,515:INFO:DecisionTreeRegressor(random_state=123)
2023-02-03 15:22:44,516:INFO:create_model() successfully completed......................................
2023-02-03 15:22:44,641:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:44,641:INFO:Creating metrics dataframe
2023-02-03 15:22:44,658:INFO:Initializing Random Forest Regressor
2023-02-03 15:22:44,658:INFO:Total runtime is 0.10162502129872639 minutes
2023-02-03 15:22:44,662:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:44,663:INFO:Initializing create_model()
2023-02-03 15:22:44,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:44,663:INFO:Checking exceptions
2023-02-03 15:22:44,664:INFO:Importing libraries
2023-02-03 15:22:44,664:INFO:Copying training dataset
2023-02-03 15:22:44,669:INFO:Defining folds
2023-02-03 15:22:44,669:INFO:Declaring metric variables
2023-02-03 15:22:44,677:INFO:Importing untrained model
2023-02-03 15:22:44,686:INFO:Random Forest Regressor Imported successfully
2023-02-03 15:22:44,707:INFO:Starting cross validation
2023-02-03 15:22:44,709:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:47,038:INFO:Calculating mean and std
2023-02-03 15:22:47,039:INFO:Creating metrics dataframe
2023-02-03 15:22:47,047:INFO:Uploading results into container
2023-02-03 15:22:47,048:INFO:Uploading model into container now
2023-02-03 15:22:47,049:INFO:_master_model_container: 106
2023-02-03 15:22:47,049:INFO:_display_container: 10
2023-02-03 15:22:47,050:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:22:47,050:INFO:create_model() successfully completed......................................
2023-02-03 15:22:47,155:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:47,155:INFO:Creating metrics dataframe
2023-02-03 15:22:47,175:INFO:Initializing Extra Trees Regressor
2023-02-03 15:22:47,176:INFO:Total runtime is 0.14360103607177732 minutes
2023-02-03 15:22:47,180:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:47,181:INFO:Initializing create_model()
2023-02-03 15:22:47,181:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:47,181:INFO:Checking exceptions
2023-02-03 15:22:47,181:INFO:Importing libraries
2023-02-03 15:22:47,181:INFO:Copying training dataset
2023-02-03 15:22:47,186:INFO:Defining folds
2023-02-03 15:22:47,186:INFO:Declaring metric variables
2023-02-03 15:22:47,194:INFO:Importing untrained model
2023-02-03 15:22:47,203:INFO:Extra Trees Regressor Imported successfully
2023-02-03 15:22:47,218:INFO:Starting cross validation
2023-02-03 15:22:47,220:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:49,458:INFO:Calculating mean and std
2023-02-03 15:22:49,461:INFO:Creating metrics dataframe
2023-02-03 15:22:49,467:INFO:Uploading results into container
2023-02-03 15:22:49,468:INFO:Uploading model into container now
2023-02-03 15:22:49,468:INFO:_master_model_container: 107
2023-02-03 15:22:49,469:INFO:_display_container: 10
2023-02-03 15:22:49,469:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:22:49,469:INFO:create_model() successfully completed......................................
2023-02-03 15:22:49,573:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:49,573:INFO:Creating metrics dataframe
2023-02-03 15:22:49,593:INFO:Initializing AdaBoost Regressor
2023-02-03 15:22:49,594:INFO:Total runtime is 0.1838779052098592 minutes
2023-02-03 15:22:49,600:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:49,601:INFO:Initializing create_model()
2023-02-03 15:22:49,601:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:49,601:INFO:Checking exceptions
2023-02-03 15:22:49,601:INFO:Importing libraries
2023-02-03 15:22:49,601:INFO:Copying training dataset
2023-02-03 15:22:49,605:INFO:Defining folds
2023-02-03 15:22:49,606:INFO:Declaring metric variables
2023-02-03 15:22:49,613:INFO:Importing untrained model
2023-02-03 15:22:49,621:INFO:AdaBoost Regressor Imported successfully
2023-02-03 15:22:49,636:INFO:Starting cross validation
2023-02-03 15:22:49,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:50,383:INFO:Calculating mean and std
2023-02-03 15:22:50,384:INFO:Creating metrics dataframe
2023-02-03 15:22:50,388:INFO:Uploading results into container
2023-02-03 15:22:50,389:INFO:Uploading model into container now
2023-02-03 15:22:50,390:INFO:_master_model_container: 108
2023-02-03 15:22:50,390:INFO:_display_container: 10
2023-02-03 15:22:50,390:INFO:AdaBoostRegressor(random_state=123)
2023-02-03 15:22:50,390:INFO:create_model() successfully completed......................................
2023-02-03 15:22:50,514:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:50,515:INFO:Creating metrics dataframe
2023-02-03 15:22:50,536:INFO:Initializing Gradient Boosting Regressor
2023-02-03 15:22:50,536:INFO:Total runtime is 0.19960221846898396 minutes
2023-02-03 15:22:50,543:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:50,545:INFO:Initializing create_model()
2023-02-03 15:22:50,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:50,547:INFO:Checking exceptions
2023-02-03 15:22:50,547:INFO:Importing libraries
2023-02-03 15:22:50,547:INFO:Copying training dataset
2023-02-03 15:22:50,555:INFO:Defining folds
2023-02-03 15:22:50,555:INFO:Declaring metric variables
2023-02-03 15:22:50,566:INFO:Importing untrained model
2023-02-03 15:22:50,575:INFO:Gradient Boosting Regressor Imported successfully
2023-02-03 15:22:50,601:INFO:Starting cross validation
2023-02-03 15:22:50,603:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:51,447:INFO:Calculating mean and std
2023-02-03 15:22:51,449:INFO:Creating metrics dataframe
2023-02-03 15:22:51,455:INFO:Uploading results into container
2023-02-03 15:22:51,456:INFO:Uploading model into container now
2023-02-03 15:22:51,457:INFO:_master_model_container: 109
2023-02-03 15:22:51,457:INFO:_display_container: 10
2023-02-03 15:22:51,458:INFO:GradientBoostingRegressor(random_state=123)
2023-02-03 15:22:51,458:INFO:create_model() successfully completed......................................
2023-02-03 15:22:51,561:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:51,561:INFO:Creating metrics dataframe
2023-02-03 15:22:51,589:INFO:Initializing Light Gradient Boosting Machine
2023-02-03 15:22:51,589:INFO:Total runtime is 0.21714218854904174 minutes
2023-02-03 15:22:51,598:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:51,598:INFO:Initializing create_model()
2023-02-03 15:22:51,599:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:51,600:INFO:Checking exceptions
2023-02-03 15:22:51,600:INFO:Importing libraries
2023-02-03 15:22:51,600:INFO:Copying training dataset
2023-02-03 15:22:51,609:INFO:Defining folds
2023-02-03 15:22:51,609:INFO:Declaring metric variables
2023-02-03 15:22:51,617:INFO:Importing untrained model
2023-02-03 15:22:51,628:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-03 15:22:51,655:INFO:Starting cross validation
2023-02-03 15:22:51,657:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:59,521:INFO:Calculating mean and std
2023-02-03 15:22:59,524:INFO:Creating metrics dataframe
2023-02-03 15:22:59,532:INFO:Uploading results into container
2023-02-03 15:22:59,534:INFO:Uploading model into container now
2023-02-03 15:22:59,535:INFO:_master_model_container: 110
2023-02-03 15:22:59,535:INFO:_display_container: 10
2023-02-03 15:22:59,537:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-02-03 15:22:59,538:INFO:create_model() successfully completed......................................
2023-02-03 15:22:59,683:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:59,683:INFO:Creating metrics dataframe
2023-02-03 15:22:59,716:INFO:Initializing Dummy Regressor
2023-02-03 15:22:59,716:INFO:Total runtime is 0.35259779294331867 minutes
2023-02-03 15:22:59,726:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:59,727:INFO:Initializing create_model()
2023-02-03 15:22:59,727:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:59,728:INFO:Checking exceptions
2023-02-03 15:22:59,728:INFO:Importing libraries
2023-02-03 15:22:59,728:INFO:Copying training dataset
2023-02-03 15:22:59,734:INFO:Defining folds
2023-02-03 15:22:59,736:INFO:Declaring metric variables
2023-02-03 15:22:59,743:INFO:Importing untrained model
2023-02-03 15:22:59,754:INFO:Dummy Regressor Imported successfully
2023-02-03 15:22:59,774:INFO:Starting cross validation
2023-02-03 15:22:59,776:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:23:00,119:INFO:Calculating mean and std
2023-02-03 15:23:00,123:INFO:Creating metrics dataframe
2023-02-03 15:23:00,129:INFO:Uploading results into container
2023-02-03 15:23:00,130:INFO:Uploading model into container now
2023-02-03 15:23:00,131:INFO:_master_model_container: 111
2023-02-03 15:23:00,131:INFO:_display_container: 10
2023-02-03 15:23:00,132:INFO:DummyRegressor()
2023-02-03 15:23:00,132:INFO:create_model() successfully completed......................................
2023-02-03 15:23:00,231:INFO:SubProcess create_model() end ==================================
2023-02-03 15:23:00,232:INFO:Creating metrics dataframe
2023-02-03 15:23:00,267:INFO:Initializing create_model()
2023-02-03 15:23:00,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:23:00,267:INFO:Checking exceptions
2023-02-03 15:23:00,270:INFO:Importing libraries
2023-02-03 15:23:00,270:INFO:Copying training dataset
2023-02-03 15:23:00,278:INFO:Defining folds
2023-02-03 15:23:00,278:INFO:Declaring metric variables
2023-02-03 15:23:00,279:INFO:Importing untrained model
2023-02-03 15:23:00,279:INFO:Declaring custom model
2023-02-03 15:23:00,279:INFO:Linear Regression Imported successfully
2023-02-03 15:23:00,280:INFO:Cross validation set to False
2023-02-03 15:23:00,280:INFO:Fitting Model
2023-02-03 15:23:00,292:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:23:00,292:INFO:create_model() successfully completed......................................
2023-02-03 15:23:00,458:INFO:_master_model_container: 111
2023-02-03 15:23:00,458:INFO:_display_container: 10
2023-02-03 15:23:00,459:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:23:00,459:INFO:compare_models() successfully completed......................................
2023-02-03 15:24:08,358:INFO:Initializing evaluate_model()
2023-02-03 15:24:08,359:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-03 15:24:08,391:INFO:Initializing plot_model()
2023-02-03 15:24:08,392:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:24:08,392:INFO:Checking exceptions
2023-02-03 15:24:08,396:INFO:Preloading libraries
2023-02-03 15:24:08,396:INFO:Copying training dataset
2023-02-03 15:24:08,397:INFO:Plot type: pipeline
2023-02-03 15:24:08,720:INFO:Visual Rendered Successfully
2023-02-03 15:24:08,952:INFO:plot_model() successfully completed......................................
2023-02-03 15:24:19,888:INFO:Initializing plot_model()
2023-02-03 15:24:19,888:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:24:19,888:INFO:Checking exceptions
2023-02-03 15:24:19,894:INFO:Preloading libraries
2023-02-03 15:24:19,894:INFO:Copying training dataset
2023-02-03 15:24:19,895:INFO:Plot type: residuals
2023-02-03 15:24:20,045:INFO:Fitting Model
2023-02-03 15:24:20,046:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2023-02-03 15:24:20,128:INFO:Scoring test/hold-out set
2023-02-03 15:24:20,912:INFO:Visual Rendered Successfully
2023-02-03 15:24:21,004:INFO:plot_model() successfully completed......................................
2023-02-03 15:24:36,254:INFO:Initializing plot_model()
2023-02-03 15:24:36,255:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:24:36,256:INFO:Checking exceptions
2023-02-03 15:24:36,261:INFO:Preloading libraries
2023-02-03 15:24:36,261:INFO:Copying training dataset
2023-02-03 15:24:36,261:INFO:Plot type: error
2023-02-03 15:24:36,320:INFO:Fitting Model
2023-02-03 15:24:36,320:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2023-02-03 15:24:36,320:INFO:Scoring test/hold-out set
2023-02-03 15:24:36,661:INFO:Visual Rendered Successfully
2023-02-03 15:24:36,769:INFO:plot_model() successfully completed......................................
2023-02-03 15:24:44,864:INFO:Initializing plot_model()
2023-02-03 15:24:44,865:INFO:plot_model(plot=tree, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:24:44,865:INFO:Checking exceptions
2023-02-03 15:24:49,464:INFO:Initializing plot_model()
2023-02-03 15:24:49,465:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:24:49,465:INFO:Checking exceptions
2023-02-03 15:24:49,471:INFO:Preloading libraries
2023-02-03 15:24:49,471:INFO:Copying training dataset
2023-02-03 15:24:49,471:INFO:Plot type: pipeline
2023-02-03 15:24:49,566:INFO:Visual Rendered Successfully
2023-02-03 15:24:49,668:INFO:plot_model() successfully completed......................................
2023-02-03 15:24:51,444:INFO:Initializing plot_model()
2023-02-03 15:24:51,444:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:24:51,444:INFO:Checking exceptions
2023-02-03 15:24:51,451:INFO:Preloading libraries
2023-02-03 15:24:51,452:INFO:Copying training dataset
2023-02-03 15:24:51,452:INFO:Plot type: feature
2023-02-03 15:24:51,591:INFO:Visual Rendered Successfully
2023-02-03 15:24:51,709:INFO:plot_model() successfully completed......................................
2023-02-03 15:24:58,498:INFO:Initializing plot_model()
2023-02-03 15:24:58,499:INFO:plot_model(plot=residuals_interactive, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:24:58,499:INFO:Checking exceptions
2023-02-03 15:24:58,504:INFO:Preloading libraries
2023-02-03 15:24:58,504:INFO:Copying training dataset
2023-02-03 15:24:58,504:INFO:Plot type: residuals_interactive
2023-02-03 15:24:58,554:INFO:Calculated model residuals
2023-02-03 15:24:59,413:INFO:Calculated Tunkey-Anscombe Plot
2023-02-03 15:24:59,591:INFO:Calculated Normal QQ Plot
2023-02-03 15:24:59,979:INFO:Calculated Scale-Location Plot
2023-02-03 15:25:00,316:INFO:Calculated Residual vs Leverage Plot inc. Cook's distance
2023-02-03 15:25:00,713:INFO:Visual Rendered Successfully
2023-02-03 15:25:00,826:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:01,197:INFO:Initializing plot_model()
2023-02-03 15:25:01,197:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:01,197:INFO:Checking exceptions
2023-02-03 15:25:01,204:INFO:Preloading libraries
2023-02-03 15:25:01,204:INFO:Copying training dataset
2023-02-03 15:25:01,204:INFO:Plot type: cooks
2023-02-03 15:25:01,248:INFO:Fitting Model
2023-02-03 15:25:01,517:INFO:Visual Rendered Successfully
2023-02-03 15:25:01,626:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:10,511:INFO:Initializing plot_model()
2023-02-03 15:25:10,512:INFO:plot_model(plot=learning, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:10,512:INFO:Checking exceptions
2023-02-03 15:25:10,518:INFO:Preloading libraries
2023-02-03 15:25:10,518:INFO:Copying training dataset
2023-02-03 15:25:10,518:INFO:Plot type: learning
2023-02-03 15:25:10,563:INFO:Fitting Model
2023-02-03 15:25:11,889:INFO:Visual Rendered Successfully
2023-02-03 15:25:12,004:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:28,816:INFO:Initializing plot_model()
2023-02-03 15:25:28,816:INFO:plot_model(plot=vc, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:28,817:INFO:Checking exceptions
2023-02-03 15:25:28,821:INFO:Preloading libraries
2023-02-03 15:25:28,822:INFO:Copying training dataset
2023-02-03 15:25:28,822:INFO:Plot type: vc
2023-02-03 15:25:28,822:INFO:Determining param_name
2023-02-03 15:25:28,823:INFO:param_name: alpha
2023-02-03 15:25:28,865:INFO:Fitting Model
2023-02-03 15:25:30,023:INFO:Visual Rendered Successfully
2023-02-03 15:25:30,126:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:34,070:INFO:Initializing plot_model()
2023-02-03 15:25:34,071:INFO:plot_model(plot=manifold, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:34,071:INFO:Checking exceptions
2023-02-03 15:25:34,076:INFO:Preloading libraries
2023-02-03 15:25:34,076:INFO:Copying training dataset
2023-02-03 15:25:34,077:INFO:Plot type: manifold
2023-02-03 15:25:34,150:INFO:Fitting & Transforming Model
2023-02-03 15:25:34,151:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\manifold\_t_sne.py:810: FutureWarning:

The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.


2023-02-03 15:25:37,039:INFO:Initializing plot_model()
2023-02-03 15:25:37,040:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:37,040:INFO:Checking exceptions
2023-02-03 15:25:37,045:INFO:Preloading libraries
2023-02-03 15:25:37,046:INFO:Copying training dataset
2023-02-03 15:25:37,046:INFO:Plot type: error
2023-02-03 15:25:37,087:INFO:Fitting Model
2023-02-03 15:25:37,088:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2023-02-03 15:25:37,088:INFO:Scoring test/hold-out set
2023-02-03 15:25:37,437:INFO:Visual Rendered Successfully
2023-02-03 15:25:37,614:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:38,954:INFO:Initializing plot_model()
2023-02-03 15:25:38,954:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:38,954:INFO:Checking exceptions
2023-02-03 15:25:38,961:INFO:Preloading libraries
2023-02-03 15:25:38,961:INFO:Copying training dataset
2023-02-03 15:25:38,961:INFO:Plot type: residuals
2023-02-03 15:25:39,027:INFO:Fitting Model
2023-02-03 15:25:39,027:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2023-02-03 15:25:39,087:INFO:Scoring test/hold-out set
2023-02-03 15:25:39,710:INFO:Visual Rendered Successfully
2023-02-03 15:25:39,857:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:40,336:INFO:Initializing plot_model()
2023-02-03 15:25:40,338:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:40,338:INFO:Checking exceptions
2023-02-03 15:25:40,341:INFO:Preloading libraries
2023-02-03 15:25:40,342:INFO:Copying training dataset
2023-02-03 15:25:40,342:INFO:Plot type: parameter
2023-02-03 15:25:40,348:INFO:Visual Rendered Successfully
2023-02-03 15:25:40,469:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:45,771:INFO:Initializing plot_model()
2023-02-03 15:25:45,771:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:45,772:INFO:Checking exceptions
2023-02-03 15:25:45,775:INFO:Preloading libraries
2023-02-03 15:25:45,776:INFO:Copying training dataset
2023-02-03 15:25:45,776:INFO:Plot type: residuals
2023-02-03 15:25:45,850:INFO:Fitting Model
2023-02-03 15:25:45,850:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2023-02-03 15:25:45,915:INFO:Scoring test/hold-out set
2023-02-03 15:25:46,418:INFO:Visual Rendered Successfully
2023-02-03 15:25:46,525:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:47,797:INFO:Initializing plot_model()
2023-02-03 15:25:47,798:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:47,798:INFO:Checking exceptions
2023-02-03 15:25:47,803:INFO:Preloading libraries
2023-02-03 15:25:47,804:INFO:Copying training dataset
2023-02-03 15:25:47,806:INFO:Plot type: error
2023-02-03 15:25:47,843:INFO:Fitting Model
2023-02-03 15:25:47,844:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2023-02-03 15:25:47,844:INFO:Scoring test/hold-out set
2023-02-03 15:25:48,188:INFO:Visual Rendered Successfully
2023-02-03 15:25:48,332:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:49,776:INFO:Initializing plot_model()
2023-02-03 15:25:49,776:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:49,777:INFO:Checking exceptions
2023-02-03 15:25:49,783:INFO:Preloading libraries
2023-02-03 15:25:49,783:INFO:Copying training dataset
2023-02-03 15:25:49,784:INFO:Plot type: residuals
2023-02-03 15:25:49,867:INFO:Fitting Model
2023-02-03 15:25:49,867:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2023-02-03 15:25:49,948:INFO:Scoring test/hold-out set
2023-02-03 15:25:51,020:INFO:Visual Rendered Successfully
2023-02-03 15:25:51,200:INFO:plot_model() successfully completed......................................
2023-02-03 15:26:04,075:INFO:Initializing create_model()
2023-02-03 15:26:04,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:26:04,076:INFO:Checking exceptions
2023-02-03 15:26:04,113:INFO:Importing libraries
2023-02-03 15:26:04,113:INFO:Copying training dataset
2023-02-03 15:26:04,120:INFO:Defining folds
2023-02-03 15:26:04,120:INFO:Declaring metric variables
2023-02-03 15:26:04,131:INFO:Importing untrained model
2023-02-03 15:26:04,131:INFO:Declaring custom model
2023-02-03 15:26:04,140:INFO:Linear Regression Imported successfully
2023-02-03 15:26:04,158:INFO:Starting cross validation
2023-02-03 15:26:04,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:26:04,492:INFO:Calculating mean and std
2023-02-03 15:26:04,493:INFO:Creating metrics dataframe
2023-02-03 15:26:04,501:INFO:Finalizing model
2023-02-03 15:26:04,521:INFO:Uploading results into container
2023-02-03 15:26:04,523:INFO:Uploading model into container now
2023-02-03 15:26:04,540:INFO:_master_model_container: 112
2023-02-03 15:26:04,540:INFO:_display_container: 11
2023-02-03 15:26:04,540:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:26:04,541:INFO:create_model() successfully completed......................................
2023-02-03 15:26:08,157:INFO:Initializing evaluate_model()
2023-02-03 15:26:08,158:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-03 15:26:08,182:INFO:Initializing plot_model()
2023-02-03 15:26:08,182:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:26:08,182:INFO:Checking exceptions
2023-02-03 15:26:08,187:INFO:Preloading libraries
2023-02-03 15:26:08,187:INFO:Copying training dataset
2023-02-03 15:26:08,188:INFO:Plot type: pipeline
2023-02-03 15:26:08,337:INFO:Visual Rendered Successfully
2023-02-03 15:26:08,478:INFO:plot_model() successfully completed......................................
2023-02-03 15:26:10,431:INFO:Initializing plot_model()
2023-02-03 15:26:10,432:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:26:10,432:INFO:Checking exceptions
2023-02-03 15:26:10,436:INFO:Preloading libraries
2023-02-03 15:26:10,436:INFO:Copying training dataset
2023-02-03 15:26:10,436:INFO:Plot type: residuals
2023-02-03 15:26:10,517:INFO:Fitting Model
2023-02-03 15:26:10,517:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but LinearRegression was fitted with feature names


2023-02-03 15:26:10,574:INFO:Scoring test/hold-out set
2023-02-03 15:26:11,075:INFO:Visual Rendered Successfully
2023-02-03 15:26:11,198:INFO:plot_model() successfully completed......................................
2023-02-03 15:26:16,584:INFO:Initializing plot_model()
2023-02-03 15:26:16,584:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:26:16,584:INFO:Checking exceptions
2023-02-03 15:26:16,590:INFO:Preloading libraries
2023-02-03 15:26:16,591:INFO:Copying training dataset
2023-02-03 15:26:16,591:INFO:Plot type: error
2023-02-03 15:26:16,623:INFO:Fitting Model
2023-02-03 15:26:16,623:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but LinearRegression was fitted with feature names


2023-02-03 15:26:16,623:INFO:Scoring test/hold-out set
2023-02-03 15:26:16,868:INFO:Visual Rendered Successfully
2023-02-03 15:26:16,988:INFO:plot_model() successfully completed......................................
2023-02-03 15:26:19,746:INFO:Initializing plot_model()
2023-02-03 15:26:19,747:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:26:19,747:INFO:Checking exceptions
2023-02-03 15:26:19,752:INFO:Preloading libraries
2023-02-03 15:26:19,753:INFO:Copying training dataset
2023-02-03 15:26:19,753:INFO:Plot type: residuals
2023-02-03 15:26:19,818:INFO:Fitting Model
2023-02-03 15:26:19,818:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but LinearRegression was fitted with feature names


2023-02-03 15:26:19,872:INFO:Scoring test/hold-out set
2023-02-03 15:26:20,379:INFO:Visual Rendered Successfully
2023-02-03 15:26:20,496:INFO:plot_model() successfully completed......................................
2023-02-03 15:26:21,252:INFO:Initializing plot_model()
2023-02-03 15:26:21,253:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:26:21,253:INFO:Checking exceptions
2023-02-03 15:26:21,258:INFO:Preloading libraries
2023-02-03 15:26:21,259:INFO:Copying training dataset
2023-02-03 15:26:21,259:INFO:Plot type: parameter
2023-02-03 15:26:21,265:INFO:Visual Rendered Successfully
2023-02-03 15:26:21,367:INFO:plot_model() successfully completed......................................
2023-02-03 15:26:22,525:INFO:Initializing plot_model()
2023-02-03 15:26:22,525:INFO:plot_model(plot=learning, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:26:22,526:INFO:Checking exceptions
2023-02-03 15:26:22,532:INFO:Preloading libraries
2023-02-03 15:26:22,533:INFO:Copying training dataset
2023-02-03 15:26:22,533:INFO:Plot type: learning
2023-02-03 15:26:22,570:INFO:Fitting Model
2023-02-03 15:26:24,085:INFO:Visual Rendered Successfully
2023-02-03 15:26:24,196:INFO:plot_model() successfully completed......................................
2023-02-03 15:26:34,189:INFO:Initializing create_model()
2023-02-03 15:26:34,189:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:26:34,189:INFO:Checking exceptions
2023-02-03 15:26:34,217:INFO:Importing libraries
2023-02-03 15:26:34,218:INFO:Copying training dataset
2023-02-03 15:26:34,227:INFO:Defining folds
2023-02-03 15:26:34,228:INFO:Declaring metric variables
2023-02-03 15:26:34,235:INFO:Importing untrained model
2023-02-03 15:26:34,248:INFO:Huber Regressor Imported successfully
2023-02-03 15:26:34,266:INFO:Starting cross validation
2023-02-03 15:26:34,268:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:26:34,717:INFO:Calculating mean and std
2023-02-03 15:26:34,718:INFO:Creating metrics dataframe
2023-02-03 15:26:34,726:INFO:Finalizing model
2023-02-03 15:26:34,753:INFO:Uploading results into container
2023-02-03 15:26:34,756:INFO:Uploading model into container now
2023-02-03 15:26:34,769:INFO:_master_model_container: 113
2023-02-03 15:26:34,769:INFO:_display_container: 12
2023-02-03 15:26:34,770:INFO:HuberRegressor()
2023-02-03 15:26:34,770:INFO:create_model() successfully completed......................................
2023-02-03 15:26:37,151:INFO:Initializing evaluate_model()
2023-02-03 15:26:37,151:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-03 15:26:37,171:INFO:Initializing plot_model()
2023-02-03 15:26:37,171:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:26:37,172:INFO:Checking exceptions
2023-02-03 15:26:37,177:INFO:Preloading libraries
2023-02-03 15:26:37,177:INFO:Copying training dataset
2023-02-03 15:26:37,178:INFO:Plot type: pipeline
2023-02-03 15:26:37,291:INFO:Visual Rendered Successfully
2023-02-03 15:26:37,408:INFO:plot_model() successfully completed......................................
2023-02-03 15:26:39,040:INFO:Initializing plot_model()
2023-02-03 15:26:39,040:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:26:39,040:INFO:Checking exceptions
2023-02-03 15:26:39,046:INFO:Preloading libraries
2023-02-03 15:26:39,046:INFO:Copying training dataset
2023-02-03 15:26:39,047:INFO:Plot type: residuals
2023-02-03 15:26:39,136:INFO:Fitting Model
2023-02-03 15:26:39,137:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2023-02-03 15:26:39,198:INFO:Scoring test/hold-out set
2023-02-03 15:26:40,035:INFO:Visual Rendered Successfully
2023-02-03 15:26:40,232:INFO:plot_model() successfully completed......................................
2023-02-03 15:28:14,375:INFO:Initializing predict_model()
2023-02-03 15:28:14,375:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000181F972FF40>)
2023-02-03 15:28:14,376:INFO:Checking exceptions
2023-02-03 15:28:14,376:INFO:Preloading libraries
2023-02-03 15:28:14,379:INFO:Set up data.
2023-02-03 15:28:14,388:INFO:Set up index.
2023-02-06 13:22:24,349:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:22:24,350:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:22:24,351:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:22:24,351:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:22:26,038:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-06 13:23:41,469:INFO:PyCaret RegressionExperiment
2023-02-06 13:23:41,470:INFO:Logging name: reg-default-name
2023-02-06 13:23:41,470:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-06 13:23:41,470:INFO:version 3.0.0.rc8
2023-02-06 13:23:41,471:INFO:Initializing setup()
2023-02-06 13:23:41,471:INFO:self.USI: 8710
2023-02-06 13:23:41,471:INFO:self._variable_keys: {'log_plots_param', 'n_jobs_param', '_available_plots', 'y', 'exp_name_log', 'USI', 'html_param', 'logging_param', 'fold_shuffle_param', 'y_test', 'memory', 'seed', 'idx', 'fold_generator', 'X', '_ml_usecase', 'data', 'exp_id', 'X_train', 'gpu_n_jobs_param', 'pipeline', 'fold_groups_param', 'gpu_param', 'target_param', 'y_train', 'transform_target_param', 'X_test'}
2023-02-06 13:23:41,472:INFO:Checking environment
2023-02-06 13:23:41,472:INFO:python_version: 3.10.9
2023-02-06 13:23:41,473:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-02-06 13:23:41,473:INFO:machine: AMD64
2023-02-06 13:23:41,474:INFO:platform: Windows-10-10.0.19045-SP0
2023-02-06 13:23:41,475:INFO:Memory: svmem(total=17090879488, available=6704939008, percent=60.8, used=10385940480, free=6704939008)
2023-02-06 13:23:41,476:INFO:Physical Core: 4
2023-02-06 13:23:41,477:INFO:Logical Core: 8
2023-02-06 13:23:41,478:INFO:Checking libraries
2023-02-06 13:23:41,479:INFO:System:
2023-02-06 13:23:41,479:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-02-06 13:23:41,480:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-02-06 13:23:41,480:INFO:   machine: Windows-10-10.0.19045-SP0
2023-02-06 13:23:41,481:INFO:PyCaret required dependencies:
2023-02-06 13:23:41,482:INFO:                 pip: 23.0
2023-02-06 13:23:41,482:INFO:          setuptools: 67.1.0
2023-02-06 13:23:41,483:INFO:             pycaret: 3.0.0rc8
2023-02-06 13:23:41,483:INFO:             IPython: 8.8.0
2023-02-06 13:23:41,483:INFO:          ipywidgets: 8.0.4
2023-02-06 13:23:41,484:INFO:                tqdm: 4.64.1
2023-02-06 13:23:41,484:INFO:               numpy: 1.23.5
2023-02-06 13:23:41,484:INFO:              pandas: 1.5.3
2023-02-06 13:23:41,485:INFO:              jinja2: 3.1.2
2023-02-06 13:23:41,485:INFO:               scipy: 1.10.0
2023-02-06 13:23:41,485:INFO:              joblib: 1.2.0
2023-02-06 13:23:41,486:INFO:             sklearn: 1.1.3
2023-02-06 13:23:41,486:INFO:                pyod: 1.0.7
2023-02-06 13:23:41,486:INFO:            imblearn: 0.10.1
2023-02-06 13:23:41,486:INFO:   category_encoders: 2.6.0
2023-02-06 13:23:41,486:INFO:            lightgbm: 3.3.5
2023-02-06 13:23:41,486:INFO:               numba: 0.56.4
2023-02-06 13:23:41,487:INFO:            requests: 2.28.2
2023-02-06 13:23:41,487:INFO:          matplotlib: 3.6.3
2023-02-06 13:23:41,487:INFO:          scikitplot: 0.3.7
2023-02-06 13:23:41,487:INFO:         yellowbrick: 1.5
2023-02-06 13:23:41,487:INFO:              plotly: 5.13.0
2023-02-06 13:23:41,487:INFO:             kaleido: 0.2.1
2023-02-06 13:23:41,487:INFO:         statsmodels: 0.13.5
2023-02-06 13:23:41,487:INFO:              sktime: 0.16.0
2023-02-06 13:23:41,487:INFO:               tbats: 1.1.2
2023-02-06 13:23:41,487:INFO:            pmdarima: 2.0.2
2023-02-06 13:23:41,487:INFO:              psutil: 5.9.0
2023-02-06 13:23:41,487:INFO:PyCaret optional dependencies:
2023-02-06 13:23:41,526:INFO:                shap: Not installed
2023-02-06 13:23:41,527:INFO:           interpret: Not installed
2023-02-06 13:23:41,527:INFO:                umap: Not installed
2023-02-06 13:23:41,527:INFO:    pandas_profiling: Not installed
2023-02-06 13:23:41,527:INFO:  explainerdashboard: Not installed
2023-02-06 13:23:41,527:INFO:             autoviz: Not installed
2023-02-06 13:23:41,527:INFO:           fairlearn: Not installed
2023-02-06 13:23:41,527:INFO:             xgboost: 1.7.3
2023-02-06 13:23:41,527:INFO:            catboost: Not installed
2023-02-06 13:23:41,527:INFO:              kmodes: Not installed
2023-02-06 13:23:41,527:INFO:             mlxtend: Not installed
2023-02-06 13:23:41,527:INFO:       statsforecast: Not installed
2023-02-06 13:23:41,527:INFO:        tune_sklearn: Not installed
2023-02-06 13:23:41,527:INFO:                 ray: Not installed
2023-02-06 13:23:41,527:INFO:            hyperopt: Not installed
2023-02-06 13:23:41,527:INFO:              optuna: Not installed
2023-02-06 13:23:41,528:INFO:               skopt: Not installed
2023-02-06 13:23:41,528:INFO:              mlflow: Not installed
2023-02-06 13:23:41,528:INFO:              gradio: Not installed
2023-02-06 13:23:41,528:INFO:             fastapi: Not installed
2023-02-06 13:23:41,528:INFO:             uvicorn: Not installed
2023-02-06 13:23:41,528:INFO:              m2cgen: Not installed
2023-02-06 13:23:41,528:INFO:           evidently: Not installed
2023-02-06 13:23:41,528:INFO:                nltk: Not installed
2023-02-06 13:23:41,528:INFO:            pyLDAvis: Not installed
2023-02-06 13:23:41,528:INFO:              gensim: Not installed
2023-02-06 13:23:41,528:INFO:               spacy: Not installed
2023-02-06 13:23:41,528:INFO:           wordcloud: Not installed
2023-02-06 13:23:41,528:INFO:            textblob: Not installed
2023-02-06 13:23:41,528:INFO:               fugue: Not installed
2023-02-06 13:23:41,528:INFO:           streamlit: Not installed
2023-02-06 13:23:41,528:INFO:             prophet: Not installed
2023-02-06 13:23:41,529:INFO:None
2023-02-06 13:23:41,529:INFO:Set up GPU usage.
2023-02-06 13:23:41,529:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:41,529:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-02-06 13:23:41,529:INFO:Set up data.
2023-02-06 13:23:41,535:INFO:Set up train/test split.
2023-02-06 13:23:41,540:INFO:Set up index.
2023-02-06 13:23:41,541:INFO:Set up folding strategy.
2023-02-06 13:23:41,542:INFO:Assigning column types.
2023-02-06 13:23:41,548:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-06 13:23:41,548:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:41,548:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-06 13:23:41,548:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:41,554:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-06 13:23:41,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:41,561:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 13:23:41,561:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:41,635:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:41,635:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:41,693:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 13:23:41,694:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:41,694:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:41,694:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:42,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:42,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:42,668:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-06 13:23:42,668:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:42,681:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-06 13:23:42,681:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:42,693:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 13:23:42,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:42,834:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:42,835:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:42,917:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 13:23:42,917:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:42,917:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:42,918:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:43,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:43,131:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-06 13:23:43,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,145:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,159:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,285:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,285:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,360:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,361:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:43,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:43,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,557:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,557:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,569:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,570:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,684:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,746:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,746:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,746:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,747:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:43,938:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:43,940:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-06 13:23:43,940:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,940:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,966:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,086:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:44,086:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,143:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 13:23:44,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,144:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:44,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:44,317:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,317:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,344:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 13:23:44,344:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,462:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:44,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,519:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 13:23:44,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,520:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:44,699:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:44,700:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-06 13:23:44,701:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,701:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,715:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,839:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:44,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,895:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 13:23:44,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,896:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:45,080:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:45,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,107:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,221:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:45,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,275:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 13:23:45,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,276:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:45,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:45,442:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-06 13:23:45,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,471:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:45,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,639:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:45,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:45,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,968:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:45,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,025:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,025:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,026:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:46,206:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:46,207:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-06 13:23:46,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,234:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,405:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:46,579:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:46,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,606:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,718:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,777:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:46,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:46,954:INFO:Preparing preprocessing pipeline...
2023-02-06 13:23:46,956:INFO:Set up simple imputation.
2023-02-06 13:23:47,040:INFO:Finished creating preprocessing pipeline.
2023-02-06 13:23:47,049:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-02-06 13:23:47,049:INFO:Creating final display dataframe.
2023-02-06 13:23:47,263:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape          (962, 2)
4        Transformed data shape          (962, 2)
5   Transformed train set shape          (673, 2)
6    Transformed test set shape          (289, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              8710
2023-02-06 13:23:47,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,428:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,428:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,429:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:47,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:47,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,807:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:47,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:47,990:INFO:setup() successfully completed in 6.52s...............
2023-02-06 13:23:51,353:INFO:Initializing compare_models()
2023-02-06 13:23:51,353:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-06 13:23:51,354:INFO:Checking exceptions
2023-02-06 13:23:51,356:INFO:Preparing display monitor
2023-02-06 13:23:51,412:INFO:Initializing Linear Regression
2023-02-06 13:23:51,413:INFO:Total runtime is 1.6669432322184246e-05 minutes
2023-02-06 13:23:51,421:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:51,421:INFO:Initializing create_model()
2023-02-06 13:23:51,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:51,424:INFO:Checking exceptions
2023-02-06 13:23:51,426:INFO:Importing libraries
2023-02-06 13:23:51,427:INFO:Copying training dataset
2023-02-06 13:23:51,434:INFO:Defining folds
2023-02-06 13:23:51,434:INFO:Declaring metric variables
2023-02-06 13:23:51,442:INFO:Importing untrained model
2023-02-06 13:23:51,449:INFO:Linear Regression Imported successfully
2023-02-06 13:23:51,464:INFO:Starting cross validation
2023-02-06 13:23:51,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:52,720:INFO:Calculating mean and std
2023-02-06 13:23:52,726:INFO:Creating metrics dataframe
2023-02-06 13:23:52,732:INFO:Uploading results into container
2023-02-06 13:23:52,733:INFO:Uploading model into container now
2023-02-06 13:23:52,734:INFO:_master_model_container: 1
2023-02-06 13:23:52,734:INFO:_display_container: 2
2023-02-06 13:23:52,735:INFO:LinearRegression(n_jobs=-1)
2023-02-06 13:23:52,735:INFO:create_model() successfully completed......................................
2023-02-06 13:23:52,848:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:52,849:INFO:Creating metrics dataframe
2023-02-06 13:23:52,862:INFO:Initializing Lasso Regression
2023-02-06 13:23:52,862:INFO:Total runtime is 0.024169143040974936 minutes
2023-02-06 13:23:52,866:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:52,867:INFO:Initializing create_model()
2023-02-06 13:23:52,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:52,867:INFO:Checking exceptions
2023-02-06 13:23:52,867:INFO:Importing libraries
2023-02-06 13:23:52,868:INFO:Copying training dataset
2023-02-06 13:23:52,875:INFO:Defining folds
2023-02-06 13:23:52,876:INFO:Declaring metric variables
2023-02-06 13:23:52,881:INFO:Importing untrained model
2023-02-06 13:23:52,889:INFO:Lasso Regression Imported successfully
2023-02-06 13:23:52,906:INFO:Starting cross validation
2023-02-06 13:23:52,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:52,962:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.632e+08, tolerance: 1.978e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,012:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+08, tolerance: 1.993e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,063:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.045e+08, tolerance: 1.929e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,109:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.157e+08, tolerance: 2.040e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,159:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.967e+08, tolerance: 1.980e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,205:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.866e+08, tolerance: 2.009e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,252:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.263e+07, tolerance: 2.011e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,298:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.086e+08, tolerance: 2.004e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,347:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.600e+08, tolerance: 1.990e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,393:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.602e+08, tolerance: 2.033e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,411:INFO:Calculating mean and std
2023-02-06 13:23:53,413:INFO:Creating metrics dataframe
2023-02-06 13:23:53,417:INFO:Uploading results into container
2023-02-06 13:23:53,417:INFO:Uploading model into container now
2023-02-06 13:23:53,418:INFO:_master_model_container: 2
2023-02-06 13:23:53,418:INFO:_display_container: 2
2023-02-06 13:23:53,418:INFO:Lasso(random_state=123)
2023-02-06 13:23:53,418:INFO:create_model() successfully completed......................................
2023-02-06 13:23:53,518:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:53,519:INFO:Creating metrics dataframe
2023-02-06 13:23:53,535:INFO:Initializing Ridge Regression
2023-02-06 13:23:53,535:INFO:Total runtime is 0.03536992073059082 minutes
2023-02-06 13:23:53,542:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:53,542:INFO:Initializing create_model()
2023-02-06 13:23:53,542:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:53,542:INFO:Checking exceptions
2023-02-06 13:23:53,542:INFO:Importing libraries
2023-02-06 13:23:53,543:INFO:Copying training dataset
2023-02-06 13:23:53,546:INFO:Defining folds
2023-02-06 13:23:53,546:INFO:Declaring metric variables
2023-02-06 13:23:53,554:INFO:Importing untrained model
2023-02-06 13:23:53,563:INFO:Ridge Regression Imported successfully
2023-02-06 13:23:53,580:INFO:Starting cross validation
2023-02-06 13:23:53,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:53,903:INFO:Calculating mean and std
2023-02-06 13:23:53,905:INFO:Creating metrics dataframe
2023-02-06 13:23:53,909:INFO:Uploading results into container
2023-02-06 13:23:53,910:INFO:Uploading model into container now
2023-02-06 13:23:53,910:INFO:_master_model_container: 3
2023-02-06 13:23:53,911:INFO:_display_container: 2
2023-02-06 13:23:53,911:INFO:Ridge(random_state=123)
2023-02-06 13:23:53,911:INFO:create_model() successfully completed......................................
2023-02-06 13:23:54,010:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:54,011:INFO:Creating metrics dataframe
2023-02-06 13:23:54,026:INFO:Initializing Elastic Net
2023-02-06 13:23:54,026:INFO:Total runtime is 0.0435551921526591 minutes
2023-02-06 13:23:54,031:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:54,032:INFO:Initializing create_model()
2023-02-06 13:23:54,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:54,032:INFO:Checking exceptions
2023-02-06 13:23:54,032:INFO:Importing libraries
2023-02-06 13:23:54,033:INFO:Copying training dataset
2023-02-06 13:23:54,040:INFO:Defining folds
2023-02-06 13:23:54,040:INFO:Declaring metric variables
2023-02-06 13:23:54,048:INFO:Importing untrained model
2023-02-06 13:23:54,057:INFO:Elastic Net Imported successfully
2023-02-06 13:23:54,071:INFO:Starting cross validation
2023-02-06 13:23:54,073:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:54,100:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.823e+08, tolerance: 1.978e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,132:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.675e+08, tolerance: 1.993e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,162:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.480e+08, tolerance: 1.929e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,190:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.003e+08, tolerance: 2.040e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,217:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.984e+08, tolerance: 1.980e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,245:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.855e+08, tolerance: 2.009e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,273:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e+08, tolerance: 2.011e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,300:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.619e+08, tolerance: 2.004e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,328:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.329e+08, tolerance: 1.990e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,355:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.757e+08, tolerance: 2.033e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,366:INFO:Calculating mean and std
2023-02-06 13:23:54,367:INFO:Creating metrics dataframe
2023-02-06 13:23:54,372:INFO:Uploading results into container
2023-02-06 13:23:54,373:INFO:Uploading model into container now
2023-02-06 13:23:54,373:INFO:_master_model_container: 4
2023-02-06 13:23:54,373:INFO:_display_container: 2
2023-02-06 13:23:54,374:INFO:ElasticNet(random_state=123)
2023-02-06 13:23:54,374:INFO:create_model() successfully completed......................................
2023-02-06 13:23:54,472:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:54,473:INFO:Creating metrics dataframe
2023-02-06 13:23:54,485:INFO:Initializing Least Angle Regression
2023-02-06 13:23:54,486:INFO:Total runtime is 0.051221716403961184 minutes
2023-02-06 13:23:54,491:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:54,492:INFO:Initializing create_model()
2023-02-06 13:23:54,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:54,492:INFO:Checking exceptions
2023-02-06 13:23:54,492:INFO:Importing libraries
2023-02-06 13:23:54,492:INFO:Copying training dataset
2023-02-06 13:23:54,496:INFO:Defining folds
2023-02-06 13:23:54,496:INFO:Declaring metric variables
2023-02-06 13:23:54,503:INFO:Importing untrained model
2023-02-06 13:23:54,509:INFO:Least Angle Regression Imported successfully
2023-02-06 13:23:54,526:INFO:Starting cross validation
2023-02-06 13:23:54,528:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:54,601:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,646:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,673:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,698:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,724:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,748:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,775:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,800:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,826:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,856:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,868:INFO:Calculating mean and std
2023-02-06 13:23:54,870:INFO:Creating metrics dataframe
2023-02-06 13:23:54,875:INFO:Uploading results into container
2023-02-06 13:23:54,876:INFO:Uploading model into container now
2023-02-06 13:23:54,876:INFO:_master_model_container: 5
2023-02-06 13:23:54,877:INFO:_display_container: 2
2023-02-06 13:23:54,877:INFO:Lars(random_state=123)
2023-02-06 13:23:54,877:INFO:create_model() successfully completed......................................
2023-02-06 13:23:54,975:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:54,975:INFO:Creating metrics dataframe
2023-02-06 13:23:54,988:INFO:Initializing Lasso Least Angle Regression
2023-02-06 13:23:54,989:INFO:Total runtime is 0.059607346852620445 minutes
2023-02-06 13:23:54,994:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:54,994:INFO:Initializing create_model()
2023-02-06 13:23:54,995:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:54,995:INFO:Checking exceptions
2023-02-06 13:23:54,995:INFO:Importing libraries
2023-02-06 13:23:54,995:INFO:Copying training dataset
2023-02-06 13:23:54,999:INFO:Defining folds
2023-02-06 13:23:54,999:INFO:Declaring metric variables
2023-02-06 13:23:55,008:INFO:Importing untrained model
2023-02-06 13:23:55,014:INFO:Lasso Least Angle Regression Imported successfully
2023-02-06 13:23:55,032:INFO:Starting cross validation
2023-02-06 13:23:55,035:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:55,061:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,091:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,120:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,144:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,170:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,201:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,227:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,252:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,279:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,306:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,319:INFO:Calculating mean and std
2023-02-06 13:23:55,320:INFO:Creating metrics dataframe
2023-02-06 13:23:55,324:INFO:Uploading results into container
2023-02-06 13:23:55,325:INFO:Uploading model into container now
2023-02-06 13:23:55,326:INFO:_master_model_container: 6
2023-02-06 13:23:55,326:INFO:_display_container: 2
2023-02-06 13:23:55,327:INFO:LassoLars(random_state=123)
2023-02-06 13:23:55,327:INFO:create_model() successfully completed......................................
2023-02-06 13:23:55,420:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:55,421:INFO:Creating metrics dataframe
2023-02-06 13:23:55,434:INFO:Initializing Orthogonal Matching Pursuit
2023-02-06 13:23:55,434:INFO:Total runtime is 0.06702644427617391 minutes
2023-02-06 13:23:55,440:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:55,441:INFO:Initializing create_model()
2023-02-06 13:23:55,441:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:55,441:INFO:Checking exceptions
2023-02-06 13:23:55,441:INFO:Importing libraries
2023-02-06 13:23:55,442:INFO:Copying training dataset
2023-02-06 13:23:55,446:INFO:Defining folds
2023-02-06 13:23:55,446:INFO:Declaring metric variables
2023-02-06 13:23:55,454:INFO:Importing untrained model
2023-02-06 13:23:55,461:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-06 13:23:55,476:INFO:Starting cross validation
2023-02-06 13:23:55,477:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:55,504:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,543:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,571:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,600:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,628:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,656:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,682:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,715:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,741:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,767:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,779:INFO:Calculating mean and std
2023-02-06 13:23:55,781:INFO:Creating metrics dataframe
2023-02-06 13:23:55,786:INFO:Uploading results into container
2023-02-06 13:23:55,787:INFO:Uploading model into container now
2023-02-06 13:23:55,788:INFO:_master_model_container: 7
2023-02-06 13:23:55,788:INFO:_display_container: 2
2023-02-06 13:23:55,789:INFO:OrthogonalMatchingPursuit()
2023-02-06 13:23:55,789:INFO:create_model() successfully completed......................................
2023-02-06 13:23:55,883:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:55,884:INFO:Creating metrics dataframe
2023-02-06 13:23:55,900:INFO:Initializing Bayesian Ridge
2023-02-06 13:23:55,900:INFO:Total runtime is 0.07478955586751301 minutes
2023-02-06 13:23:55,905:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:55,905:INFO:Initializing create_model()
2023-02-06 13:23:55,905:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:55,905:INFO:Checking exceptions
2023-02-06 13:23:55,905:INFO:Importing libraries
2023-02-06 13:23:55,906:INFO:Copying training dataset
2023-02-06 13:23:55,911:INFO:Defining folds
2023-02-06 13:23:55,911:INFO:Declaring metric variables
2023-02-06 13:23:55,919:INFO:Importing untrained model
2023-02-06 13:23:55,926:INFO:Bayesian Ridge Imported successfully
2023-02-06 13:23:55,941:INFO:Starting cross validation
2023-02-06 13:23:55,942:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:56,236:INFO:Calculating mean and std
2023-02-06 13:23:56,237:INFO:Creating metrics dataframe
2023-02-06 13:23:56,242:INFO:Uploading results into container
2023-02-06 13:23:56,242:INFO:Uploading model into container now
2023-02-06 13:23:56,243:INFO:_master_model_container: 8
2023-02-06 13:23:56,243:INFO:_display_container: 2
2023-02-06 13:23:56,244:INFO:BayesianRidge()
2023-02-06 13:23:56,244:INFO:create_model() successfully completed......................................
2023-02-06 13:23:56,342:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:56,342:INFO:Creating metrics dataframe
2023-02-06 13:23:56,358:INFO:Initializing Passive Aggressive Regressor
2023-02-06 13:23:56,358:INFO:Total runtime is 0.08243235747019449 minutes
2023-02-06 13:23:56,363:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:56,364:INFO:Initializing create_model()
2023-02-06 13:23:56,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:56,364:INFO:Checking exceptions
2023-02-06 13:23:56,364:INFO:Importing libraries
2023-02-06 13:23:56,365:INFO:Copying training dataset
2023-02-06 13:23:56,370:INFO:Defining folds
2023-02-06 13:23:56,370:INFO:Declaring metric variables
2023-02-06 13:23:56,376:INFO:Importing untrained model
2023-02-06 13:23:56,384:INFO:Passive Aggressive Regressor Imported successfully
2023-02-06 13:23:56,396:INFO:Starting cross validation
2023-02-06 13:23:56,398:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:56,726:INFO:Calculating mean and std
2023-02-06 13:23:56,727:INFO:Creating metrics dataframe
2023-02-06 13:23:56,732:INFO:Uploading results into container
2023-02-06 13:23:56,732:INFO:Uploading model into container now
2023-02-06 13:23:56,734:INFO:_master_model_container: 9
2023-02-06 13:23:56,734:INFO:_display_container: 2
2023-02-06 13:23:56,735:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-06 13:23:56,735:INFO:create_model() successfully completed......................................
2023-02-06 13:23:56,829:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:56,830:INFO:Creating metrics dataframe
2023-02-06 13:23:56,845:INFO:Initializing Huber Regressor
2023-02-06 13:23:56,845:INFO:Total runtime is 0.09054499069849649 minutes
2023-02-06 13:23:56,852:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:56,853:INFO:Initializing create_model()
2023-02-06 13:23:56,853:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:56,853:INFO:Checking exceptions
2023-02-06 13:23:56,854:INFO:Importing libraries
2023-02-06 13:23:56,854:INFO:Copying training dataset
2023-02-06 13:23:56,859:INFO:Defining folds
2023-02-06 13:23:56,859:INFO:Declaring metric variables
2023-02-06 13:23:56,866:INFO:Importing untrained model
2023-02-06 13:23:56,872:INFO:Huber Regressor Imported successfully
2023-02-06 13:23:56,888:INFO:Starting cross validation
2023-02-06 13:23:56,889:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:57,240:INFO:Calculating mean and std
2023-02-06 13:23:57,241:INFO:Creating metrics dataframe
2023-02-06 13:23:57,245:INFO:Uploading results into container
2023-02-06 13:23:57,245:INFO:Uploading model into container now
2023-02-06 13:23:57,246:INFO:_master_model_container: 10
2023-02-06 13:23:57,246:INFO:_display_container: 2
2023-02-06 13:23:57,247:INFO:HuberRegressor()
2023-02-06 13:23:57,248:INFO:create_model() successfully completed......................................
2023-02-06 13:23:57,343:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:57,343:INFO:Creating metrics dataframe
2023-02-06 13:23:57,358:INFO:Initializing K Neighbors Regressor
2023-02-06 13:23:57,359:INFO:Total runtime is 0.0991073727607727 minutes
2023-02-06 13:23:57,364:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:57,365:INFO:Initializing create_model()
2023-02-06 13:23:57,365:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:57,365:INFO:Checking exceptions
2023-02-06 13:23:57,366:INFO:Importing libraries
2023-02-06 13:23:57,366:INFO:Copying training dataset
2023-02-06 13:23:57,370:INFO:Defining folds
2023-02-06 13:23:57,370:INFO:Declaring metric variables
2023-02-06 13:23:57,376:INFO:Importing untrained model
2023-02-06 13:23:57,383:INFO:K Neighbors Regressor Imported successfully
2023-02-06 13:23:57,394:INFO:Starting cross validation
2023-02-06 13:23:57,397:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:03,290:INFO:Calculating mean and std
2023-02-06 13:24:03,291:INFO:Creating metrics dataframe
2023-02-06 13:24:03,295:INFO:Uploading results into container
2023-02-06 13:24:03,295:INFO:Uploading model into container now
2023-02-06 13:24:03,296:INFO:_master_model_container: 11
2023-02-06 13:24:03,296:INFO:_display_container: 2
2023-02-06 13:24:03,297:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-06 13:24:03,297:INFO:create_model() successfully completed......................................
2023-02-06 13:24:03,392:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:03,392:INFO:Creating metrics dataframe
2023-02-06 13:24:03,406:INFO:Initializing Decision Tree Regressor
2023-02-06 13:24:03,406:INFO:Total runtime is 0.19990280469258626 minutes
2023-02-06 13:24:03,412:INFO:SubProcess create_model() called ==================================
2023-02-06 13:24:03,412:INFO:Initializing create_model()
2023-02-06 13:24:03,412:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:03,413:INFO:Checking exceptions
2023-02-06 13:24:03,413:INFO:Importing libraries
2023-02-06 13:24:03,413:INFO:Copying training dataset
2023-02-06 13:24:03,417:INFO:Defining folds
2023-02-06 13:24:03,417:INFO:Declaring metric variables
2023-02-06 13:24:03,424:INFO:Importing untrained model
2023-02-06 13:24:03,430:INFO:Decision Tree Regressor Imported successfully
2023-02-06 13:24:03,445:INFO:Starting cross validation
2023-02-06 13:24:03,447:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:03,744:INFO:Calculating mean and std
2023-02-06 13:24:03,745:INFO:Creating metrics dataframe
2023-02-06 13:24:03,749:INFO:Uploading results into container
2023-02-06 13:24:03,750:INFO:Uploading model into container now
2023-02-06 13:24:03,750:INFO:_master_model_container: 12
2023-02-06 13:24:03,751:INFO:_display_container: 2
2023-02-06 13:24:03,751:INFO:DecisionTreeRegressor(random_state=123)
2023-02-06 13:24:03,752:INFO:create_model() successfully completed......................................
2023-02-06 13:24:03,847:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:03,847:INFO:Creating metrics dataframe
2023-02-06 13:24:03,864:INFO:Initializing Random Forest Regressor
2023-02-06 13:24:03,864:INFO:Total runtime is 0.20753448009490966 minutes
2023-02-06 13:24:03,870:INFO:SubProcess create_model() called ==================================
2023-02-06 13:24:03,871:INFO:Initializing create_model()
2023-02-06 13:24:03,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:03,871:INFO:Checking exceptions
2023-02-06 13:24:03,872:INFO:Importing libraries
2023-02-06 13:24:03,872:INFO:Copying training dataset
2023-02-06 13:24:03,876:INFO:Defining folds
2023-02-06 13:24:03,876:INFO:Declaring metric variables
2023-02-06 13:24:03,884:INFO:Importing untrained model
2023-02-06 13:24:03,892:INFO:Random Forest Regressor Imported successfully
2023-02-06 13:24:03,912:INFO:Starting cross validation
2023-02-06 13:24:03,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:06,226:INFO:Calculating mean and std
2023-02-06 13:24:06,228:INFO:Creating metrics dataframe
2023-02-06 13:24:06,236:INFO:Uploading results into container
2023-02-06 13:24:06,237:INFO:Uploading model into container now
2023-02-06 13:24:06,238:INFO:_master_model_container: 13
2023-02-06 13:24:06,238:INFO:_display_container: 2
2023-02-06 13:24:06,238:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-06 13:24:06,239:INFO:create_model() successfully completed......................................
2023-02-06 13:24:06,345:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:06,345:INFO:Creating metrics dataframe
2023-02-06 13:24:06,367:INFO:Initializing Extra Trees Regressor
2023-02-06 13:24:06,368:INFO:Total runtime is 0.24925457239151 minutes
2023-02-06 13:24:06,372:INFO:SubProcess create_model() called ==================================
2023-02-06 13:24:06,372:INFO:Initializing create_model()
2023-02-06 13:24:06,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:06,373:INFO:Checking exceptions
2023-02-06 13:24:06,373:INFO:Importing libraries
2023-02-06 13:24:06,373:INFO:Copying training dataset
2023-02-06 13:24:06,378:INFO:Defining folds
2023-02-06 13:24:06,378:INFO:Declaring metric variables
2023-02-06 13:24:06,387:INFO:Importing untrained model
2023-02-06 13:24:06,396:INFO:Extra Trees Regressor Imported successfully
2023-02-06 13:24:06,411:INFO:Starting cross validation
2023-02-06 13:24:06,412:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:08,584:INFO:Calculating mean and std
2023-02-06 13:24:08,586:INFO:Creating metrics dataframe
2023-02-06 13:24:08,591:INFO:Uploading results into container
2023-02-06 13:24:08,592:INFO:Uploading model into container now
2023-02-06 13:24:08,592:INFO:_master_model_container: 14
2023-02-06 13:24:08,592:INFO:_display_container: 2
2023-02-06 13:24:08,593:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-06 13:24:08,594:INFO:create_model() successfully completed......................................
2023-02-06 13:24:08,696:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:08,696:INFO:Creating metrics dataframe
2023-02-06 13:24:08,713:INFO:Initializing AdaBoost Regressor
2023-02-06 13:24:08,714:INFO:Total runtime is 0.2883580684661865 minutes
2023-02-06 13:24:08,720:INFO:SubProcess create_model() called ==================================
2023-02-06 13:24:08,721:INFO:Initializing create_model()
2023-02-06 13:24:08,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:08,722:INFO:Checking exceptions
2023-02-06 13:24:08,722:INFO:Importing libraries
2023-02-06 13:24:08,722:INFO:Copying training dataset
2023-02-06 13:24:08,728:INFO:Defining folds
2023-02-06 13:24:08,730:INFO:Declaring metric variables
2023-02-06 13:24:08,739:INFO:Importing untrained model
2023-02-06 13:24:08,747:INFO:AdaBoost Regressor Imported successfully
2023-02-06 13:24:08,760:INFO:Starting cross validation
2023-02-06 13:24:08,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:09,437:INFO:Calculating mean and std
2023-02-06 13:24:09,439:INFO:Creating metrics dataframe
2023-02-06 13:24:09,446:INFO:Uploading results into container
2023-02-06 13:24:09,447:INFO:Uploading model into container now
2023-02-06 13:24:09,448:INFO:_master_model_container: 15
2023-02-06 13:24:09,448:INFO:_display_container: 2
2023-02-06 13:24:09,449:INFO:AdaBoostRegressor(random_state=123)
2023-02-06 13:24:09,449:INFO:create_model() successfully completed......................................
2023-02-06 13:24:09,550:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:09,550:INFO:Creating metrics dataframe
2023-02-06 13:24:09,569:INFO:Initializing Gradient Boosting Regressor
2023-02-06 13:24:09,570:INFO:Total runtime is 0.3026328881581624 minutes
2023-02-06 13:24:09,576:INFO:SubProcess create_model() called ==================================
2023-02-06 13:24:09,577:INFO:Initializing create_model()
2023-02-06 13:24:09,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:09,577:INFO:Checking exceptions
2023-02-06 13:24:09,577:INFO:Importing libraries
2023-02-06 13:24:09,578:INFO:Copying training dataset
2023-02-06 13:24:09,581:INFO:Defining folds
2023-02-06 13:24:09,581:INFO:Declaring metric variables
2023-02-06 13:24:09,588:INFO:Importing untrained model
2023-02-06 13:24:09,596:INFO:Gradient Boosting Regressor Imported successfully
2023-02-06 13:24:09,608:INFO:Starting cross validation
2023-02-06 13:24:09,611:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:10,382:INFO:Calculating mean and std
2023-02-06 13:24:10,383:INFO:Creating metrics dataframe
2023-02-06 13:24:10,388:INFO:Uploading results into container
2023-02-06 13:24:10,389:INFO:Uploading model into container now
2023-02-06 13:24:10,391:INFO:_master_model_container: 16
2023-02-06 13:24:10,391:INFO:_display_container: 2
2023-02-06 13:24:10,392:INFO:GradientBoostingRegressor(random_state=123)
2023-02-06 13:24:10,392:INFO:create_model() successfully completed......................................
2023-02-06 13:24:10,491:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:10,491:INFO:Creating metrics dataframe
2023-02-06 13:24:10,510:INFO:Initializing Extreme Gradient Boosting
2023-02-06 13:24:10,511:INFO:Total runtime is 0.3183120290438334 minutes
2023-02-06 13:24:10,518:INFO:SubProcess create_model() called ==================================
2023-02-06 13:24:10,518:INFO:Initializing create_model()
2023-02-06 13:24:10,519:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:10,519:INFO:Checking exceptions
2023-02-06 13:24:10,519:INFO:Importing libraries
2023-02-06 13:24:10,519:INFO:Copying training dataset
2023-02-06 13:24:10,524:INFO:Defining folds
2023-02-06 13:24:10,524:INFO:Declaring metric variables
2023-02-06 13:24:10,532:INFO:Importing untrained model
2023-02-06 13:24:10,538:INFO:Extreme Gradient Boosting Imported successfully
2023-02-06 13:24:10,552:INFO:Starting cross validation
2023-02-06 13:24:10,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:16,073:INFO:Calculating mean and std
2023-02-06 13:24:16,077:INFO:Creating metrics dataframe
2023-02-06 13:24:16,085:INFO:Uploading results into container
2023-02-06 13:24:16,086:INFO:Uploading model into container now
2023-02-06 13:24:16,087:INFO:_master_model_container: 17
2023-02-06 13:24:16,088:INFO:_display_container: 2
2023-02-06 13:24:16,090:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-02-06 13:24:16,090:INFO:create_model() successfully completed......................................
2023-02-06 13:24:16,227:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:16,227:INFO:Creating metrics dataframe
2023-02-06 13:24:16,245:INFO:Initializing Light Gradient Boosting Machine
2023-02-06 13:24:16,245:INFO:Total runtime is 0.41387817064921056 minutes
2023-02-06 13:24:16,253:INFO:SubProcess create_model() called ==================================
2023-02-06 13:24:16,254:INFO:Initializing create_model()
2023-02-06 13:24:16,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:16,254:INFO:Checking exceptions
2023-02-06 13:24:16,255:INFO:Importing libraries
2023-02-06 13:24:16,255:INFO:Copying training dataset
2023-02-06 13:24:16,258:INFO:Defining folds
2023-02-06 13:24:16,259:INFO:Declaring metric variables
2023-02-06 13:24:16,265:INFO:Importing untrained model
2023-02-06 13:24:16,274:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-06 13:24:16,287:INFO:Starting cross validation
2023-02-06 13:24:16,288:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:24,303:INFO:Calculating mean and std
2023-02-06 13:24:24,305:INFO:Creating metrics dataframe
2023-02-06 13:24:24,312:INFO:Uploading results into container
2023-02-06 13:24:24,314:INFO:Uploading model into container now
2023-02-06 13:24:24,315:INFO:_master_model_container: 18
2023-02-06 13:24:24,315:INFO:_display_container: 2
2023-02-06 13:24:24,316:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-02-06 13:24:24,317:INFO:create_model() successfully completed......................................
2023-02-06 13:24:24,442:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:24,442:INFO:Creating metrics dataframe
2023-02-06 13:24:24,461:INFO:Initializing Dummy Regressor
2023-02-06 13:24:24,461:INFO:Total runtime is 0.5508141994476318 minutes
2023-02-06 13:24:24,468:INFO:SubProcess create_model() called ==================================
2023-02-06 13:24:24,469:INFO:Initializing create_model()
2023-02-06 13:24:24,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:24,469:INFO:Checking exceptions
2023-02-06 13:24:24,469:INFO:Importing libraries
2023-02-06 13:24:24,469:INFO:Copying training dataset
2023-02-06 13:24:24,474:INFO:Defining folds
2023-02-06 13:24:24,474:INFO:Declaring metric variables
2023-02-06 13:24:24,480:INFO:Importing untrained model
2023-02-06 13:24:24,489:INFO:Dummy Regressor Imported successfully
2023-02-06 13:24:24,508:INFO:Starting cross validation
2023-02-06 13:24:24,509:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:24,798:INFO:Calculating mean and std
2023-02-06 13:24:24,801:INFO:Creating metrics dataframe
2023-02-06 13:24:24,806:INFO:Uploading results into container
2023-02-06 13:24:24,807:INFO:Uploading model into container now
2023-02-06 13:24:24,807:INFO:_master_model_container: 19
2023-02-06 13:24:24,807:INFO:_display_container: 2
2023-02-06 13:24:24,808:INFO:DummyRegressor()
2023-02-06 13:24:24,808:INFO:create_model() successfully completed......................................
2023-02-06 13:24:24,916:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:24,916:INFO:Creating metrics dataframe
2023-02-06 13:24:24,955:INFO:Initializing create_model()
2023-02-06 13:24:24,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:24,955:INFO:Checking exceptions
2023-02-06 13:24:24,960:INFO:Importing libraries
2023-02-06 13:24:24,960:INFO:Copying training dataset
2023-02-06 13:24:24,968:INFO:Defining folds
2023-02-06 13:24:24,969:INFO:Declaring metric variables
2023-02-06 13:24:24,969:INFO:Importing untrained model
2023-02-06 13:24:24,970:INFO:Declaring custom model
2023-02-06 13:24:24,971:INFO:Linear Regression Imported successfully
2023-02-06 13:24:24,973:INFO:Cross validation set to False
2023-02-06 13:24:24,973:INFO:Fitting Model
2023-02-06 13:24:25,011:INFO:LinearRegression(n_jobs=-1)
2023-02-06 13:24:25,012:INFO:create_model() successfully completed......................................
2023-02-06 13:24:25,178:INFO:_master_model_container: 19
2023-02-06 13:24:25,178:INFO:_display_container: 2
2023-02-06 13:24:25,178:INFO:LinearRegression(n_jobs=-1)
2023-02-06 13:24:25,179:INFO:compare_models() successfully completed......................................
2023-02-06 13:24:31,697:INFO:Initializing create_model()
2023-02-06 13:24:31,698:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:31,698:INFO:Checking exceptions
2023-02-06 13:24:31,741:INFO:Importing libraries
2023-02-06 13:24:31,741:INFO:Copying training dataset
2023-02-06 13:24:31,751:INFO:Defining folds
2023-02-06 13:24:31,751:INFO:Declaring metric variables
2023-02-06 13:24:31,761:INFO:Importing untrained model
2023-02-06 13:24:31,766:INFO:Huber Regressor Imported successfully
2023-02-06 13:24:31,783:INFO:Starting cross validation
2023-02-06 13:24:31,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:32,360:INFO:Calculating mean and std
2023-02-06 13:24:32,361:INFO:Creating metrics dataframe
2023-02-06 13:24:32,367:INFO:Finalizing model
2023-02-06 13:24:32,417:INFO:Uploading results into container
2023-02-06 13:24:32,420:INFO:Uploading model into container now
2023-02-06 13:24:32,437:INFO:_master_model_container: 20
2023-02-06 13:24:32,437:INFO:_display_container: 3
2023-02-06 13:24:32,438:INFO:HuberRegressor()
2023-02-06 13:24:32,438:INFO:create_model() successfully completed......................................
2023-02-06 13:24:36,800:INFO:Initializing evaluate_model()
2023-02-06 13:24:36,800:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-06 13:24:36,828:INFO:Initializing plot_model()
2023-02-06 13:24:36,829:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, system=True)
2023-02-06 13:24:36,829:INFO:Checking exceptions
2023-02-06 13:24:36,836:INFO:Preloading libraries
2023-02-06 13:24:36,837:INFO:Copying training dataset
2023-02-06 13:24:36,837:INFO:Plot type: pipeline
2023-02-06 13:24:37,174:INFO:Visual Rendered Successfully
2023-02-06 13:24:37,291:INFO:plot_model() successfully completed......................................
2023-02-06 13:24:41,034:INFO:Initializing plot_model()
2023-02-06 13:24:41,035:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, system=True)
2023-02-06 13:24:41,035:INFO:Checking exceptions
2023-02-06 13:24:41,041:INFO:Preloading libraries
2023-02-06 13:24:41,041:INFO:Copying training dataset
2023-02-06 13:24:41,042:INFO:Plot type: parameter
2023-02-06 13:24:41,049:INFO:Visual Rendered Successfully
2023-02-06 13:24:41,174:INFO:plot_model() successfully completed......................................
2023-02-06 13:24:41,895:INFO:Initializing plot_model()
2023-02-06 13:24:41,896:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, system=True)
2023-02-06 13:24:41,896:INFO:Checking exceptions
2023-02-06 13:24:41,902:INFO:Preloading libraries
2023-02-06 13:24:41,903:INFO:Copying training dataset
2023-02-06 13:24:41,904:INFO:Plot type: residuals
2023-02-06 13:24:42,045:INFO:Fitting Model
2023-02-06 13:24:42,046:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2023-02-06 13:24:42,104:INFO:Scoring test/hold-out set
2023-02-06 13:24:42,889:INFO:Visual Rendered Successfully
2023-02-06 13:24:43,005:INFO:plot_model() successfully completed......................................
2023-02-06 13:24:46,748:INFO:Initializing predict_model()
2023-02-06 13:24:46,748:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001B4836C3520>)
2023-02-06 13:24:46,749:INFO:Checking exceptions
2023-02-06 13:24:46,749:INFO:Preloading libraries
2023-02-06 13:24:46,753:INFO:Set up data.
2023-02-06 13:24:46,761:INFO:Set up index.
2023-02-06 16:33:30,803:INFO:PyCaret RegressionExperiment
2023-02-06 16:33:30,804:INFO:Logging name: reg-default-name
2023-02-06 16:33:30,805:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-06 16:33:30,805:INFO:version 3.0.0.rc8
2023-02-06 16:33:30,806:INFO:Initializing setup()
2023-02-06 16:33:30,806:INFO:self.USI: 120e
2023-02-06 16:33:30,807:INFO:self._variable_keys: {'log_plots_param', 'n_jobs_param', '_available_plots', 'y', 'exp_name_log', 'USI', 'html_param', 'logging_param', 'fold_shuffle_param', 'y_test', 'memory', 'seed', 'idx', 'fold_generator', 'X', '_ml_usecase', 'data', 'exp_id', 'X_train', 'gpu_n_jobs_param', 'pipeline', 'fold_groups_param', 'gpu_param', 'target_param', 'y_train', 'transform_target_param', 'X_test'}
2023-02-06 16:33:30,808:INFO:Checking environment
2023-02-06 16:33:30,808:INFO:python_version: 3.10.9
2023-02-06 16:33:30,809:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-02-06 16:33:30,810:INFO:machine: AMD64
2023-02-06 16:33:30,811:INFO:platform: Windows-10-10.0.19045-SP0
2023-02-06 16:33:30,812:INFO:Memory: svmem(total=17090879488, available=6271623168, percent=63.3, used=10819256320, free=6271623168)
2023-02-06 16:33:30,813:INFO:Physical Core: 4
2023-02-06 16:33:30,814:INFO:Logical Core: 8
2023-02-06 16:33:30,815:INFO:Checking libraries
2023-02-06 16:33:30,816:INFO:System:
2023-02-06 16:33:30,816:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-02-06 16:33:30,817:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-02-06 16:33:30,818:INFO:   machine: Windows-10-10.0.19045-SP0
2023-02-06 16:33:30,818:INFO:PyCaret required dependencies:
2023-02-06 16:33:30,820:INFO:                 pip: 23.0
2023-02-06 16:33:30,821:INFO:          setuptools: 67.1.0
2023-02-06 16:33:30,822:INFO:             pycaret: 3.0.0rc8
2023-02-06 16:33:30,823:INFO:             IPython: 8.8.0
2023-02-06 16:33:30,823:INFO:          ipywidgets: 8.0.4
2023-02-06 16:33:30,824:INFO:                tqdm: 4.64.1
2023-02-06 16:33:30,824:INFO:               numpy: 1.23.5
2023-02-06 16:33:30,825:INFO:              pandas: 1.5.3
2023-02-06 16:33:30,825:INFO:              jinja2: 3.1.2
2023-02-06 16:33:30,826:INFO:               scipy: 1.10.0
2023-02-06 16:33:30,827:INFO:              joblib: 1.2.0
2023-02-06 16:33:30,828:INFO:             sklearn: 1.1.3
2023-02-06 16:33:30,829:INFO:                pyod: 1.0.7
2023-02-06 16:33:30,830:INFO:            imblearn: 0.10.1
2023-02-06 16:33:30,831:INFO:   category_encoders: 2.6.0
2023-02-06 16:33:30,832:INFO:            lightgbm: 3.3.5
2023-02-06 16:33:30,832:INFO:               numba: 0.56.4
2023-02-06 16:33:30,833:INFO:            requests: 2.28.2
2023-02-06 16:33:30,833:INFO:          matplotlib: 3.6.3
2023-02-06 16:33:30,834:INFO:          scikitplot: 0.3.7
2023-02-06 16:33:30,835:INFO:         yellowbrick: 1.5
2023-02-06 16:33:30,835:INFO:              plotly: 5.13.0
2023-02-06 16:33:30,836:INFO:             kaleido: 0.2.1
2023-02-06 16:33:30,836:INFO:         statsmodels: 0.13.5
2023-02-06 16:33:30,837:INFO:              sktime: 0.16.0
2023-02-06 16:33:30,837:INFO:               tbats: 1.1.2
2023-02-06 16:33:30,838:INFO:            pmdarima: 2.0.2
2023-02-06 16:33:30,838:INFO:              psutil: 5.9.0
2023-02-06 16:33:30,838:INFO:PyCaret optional dependencies:
2023-02-06 16:33:30,838:INFO:                shap: Not installed
2023-02-06 16:33:30,839:INFO:           interpret: Not installed
2023-02-06 16:33:30,839:INFO:                umap: Not installed
2023-02-06 16:33:30,839:INFO:    pandas_profiling: Not installed
2023-02-06 16:33:30,839:INFO:  explainerdashboard: Not installed
2023-02-06 16:33:30,839:INFO:             autoviz: Not installed
2023-02-06 16:33:30,840:INFO:           fairlearn: Not installed
2023-02-06 16:33:30,840:INFO:             xgboost: 1.7.3
2023-02-06 16:33:30,840:INFO:            catboost: Not installed
2023-02-06 16:33:30,841:INFO:              kmodes: Not installed
2023-02-06 16:33:30,842:INFO:             mlxtend: Not installed
2023-02-06 16:33:30,842:INFO:       statsforecast: Not installed
2023-02-06 16:33:30,842:INFO:        tune_sklearn: Not installed
2023-02-06 16:33:30,843:INFO:                 ray: Not installed
2023-02-06 16:33:30,843:INFO:            hyperopt: Not installed
2023-02-06 16:33:30,844:INFO:              optuna: Not installed
2023-02-06 16:33:30,844:INFO:               skopt: Not installed
2023-02-06 16:33:30,844:INFO:              mlflow: Not installed
2023-02-06 16:33:30,845:INFO:              gradio: Not installed
2023-02-06 16:33:30,845:INFO:             fastapi: Not installed
2023-02-06 16:33:30,845:INFO:             uvicorn: Not installed
2023-02-06 16:33:30,845:INFO:              m2cgen: Not installed
2023-02-06 16:33:30,846:INFO:           evidently: Not installed
2023-02-06 16:33:30,847:INFO:                nltk: Not installed
2023-02-06 16:33:30,848:INFO:            pyLDAvis: Not installed
2023-02-06 16:33:30,849:INFO:              gensim: Not installed
2023-02-06 16:33:30,849:INFO:               spacy: Not installed
2023-02-06 16:33:30,849:INFO:           wordcloud: Not installed
2023-02-06 16:33:30,849:INFO:            textblob: Not installed
2023-02-06 16:33:30,850:INFO:               fugue: Not installed
2023-02-06 16:33:30,850:INFO:           streamlit: Not installed
2023-02-06 16:33:30,850:INFO:             prophet: Not installed
2023-02-06 16:33:30,850:INFO:None
2023-02-06 16:33:30,851:INFO:Set up GPU usage.
2023-02-06 16:33:30,852:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:30,852:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-02-06 16:33:30,853:INFO:Set up data.
2023-02-06 16:33:30,865:INFO:Set up train/test split.
2023-02-06 16:33:30,877:INFO:Set up index.
2023-02-06 16:33:30,877:INFO:Set up folding strategy.
2023-02-06 16:33:30,878:INFO:Assigning column types.
2023-02-06 16:33:30,887:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-06 16:33:30,888:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:30,889:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-06 16:33:30,890:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:30,899:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-06 16:33:30,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:30,908:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 16:33:30,908:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:30,992:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:30,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,053:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 16:33:31,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,056:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:31,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:31,586:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,586:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-06 16:33:31,587:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,600:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-06 16:33:31,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,613:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 16:33:31,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,739:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:31,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,816:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 16:33:31,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,818:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:32,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:32,012:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-06 16:33:32,012:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,012:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,022:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,038:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,151:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,151:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,214:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,215:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:32,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:32,433:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,433:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,446:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,469:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,470:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,594:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,672:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,673:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,673:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,675:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:32,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:32,841:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-06 16:33:32,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,868:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,868:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,993:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,065:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 16:33:33,065:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,065:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,066:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:33,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:33,230:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,230:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,257:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 16:33:33,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,376:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:33,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,437:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 16:33:33,437:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,437:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,438:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:33,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:33,613:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-06 16:33:33,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,646:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,770:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:33,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,836:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 16:33:33,836:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,836:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,837:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:34,010:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:34,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,040:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,158:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:34,158:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 16:33:34,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,216:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:34,381:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:34,382:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-06 16:33:34,382:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,395:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,537:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:34,537:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,611:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,611:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:34,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:34,777:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,777:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,807:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,932:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:34,932:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,996:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:35,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:35,157:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-06 16:33:35,158:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,158:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,172:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,308:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,399:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:35,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:35,571:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,571:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,717:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,776:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:35,953:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:35,956:INFO:Preparing preprocessing pipeline...
2023-02-06 16:33:35,958:INFO:Set up simple imputation.
2023-02-06 16:33:35,982:INFO:Finished creating preprocessing pipeline.
2023-02-06 16:33:35,996:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-02-06 16:33:35,996:INFO:Creating final display dataframe.
2023-02-06 16:33:36,112:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape          (962, 2)
4        Transformed data shape          (962, 2)
5   Transformed train set shape          (673, 2)
6    Transformed test set shape          (289, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              120e
2023-02-06 16:33:36,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,139:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,278:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:36,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:36,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,454:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,480:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,658:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,658:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,658:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:36,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:36,832:INFO:setup() successfully completed in 6.04s...............
2023-02-06 16:33:43,922:INFO:Initializing compare_models()
2023-02-06 16:33:43,923:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-06 16:33:43,923:INFO:Checking exceptions
2023-02-06 16:33:43,926:INFO:Preparing display monitor
2023-02-06 16:33:44,007:INFO:Initializing Linear Regression
2023-02-06 16:33:44,007:INFO:Total runtime is 0.0 minutes
2023-02-06 16:33:44,016:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:44,017:INFO:Initializing create_model()
2023-02-06 16:33:44,017:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:44,018:INFO:Checking exceptions
2023-02-06 16:33:44,018:INFO:Importing libraries
2023-02-06 16:33:44,019:INFO:Copying training dataset
2023-02-06 16:33:44,026:INFO:Defining folds
2023-02-06 16:33:44,026:INFO:Declaring metric variables
2023-02-06 16:33:44,034:INFO:Importing untrained model
2023-02-06 16:33:44,045:INFO:Linear Regression Imported successfully
2023-02-06 16:33:44,063:INFO:Starting cross validation
2023-02-06 16:33:44,066:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:44,478:INFO:Calculating mean and std
2023-02-06 16:33:44,479:INFO:Creating metrics dataframe
2023-02-06 16:33:44,483:INFO:Uploading results into container
2023-02-06 16:33:44,484:INFO:Uploading model into container now
2023-02-06 16:33:44,484:INFO:_master_model_container: 1
2023-02-06 16:33:44,484:INFO:_display_container: 2
2023-02-06 16:33:44,485:INFO:LinearRegression(n_jobs=-1)
2023-02-06 16:33:44,485:INFO:create_model() successfully completed......................................
2023-02-06 16:33:44,732:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:44,732:INFO:Creating metrics dataframe
2023-02-06 16:33:44,748:INFO:Initializing Lasso Regression
2023-02-06 16:33:44,748:INFO:Total runtime is 0.012342242399851482 minutes
2023-02-06 16:33:44,755:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:44,756:INFO:Initializing create_model()
2023-02-06 16:33:44,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:44,756:INFO:Checking exceptions
2023-02-06 16:33:44,757:INFO:Importing libraries
2023-02-06 16:33:44,757:INFO:Copying training dataset
2023-02-06 16:33:44,761:INFO:Defining folds
2023-02-06 16:33:44,761:INFO:Declaring metric variables
2023-02-06 16:33:44,767:INFO:Importing untrained model
2023-02-06 16:33:44,780:INFO:Lasso Regression Imported successfully
2023-02-06 16:33:44,800:INFO:Starting cross validation
2023-02-06 16:33:44,801:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:44,832:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.632e+08, tolerance: 1.978e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:44,883:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+08, tolerance: 1.993e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:44,921:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.045e+08, tolerance: 1.929e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:44,955:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.157e+08, tolerance: 2.040e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:44,993:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.967e+08, tolerance: 1.980e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:45,028:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.866e+08, tolerance: 2.009e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:45,063:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.263e+07, tolerance: 2.011e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:45,096:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.086e+08, tolerance: 2.004e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:45,132:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.600e+08, tolerance: 1.990e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:45,165:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.602e+08, tolerance: 2.033e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:45,180:INFO:Calculating mean and std
2023-02-06 16:33:45,182:INFO:Creating metrics dataframe
2023-02-06 16:33:45,191:INFO:Uploading results into container
2023-02-06 16:33:45,192:INFO:Uploading model into container now
2023-02-06 16:33:45,192:INFO:_master_model_container: 2
2023-02-06 16:33:45,193:INFO:_display_container: 2
2023-02-06 16:33:45,194:INFO:Lasso(random_state=123)
2023-02-06 16:33:45,194:INFO:create_model() successfully completed......................................
2023-02-06 16:33:45,325:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:45,325:INFO:Creating metrics dataframe
2023-02-06 16:33:45,341:INFO:Initializing Ridge Regression
2023-02-06 16:33:45,342:INFO:Total runtime is 0.022249281406402588 minutes
2023-02-06 16:33:45,347:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:45,348:INFO:Initializing create_model()
2023-02-06 16:33:45,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:45,348:INFO:Checking exceptions
2023-02-06 16:33:45,348:INFO:Importing libraries
2023-02-06 16:33:45,348:INFO:Copying training dataset
2023-02-06 16:33:45,356:INFO:Defining folds
2023-02-06 16:33:45,356:INFO:Declaring metric variables
2023-02-06 16:33:45,362:INFO:Importing untrained model
2023-02-06 16:33:45,369:INFO:Ridge Regression Imported successfully
2023-02-06 16:33:45,388:INFO:Starting cross validation
2023-02-06 16:33:45,390:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:45,692:INFO:Calculating mean and std
2023-02-06 16:33:45,694:INFO:Creating metrics dataframe
2023-02-06 16:33:45,698:INFO:Uploading results into container
2023-02-06 16:33:45,698:INFO:Uploading model into container now
2023-02-06 16:33:45,699:INFO:_master_model_container: 3
2023-02-06 16:33:45,699:INFO:_display_container: 2
2023-02-06 16:33:45,699:INFO:Ridge(random_state=123)
2023-02-06 16:33:45,699:INFO:create_model() successfully completed......................................
2023-02-06 16:33:45,813:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:45,813:INFO:Creating metrics dataframe
2023-02-06 16:33:45,829:INFO:Initializing Elastic Net
2023-02-06 16:33:45,829:INFO:Total runtime is 0.030365554491678874 minutes
2023-02-06 16:33:45,836:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:45,837:INFO:Initializing create_model()
2023-02-06 16:33:45,837:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:45,837:INFO:Checking exceptions
2023-02-06 16:33:45,837:INFO:Importing libraries
2023-02-06 16:33:45,837:INFO:Copying training dataset
2023-02-06 16:33:45,841:INFO:Defining folds
2023-02-06 16:33:45,842:INFO:Declaring metric variables
2023-02-06 16:33:45,847:INFO:Importing untrained model
2023-02-06 16:33:45,856:INFO:Elastic Net Imported successfully
2023-02-06 16:33:45,874:INFO:Starting cross validation
2023-02-06 16:33:45,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:45,901:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.823e+08, tolerance: 1.978e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:45,937:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.675e+08, tolerance: 1.993e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:45,970:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.480e+08, tolerance: 1.929e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:46,003:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.003e+08, tolerance: 2.040e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:46,033:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.984e+08, tolerance: 1.980e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:46,062:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.855e+08, tolerance: 2.009e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:46,100:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e+08, tolerance: 2.011e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:46,141:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.619e+08, tolerance: 2.004e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:46,180:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.329e+08, tolerance: 1.990e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:46,213:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.757e+08, tolerance: 2.033e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:46,226:INFO:Calculating mean and std
2023-02-06 16:33:46,228:INFO:Creating metrics dataframe
2023-02-06 16:33:46,231:INFO:Uploading results into container
2023-02-06 16:33:46,232:INFO:Uploading model into container now
2023-02-06 16:33:46,233:INFO:_master_model_container: 4
2023-02-06 16:33:46,234:INFO:_display_container: 2
2023-02-06 16:33:46,235:INFO:ElasticNet(random_state=123)
2023-02-06 16:33:46,235:INFO:create_model() successfully completed......................................
2023-02-06 16:33:46,347:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:46,347:INFO:Creating metrics dataframe
2023-02-06 16:33:46,363:INFO:Initializing Least Angle Regression
2023-02-06 16:33:46,364:INFO:Total runtime is 0.0392874002456665 minutes
2023-02-06 16:33:46,375:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:46,375:INFO:Initializing create_model()
2023-02-06 16:33:46,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:46,376:INFO:Checking exceptions
2023-02-06 16:33:46,376:INFO:Importing libraries
2023-02-06 16:33:46,376:INFO:Copying training dataset
2023-02-06 16:33:46,381:INFO:Defining folds
2023-02-06 16:33:46,383:INFO:Declaring metric variables
2023-02-06 16:33:46,393:INFO:Importing untrained model
2023-02-06 16:33:46,398:INFO:Least Angle Regression Imported successfully
2023-02-06 16:33:46,418:INFO:Starting cross validation
2023-02-06 16:33:46,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:46,450:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,509:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,571:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,602:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,630:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,658:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,688:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,718:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,747:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,777:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,794:INFO:Calculating mean and std
2023-02-06 16:33:46,796:INFO:Creating metrics dataframe
2023-02-06 16:33:46,804:INFO:Uploading results into container
2023-02-06 16:33:46,805:INFO:Uploading model into container now
2023-02-06 16:33:46,806:INFO:_master_model_container: 5
2023-02-06 16:33:46,806:INFO:_display_container: 2
2023-02-06 16:33:46,807:INFO:Lars(random_state=123)
2023-02-06 16:33:46,807:INFO:create_model() successfully completed......................................
2023-02-06 16:33:46,931:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:46,931:INFO:Creating metrics dataframe
2023-02-06 16:33:46,947:INFO:Initializing Lasso Least Angle Regression
2023-02-06 16:33:46,947:INFO:Total runtime is 0.04899345239003499 minutes
2023-02-06 16:33:46,957:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:46,958:INFO:Initializing create_model()
2023-02-06 16:33:46,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:46,958:INFO:Checking exceptions
2023-02-06 16:33:46,958:INFO:Importing libraries
2023-02-06 16:33:46,959:INFO:Copying training dataset
2023-02-06 16:33:46,963:INFO:Defining folds
2023-02-06 16:33:46,963:INFO:Declaring metric variables
2023-02-06 16:33:46,972:INFO:Importing untrained model
2023-02-06 16:33:46,978:INFO:Lasso Least Angle Regression Imported successfully
2023-02-06 16:33:46,992:INFO:Starting cross validation
2023-02-06 16:33:46,993:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:47,019:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,054:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,080:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,110:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,138:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,166:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,196:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,235:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,273:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,309:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,324:INFO:Calculating mean and std
2023-02-06 16:33:47,325:INFO:Creating metrics dataframe
2023-02-06 16:33:47,330:INFO:Uploading results into container
2023-02-06 16:33:47,336:INFO:Uploading model into container now
2023-02-06 16:33:47,337:INFO:_master_model_container: 6
2023-02-06 16:33:47,338:INFO:_display_container: 2
2023-02-06 16:33:47,338:INFO:LassoLars(random_state=123)
2023-02-06 16:33:47,338:INFO:create_model() successfully completed......................................
2023-02-06 16:33:47,438:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:47,438:INFO:Creating metrics dataframe
2023-02-06 16:33:47,454:INFO:Initializing Orthogonal Matching Pursuit
2023-02-06 16:33:47,454:INFO:Total runtime is 0.057446106274922686 minutes
2023-02-06 16:33:47,459:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:47,459:INFO:Initializing create_model()
2023-02-06 16:33:47,459:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:47,460:INFO:Checking exceptions
2023-02-06 16:33:47,460:INFO:Importing libraries
2023-02-06 16:33:47,460:INFO:Copying training dataset
2023-02-06 16:33:47,464:INFO:Defining folds
2023-02-06 16:33:47,464:INFO:Declaring metric variables
2023-02-06 16:33:47,471:INFO:Importing untrained model
2023-02-06 16:33:47,475:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-06 16:33:47,487:INFO:Starting cross validation
2023-02-06 16:33:47,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:47,505:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,533:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,560:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,588:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,617:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,643:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,673:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,700:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,725:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,753:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,767:INFO:Calculating mean and std
2023-02-06 16:33:47,769:INFO:Creating metrics dataframe
2023-02-06 16:33:47,775:INFO:Uploading results into container
2023-02-06 16:33:47,775:INFO:Uploading model into container now
2023-02-06 16:33:47,776:INFO:_master_model_container: 7
2023-02-06 16:33:47,776:INFO:_display_container: 2
2023-02-06 16:33:47,776:INFO:OrthogonalMatchingPursuit()
2023-02-06 16:33:47,777:INFO:create_model() successfully completed......................................
2023-02-06 16:33:47,883:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:47,883:INFO:Creating metrics dataframe
2023-02-06 16:33:47,895:INFO:Initializing Bayesian Ridge
2023-02-06 16:33:47,896:INFO:Total runtime is 0.06480961243311564 minutes
2023-02-06 16:33:47,903:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:47,904:INFO:Initializing create_model()
2023-02-06 16:33:47,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:47,904:INFO:Checking exceptions
2023-02-06 16:33:47,904:INFO:Importing libraries
2023-02-06 16:33:47,904:INFO:Copying training dataset
2023-02-06 16:33:47,908:INFO:Defining folds
2023-02-06 16:33:47,909:INFO:Declaring metric variables
2023-02-06 16:33:47,915:INFO:Importing untrained model
2023-02-06 16:33:47,923:INFO:Bayesian Ridge Imported successfully
2023-02-06 16:33:47,935:INFO:Starting cross validation
2023-02-06 16:33:47,936:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:48,210:INFO:Calculating mean and std
2023-02-06 16:33:48,211:INFO:Creating metrics dataframe
2023-02-06 16:33:48,219:INFO:Uploading results into container
2023-02-06 16:33:48,220:INFO:Uploading model into container now
2023-02-06 16:33:48,220:INFO:_master_model_container: 8
2023-02-06 16:33:48,221:INFO:_display_container: 2
2023-02-06 16:33:48,221:INFO:BayesianRidge()
2023-02-06 16:33:48,221:INFO:create_model() successfully completed......................................
2023-02-06 16:33:48,320:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:48,320:INFO:Creating metrics dataframe
2023-02-06 16:33:48,337:INFO:Initializing Passive Aggressive Regressor
2023-02-06 16:33:48,337:INFO:Total runtime is 0.07216133673985799 minutes
2023-02-06 16:33:48,342:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:48,342:INFO:Initializing create_model()
2023-02-06 16:33:48,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:48,343:INFO:Checking exceptions
2023-02-06 16:33:48,343:INFO:Importing libraries
2023-02-06 16:33:48,343:INFO:Copying training dataset
2023-02-06 16:33:48,349:INFO:Defining folds
2023-02-06 16:33:48,349:INFO:Declaring metric variables
2023-02-06 16:33:48,356:INFO:Importing untrained model
2023-02-06 16:33:48,361:INFO:Passive Aggressive Regressor Imported successfully
2023-02-06 16:33:48,372:INFO:Starting cross validation
2023-02-06 16:33:48,373:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:48,677:INFO:Calculating mean and std
2023-02-06 16:33:48,681:INFO:Creating metrics dataframe
2023-02-06 16:33:48,688:INFO:Uploading results into container
2023-02-06 16:33:48,689:INFO:Uploading model into container now
2023-02-06 16:33:48,690:INFO:_master_model_container: 9
2023-02-06 16:33:48,690:INFO:_display_container: 2
2023-02-06 16:33:48,690:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-06 16:33:48,691:INFO:create_model() successfully completed......................................
2023-02-06 16:33:48,806:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:48,806:INFO:Creating metrics dataframe
2023-02-06 16:33:48,822:INFO:Initializing Huber Regressor
2023-02-06 16:33:48,822:INFO:Total runtime is 0.08025193214416504 minutes
2023-02-06 16:33:48,827:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:48,829:INFO:Initializing create_model()
2023-02-06 16:33:48,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:48,829:INFO:Checking exceptions
2023-02-06 16:33:48,829:INFO:Importing libraries
2023-02-06 16:33:48,829:INFO:Copying training dataset
2023-02-06 16:33:48,833:INFO:Defining folds
2023-02-06 16:33:48,834:INFO:Declaring metric variables
2023-02-06 16:33:48,840:INFO:Importing untrained model
2023-02-06 16:33:48,846:INFO:Huber Regressor Imported successfully
2023-02-06 16:33:48,859:INFO:Starting cross validation
2023-02-06 16:33:48,861:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:49,354:INFO:Calculating mean and std
2023-02-06 16:33:49,355:INFO:Creating metrics dataframe
2023-02-06 16:33:49,360:INFO:Uploading results into container
2023-02-06 16:33:49,362:INFO:Uploading model into container now
2023-02-06 16:33:49,363:INFO:_master_model_container: 10
2023-02-06 16:33:49,363:INFO:_display_container: 2
2023-02-06 16:33:49,365:INFO:HuberRegressor()
2023-02-06 16:33:49,365:INFO:create_model() successfully completed......................................
2023-02-06 16:33:49,502:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:49,502:INFO:Creating metrics dataframe
2023-02-06 16:33:49,520:INFO:Initializing K Neighbors Regressor
2023-02-06 16:33:49,520:INFO:Total runtime is 0.09188435077667237 minutes
2023-02-06 16:33:49,524:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:49,525:INFO:Initializing create_model()
2023-02-06 16:33:49,525:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:49,525:INFO:Checking exceptions
2023-02-06 16:33:49,525:INFO:Importing libraries
2023-02-06 16:33:49,526:INFO:Copying training dataset
2023-02-06 16:33:49,533:INFO:Defining folds
2023-02-06 16:33:49,533:INFO:Declaring metric variables
2023-02-06 16:33:49,541:INFO:Importing untrained model
2023-02-06 16:33:49,550:INFO:K Neighbors Regressor Imported successfully
2023-02-06 16:33:49,570:INFO:Starting cross validation
2023-02-06 16:33:49,572:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:55,658:INFO:Calculating mean and std
2023-02-06 16:33:55,659:INFO:Creating metrics dataframe
2023-02-06 16:33:55,663:INFO:Uploading results into container
2023-02-06 16:33:55,664:INFO:Uploading model into container now
2023-02-06 16:33:55,665:INFO:_master_model_container: 11
2023-02-06 16:33:55,665:INFO:_display_container: 2
2023-02-06 16:33:55,666:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-06 16:33:55,666:INFO:create_model() successfully completed......................................
2023-02-06 16:33:55,772:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:55,772:INFO:Creating metrics dataframe
2023-02-06 16:33:55,788:INFO:Initializing Decision Tree Regressor
2023-02-06 16:33:55,788:INFO:Total runtime is 0.19634258349736533 minutes
2023-02-06 16:33:55,792:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:55,793:INFO:Initializing create_model()
2023-02-06 16:33:55,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:55,793:INFO:Checking exceptions
2023-02-06 16:33:55,794:INFO:Importing libraries
2023-02-06 16:33:55,794:INFO:Copying training dataset
2023-02-06 16:33:55,798:INFO:Defining folds
2023-02-06 16:33:55,799:INFO:Declaring metric variables
2023-02-06 16:33:55,805:INFO:Importing untrained model
2023-02-06 16:33:55,811:INFO:Decision Tree Regressor Imported successfully
2023-02-06 16:33:55,827:INFO:Starting cross validation
2023-02-06 16:33:55,828:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:56,113:INFO:Calculating mean and std
2023-02-06 16:33:56,115:INFO:Creating metrics dataframe
2023-02-06 16:33:56,121:INFO:Uploading results into container
2023-02-06 16:33:56,122:INFO:Uploading model into container now
2023-02-06 16:33:56,123:INFO:_master_model_container: 12
2023-02-06 16:33:56,123:INFO:_display_container: 2
2023-02-06 16:33:56,124:INFO:DecisionTreeRegressor(random_state=123)
2023-02-06 16:33:56,124:INFO:create_model() successfully completed......................................
2023-02-06 16:33:56,231:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:56,232:INFO:Creating metrics dataframe
2023-02-06 16:33:56,255:INFO:Initializing Random Forest Regressor
2023-02-06 16:33:56,256:INFO:Total runtime is 0.2041469653447469 minutes
2023-02-06 16:33:56,262:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:56,262:INFO:Initializing create_model()
2023-02-06 16:33:56,262:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:56,263:INFO:Checking exceptions
2023-02-06 16:33:56,263:INFO:Importing libraries
2023-02-06 16:33:56,263:INFO:Copying training dataset
2023-02-06 16:33:56,269:INFO:Defining folds
2023-02-06 16:33:56,270:INFO:Declaring metric variables
2023-02-06 16:33:56,278:INFO:Importing untrained model
2023-02-06 16:33:56,289:INFO:Random Forest Regressor Imported successfully
2023-02-06 16:33:56,306:INFO:Starting cross validation
2023-02-06 16:33:56,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:58,584:INFO:Calculating mean and std
2023-02-06 16:33:58,585:INFO:Creating metrics dataframe
2023-02-06 16:33:58,589:INFO:Uploading results into container
2023-02-06 16:33:58,590:INFO:Uploading model into container now
2023-02-06 16:33:58,590:INFO:_master_model_container: 13
2023-02-06 16:33:58,591:INFO:_display_container: 2
2023-02-06 16:33:58,591:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-06 16:33:58,591:INFO:create_model() successfully completed......................................
2023-02-06 16:33:58,700:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:58,701:INFO:Creating metrics dataframe
2023-02-06 16:33:58,719:INFO:Initializing Extra Trees Regressor
2023-02-06 16:33:58,719:INFO:Total runtime is 0.2451942523320516 minutes
2023-02-06 16:33:58,724:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:58,724:INFO:Initializing create_model()
2023-02-06 16:33:58,725:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:58,725:INFO:Checking exceptions
2023-02-06 16:33:58,725:INFO:Importing libraries
2023-02-06 16:33:58,725:INFO:Copying training dataset
2023-02-06 16:33:58,730:INFO:Defining folds
2023-02-06 16:33:58,731:INFO:Declaring metric variables
2023-02-06 16:33:58,738:INFO:Importing untrained model
2023-02-06 16:33:58,745:INFO:Extra Trees Regressor Imported successfully
2023-02-06 16:33:58,760:INFO:Starting cross validation
2023-02-06 16:33:58,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:34:00,970:INFO:Calculating mean and std
2023-02-06 16:34:00,972:INFO:Creating metrics dataframe
2023-02-06 16:34:00,980:INFO:Uploading results into container
2023-02-06 16:34:00,981:INFO:Uploading model into container now
2023-02-06 16:34:00,982:INFO:_master_model_container: 14
2023-02-06 16:34:00,982:INFO:_display_container: 2
2023-02-06 16:34:00,983:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-06 16:34:00,983:INFO:create_model() successfully completed......................................
2023-02-06 16:34:01,099:INFO:SubProcess create_model() end ==================================
2023-02-06 16:34:01,099:INFO:Creating metrics dataframe
2023-02-06 16:34:01,120:INFO:Initializing AdaBoost Regressor
2023-02-06 16:34:01,120:INFO:Total runtime is 0.28521345059076947 minutes
2023-02-06 16:34:01,127:INFO:SubProcess create_model() called ==================================
2023-02-06 16:34:01,127:INFO:Initializing create_model()
2023-02-06 16:34:01,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:34:01,127:INFO:Checking exceptions
2023-02-06 16:34:01,128:INFO:Importing libraries
2023-02-06 16:34:01,128:INFO:Copying training dataset
2023-02-06 16:34:01,132:INFO:Defining folds
2023-02-06 16:34:01,133:INFO:Declaring metric variables
2023-02-06 16:34:01,139:INFO:Importing untrained model
2023-02-06 16:34:01,151:INFO:AdaBoost Regressor Imported successfully
2023-02-06 16:34:01,166:INFO:Starting cross validation
2023-02-06 16:34:01,167:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:34:01,876:INFO:Calculating mean and std
2023-02-06 16:34:01,877:INFO:Creating metrics dataframe
2023-02-06 16:34:01,881:INFO:Uploading results into container
2023-02-06 16:34:01,882:INFO:Uploading model into container now
2023-02-06 16:34:01,883:INFO:_master_model_container: 15
2023-02-06 16:34:01,883:INFO:_display_container: 2
2023-02-06 16:34:01,884:INFO:AdaBoostRegressor(random_state=123)
2023-02-06 16:34:01,884:INFO:create_model() successfully completed......................................
2023-02-06 16:34:01,989:INFO:SubProcess create_model() end ==================================
2023-02-06 16:34:01,990:INFO:Creating metrics dataframe
2023-02-06 16:34:02,008:INFO:Initializing Gradient Boosting Regressor
2023-02-06 16:34:02,008:INFO:Total runtime is 0.3000239491462708 minutes
2023-02-06 16:34:02,013:INFO:SubProcess create_model() called ==================================
2023-02-06 16:34:02,014:INFO:Initializing create_model()
2023-02-06 16:34:02,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:34:02,014:INFO:Checking exceptions
2023-02-06 16:34:02,014:INFO:Importing libraries
2023-02-06 16:34:02,014:INFO:Copying training dataset
2023-02-06 16:34:02,018:INFO:Defining folds
2023-02-06 16:34:02,019:INFO:Declaring metric variables
2023-02-06 16:34:02,026:INFO:Importing untrained model
2023-02-06 16:34:02,033:INFO:Gradient Boosting Regressor Imported successfully
2023-02-06 16:34:02,049:INFO:Starting cross validation
2023-02-06 16:34:02,050:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:34:02,816:INFO:Calculating mean and std
2023-02-06 16:34:02,817:INFO:Creating metrics dataframe
2023-02-06 16:34:02,823:INFO:Uploading results into container
2023-02-06 16:34:02,824:INFO:Uploading model into container now
2023-02-06 16:34:02,825:INFO:_master_model_container: 16
2023-02-06 16:34:02,825:INFO:_display_container: 2
2023-02-06 16:34:02,826:INFO:GradientBoostingRegressor(random_state=123)
2023-02-06 16:34:02,826:INFO:create_model() successfully completed......................................
2023-02-06 16:34:02,926:INFO:SubProcess create_model() end ==================================
2023-02-06 16:34:02,927:INFO:Creating metrics dataframe
2023-02-06 16:34:02,944:INFO:Initializing Extreme Gradient Boosting
2023-02-06 16:34:02,944:INFO:Total runtime is 0.31561100085576377 minutes
2023-02-06 16:34:02,949:INFO:SubProcess create_model() called ==================================
2023-02-06 16:34:02,949:INFO:Initializing create_model()
2023-02-06 16:34:02,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:34:02,950:INFO:Checking exceptions
2023-02-06 16:34:02,950:INFO:Importing libraries
2023-02-06 16:34:02,950:INFO:Copying training dataset
2023-02-06 16:34:02,955:INFO:Defining folds
2023-02-06 16:34:02,955:INFO:Declaring metric variables
2023-02-06 16:34:02,962:INFO:Importing untrained model
2023-02-06 16:34:02,969:INFO:Extreme Gradient Boosting Imported successfully
2023-02-06 16:34:02,988:INFO:Starting cross validation
2023-02-06 16:34:02,989:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:34:09,937:INFO:Calculating mean and std
2023-02-06 16:34:09,940:INFO:Creating metrics dataframe
2023-02-06 16:34:09,950:INFO:Uploading results into container
2023-02-06 16:34:09,952:INFO:Uploading model into container now
2023-02-06 16:34:09,953:INFO:_master_model_container: 17
2023-02-06 16:34:09,953:INFO:_display_container: 2
2023-02-06 16:34:09,956:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-02-06 16:34:09,956:INFO:create_model() successfully completed......................................
2023-02-06 16:34:10,090:INFO:SubProcess create_model() end ==================================
2023-02-06 16:34:10,090:INFO:Creating metrics dataframe
2023-02-06 16:34:10,110:INFO:Initializing Light Gradient Boosting Machine
2023-02-06 16:34:10,111:INFO:Total runtime is 0.4350594798723857 minutes
2023-02-06 16:34:10,117:INFO:SubProcess create_model() called ==================================
2023-02-06 16:34:10,117:INFO:Initializing create_model()
2023-02-06 16:34:10,117:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:34:10,117:INFO:Checking exceptions
2023-02-06 16:34:10,118:INFO:Importing libraries
2023-02-06 16:34:10,118:INFO:Copying training dataset
2023-02-06 16:34:10,122:INFO:Defining folds
2023-02-06 16:34:10,122:INFO:Declaring metric variables
2023-02-06 16:34:10,131:INFO:Importing untrained model
2023-02-06 16:34:10,137:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-06 16:34:10,149:INFO:Starting cross validation
2023-02-06 16:34:10,151:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:34:17,872:INFO:Calculating mean and std
2023-02-06 16:34:17,875:INFO:Creating metrics dataframe
2023-02-06 16:34:17,887:INFO:Uploading results into container
2023-02-06 16:34:17,888:INFO:Uploading model into container now
2023-02-06 16:34:17,889:INFO:_master_model_container: 18
2023-02-06 16:34:17,889:INFO:_display_container: 2
2023-02-06 16:34:17,890:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-02-06 16:34:17,891:INFO:create_model() successfully completed......................................
2023-02-06 16:34:18,025:INFO:SubProcess create_model() end ==================================
2023-02-06 16:34:18,025:INFO:Creating metrics dataframe
2023-02-06 16:34:18,045:INFO:Initializing Dummy Regressor
2023-02-06 16:34:18,045:INFO:Total runtime is 0.5672948320706686 minutes
2023-02-06 16:34:18,051:INFO:SubProcess create_model() called ==================================
2023-02-06 16:34:18,052:INFO:Initializing create_model()
2023-02-06 16:34:18,052:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:34:18,052:INFO:Checking exceptions
2023-02-06 16:34:18,052:INFO:Importing libraries
2023-02-06 16:34:18,052:INFO:Copying training dataset
2023-02-06 16:34:18,056:INFO:Defining folds
2023-02-06 16:34:18,057:INFO:Declaring metric variables
2023-02-06 16:34:18,063:INFO:Importing untrained model
2023-02-06 16:34:18,070:INFO:Dummy Regressor Imported successfully
2023-02-06 16:34:18,085:INFO:Starting cross validation
2023-02-06 16:34:18,087:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:34:18,340:INFO:Calculating mean and std
2023-02-06 16:34:18,342:INFO:Creating metrics dataframe
2023-02-06 16:34:18,348:INFO:Uploading results into container
2023-02-06 16:34:18,348:INFO:Uploading model into container now
2023-02-06 16:34:18,349:INFO:_master_model_container: 19
2023-02-06 16:34:18,349:INFO:_display_container: 2
2023-02-06 16:34:18,350:INFO:DummyRegressor()
2023-02-06 16:34:18,350:INFO:create_model() successfully completed......................................
2023-02-06 16:34:18,453:INFO:SubProcess create_model() end ==================================
2023-02-06 16:34:18,453:INFO:Creating metrics dataframe
2023-02-06 16:34:18,488:INFO:Initializing create_model()
2023-02-06 16:34:18,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:34:18,489:INFO:Checking exceptions
2023-02-06 16:34:18,491:INFO:Importing libraries
2023-02-06 16:34:18,491:INFO:Copying training dataset
2023-02-06 16:34:18,497:INFO:Defining folds
2023-02-06 16:34:18,497:INFO:Declaring metric variables
2023-02-06 16:34:18,498:INFO:Importing untrained model
2023-02-06 16:34:18,498:INFO:Declaring custom model
2023-02-06 16:34:18,499:INFO:Linear Regression Imported successfully
2023-02-06 16:34:18,501:INFO:Cross validation set to False
2023-02-06 16:34:18,501:INFO:Fitting Model
2023-02-06 16:34:18,518:INFO:LinearRegression(n_jobs=-1)
2023-02-06 16:34:18,518:INFO:create_model() successfully completed......................................
2023-02-06 16:34:18,686:INFO:_master_model_container: 19
2023-02-06 16:34:18,687:INFO:_display_container: 2
2023-02-06 16:34:18,687:INFO:LinearRegression(n_jobs=-1)
2023-02-06 16:34:18,688:INFO:compare_models() successfully completed......................................
2023-02-06 16:34:21,464:INFO:Initializing create_model()
2023-02-06 16:34:21,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:34:21,465:INFO:Checking exceptions
2023-02-06 16:34:21,508:INFO:Importing libraries
2023-02-06 16:34:21,508:INFO:Copying training dataset
2023-02-06 16:34:21,518:INFO:Defining folds
2023-02-06 16:34:21,519:INFO:Declaring metric variables
2023-02-06 16:34:21,527:INFO:Importing untrained model
2023-02-06 16:34:21,534:INFO:Huber Regressor Imported successfully
2023-02-06 16:34:21,551:INFO:Starting cross validation
2023-02-06 16:34:21,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:34:22,014:INFO:Calculating mean and std
2023-02-06 16:34:22,015:INFO:Creating metrics dataframe
2023-02-06 16:34:22,021:INFO:Finalizing model
2023-02-06 16:34:22,050:INFO:Uploading results into container
2023-02-06 16:34:22,052:INFO:Uploading model into container now
2023-02-06 16:34:22,076:INFO:_master_model_container: 20
2023-02-06 16:34:22,076:INFO:_display_container: 3
2023-02-06 16:34:22,077:INFO:HuberRegressor()
2023-02-06 16:34:22,078:INFO:create_model() successfully completed......................................
2023-02-06 16:34:26,335:INFO:Initializing predict_model()
2023-02-06 16:34:26,335:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001B483675CF0>)
2023-02-06 16:34:26,335:INFO:Checking exceptions
2023-02-06 16:34:26,335:INFO:Preloading libraries
2023-02-06 16:34:26,338:INFO:Set up data.
2023-02-06 16:34:26,344:INFO:Set up index.
2023-05-12 14:51:35,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:35,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:35,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:35,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:37,274:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-12 14:51:41,283:INFO:PyCaret RegressionExperiment
2023-05-12 14:51:41,284:INFO:Logging name: reg-default-name
2023-05-12 14:51:41,284:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-12 14:51:41,285:INFO:version 3.0.0.rc8
2023-05-12 14:51:41,285:INFO:Initializing setup()
2023-05-12 14:51:41,285:INFO:self.USI: 713a
2023-05-12 14:51:41,286:INFO:self._variable_keys: {'target_param', 'y', 'X_train', 'fold_generator', 'X', 'idx', 'n_jobs_param', 'y_test', 'X_test', 'memory', '_available_plots', 'logging_param', 'gpu_param', 'data', 'seed', 'exp_name_log', '_ml_usecase', 'exp_id', 'pipeline', 'fold_groups_param', 'y_train', 'html_param', 'gpu_n_jobs_param', 'USI', 'fold_shuffle_param', 'log_plots_param', 'transform_target_param'}
2023-05-12 14:51:41,286:INFO:Checking environment
2023-05-12 14:51:41,287:INFO:python_version: 3.10.9
2023-05-12 14:51:41,288:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-05-12 14:51:41,289:INFO:machine: AMD64
2023-05-12 14:51:41,289:INFO:platform: Windows-10-10.0.19045-SP0
2023-05-12 14:51:41,290:INFO:Memory: svmem(total=17090879488, available=3019161600, percent=82.3, used=14071717888, free=3019161600)
2023-05-12 14:51:41,290:INFO:Physical Core: 4
2023-05-12 14:51:41,290:INFO:Logical Core: 8
2023-05-12 14:51:41,291:INFO:Checking libraries
2023-05-12 14:51:41,291:INFO:System:
2023-05-12 14:51:41,291:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-05-12 14:51:41,292:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-05-12 14:51:41,292:INFO:   machine: Windows-10-10.0.19045-SP0
2023-05-12 14:51:41,292:INFO:PyCaret required dependencies:
2023-05-12 14:51:41,293:INFO:                 pip: 23.0
2023-05-12 14:51:41,293:INFO:          setuptools: 67.1.0
2023-05-12 14:51:41,294:INFO:             pycaret: 3.0.0rc8
2023-05-12 14:51:41,294:INFO:             IPython: 8.8.0
2023-05-12 14:51:41,294:INFO:          ipywidgets: 8.0.4
2023-05-12 14:51:41,295:INFO:                tqdm: 4.64.1
2023-05-12 14:51:41,295:INFO:               numpy: 1.23.5
2023-05-12 14:51:41,295:INFO:              pandas: 1.5.3
2023-05-12 14:51:41,296:INFO:              jinja2: 3.1.2
2023-05-12 14:51:41,296:INFO:               scipy: 1.10.0
2023-05-12 14:51:41,296:INFO:              joblib: 1.2.0
2023-05-12 14:51:41,297:INFO:             sklearn: 1.1.3
2023-05-12 14:51:41,297:INFO:                pyod: 1.0.7
2023-05-12 14:51:41,297:INFO:            imblearn: 0.10.1
2023-05-12 14:51:41,298:INFO:   category_encoders: 2.6.0
2023-05-12 14:51:41,298:INFO:            lightgbm: 3.3.5
2023-05-12 14:51:41,298:INFO:               numba: 0.56.4
2023-05-12 14:51:41,298:INFO:            requests: 2.28.2
2023-05-12 14:51:41,298:INFO:          matplotlib: 3.6.3
2023-05-12 14:51:41,298:INFO:          scikitplot: 0.3.7
2023-05-12 14:51:41,298:INFO:         yellowbrick: 1.5
2023-05-12 14:51:41,298:INFO:              plotly: 5.13.0
2023-05-12 14:51:41,298:INFO:             kaleido: 0.2.1
2023-05-12 14:51:41,299:INFO:         statsmodels: 0.13.5
2023-05-12 14:51:41,299:INFO:              sktime: 0.16.0
2023-05-12 14:51:41,299:INFO:               tbats: 1.1.2
2023-05-12 14:51:41,299:INFO:            pmdarima: 2.0.2
2023-05-12 14:51:41,299:INFO:              psutil: 5.9.0
2023-05-12 14:51:41,299:INFO:PyCaret optional dependencies:
2023-05-12 14:51:41,330:INFO:                shap: Not installed
2023-05-12 14:51:41,331:INFO:           interpret: Not installed
2023-05-12 14:51:41,331:INFO:                umap: Not installed
2023-05-12 14:51:41,331:INFO:    pandas_profiling: Not installed
2023-05-12 14:51:41,331:INFO:  explainerdashboard: Not installed
2023-05-12 14:51:41,331:INFO:             autoviz: Not installed
2023-05-12 14:51:41,331:INFO:           fairlearn: Not installed
2023-05-12 14:51:41,331:INFO:             xgboost: 1.7.3
2023-05-12 14:51:41,331:INFO:            catboost: Not installed
2023-05-12 14:51:41,331:INFO:              kmodes: Not installed
2023-05-12 14:51:41,331:INFO:             mlxtend: Not installed
2023-05-12 14:51:41,331:INFO:       statsforecast: Not installed
2023-05-12 14:51:41,331:INFO:        tune_sklearn: Not installed
2023-05-12 14:51:41,331:INFO:                 ray: Not installed
2023-05-12 14:51:41,331:INFO:            hyperopt: Not installed
2023-05-12 14:51:41,332:INFO:              optuna: Not installed
2023-05-12 14:51:41,332:INFO:               skopt: Not installed
2023-05-12 14:51:41,332:INFO:              mlflow: Not installed
2023-05-12 14:51:41,332:INFO:              gradio: Not installed
2023-05-12 14:51:41,332:INFO:             fastapi: Not installed
2023-05-12 14:51:41,332:INFO:             uvicorn: Not installed
2023-05-12 14:51:41,332:INFO:              m2cgen: Not installed
2023-05-12 14:51:41,332:INFO:           evidently: Not installed
2023-05-12 14:51:41,332:INFO:                nltk: Not installed
2023-05-12 14:51:41,332:INFO:            pyLDAvis: Not installed
2023-05-12 14:51:41,332:INFO:              gensim: Not installed
2023-05-12 14:51:41,332:INFO:               spacy: Not installed
2023-05-12 14:51:41,332:INFO:           wordcloud: Not installed
2023-05-12 14:51:41,332:INFO:            textblob: Not installed
2023-05-12 14:51:41,332:INFO:               fugue: Not installed
2023-05-12 14:51:41,332:INFO:           streamlit: Not installed
2023-05-12 14:51:41,333:INFO:             prophet: Not installed
2023-05-12 14:51:41,333:INFO:None
2023-05-12 14:51:41,333:INFO:Set up GPU usage.
2023-05-12 14:51:41,333:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:41,333:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-05-12 14:51:41,333:INFO:Set up data.
2023-05-12 14:51:41,339:INFO:Set up train/test split.
2023-05-12 14:51:41,343:INFO:Set up index.
2023-05-12 14:51:41,344:INFO:Set up folding strategy.
2023-05-12 14:51:41,344:INFO:Assigning column types.
2023-05-12 14:51:41,347:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-12 14:51:41,348:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:41,348:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 14:51:41,348:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:41,359:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 14:51:41,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:41,370:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:51:41,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:41,441:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:41,441:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:41,494:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:51:41,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:41,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:41,495:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:43,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:43,307:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,307:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,307:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,320:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,331:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,440:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,440:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,492:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,492:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,492:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,493:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:43,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:43,666:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-12 14:51:43,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,678:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,679:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,690:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,802:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,856:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,857:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,857:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:44,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:44,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,053:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,066:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,067:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,176:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,176:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,230:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,231:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,231:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,232:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:44,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:44,420:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-12 14:51:44,420:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,420:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,445:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,446:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,557:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,611:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,612:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:44,800:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:44,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,827:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,943:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,997:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,997:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,997:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,998:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:45,176:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:45,176:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-12 14:51:45,177:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,177:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,190:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,202:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,315:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:45,315:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,375:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:51:45,375:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,375:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,379:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:45,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:45,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,561:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,574:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,689:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:45,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,745:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:51:45,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,746:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:45,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:45,934:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-12 14:51:45,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,935:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,959:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,072:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:46,073:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,130:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:46,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:46,317:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,317:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,454:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:46,454:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,508:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,508:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,508:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:46,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:46,666:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-12 14:51:46,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,694:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,855:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:47,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:47,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,226:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,227:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:47,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:47,411:INFO:Preparing preprocessing pipeline...
2023-05-12 14:51:47,412:INFO:Set up simple imputation.
2023-05-12 14:51:47,472:INFO:Finished creating preprocessing pipeline.
2023-05-12 14:51:47,483:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-05-12 14:51:47,483:INFO:Creating final display dataframe.
2023-05-12 14:51:47,687:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape         (1042, 2)
4        Transformed data shape         (1042, 2)
5   Transformed train set shape          (729, 2)
6    Transformed test set shape          (313, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              713a
2023-05-12 14:51:47,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,704:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,777:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,830:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:47,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:47,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:48,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:48,020:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:48,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:48,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:48,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:48,186:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:48,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:48,362:INFO:setup() successfully completed in 7.08s...............
2023-05-12 14:51:48,414:INFO:Initializing compare_models()
2023-05-12 14:51:48,414:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-12 14:51:48,414:INFO:Checking exceptions
2023-05-12 14:51:48,419:INFO:Preparing display monitor
2023-05-12 14:51:48,479:INFO:Initializing Linear Regression
2023-05-12 14:51:48,479:INFO:Total runtime is 0.0 minutes
2023-05-12 14:51:48,487:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:48,488:INFO:Initializing create_model()
2023-05-12 14:51:48,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:48,488:INFO:Checking exceptions
2023-05-12 14:51:48,488:INFO:Importing libraries
2023-05-12 14:51:48,489:INFO:Copying training dataset
2023-05-12 14:51:48,492:INFO:Defining folds
2023-05-12 14:51:48,492:INFO:Declaring metric variables
2023-05-12 14:51:48,497:INFO:Importing untrained model
2023-05-12 14:51:48,503:INFO:Linear Regression Imported successfully
2023-05-12 14:51:48,515:INFO:Starting cross validation
2023-05-12 14:51:48,530:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:49,400:INFO:Calculating mean and std
2023-05-12 14:51:49,401:INFO:Creating metrics dataframe
2023-05-12 14:51:49,407:INFO:Uploading results into container
2023-05-12 14:51:49,408:INFO:Uploading model into container now
2023-05-12 14:51:49,408:INFO:_master_model_container: 1
2023-05-12 14:51:49,408:INFO:_display_container: 2
2023-05-12 14:51:49,408:INFO:LinearRegression(n_jobs=-1)
2023-05-12 14:51:49,408:INFO:create_model() successfully completed......................................
2023-05-12 14:51:49,511:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:49,512:INFO:Creating metrics dataframe
2023-05-12 14:51:49,527:INFO:Initializing Lasso Regression
2023-05-12 14:51:49,527:INFO:Total runtime is 0.01746841271718343 minutes
2023-05-12 14:51:49,534:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:49,535:INFO:Initializing create_model()
2023-05-12 14:51:49,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:49,536:INFO:Checking exceptions
2023-05-12 14:51:49,536:INFO:Importing libraries
2023-05-12 14:51:49,536:INFO:Copying training dataset
2023-05-12 14:51:49,540:INFO:Defining folds
2023-05-12 14:51:49,541:INFO:Declaring metric variables
2023-05-12 14:51:49,549:INFO:Importing untrained model
2023-05-12 14:51:49,559:INFO:Lasso Regression Imported successfully
2023-05-12 14:51:49,571:INFO:Starting cross validation
2023-05-12 14:51:49,572:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:49,608:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.228e+08, tolerance: 1.948e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,653:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.926e+08, tolerance: 1.970e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,696:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.543e+08, tolerance: 1.940e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,736:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.701e+08, tolerance: 1.938e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,775:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.060e+08, tolerance: 1.941e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,814:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.280e+08, tolerance: 1.951e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,859:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.429e+08, tolerance: 1.974e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,898:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.178e+08, tolerance: 1.907e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,938:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.602e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,978:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.286e+08, tolerance: 1.982e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,995:INFO:Calculating mean and std
2023-05-12 14:51:49,996:INFO:Creating metrics dataframe
2023-05-12 14:51:50,000:INFO:Uploading results into container
2023-05-12 14:51:50,001:INFO:Uploading model into container now
2023-05-12 14:51:50,002:INFO:_master_model_container: 2
2023-05-12 14:51:50,002:INFO:_display_container: 2
2023-05-12 14:51:50,002:INFO:Lasso(random_state=123)
2023-05-12 14:51:50,003:INFO:create_model() successfully completed......................................
2023-05-12 14:51:50,085:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:50,085:INFO:Creating metrics dataframe
2023-05-12 14:51:50,097:INFO:Initializing Ridge Regression
2023-05-12 14:51:50,097:INFO:Total runtime is 0.026957058906555177 minutes
2023-05-12 14:51:50,103:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:50,104:INFO:Initializing create_model()
2023-05-12 14:51:50,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:50,104:INFO:Checking exceptions
2023-05-12 14:51:50,104:INFO:Importing libraries
2023-05-12 14:51:50,104:INFO:Copying training dataset
2023-05-12 14:51:50,108:INFO:Defining folds
2023-05-12 14:51:50,108:INFO:Declaring metric variables
2023-05-12 14:51:50,114:INFO:Importing untrained model
2023-05-12 14:51:50,120:INFO:Ridge Regression Imported successfully
2023-05-12 14:51:50,130:INFO:Starting cross validation
2023-05-12 14:51:50,131:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:50,384:INFO:Calculating mean and std
2023-05-12 14:51:50,386:INFO:Creating metrics dataframe
2023-05-12 14:51:50,392:INFO:Uploading results into container
2023-05-12 14:51:50,393:INFO:Uploading model into container now
2023-05-12 14:51:50,394:INFO:_master_model_container: 3
2023-05-12 14:51:50,394:INFO:_display_container: 2
2023-05-12 14:51:50,395:INFO:Ridge(random_state=123)
2023-05-12 14:51:50,395:INFO:create_model() successfully completed......................................
2023-05-12 14:51:50,482:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:50,482:INFO:Creating metrics dataframe
2023-05-12 14:51:50,500:INFO:Initializing Elastic Net
2023-05-12 14:51:50,500:INFO:Total runtime is 0.03367509444554647 minutes
2023-05-12 14:51:50,506:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:50,506:INFO:Initializing create_model()
2023-05-12 14:51:50,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:50,507:INFO:Checking exceptions
2023-05-12 14:51:50,507:INFO:Importing libraries
2023-05-12 14:51:50,507:INFO:Copying training dataset
2023-05-12 14:51:50,512:INFO:Defining folds
2023-05-12 14:51:50,513:INFO:Declaring metric variables
2023-05-12 14:51:50,520:INFO:Importing untrained model
2023-05-12 14:51:50,527:INFO:Elastic Net Imported successfully
2023-05-12 14:51:50,538:INFO:Starting cross validation
2023-05-12 14:51:50,539:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:50,561:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.219e+08, tolerance: 1.948e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,589:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.152e+08, tolerance: 1.970e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,621:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.940e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,645:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.927e+08, tolerance: 1.938e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,669:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.434e+08, tolerance: 1.941e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,693:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.622e+08, tolerance: 1.951e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,717:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.840e+08, tolerance: 1.974e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,743:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.019e+08, tolerance: 1.907e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,766:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.858e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,790:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.022e+08, tolerance: 1.982e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,800:INFO:Calculating mean and std
2023-05-12 14:51:50,801:INFO:Creating metrics dataframe
2023-05-12 14:51:50,806:INFO:Uploading results into container
2023-05-12 14:51:50,807:INFO:Uploading model into container now
2023-05-12 14:51:50,807:INFO:_master_model_container: 4
2023-05-12 14:51:50,808:INFO:_display_container: 2
2023-05-12 14:51:50,808:INFO:ElasticNet(random_state=123)
2023-05-12 14:51:50,809:INFO:create_model() successfully completed......................................
2023-05-12 14:51:50,885:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:50,886:INFO:Creating metrics dataframe
2023-05-12 14:51:50,898:INFO:Initializing Least Angle Regression
2023-05-12 14:51:50,898:INFO:Total runtime is 0.04031027952829997 minutes
2023-05-12 14:51:50,903:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:50,904:INFO:Initializing create_model()
2023-05-12 14:51:50,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:50,904:INFO:Checking exceptions
2023-05-12 14:51:50,904:INFO:Importing libraries
2023-05-12 14:51:50,905:INFO:Copying training dataset
2023-05-12 14:51:50,908:INFO:Defining folds
2023-05-12 14:51:50,909:INFO:Declaring metric variables
2023-05-12 14:51:50,914:INFO:Importing untrained model
2023-05-12 14:51:50,920:INFO:Least Angle Regression Imported successfully
2023-05-12 14:51:50,929:INFO:Starting cross validation
2023-05-12 14:51:50,930:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:50,951:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:50,977:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,000:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,024:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,046:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,067:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,090:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,112:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,137:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,158:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,170:INFO:Calculating mean and std
2023-05-12 14:51:51,171:INFO:Creating metrics dataframe
2023-05-12 14:51:51,174:INFO:Uploading results into container
2023-05-12 14:51:51,175:INFO:Uploading model into container now
2023-05-12 14:51:51,176:INFO:_master_model_container: 5
2023-05-12 14:51:51,176:INFO:_display_container: 2
2023-05-12 14:51:51,177:INFO:Lars(random_state=123)
2023-05-12 14:51:51,177:INFO:create_model() successfully completed......................................
2023-05-12 14:51:51,255:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:51,255:INFO:Creating metrics dataframe
2023-05-12 14:51:51,268:INFO:Initializing Lasso Least Angle Regression
2023-05-12 14:51:51,268:INFO:Total runtime is 0.0464728315671285 minutes
2023-05-12 14:51:51,274:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:51,274:INFO:Initializing create_model()
2023-05-12 14:51:51,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:51,275:INFO:Checking exceptions
2023-05-12 14:51:51,275:INFO:Importing libraries
2023-05-12 14:51:51,275:INFO:Copying training dataset
2023-05-12 14:51:51,278:INFO:Defining folds
2023-05-12 14:51:51,279:INFO:Declaring metric variables
2023-05-12 14:51:51,284:INFO:Importing untrained model
2023-05-12 14:51:51,289:INFO:Lasso Least Angle Regression Imported successfully
2023-05-12 14:51:51,298:INFO:Starting cross validation
2023-05-12 14:51:51,299:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:51,312:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,333:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,360:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,382:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,405:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,427:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,450:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,473:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,495:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,517:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,528:INFO:Calculating mean and std
2023-05-12 14:51:51,529:INFO:Creating metrics dataframe
2023-05-12 14:51:51,532:INFO:Uploading results into container
2023-05-12 14:51:51,533:INFO:Uploading model into container now
2023-05-12 14:51:51,534:INFO:_master_model_container: 6
2023-05-12 14:51:51,534:INFO:_display_container: 2
2023-05-12 14:51:51,535:INFO:LassoLars(random_state=123)
2023-05-12 14:51:51,536:INFO:create_model() successfully completed......................................
2023-05-12 14:51:51,615:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:51,615:INFO:Creating metrics dataframe
2023-05-12 14:51:51,630:INFO:Initializing Orthogonal Matching Pursuit
2023-05-12 14:51:51,630:INFO:Total runtime is 0.05250598986943563 minutes
2023-05-12 14:51:51,635:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:51,636:INFO:Initializing create_model()
2023-05-12 14:51:51,636:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:51,636:INFO:Checking exceptions
2023-05-12 14:51:51,636:INFO:Importing libraries
2023-05-12 14:51:51,636:INFO:Copying training dataset
2023-05-12 14:51:51,640:INFO:Defining folds
2023-05-12 14:51:51,640:INFO:Declaring metric variables
2023-05-12 14:51:51,644:INFO:Importing untrained model
2023-05-12 14:51:51,652:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-12 14:51:51,680:INFO:Starting cross validation
2023-05-12 14:51:51,682:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:51,711:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,737:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,759:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,781:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,804:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,827:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,848:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,871:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,893:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,915:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,928:INFO:Calculating mean and std
2023-05-12 14:51:51,929:INFO:Creating metrics dataframe
2023-05-12 14:51:51,934:INFO:Uploading results into container
2023-05-12 14:51:51,935:INFO:Uploading model into container now
2023-05-12 14:51:51,936:INFO:_master_model_container: 7
2023-05-12 14:51:51,936:INFO:_display_container: 2
2023-05-12 14:51:51,936:INFO:OrthogonalMatchingPursuit()
2023-05-12 14:51:51,937:INFO:create_model() successfully completed......................................
2023-05-12 14:51:52,015:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:52,016:INFO:Creating metrics dataframe
2023-05-12 14:51:52,029:INFO:Initializing Bayesian Ridge
2023-05-12 14:51:52,029:INFO:Total runtime is 0.05916630029678345 minutes
2023-05-12 14:51:52,035:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:52,035:INFO:Initializing create_model()
2023-05-12 14:51:52,035:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:52,035:INFO:Checking exceptions
2023-05-12 14:51:52,036:INFO:Importing libraries
2023-05-12 14:51:52,036:INFO:Copying training dataset
2023-05-12 14:51:52,039:INFO:Defining folds
2023-05-12 14:51:52,040:INFO:Declaring metric variables
2023-05-12 14:51:52,045:INFO:Importing untrained model
2023-05-12 14:51:52,051:INFO:Bayesian Ridge Imported successfully
2023-05-12 14:51:52,060:INFO:Starting cross validation
2023-05-12 14:51:52,061:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:52,292:INFO:Calculating mean and std
2023-05-12 14:51:52,293:INFO:Creating metrics dataframe
2023-05-12 14:51:52,297:INFO:Uploading results into container
2023-05-12 14:51:52,298:INFO:Uploading model into container now
2023-05-12 14:51:52,298:INFO:_master_model_container: 8
2023-05-12 14:51:52,299:INFO:_display_container: 2
2023-05-12 14:51:52,299:INFO:BayesianRidge()
2023-05-12 14:51:52,300:INFO:create_model() successfully completed......................................
2023-05-12 14:51:52,380:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:52,380:INFO:Creating metrics dataframe
2023-05-12 14:51:52,395:INFO:Initializing Passive Aggressive Regressor
2023-05-12 14:51:52,396:INFO:Total runtime is 0.06528769731521607 minutes
2023-05-12 14:51:52,401:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:52,401:INFO:Initializing create_model()
2023-05-12 14:51:52,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:52,401:INFO:Checking exceptions
2023-05-12 14:51:52,401:INFO:Importing libraries
2023-05-12 14:51:52,402:INFO:Copying training dataset
2023-05-12 14:51:52,406:INFO:Defining folds
2023-05-12 14:51:52,406:INFO:Declaring metric variables
2023-05-12 14:51:52,411:INFO:Importing untrained model
2023-05-12 14:51:52,416:INFO:Passive Aggressive Regressor Imported successfully
2023-05-12 14:51:52,426:INFO:Starting cross validation
2023-05-12 14:51:52,427:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:52,644:INFO:Calculating mean and std
2023-05-12 14:51:52,646:INFO:Creating metrics dataframe
2023-05-12 14:51:52,649:INFO:Uploading results into container
2023-05-12 14:51:52,650:INFO:Uploading model into container now
2023-05-12 14:51:52,652:INFO:_master_model_container: 9
2023-05-12 14:51:52,652:INFO:_display_container: 2
2023-05-12 14:51:52,652:INFO:PassiveAggressiveRegressor(random_state=123)
2023-05-12 14:51:52,652:INFO:create_model() successfully completed......................................
2023-05-12 14:51:52,729:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:52,730:INFO:Creating metrics dataframe
2023-05-12 14:51:52,745:INFO:Initializing Huber Regressor
2023-05-12 14:51:52,745:INFO:Total runtime is 0.07110445102055868 minutes
2023-05-12 14:51:52,750:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:52,750:INFO:Initializing create_model()
2023-05-12 14:51:52,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:52,752:INFO:Checking exceptions
2023-05-12 14:51:52,752:INFO:Importing libraries
2023-05-12 14:51:52,752:INFO:Copying training dataset
2023-05-12 14:51:52,755:INFO:Defining folds
2023-05-12 14:51:52,755:INFO:Declaring metric variables
2023-05-12 14:51:52,760:INFO:Importing untrained model
2023-05-12 14:51:52,767:INFO:Huber Regressor Imported successfully
2023-05-12 14:51:52,775:INFO:Starting cross validation
2023-05-12 14:51:52,776:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:53,044:INFO:Calculating mean and std
2023-05-12 14:51:53,046:INFO:Creating metrics dataframe
2023-05-12 14:51:53,049:INFO:Uploading results into container
2023-05-12 14:51:53,050:INFO:Uploading model into container now
2023-05-12 14:51:53,051:INFO:_master_model_container: 10
2023-05-12 14:51:53,051:INFO:_display_container: 2
2023-05-12 14:51:53,052:INFO:HuberRegressor()
2023-05-12 14:51:53,052:INFO:create_model() successfully completed......................................
2023-05-12 14:51:53,129:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:53,129:INFO:Creating metrics dataframe
2023-05-12 14:51:53,143:INFO:Initializing K Neighbors Regressor
2023-05-12 14:51:53,143:INFO:Total runtime is 0.07772698799769084 minutes
2023-05-12 14:51:53,147:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:53,148:INFO:Initializing create_model()
2023-05-12 14:51:53,148:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:53,148:INFO:Checking exceptions
2023-05-12 14:51:53,148:INFO:Importing libraries
2023-05-12 14:51:53,149:INFO:Copying training dataset
2023-05-12 14:51:53,153:INFO:Defining folds
2023-05-12 14:51:53,153:INFO:Declaring metric variables
2023-05-12 14:51:53,171:INFO:Importing untrained model
2023-05-12 14:51:53,182:INFO:K Neighbors Regressor Imported successfully
2023-05-12 14:51:53,196:INFO:Starting cross validation
2023-05-12 14:51:53,198:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:58,476:INFO:Calculating mean and std
2023-05-12 14:51:58,477:INFO:Creating metrics dataframe
2023-05-12 14:51:58,481:INFO:Uploading results into container
2023-05-12 14:51:58,481:INFO:Uploading model into container now
2023-05-12 14:51:58,482:INFO:_master_model_container: 11
2023-05-12 14:51:58,483:INFO:_display_container: 2
2023-05-12 14:51:58,484:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-12 14:51:58,484:INFO:create_model() successfully completed......................................
2023-05-12 14:51:58,569:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:58,569:INFO:Creating metrics dataframe
2023-05-12 14:51:58,584:INFO:Initializing Decision Tree Regressor
2023-05-12 14:51:58,584:INFO:Total runtime is 0.16841310660044354 minutes
2023-05-12 14:51:58,588:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:58,589:INFO:Initializing create_model()
2023-05-12 14:51:58,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:58,589:INFO:Checking exceptions
2023-05-12 14:51:58,589:INFO:Importing libraries
2023-05-12 14:51:58,589:INFO:Copying training dataset
2023-05-12 14:51:58,593:INFO:Defining folds
2023-05-12 14:51:58,594:INFO:Declaring metric variables
2023-05-12 14:51:58,598:INFO:Importing untrained model
2023-05-12 14:51:58,605:INFO:Decision Tree Regressor Imported successfully
2023-05-12 14:51:58,615:INFO:Starting cross validation
2023-05-12 14:51:58,617:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:58,854:INFO:Calculating mean and std
2023-05-12 14:51:58,855:INFO:Creating metrics dataframe
2023-05-12 14:51:58,859:INFO:Uploading results into container
2023-05-12 14:51:58,860:INFO:Uploading model into container now
2023-05-12 14:51:58,861:INFO:_master_model_container: 12
2023-05-12 14:51:58,861:INFO:_display_container: 2
2023-05-12 14:51:58,861:INFO:DecisionTreeRegressor(random_state=123)
2023-05-12 14:51:58,862:INFO:create_model() successfully completed......................................
2023-05-12 14:51:58,941:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:58,941:INFO:Creating metrics dataframe
2023-05-12 14:51:58,957:INFO:Initializing Random Forest Regressor
2023-05-12 14:51:58,957:INFO:Total runtime is 0.17462968031565348 minutes
2023-05-12 14:51:58,962:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:58,963:INFO:Initializing create_model()
2023-05-12 14:51:58,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:58,963:INFO:Checking exceptions
2023-05-12 14:51:58,963:INFO:Importing libraries
2023-05-12 14:51:58,963:INFO:Copying training dataset
2023-05-12 14:51:58,968:INFO:Defining folds
2023-05-12 14:51:58,968:INFO:Declaring metric variables
2023-05-12 14:51:58,975:INFO:Importing untrained model
2023-05-12 14:51:58,980:INFO:Random Forest Regressor Imported successfully
2023-05-12 14:51:58,991:INFO:Starting cross validation
2023-05-12 14:51:58,992:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:52:01,406:INFO:Calculating mean and std
2023-05-12 14:52:01,407:INFO:Creating metrics dataframe
2023-05-12 14:52:01,411:INFO:Uploading results into container
2023-05-12 14:52:01,412:INFO:Uploading model into container now
2023-05-12 14:52:01,412:INFO:_master_model_container: 13
2023-05-12 14:52:01,412:INFO:_display_container: 2
2023-05-12 14:52:01,413:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-05-12 14:52:01,413:INFO:create_model() successfully completed......................................
2023-05-12 14:52:01,492:INFO:SubProcess create_model() end ==================================
2023-05-12 14:52:01,492:INFO:Creating metrics dataframe
2023-05-12 14:52:01,508:INFO:Initializing Extra Trees Regressor
2023-05-12 14:52:01,509:INFO:Total runtime is 0.21714743773142497 minutes
2023-05-12 14:52:01,514:INFO:SubProcess create_model() called ==================================
2023-05-12 14:52:01,514:INFO:Initializing create_model()
2023-05-12 14:52:01,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:52:01,514:INFO:Checking exceptions
2023-05-12 14:52:01,515:INFO:Importing libraries
2023-05-12 14:52:01,515:INFO:Copying training dataset
2023-05-12 14:52:01,518:INFO:Defining folds
2023-05-12 14:52:01,519:INFO:Declaring metric variables
2023-05-12 14:52:01,524:INFO:Importing untrained model
2023-05-12 14:52:01,530:INFO:Extra Trees Regressor Imported successfully
2023-05-12 14:52:01,539:INFO:Starting cross validation
2023-05-12 14:52:01,540:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:52:03,588:INFO:Calculating mean and std
2023-05-12 14:52:03,590:INFO:Creating metrics dataframe
2023-05-12 14:52:03,594:INFO:Uploading results into container
2023-05-12 14:52:03,596:INFO:Uploading model into container now
2023-05-12 14:52:03,597:INFO:_master_model_container: 14
2023-05-12 14:52:03,597:INFO:_display_container: 2
2023-05-12 14:52:03,598:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-05-12 14:52:03,599:INFO:create_model() successfully completed......................................
2023-05-12 14:52:03,681:INFO:SubProcess create_model() end ==================================
2023-05-12 14:52:03,682:INFO:Creating metrics dataframe
2023-05-12 14:52:03,705:INFO:Initializing AdaBoost Regressor
2023-05-12 14:52:03,705:INFO:Total runtime is 0.2537640929222107 minutes
2023-05-12 14:52:03,713:INFO:SubProcess create_model() called ==================================
2023-05-12 14:52:03,713:INFO:Initializing create_model()
2023-05-12 14:52:03,714:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:52:03,714:INFO:Checking exceptions
2023-05-12 14:52:03,714:INFO:Importing libraries
2023-05-12 14:52:03,714:INFO:Copying training dataset
2023-05-12 14:52:03,720:INFO:Defining folds
2023-05-12 14:52:03,721:INFO:Declaring metric variables
2023-05-12 14:52:03,729:INFO:Importing untrained model
2023-05-12 14:52:03,737:INFO:AdaBoost Regressor Imported successfully
2023-05-12 14:52:03,746:INFO:Starting cross validation
2023-05-12 14:52:03,748:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:52:04,546:INFO:Calculating mean and std
2023-05-12 14:52:04,548:INFO:Creating metrics dataframe
2023-05-12 14:52:04,555:INFO:Uploading results into container
2023-05-12 14:52:04,556:INFO:Uploading model into container now
2023-05-12 14:52:04,558:INFO:_master_model_container: 15
2023-05-12 14:52:04,558:INFO:_display_container: 2
2023-05-12 14:52:04,559:INFO:AdaBoostRegressor(random_state=123)
2023-05-12 14:52:04,559:INFO:create_model() successfully completed......................................
2023-05-12 14:52:04,667:INFO:SubProcess create_model() end ==================================
2023-05-12 14:52:04,667:INFO:Creating metrics dataframe
2023-05-12 14:52:04,690:INFO:Initializing Gradient Boosting Regressor
2023-05-12 14:52:04,691:INFO:Total runtime is 0.27019739548365274 minutes
2023-05-12 14:52:04,697:INFO:SubProcess create_model() called ==================================
2023-05-12 14:52:04,698:INFO:Initializing create_model()
2023-05-12 14:52:04,698:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:52:04,699:INFO:Checking exceptions
2023-05-12 14:52:04,699:INFO:Importing libraries
2023-05-12 14:52:04,699:INFO:Copying training dataset
2023-05-12 14:52:04,705:INFO:Defining folds
2023-05-12 14:52:04,705:INFO:Declaring metric variables
2023-05-12 14:52:04,713:INFO:Importing untrained model
2023-05-12 14:52:04,722:INFO:Gradient Boosting Regressor Imported successfully
2023-05-12 14:52:04,740:INFO:Starting cross validation
2023-05-12 14:52:04,742:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:52:05,977:INFO:Calculating mean and std
2023-05-12 14:52:05,982:INFO:Creating metrics dataframe
2023-05-12 14:52:05,991:INFO:Uploading results into container
2023-05-12 14:52:05,993:INFO:Uploading model into container now
2023-05-12 14:52:05,994:INFO:_master_model_container: 16
2023-05-12 14:52:05,994:INFO:_display_container: 2
2023-05-12 14:52:05,995:INFO:GradientBoostingRegressor(random_state=123)
2023-05-12 14:52:05,995:INFO:create_model() successfully completed......................................
2023-05-12 14:52:06,124:INFO:SubProcess create_model() end ==================================
2023-05-12 14:52:06,124:INFO:Creating metrics dataframe
2023-05-12 14:52:06,158:INFO:Initializing Extreme Gradient Boosting
2023-05-12 14:52:06,159:INFO:Total runtime is 0.29466408491134644 minutes
2023-05-12 14:52:06,169:INFO:SubProcess create_model() called ==================================
2023-05-12 14:52:06,170:INFO:Initializing create_model()
2023-05-12 14:52:06,170:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:52:06,170:INFO:Checking exceptions
2023-05-12 14:52:06,171:INFO:Importing libraries
2023-05-12 14:52:06,171:INFO:Copying training dataset
2023-05-12 14:52:06,180:INFO:Defining folds
2023-05-12 14:52:06,180:INFO:Declaring metric variables
2023-05-12 14:52:06,190:INFO:Importing untrained model
2023-05-12 14:52:06,200:INFO:Extreme Gradient Boosting Imported successfully
2023-05-12 14:52:06,217:INFO:Starting cross validation
2023-05-12 14:52:06,219:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:52:12,139:INFO:Calculating mean and std
2023-05-12 14:52:12,142:INFO:Creating metrics dataframe
2023-05-12 14:52:12,151:INFO:Uploading results into container
2023-05-12 14:52:12,152:INFO:Uploading model into container now
2023-05-12 14:52:12,153:INFO:_master_model_container: 17
2023-05-12 14:52:12,153:INFO:_display_container: 2
2023-05-12 14:52:12,156:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-05-12 14:52:12,156:INFO:create_model() successfully completed......................................
2023-05-12 14:52:12,271:INFO:SubProcess create_model() end ==================================
2023-05-12 14:52:12,271:INFO:Creating metrics dataframe
2023-05-12 14:52:12,290:INFO:Initializing Light Gradient Boosting Machine
2023-05-12 14:52:12,290:INFO:Total runtime is 0.3968480110168457 minutes
2023-05-12 14:52:12,296:INFO:SubProcess create_model() called ==================================
2023-05-12 14:52:12,297:INFO:Initializing create_model()
2023-05-12 14:52:12,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:52:12,297:INFO:Checking exceptions
2023-05-12 14:52:12,297:INFO:Importing libraries
2023-05-12 14:52:12,298:INFO:Copying training dataset
2023-05-12 14:52:12,303:INFO:Defining folds
2023-05-12 14:52:12,303:INFO:Declaring metric variables
2023-05-12 14:52:12,309:INFO:Importing untrained model
2023-05-12 14:52:12,316:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-12 14:52:12,327:INFO:Starting cross validation
2023-05-12 14:52:12,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:52:21,513:INFO:Calculating mean and std
2023-05-12 14:52:21,518:INFO:Creating metrics dataframe
2023-05-12 14:52:21,526:INFO:Uploading results into container
2023-05-12 14:52:21,528:INFO:Uploading model into container now
2023-05-12 14:52:21,529:INFO:_master_model_container: 18
2023-05-12 14:52:21,529:INFO:_display_container: 2
2023-05-12 14:52:21,530:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-05-12 14:52:21,530:INFO:create_model() successfully completed......................................
2023-05-12 14:52:21,645:INFO:SubProcess create_model() end ==================================
2023-05-12 14:52:21,645:INFO:Creating metrics dataframe
2023-05-12 14:52:21,661:INFO:Initializing Dummy Regressor
2023-05-12 14:52:21,661:INFO:Total runtime is 0.5530237158139546 minutes
2023-05-12 14:52:21,666:INFO:SubProcess create_model() called ==================================
2023-05-12 14:52:21,666:INFO:Initializing create_model()
2023-05-12 14:52:21,666:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:52:21,667:INFO:Checking exceptions
2023-05-12 14:52:21,667:INFO:Importing libraries
2023-05-12 14:52:21,667:INFO:Copying training dataset
2023-05-12 14:52:21,671:INFO:Defining folds
2023-05-12 14:52:21,671:INFO:Declaring metric variables
2023-05-12 14:52:21,677:INFO:Importing untrained model
2023-05-12 14:52:21,682:INFO:Dummy Regressor Imported successfully
2023-05-12 14:52:21,692:INFO:Starting cross validation
2023-05-12 14:52:21,694:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:52:21,887:INFO:Calculating mean and std
2023-05-12 14:52:21,888:INFO:Creating metrics dataframe
2023-05-12 14:52:21,892:INFO:Uploading results into container
2023-05-12 14:52:21,893:INFO:Uploading model into container now
2023-05-12 14:52:21,894:INFO:_master_model_container: 19
2023-05-12 14:52:21,894:INFO:_display_container: 2
2023-05-12 14:52:21,895:INFO:DummyRegressor()
2023-05-12 14:52:21,895:INFO:create_model() successfully completed......................................
2023-05-12 14:52:21,973:INFO:SubProcess create_model() end ==================================
2023-05-12 14:52:21,974:INFO:Creating metrics dataframe
2023-05-12 14:52:22,003:INFO:Initializing create_model()
2023-05-12 14:52:22,004:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:52:22,004:INFO:Checking exceptions
2023-05-12 14:52:22,006:INFO:Importing libraries
2023-05-12 14:52:22,007:INFO:Copying training dataset
2023-05-12 14:52:22,009:INFO:Defining folds
2023-05-12 14:52:22,009:INFO:Declaring metric variables
2023-05-12 14:52:22,010:INFO:Importing untrained model
2023-05-12 14:52:22,010:INFO:Declaring custom model
2023-05-12 14:52:22,010:INFO:Linear Regression Imported successfully
2023-05-12 14:52:22,011:INFO:Cross validation set to False
2023-05-12 14:52:22,011:INFO:Fitting Model
2023-05-12 14:52:22,040:INFO:LinearRegression(n_jobs=-1)
2023-05-12 14:52:22,040:INFO:create_model() successfully completed......................................
2023-05-12 14:52:22,168:INFO:_master_model_container: 19
2023-05-12 14:52:22,168:INFO:_display_container: 2
2023-05-12 14:52:22,168:INFO:LinearRegression(n_jobs=-1)
2023-05-12 14:52:22,169:INFO:compare_models() successfully completed......................................
2023-05-12 14:52:22,306:INFO:Initializing create_model()
2023-05-12 14:52:22,306:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:52:22,306:INFO:Checking exceptions
2023-05-12 14:52:22,364:INFO:Importing libraries
2023-05-12 14:52:22,364:INFO:Copying training dataset
2023-05-12 14:52:22,369:INFO:Defining folds
2023-05-12 14:52:22,370:INFO:Declaring metric variables
2023-05-12 14:52:22,376:INFO:Importing untrained model
2023-05-12 14:52:22,387:INFO:Huber Regressor Imported successfully
2023-05-12 14:52:22,404:INFO:Starting cross validation
2023-05-12 14:52:22,406:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:52:22,749:INFO:Calculating mean and std
2023-05-12 14:52:22,749:INFO:Creating metrics dataframe
2023-05-12 14:52:22,756:INFO:Finalizing model
2023-05-12 14:52:22,794:INFO:Uploading results into container
2023-05-12 14:52:22,796:INFO:Uploading model into container now
2023-05-12 14:52:22,809:INFO:_master_model_container: 20
2023-05-12 14:52:22,809:INFO:_display_container: 3
2023-05-12 14:52:22,810:INFO:HuberRegressor()
2023-05-12 14:52:22,810:INFO:create_model() successfully completed......................................
2023-05-12 14:52:23,024:INFO:Initializing evaluate_model()
2023-05-12 14:52:23,025:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-05-12 14:52:23,058:INFO:Initializing plot_model()
2023-05-12 14:52:23,058:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, system=True)
2023-05-12 14:52:23,059:INFO:Checking exceptions
2023-05-12 14:52:23,062:INFO:Preloading libraries
2023-05-12 14:52:23,062:INFO:Copying training dataset
2023-05-12 14:52:23,062:INFO:Plot type: pipeline
2023-05-12 14:52:23,321:INFO:Visual Rendered Successfully
2023-05-12 14:52:23,417:INFO:plot_model() successfully completed......................................
2023-05-12 14:52:23,518:INFO:Initializing predict_model()
2023-05-12 14:52:23,518:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000025CF781BEB0>)
2023-05-12 14:52:23,518:INFO:Checking exceptions
2023-05-12 14:52:23,518:INFO:Preloading libraries
2023-05-12 14:52:23,522:INFO:Set up data.
2023-05-12 14:52:23,532:INFO:Set up index.
2023-05-12 14:55:09,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:09,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:09,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:09,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:11,043:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-12 14:55:13,937:INFO:PyCaret RegressionExperiment
2023-05-12 14:55:13,938:INFO:Logging name: reg-default-name
2023-05-12 14:55:13,939:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-12 14:55:13,940:INFO:version 3.0.0.rc8
2023-05-12 14:55:13,941:INFO:Initializing setup()
2023-05-12 14:55:13,942:INFO:self.USI: 4fe9
2023-05-12 14:55:13,943:INFO:self._variable_keys: {'html_param', 'memory', '_available_plots', 'seed', 'idx', 'fold_groups_param', 'X', 'data', 'y_test', 'gpu_param', 'exp_name_log', 'exp_id', 'X_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'logging_param', 'USI', 'log_plots_param', 'y', 'n_jobs_param', '_ml_usecase', 'y_train', 'fold_generator', 'transform_target_param', 'pipeline', 'X_train', 'target_param'}
2023-05-12 14:55:13,944:INFO:Checking environment
2023-05-12 14:55:13,944:INFO:python_version: 3.10.9
2023-05-12 14:55:13,945:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-05-12 14:55:13,945:INFO:machine: AMD64
2023-05-12 14:55:13,945:INFO:platform: Windows-10-10.0.19045-SP0
2023-05-12 14:55:13,946:INFO:Memory: svmem(total=17090879488, available=2996797440, percent=82.5, used=14094082048, free=2996797440)
2023-05-12 14:55:13,946:INFO:Physical Core: 4
2023-05-12 14:55:13,946:INFO:Logical Core: 8
2023-05-12 14:55:13,946:INFO:Checking libraries
2023-05-12 14:55:13,947:INFO:System:
2023-05-12 14:55:13,947:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-05-12 14:55:13,947:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-05-12 14:55:13,947:INFO:   machine: Windows-10-10.0.19045-SP0
2023-05-12 14:55:13,948:INFO:PyCaret required dependencies:
2023-05-12 14:55:13,948:INFO:                 pip: 23.0
2023-05-12 14:55:13,948:INFO:          setuptools: 67.1.0
2023-05-12 14:55:13,948:INFO:             pycaret: 3.0.0rc8
2023-05-12 14:55:13,949:INFO:             IPython: 8.8.0
2023-05-12 14:55:13,949:INFO:          ipywidgets: 8.0.4
2023-05-12 14:55:13,949:INFO:                tqdm: 4.64.1
2023-05-12 14:55:13,949:INFO:               numpy: 1.23.5
2023-05-12 14:55:13,949:INFO:              pandas: 1.5.3
2023-05-12 14:55:13,949:INFO:              jinja2: 3.1.2
2023-05-12 14:55:13,949:INFO:               scipy: 1.10.0
2023-05-12 14:55:13,950:INFO:              joblib: 1.2.0
2023-05-12 14:55:13,950:INFO:             sklearn: 1.1.3
2023-05-12 14:55:13,950:INFO:                pyod: 1.0.7
2023-05-12 14:55:13,950:INFO:            imblearn: 0.10.1
2023-05-12 14:55:13,950:INFO:   category_encoders: 2.6.0
2023-05-12 14:55:13,950:INFO:            lightgbm: 3.3.5
2023-05-12 14:55:13,950:INFO:               numba: 0.56.4
2023-05-12 14:55:13,950:INFO:            requests: 2.28.2
2023-05-12 14:55:13,951:INFO:          matplotlib: 3.6.3
2023-05-12 14:55:13,951:INFO:          scikitplot: 0.3.7
2023-05-12 14:55:13,951:INFO:         yellowbrick: 1.5
2023-05-12 14:55:13,951:INFO:              plotly: 5.13.0
2023-05-12 14:55:13,951:INFO:             kaleido: 0.2.1
2023-05-12 14:55:13,951:INFO:         statsmodels: 0.13.5
2023-05-12 14:55:13,951:INFO:              sktime: 0.16.0
2023-05-12 14:55:13,951:INFO:               tbats: 1.1.2
2023-05-12 14:55:13,952:INFO:            pmdarima: 2.0.2
2023-05-12 14:55:13,952:INFO:              psutil: 5.9.0
2023-05-12 14:55:13,952:INFO:PyCaret optional dependencies:
2023-05-12 14:55:13,986:INFO:                shap: Not installed
2023-05-12 14:55:13,986:INFO:           interpret: Not installed
2023-05-12 14:55:13,986:INFO:                umap: Not installed
2023-05-12 14:55:13,986:INFO:    pandas_profiling: Not installed
2023-05-12 14:55:13,986:INFO:  explainerdashboard: Not installed
2023-05-12 14:55:13,986:INFO:             autoviz: Not installed
2023-05-12 14:55:13,986:INFO:           fairlearn: Not installed
2023-05-12 14:55:13,987:INFO:             xgboost: 1.7.3
2023-05-12 14:55:13,987:INFO:            catboost: Not installed
2023-05-12 14:55:13,987:INFO:              kmodes: Not installed
2023-05-12 14:55:13,987:INFO:             mlxtend: Not installed
2023-05-12 14:55:13,987:INFO:       statsforecast: Not installed
2023-05-12 14:55:13,987:INFO:        tune_sklearn: Not installed
2023-05-12 14:55:13,987:INFO:                 ray: Not installed
2023-05-12 14:55:13,987:INFO:            hyperopt: Not installed
2023-05-12 14:55:13,987:INFO:              optuna: Not installed
2023-05-12 14:55:13,987:INFO:               skopt: Not installed
2023-05-12 14:55:13,987:INFO:              mlflow: Not installed
2023-05-12 14:55:13,987:INFO:              gradio: Not installed
2023-05-12 14:55:13,987:INFO:             fastapi: Not installed
2023-05-12 14:55:13,987:INFO:             uvicorn: Not installed
2023-05-12 14:55:13,988:INFO:              m2cgen: Not installed
2023-05-12 14:55:13,988:INFO:           evidently: Not installed
2023-05-12 14:55:13,988:INFO:                nltk: Not installed
2023-05-12 14:55:13,988:INFO:            pyLDAvis: Not installed
2023-05-12 14:55:13,988:INFO:              gensim: Not installed
2023-05-12 14:55:13,988:INFO:               spacy: Not installed
2023-05-12 14:55:13,988:INFO:           wordcloud: Not installed
2023-05-12 14:55:13,988:INFO:            textblob: Not installed
2023-05-12 14:55:13,988:INFO:               fugue: Not installed
2023-05-12 14:55:13,988:INFO:           streamlit: Not installed
2023-05-12 14:55:13,988:INFO:             prophet: Not installed
2023-05-12 14:55:13,988:INFO:None
2023-05-12 14:55:13,988:INFO:Set up GPU usage.
2023-05-12 14:55:13,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:13,988:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-05-12 14:55:13,989:INFO:Set up data.
2023-05-12 14:55:13,993:INFO:Set up train/test split.
2023-05-12 14:55:13,995:INFO:Set up index.
2023-05-12 14:55:13,995:INFO:Set up folding strategy.
2023-05-12 14:55:13,996:INFO:Assigning column types.
2023-05-12 14:55:13,999:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-12 14:55:13,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:13,999:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 14:55:13,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,005:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,010:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,089:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,089:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,144:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,145:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:14,522:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:14,523:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,523:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,537:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,552:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,666:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,717:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,717:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,718:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,718:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:14,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:14,900:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-12 14:55:14,900:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,901:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,913:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,913:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,925:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,925:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,034:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,090:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,091:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:15,310:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:15,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,326:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,340:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,341:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,465:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,465:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,544:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,546:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:15,713:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:15,714:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-12 14:55:15,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,727:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,739:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,862:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,925:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,925:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,926:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,927:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:16,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:16,092:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,117:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:55:16,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,227:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:16,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,279:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:55:16,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,281:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:16,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:16,449:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-12 14:55:16,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,477:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,584:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:16,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,639:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:55:16,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,643:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:16,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:16,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,847:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,970:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:16,971:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,040:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:55:17,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,042:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:17,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:17,228:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-12 14:55:17,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,365:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:17,366:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,425:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,425:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,426:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:17,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:17,590:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,740:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:17,740:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,794:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:17,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:17,972:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-12 14:55:17,972:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,110:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,162:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,162:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,162:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:18,329:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:18,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,344:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,471:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,522:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,523:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,523:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:18,688:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:18,691:INFO:Preparing preprocessing pipeline...
2023-05-12 14:55:18,693:INFO:Set up simple imputation.
2023-05-12 14:55:18,759:INFO:Finished creating preprocessing pipeline.
2023-05-12 14:55:18,769:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-05-12 14:55:18,769:INFO:Creating final display dataframe.
2023-05-12 14:55:18,969:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape          (731, 2)
4        Transformed data shape          (731, 2)
5   Transformed train set shape          (511, 2)
6    Transformed test set shape          (220, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              4fe9
2023-05-12 14:55:18,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,120:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:19,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:19,312:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,340:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,450:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,506:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:19,679:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:19,681:INFO:setup() successfully completed in 5.75s...............
2023-05-12 14:55:19,719:INFO:Initializing compare_models()
2023-05-12 14:55:19,720:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-12 14:55:19,720:INFO:Checking exceptions
2023-05-12 14:55:19,724:INFO:Preparing display monitor
2023-05-12 14:55:19,795:INFO:Initializing Linear Regression
2023-05-12 14:55:19,795:INFO:Total runtime is 0.0 minutes
2023-05-12 14:55:19,803:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:19,803:INFO:Initializing create_model()
2023-05-12 14:55:19,804:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:19,804:INFO:Checking exceptions
2023-05-12 14:55:19,804:INFO:Importing libraries
2023-05-12 14:55:19,804:INFO:Copying training dataset
2023-05-12 14:55:19,808:INFO:Defining folds
2023-05-12 14:55:19,808:INFO:Declaring metric variables
2023-05-12 14:55:19,813:INFO:Importing untrained model
2023-05-12 14:55:19,819:INFO:Linear Regression Imported successfully
2023-05-12 14:55:19,830:INFO:Starting cross validation
2023-05-12 14:55:19,840:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:20,671:INFO:Calculating mean and std
2023-05-12 14:55:20,671:INFO:Creating metrics dataframe
2023-05-12 14:55:20,675:INFO:Uploading results into container
2023-05-12 14:55:20,676:INFO:Uploading model into container now
2023-05-12 14:55:20,677:INFO:_master_model_container: 1
2023-05-12 14:55:20,677:INFO:_display_container: 2
2023-05-12 14:55:20,677:INFO:LinearRegression(n_jobs=-1)
2023-05-12 14:55:20,677:INFO:create_model() successfully completed......................................
2023-05-12 14:55:20,762:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:20,762:INFO:Creating metrics dataframe
2023-05-12 14:55:20,774:INFO:Initializing Lasso Regression
2023-05-12 14:55:20,774:INFO:Total runtime is 0.016316898663838706 minutes
2023-05-12 14:55:20,778:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:20,779:INFO:Initializing create_model()
2023-05-12 14:55:20,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:20,779:INFO:Checking exceptions
2023-05-12 14:55:20,779:INFO:Importing libraries
2023-05-12 14:55:20,779:INFO:Copying training dataset
2023-05-12 14:55:20,783:INFO:Defining folds
2023-05-12 14:55:20,784:INFO:Declaring metric variables
2023-05-12 14:55:20,789:INFO:Importing untrained model
2023-05-12 14:55:20,795:INFO:Lasso Regression Imported successfully
2023-05-12 14:55:20,805:INFO:Starting cross validation
2023-05-12 14:55:20,806:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:20,878:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.814e+08, tolerance: 9.007e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:20,926:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.327e+08, tolerance: 9.082e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:20,967:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.914e+08, tolerance: 9.031e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:21,007:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.116e+08, tolerance: 9.143e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:21,047:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.606e+08, tolerance: 9.165e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:21,087:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.105e+08, tolerance: 8.948e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:21,127:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.059e+08, tolerance: 8.970e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:21,167:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.385e+08, tolerance: 9.263e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:21,207:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.838e+08, tolerance: 9.056e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:21,224:INFO:Calculating mean and std
2023-05-12 14:55:21,225:INFO:Creating metrics dataframe
2023-05-12 14:55:21,230:INFO:Uploading results into container
2023-05-12 14:55:21,231:INFO:Uploading model into container now
2023-05-12 14:55:21,231:INFO:_master_model_container: 2
2023-05-12 14:55:21,231:INFO:_display_container: 2
2023-05-12 14:55:21,232:INFO:Lasso(random_state=123)
2023-05-12 14:55:21,232:INFO:create_model() successfully completed......................................
2023-05-12 14:55:21,314:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:21,314:INFO:Creating metrics dataframe
2023-05-12 14:55:21,327:INFO:Initializing Ridge Regression
2023-05-12 14:55:21,327:INFO:Total runtime is 0.025526857376098635 minutes
2023-05-12 14:55:21,332:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:21,332:INFO:Initializing create_model()
2023-05-12 14:55:21,333:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:21,333:INFO:Checking exceptions
2023-05-12 14:55:21,333:INFO:Importing libraries
2023-05-12 14:55:21,333:INFO:Copying training dataset
2023-05-12 14:55:21,338:INFO:Defining folds
2023-05-12 14:55:21,338:INFO:Declaring metric variables
2023-05-12 14:55:21,344:INFO:Importing untrained model
2023-05-12 14:55:21,350:INFO:Ridge Regression Imported successfully
2023-05-12 14:55:21,360:INFO:Starting cross validation
2023-05-12 14:55:21,361:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:21,816:INFO:Calculating mean and std
2023-05-12 14:55:21,819:INFO:Creating metrics dataframe
2023-05-12 14:55:21,823:INFO:Uploading results into container
2023-05-12 14:55:21,824:INFO:Uploading model into container now
2023-05-12 14:55:21,825:INFO:_master_model_container: 3
2023-05-12 14:55:21,825:INFO:_display_container: 2
2023-05-12 14:55:21,826:INFO:Ridge(random_state=123)
2023-05-12 14:55:21,826:INFO:create_model() successfully completed......................................
2023-05-12 14:55:21,909:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:21,909:INFO:Creating metrics dataframe
2023-05-12 14:55:21,921:INFO:Initializing Elastic Net
2023-05-12 14:55:21,922:INFO:Total runtime is 0.035443580150604254 minutes
2023-05-12 14:55:21,928:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:21,928:INFO:Initializing create_model()
2023-05-12 14:55:21,928:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:21,928:INFO:Checking exceptions
2023-05-12 14:55:21,928:INFO:Importing libraries
2023-05-12 14:55:21,928:INFO:Copying training dataset
2023-05-12 14:55:21,932:INFO:Defining folds
2023-05-12 14:55:21,932:INFO:Declaring metric variables
2023-05-12 14:55:21,938:INFO:Importing untrained model
2023-05-12 14:55:21,944:INFO:Elastic Net Imported successfully
2023-05-12 14:55:21,955:INFO:Starting cross validation
2023-05-12 14:55:21,956:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:22,002:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.236e+08, tolerance: 9.007e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,030:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.542e+08, tolerance: 9.082e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,057:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.170e+08, tolerance: 9.031e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,080:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.308e+08, tolerance: 9.143e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,107:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.676e+08, tolerance: 9.165e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,136:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.372e+08, tolerance: 8.948e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,172:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.400e+08, tolerance: 8.970e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,197:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.545e+08, tolerance: 9.263e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,222:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.233e+08, tolerance: 9.056e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,232:INFO:Calculating mean and std
2023-05-12 14:55:22,233:INFO:Creating metrics dataframe
2023-05-12 14:55:22,238:INFO:Uploading results into container
2023-05-12 14:55:22,239:INFO:Uploading model into container now
2023-05-12 14:55:22,239:INFO:_master_model_container: 4
2023-05-12 14:55:22,239:INFO:_display_container: 2
2023-05-12 14:55:22,240:INFO:ElasticNet(random_state=123)
2023-05-12 14:55:22,240:INFO:create_model() successfully completed......................................
2023-05-12 14:55:22,319:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:22,319:INFO:Creating metrics dataframe
2023-05-12 14:55:22,332:INFO:Initializing Least Angle Regression
2023-05-12 14:55:22,332:INFO:Total runtime is 0.042277646064758305 minutes
2023-05-12 14:55:22,338:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:22,338:INFO:Initializing create_model()
2023-05-12 14:55:22,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:22,339:INFO:Checking exceptions
2023-05-12 14:55:22,339:INFO:Importing libraries
2023-05-12 14:55:22,339:INFO:Copying training dataset
2023-05-12 14:55:22,342:INFO:Defining folds
2023-05-12 14:55:22,343:INFO:Declaring metric variables
2023-05-12 14:55:22,348:INFO:Importing untrained model
2023-05-12 14:55:22,353:INFO:Least Angle Regression Imported successfully
2023-05-12 14:55:22,362:INFO:Starting cross validation
2023-05-12 14:55:22,363:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:22,380:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,404:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,428:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,451:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,477:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,500:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,524:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,553:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,582:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,612:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,625:INFO:Calculating mean and std
2023-05-12 14:55:22,626:INFO:Creating metrics dataframe
2023-05-12 14:55:22,630:INFO:Uploading results into container
2023-05-12 14:55:22,631:INFO:Uploading model into container now
2023-05-12 14:55:22,631:INFO:_master_model_container: 5
2023-05-12 14:55:22,631:INFO:_display_container: 2
2023-05-12 14:55:22,632:INFO:Lars(random_state=123)
2023-05-12 14:55:22,632:INFO:create_model() successfully completed......................................
2023-05-12 14:55:22,714:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:22,715:INFO:Creating metrics dataframe
2023-05-12 14:55:22,729:INFO:Initializing Lasso Least Angle Regression
2023-05-12 14:55:22,729:INFO:Total runtime is 0.04889397223790487 minutes
2023-05-12 14:55:22,735:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:22,736:INFO:Initializing create_model()
2023-05-12 14:55:22,737:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:22,737:INFO:Checking exceptions
2023-05-12 14:55:22,737:INFO:Importing libraries
2023-05-12 14:55:22,737:INFO:Copying training dataset
2023-05-12 14:55:22,741:INFO:Defining folds
2023-05-12 14:55:22,741:INFO:Declaring metric variables
2023-05-12 14:55:22,748:INFO:Importing untrained model
2023-05-12 14:55:22,754:INFO:Lasso Least Angle Regression Imported successfully
2023-05-12 14:55:22,765:INFO:Starting cross validation
2023-05-12 14:55:22,766:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:22,784:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:22,810:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:22,835:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:22,859:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:22,883:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:22,908:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:22,934:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:22,960:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:22,990:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:23,016:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:23,029:INFO:Calculating mean and std
2023-05-12 14:55:23,031:INFO:Creating metrics dataframe
2023-05-12 14:55:23,037:INFO:Uploading results into container
2023-05-12 14:55:23,038:INFO:Uploading model into container now
2023-05-12 14:55:23,039:INFO:_master_model_container: 6
2023-05-12 14:55:23,039:INFO:_display_container: 2
2023-05-12 14:55:23,040:INFO:LassoLars(random_state=123)
2023-05-12 14:55:23,040:INFO:create_model() successfully completed......................................
2023-05-12 14:55:23,130:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:23,130:INFO:Creating metrics dataframe
2023-05-12 14:55:23,145:INFO:Initializing Orthogonal Matching Pursuit
2023-05-12 14:55:23,146:INFO:Total runtime is 0.05584694147109986 minutes
2023-05-12 14:55:23,151:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:23,152:INFO:Initializing create_model()
2023-05-12 14:55:23,152:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:23,152:INFO:Checking exceptions
2023-05-12 14:55:23,153:INFO:Importing libraries
2023-05-12 14:55:23,153:INFO:Copying training dataset
2023-05-12 14:55:23,157:INFO:Defining folds
2023-05-12 14:55:23,157:INFO:Declaring metric variables
2023-05-12 14:55:23,162:INFO:Importing untrained model
2023-05-12 14:55:23,169:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-12 14:55:23,182:INFO:Starting cross validation
2023-05-12 14:55:23,183:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:23,199:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,226:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,250:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,274:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,297:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,321:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,345:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,372:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,398:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,428:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,443:INFO:Calculating mean and std
2023-05-12 14:55:23,445:INFO:Creating metrics dataframe
2023-05-12 14:55:23,451:INFO:Uploading results into container
2023-05-12 14:55:23,452:INFO:Uploading model into container now
2023-05-12 14:55:23,453:INFO:_master_model_container: 7
2023-05-12 14:55:23,453:INFO:_display_container: 2
2023-05-12 14:55:23,453:INFO:OrthogonalMatchingPursuit()
2023-05-12 14:55:23,453:INFO:create_model() successfully completed......................................
2023-05-12 14:55:23,549:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:23,549:INFO:Creating metrics dataframe
2023-05-12 14:55:23,574:INFO:Initializing Bayesian Ridge
2023-05-12 14:55:23,575:INFO:Total runtime is 0.06299696365992229 minutes
2023-05-12 14:55:23,581:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:23,581:INFO:Initializing create_model()
2023-05-12 14:55:23,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:23,582:INFO:Checking exceptions
2023-05-12 14:55:23,582:INFO:Importing libraries
2023-05-12 14:55:23,582:INFO:Copying training dataset
2023-05-12 14:55:23,588:INFO:Defining folds
2023-05-12 14:55:23,589:INFO:Declaring metric variables
2023-05-12 14:55:23,595:INFO:Importing untrained model
2023-05-12 14:55:23,607:INFO:Bayesian Ridge Imported successfully
2023-05-12 14:55:23,623:INFO:Starting cross validation
2023-05-12 14:55:23,624:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:24,024:INFO:Calculating mean and std
2023-05-12 14:55:24,025:INFO:Creating metrics dataframe
2023-05-12 14:55:24,029:INFO:Uploading results into container
2023-05-12 14:55:24,030:INFO:Uploading model into container now
2023-05-12 14:55:24,031:INFO:_master_model_container: 8
2023-05-12 14:55:24,031:INFO:_display_container: 2
2023-05-12 14:55:24,032:INFO:BayesianRidge()
2023-05-12 14:55:24,032:INFO:create_model() successfully completed......................................
2023-05-12 14:55:24,131:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:24,131:INFO:Creating metrics dataframe
2023-05-12 14:55:24,149:INFO:Initializing Passive Aggressive Regressor
2023-05-12 14:55:24,149:INFO:Total runtime is 0.07256452242533366 minutes
2023-05-12 14:55:24,157:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:24,157:INFO:Initializing create_model()
2023-05-12 14:55:24,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:24,157:INFO:Checking exceptions
2023-05-12 14:55:24,158:INFO:Importing libraries
2023-05-12 14:55:24,158:INFO:Copying training dataset
2023-05-12 14:55:24,162:INFO:Defining folds
2023-05-12 14:55:24,162:INFO:Declaring metric variables
2023-05-12 14:55:24,171:INFO:Importing untrained model
2023-05-12 14:55:24,177:INFO:Passive Aggressive Regressor Imported successfully
2023-05-12 14:55:24,193:INFO:Starting cross validation
2023-05-12 14:55:24,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:24,523:INFO:Calculating mean and std
2023-05-12 14:55:24,526:INFO:Creating metrics dataframe
2023-05-12 14:55:24,530:INFO:Uploading results into container
2023-05-12 14:55:24,531:INFO:Uploading model into container now
2023-05-12 14:55:24,533:INFO:_master_model_container: 9
2023-05-12 14:55:24,534:INFO:_display_container: 2
2023-05-12 14:55:24,535:INFO:PassiveAggressiveRegressor(random_state=123)
2023-05-12 14:55:24,536:INFO:create_model() successfully completed......................................
2023-05-12 14:55:24,632:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:24,633:INFO:Creating metrics dataframe
2023-05-12 14:55:24,654:INFO:Initializing Huber Regressor
2023-05-12 14:55:24,654:INFO:Total runtime is 0.08098121881484986 minutes
2023-05-12 14:55:24,661:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:24,661:INFO:Initializing create_model()
2023-05-12 14:55:24,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:24,661:INFO:Checking exceptions
2023-05-12 14:55:24,662:INFO:Importing libraries
2023-05-12 14:55:24,662:INFO:Copying training dataset
2023-05-12 14:55:24,665:INFO:Defining folds
2023-05-12 14:55:24,665:INFO:Declaring metric variables
2023-05-12 14:55:24,672:INFO:Importing untrained model
2023-05-12 14:55:24,679:INFO:Huber Regressor Imported successfully
2023-05-12 14:55:24,691:INFO:Starting cross validation
2023-05-12 14:55:24,692:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:25,075:INFO:Calculating mean and std
2023-05-12 14:55:25,077:INFO:Creating metrics dataframe
2023-05-12 14:55:25,081:INFO:Uploading results into container
2023-05-12 14:55:25,082:INFO:Uploading model into container now
2023-05-12 14:55:25,084:INFO:_master_model_container: 10
2023-05-12 14:55:25,085:INFO:_display_container: 2
2023-05-12 14:55:25,086:INFO:HuberRegressor()
2023-05-12 14:55:25,087:INFO:create_model() successfully completed......................................
2023-05-12 14:55:25,180:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:25,180:INFO:Creating metrics dataframe
2023-05-12 14:55:25,196:INFO:Initializing K Neighbors Regressor
2023-05-12 14:55:25,197:INFO:Total runtime is 0.09002394676208497 minutes
2023-05-12 14:55:25,204:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:25,205:INFO:Initializing create_model()
2023-05-12 14:55:25,205:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:25,205:INFO:Checking exceptions
2023-05-12 14:55:25,205:INFO:Importing libraries
2023-05-12 14:55:25,205:INFO:Copying training dataset
2023-05-12 14:55:25,209:INFO:Defining folds
2023-05-12 14:55:25,209:INFO:Declaring metric variables
2023-05-12 14:55:25,216:INFO:Importing untrained model
2023-05-12 14:55:25,226:INFO:K Neighbors Regressor Imported successfully
2023-05-12 14:55:25,237:INFO:Starting cross validation
2023-05-12 14:55:25,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:32,367:INFO:Calculating mean and std
2023-05-12 14:55:32,368:INFO:Creating metrics dataframe
2023-05-12 14:55:32,372:INFO:Uploading results into container
2023-05-12 14:55:32,373:INFO:Uploading model into container now
2023-05-12 14:55:32,373:INFO:_master_model_container: 11
2023-05-12 14:55:32,373:INFO:_display_container: 2
2023-05-12 14:55:32,374:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-12 14:55:32,374:INFO:create_model() successfully completed......................................
2023-05-12 14:55:32,456:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:32,456:INFO:Creating metrics dataframe
2023-05-12 14:55:32,479:INFO:Initializing Decision Tree Regressor
2023-05-12 14:55:32,480:INFO:Total runtime is 0.2113990902900696 minutes
2023-05-12 14:55:32,487:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:32,488:INFO:Initializing create_model()
2023-05-12 14:55:32,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:32,488:INFO:Checking exceptions
2023-05-12 14:55:32,488:INFO:Importing libraries
2023-05-12 14:55:32,488:INFO:Copying training dataset
2023-05-12 14:55:32,493:INFO:Defining folds
2023-05-12 14:55:32,494:INFO:Declaring metric variables
2023-05-12 14:55:32,502:INFO:Importing untrained model
2023-05-12 14:55:32,511:INFO:Decision Tree Regressor Imported successfully
2023-05-12 14:55:32,528:INFO:Starting cross validation
2023-05-12 14:55:32,529:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:32,785:INFO:Calculating mean and std
2023-05-12 14:55:32,786:INFO:Creating metrics dataframe
2023-05-12 14:55:32,791:INFO:Uploading results into container
2023-05-12 14:55:32,792:INFO:Uploading model into container now
2023-05-12 14:55:32,793:INFO:_master_model_container: 12
2023-05-12 14:55:32,793:INFO:_display_container: 2
2023-05-12 14:55:32,794:INFO:DecisionTreeRegressor(random_state=123)
2023-05-12 14:55:32,794:INFO:create_model() successfully completed......................................
2023-05-12 14:55:32,886:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:32,887:INFO:Creating metrics dataframe
2023-05-12 14:55:32,904:INFO:Initializing Random Forest Regressor
2023-05-12 14:55:32,904:INFO:Total runtime is 0.21848249435424805 minutes
2023-05-12 14:55:32,911:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:32,912:INFO:Initializing create_model()
2023-05-12 14:55:32,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:32,912:INFO:Checking exceptions
2023-05-12 14:55:32,912:INFO:Importing libraries
2023-05-12 14:55:32,912:INFO:Copying training dataset
2023-05-12 14:55:32,918:INFO:Defining folds
2023-05-12 14:55:32,919:INFO:Declaring metric variables
2023-05-12 14:55:32,925:INFO:Importing untrained model
2023-05-12 14:55:32,932:INFO:Random Forest Regressor Imported successfully
2023-05-12 14:55:32,945:INFO:Starting cross validation
2023-05-12 14:55:32,946:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:35,023:INFO:Calculating mean and std
2023-05-12 14:55:35,027:INFO:Creating metrics dataframe
2023-05-12 14:55:35,036:INFO:Uploading results into container
2023-05-12 14:55:35,038:INFO:Uploading model into container now
2023-05-12 14:55:35,038:INFO:_master_model_container: 13
2023-05-12 14:55:35,039:INFO:_display_container: 2
2023-05-12 14:55:35,040:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-05-12 14:55:35,040:INFO:create_model() successfully completed......................................
2023-05-12 14:55:35,156:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:35,156:INFO:Creating metrics dataframe
2023-05-12 14:55:35,179:INFO:Initializing Extra Trees Regressor
2023-05-12 14:55:35,179:INFO:Total runtime is 0.2563991109530131 minutes
2023-05-12 14:55:35,189:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:35,189:INFO:Initializing create_model()
2023-05-12 14:55:35,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:35,190:INFO:Checking exceptions
2023-05-12 14:55:35,190:INFO:Importing libraries
2023-05-12 14:55:35,190:INFO:Copying training dataset
2023-05-12 14:55:35,195:INFO:Defining folds
2023-05-12 14:55:35,196:INFO:Declaring metric variables
2023-05-12 14:55:35,202:INFO:Importing untrained model
2023-05-12 14:55:35,210:INFO:Extra Trees Regressor Imported successfully
2023-05-12 14:55:35,227:INFO:Starting cross validation
2023-05-12 14:55:35,229:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:37,263:INFO:Calculating mean and std
2023-05-12 14:55:37,265:INFO:Creating metrics dataframe
2023-05-12 14:55:37,271:INFO:Uploading results into container
2023-05-12 14:55:37,272:INFO:Uploading model into container now
2023-05-12 14:55:37,273:INFO:_master_model_container: 14
2023-05-12 14:55:37,273:INFO:_display_container: 2
2023-05-12 14:55:37,274:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-05-12 14:55:37,274:INFO:create_model() successfully completed......................................
2023-05-12 14:55:37,358:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:37,358:INFO:Creating metrics dataframe
2023-05-12 14:55:37,375:INFO:Initializing AdaBoost Regressor
2023-05-12 14:55:37,375:INFO:Total runtime is 0.2929990847905477 minutes
2023-05-12 14:55:37,380:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:37,380:INFO:Initializing create_model()
2023-05-12 14:55:37,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:37,381:INFO:Checking exceptions
2023-05-12 14:55:37,381:INFO:Importing libraries
2023-05-12 14:55:37,381:INFO:Copying training dataset
2023-05-12 14:55:37,387:INFO:Defining folds
2023-05-12 14:55:37,387:INFO:Declaring metric variables
2023-05-12 14:55:37,393:INFO:Importing untrained model
2023-05-12 14:55:37,401:INFO:AdaBoost Regressor Imported successfully
2023-05-12 14:55:37,413:INFO:Starting cross validation
2023-05-12 14:55:37,414:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:37,923:INFO:Calculating mean and std
2023-05-12 14:55:37,924:INFO:Creating metrics dataframe
2023-05-12 14:55:37,928:INFO:Uploading results into container
2023-05-12 14:55:37,929:INFO:Uploading model into container now
2023-05-12 14:55:37,930:INFO:_master_model_container: 15
2023-05-12 14:55:37,930:INFO:_display_container: 2
2023-05-12 14:55:37,931:INFO:AdaBoostRegressor(random_state=123)
2023-05-12 14:55:37,931:INFO:create_model() successfully completed......................................
2023-05-12 14:55:38,037:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:38,038:INFO:Creating metrics dataframe
2023-05-12 14:55:38,060:INFO:Initializing Gradient Boosting Regressor
2023-05-12 14:55:38,061:INFO:Total runtime is 0.3044326980908712 minutes
2023-05-12 14:55:38,068:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:38,069:INFO:Initializing create_model()
2023-05-12 14:55:38,069:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:38,070:INFO:Checking exceptions
2023-05-12 14:55:38,070:INFO:Importing libraries
2023-05-12 14:55:38,070:INFO:Copying training dataset
2023-05-12 14:55:38,076:INFO:Defining folds
2023-05-12 14:55:38,076:INFO:Declaring metric variables
2023-05-12 14:55:38,085:INFO:Importing untrained model
2023-05-12 14:55:38,094:INFO:Gradient Boosting Regressor Imported successfully
2023-05-12 14:55:38,111:INFO:Starting cross validation
2023-05-12 14:55:38,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:38,737:INFO:Calculating mean and std
2023-05-12 14:55:38,739:INFO:Creating metrics dataframe
2023-05-12 14:55:38,743:INFO:Uploading results into container
2023-05-12 14:55:38,744:INFO:Uploading model into container now
2023-05-12 14:55:38,744:INFO:_master_model_container: 16
2023-05-12 14:55:38,745:INFO:_display_container: 2
2023-05-12 14:55:38,745:INFO:GradientBoostingRegressor(random_state=123)
2023-05-12 14:55:38,745:INFO:create_model() successfully completed......................................
2023-05-12 14:55:38,826:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:38,826:INFO:Creating metrics dataframe
2023-05-12 14:55:38,843:INFO:Initializing Extreme Gradient Boosting
2023-05-12 14:55:38,843:INFO:Total runtime is 0.31746578216552734 minutes
2023-05-12 14:55:38,848:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:38,849:INFO:Initializing create_model()
2023-05-12 14:55:38,849:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:38,849:INFO:Checking exceptions
2023-05-12 14:55:38,849:INFO:Importing libraries
2023-05-12 14:55:38,850:INFO:Copying training dataset
2023-05-12 14:55:38,856:INFO:Defining folds
2023-05-12 14:55:38,856:INFO:Declaring metric variables
2023-05-12 14:55:38,861:INFO:Importing untrained model
2023-05-12 14:55:38,870:INFO:Extreme Gradient Boosting Imported successfully
2023-05-12 14:55:38,882:INFO:Starting cross validation
2023-05-12 14:55:38,883:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:44,459:INFO:Calculating mean and std
2023-05-12 14:55:44,462:INFO:Creating metrics dataframe
2023-05-12 14:55:44,469:INFO:Uploading results into container
2023-05-12 14:55:44,470:INFO:Uploading model into container now
2023-05-12 14:55:44,471:INFO:_master_model_container: 17
2023-05-12 14:55:44,472:INFO:_display_container: 2
2023-05-12 14:55:44,474:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-05-12 14:55:44,474:INFO:create_model() successfully completed......................................
2023-05-12 14:55:44,587:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:44,587:INFO:Creating metrics dataframe
2023-05-12 14:55:44,609:INFO:Initializing Light Gradient Boosting Machine
2023-05-12 14:55:44,610:INFO:Total runtime is 0.4135751247406006 minutes
2023-05-12 14:55:44,617:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:44,618:INFO:Initializing create_model()
2023-05-12 14:55:44,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:44,618:INFO:Checking exceptions
2023-05-12 14:55:44,618:INFO:Importing libraries
2023-05-12 14:55:44,618:INFO:Copying training dataset
2023-05-12 14:55:44,622:INFO:Defining folds
2023-05-12 14:55:44,622:INFO:Declaring metric variables
2023-05-12 14:55:44,632:INFO:Importing untrained model
2023-05-12 14:55:44,656:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-12 14:55:44,673:INFO:Starting cross validation
2023-05-12 14:55:44,675:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:51,924:INFO:Calculating mean and std
2023-05-12 14:55:51,927:INFO:Creating metrics dataframe
2023-05-12 14:55:51,935:INFO:Uploading results into container
2023-05-12 14:55:51,936:INFO:Uploading model into container now
2023-05-12 14:55:51,937:INFO:_master_model_container: 18
2023-05-12 14:55:51,937:INFO:_display_container: 2
2023-05-12 14:55:51,938:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-05-12 14:55:51,938:INFO:create_model() successfully completed......................................
2023-05-12 14:55:52,074:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:52,074:INFO:Creating metrics dataframe
2023-05-12 14:55:52,092:INFO:Initializing Dummy Regressor
2023-05-12 14:55:52,092:INFO:Total runtime is 0.5382695674896241 minutes
2023-05-12 14:55:52,097:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:52,098:INFO:Initializing create_model()
2023-05-12 14:55:52,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:52,098:INFO:Checking exceptions
2023-05-12 14:55:52,098:INFO:Importing libraries
2023-05-12 14:55:52,098:INFO:Copying training dataset
2023-05-12 14:55:52,103:INFO:Defining folds
2023-05-12 14:55:52,103:INFO:Declaring metric variables
2023-05-12 14:55:52,109:INFO:Importing untrained model
2023-05-12 14:55:52,115:INFO:Dummy Regressor Imported successfully
2023-05-12 14:55:52,125:INFO:Starting cross validation
2023-05-12 14:55:52,126:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:52,346:INFO:Calculating mean and std
2023-05-12 14:55:52,347:INFO:Creating metrics dataframe
2023-05-12 14:55:52,352:INFO:Uploading results into container
2023-05-12 14:55:52,352:INFO:Uploading model into container now
2023-05-12 14:55:52,353:INFO:_master_model_container: 19
2023-05-12 14:55:52,353:INFO:_display_container: 2
2023-05-12 14:55:52,353:INFO:DummyRegressor()
2023-05-12 14:55:52,354:INFO:create_model() successfully completed......................................
2023-05-12 14:55:52,434:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:52,434:INFO:Creating metrics dataframe
2023-05-12 14:55:52,467:INFO:Initializing create_model()
2023-05-12 14:55:52,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:52,467:INFO:Checking exceptions
2023-05-12 14:55:52,470:INFO:Importing libraries
2023-05-12 14:55:52,470:INFO:Copying training dataset
2023-05-12 14:55:52,473:INFO:Defining folds
2023-05-12 14:55:52,473:INFO:Declaring metric variables
2023-05-12 14:55:52,473:INFO:Importing untrained model
2023-05-12 14:55:52,473:INFO:Declaring custom model
2023-05-12 14:55:52,474:INFO:Huber Regressor Imported successfully
2023-05-12 14:55:52,475:INFO:Cross validation set to False
2023-05-12 14:55:52,475:INFO:Fitting Model
2023-05-12 14:55:52,514:INFO:HuberRegressor()
2023-05-12 14:55:52,514:INFO:create_model() successfully completed......................................
2023-05-12 14:55:52,653:INFO:_master_model_container: 19
2023-05-12 14:55:52,653:INFO:_display_container: 2
2023-05-12 14:55:52,654:INFO:HuberRegressor()
2023-05-12 14:55:52,654:INFO:compare_models() successfully completed......................................
2023-05-12 14:55:52,814:INFO:Initializing create_model()
2023-05-12 14:55:52,814:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:52,814:INFO:Checking exceptions
2023-05-12 14:55:52,858:INFO:Importing libraries
2023-05-12 14:55:52,858:INFO:Copying training dataset
2023-05-12 14:55:52,865:INFO:Defining folds
2023-05-12 14:55:52,865:INFO:Declaring metric variables
2023-05-12 14:55:52,870:INFO:Importing untrained model
2023-05-12 14:55:52,875:INFO:Huber Regressor Imported successfully
2023-05-12 14:55:52,893:INFO:Starting cross validation
2023-05-12 14:55:52,897:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:53,282:INFO:Calculating mean and std
2023-05-12 14:55:53,283:INFO:Creating metrics dataframe
2023-05-12 14:55:53,289:INFO:Finalizing model
2023-05-12 14:55:53,330:INFO:Uploading results into container
2023-05-12 14:55:53,331:INFO:Uploading model into container now
2023-05-12 14:55:53,346:INFO:_master_model_container: 20
2023-05-12 14:55:53,346:INFO:_display_container: 3
2023-05-12 14:55:53,346:INFO:HuberRegressor()
2023-05-12 14:55:53,347:INFO:create_model() successfully completed......................................
2023-05-12 14:55:53,601:INFO:Initializing evaluate_model()
2023-05-12 14:55:53,601:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-05-12 14:55:53,645:INFO:Initializing plot_model()
2023-05-12 14:55:53,646:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, system=True)
2023-05-12 14:55:53,646:INFO:Checking exceptions
2023-05-12 14:55:53,649:INFO:Preloading libraries
2023-05-12 14:55:53,650:INFO:Copying training dataset
2023-05-12 14:55:53,650:INFO:Plot type: pipeline
2023-05-12 14:55:53,880:INFO:Visual Rendered Successfully
2023-05-12 14:55:53,989:INFO:plot_model() successfully completed......................................
2023-05-12 14:55:54,104:INFO:Initializing predict_model()
2023-05-12 14:55:54,105:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A4A16EFC70>)
2023-05-12 14:55:54,105:INFO:Checking exceptions
2023-05-12 14:55:54,106:INFO:Preloading libraries
2023-05-12 14:55:54,110:INFO:Set up data.
2023-05-12 14:55:54,116:INFO:Set up index.
