2023-02-03 14:46:41,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 14:46:41,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 14:46:41,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 14:46:41,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 14:46:42,898:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-03 15:11:05,142:INFO:PyCaret RegressionExperiment
2023-02-03 15:11:05,143:INFO:Logging name: reg-default-name
2023-02-03 15:11:05,143:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-03 15:11:05,143:INFO:version 3.0.0.rc8
2023-02-03 15:11:05,143:INFO:Initializing setup()
2023-02-03 15:11:05,144:INFO:self.USI: b860
2023-02-03 15:11:05,144:INFO:self._variable_keys: {'_available_plots', 'n_jobs_param', '_ml_usecase', 'exp_id', 'logging_param', 'fold_generator', 'html_param', 'USI', 'gpu_param', 'fold_groups_param', 'exp_name_log', 'idx', 'memory', 'fold_shuffle_param', 'seed', 'gpu_n_jobs_param', 'y', 'y_train', 'X_train', 'X', 'X_test', 'pipeline', 'log_plots_param', 'data', 'transform_target_param', 'y_test', 'target_param'}
2023-02-03 15:11:05,145:INFO:Checking environment
2023-02-03 15:11:05,145:INFO:python_version: 3.10.9
2023-02-03 15:11:05,145:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-02-03 15:11:05,145:INFO:machine: AMD64
2023-02-03 15:11:05,145:INFO:platform: Windows-10-10.0.19045-SP0
2023-02-03 15:11:05,146:INFO:Memory: svmem(total=17090879488, available=6431473664, percent=62.4, used=10659405824, free=6431473664)
2023-02-03 15:11:05,146:INFO:Physical Core: 4
2023-02-03 15:11:05,146:INFO:Logical Core: 8
2023-02-03 15:11:05,147:INFO:Checking libraries
2023-02-03 15:11:05,147:INFO:System:
2023-02-03 15:11:05,147:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-02-03 15:11:05,147:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-02-03 15:11:05,147:INFO:   machine: Windows-10-10.0.19045-SP0
2023-02-03 15:11:05,147:INFO:PyCaret required dependencies:
2023-02-03 15:11:05,147:INFO:                 pip: 23.0
2023-02-03 15:11:05,147:INFO:          setuptools: 67.1.0
2023-02-03 15:11:05,147:INFO:             pycaret: 3.0.0rc8
2023-02-03 15:11:05,148:INFO:             IPython: 8.8.0
2023-02-03 15:11:05,148:INFO:          ipywidgets: 8.0.4
2023-02-03 15:11:05,148:INFO:                tqdm: 4.64.1
2023-02-03 15:11:05,148:INFO:               numpy: 1.23.5
2023-02-03 15:11:05,148:INFO:              pandas: 1.5.3
2023-02-03 15:11:05,148:INFO:              jinja2: 3.1.2
2023-02-03 15:11:05,148:INFO:               scipy: 1.10.0
2023-02-03 15:11:05,148:INFO:              joblib: 1.2.0
2023-02-03 15:11:05,148:INFO:             sklearn: 1.1.3
2023-02-03 15:11:05,148:INFO:                pyod: 1.0.7
2023-02-03 15:11:05,148:INFO:            imblearn: 0.10.1
2023-02-03 15:11:05,148:INFO:   category_encoders: 2.6.0
2023-02-03 15:11:05,148:INFO:            lightgbm: 3.3.5
2023-02-03 15:11:05,148:INFO:               numba: 0.56.4
2023-02-03 15:11:05,149:INFO:            requests: 2.28.2
2023-02-03 15:11:05,149:INFO:          matplotlib: 3.6.3
2023-02-03 15:11:05,149:INFO:          scikitplot: 0.3.7
2023-02-03 15:11:05,149:INFO:         yellowbrick: 1.5
2023-02-03 15:11:05,149:INFO:              plotly: 5.13.0
2023-02-03 15:11:05,149:INFO:             kaleido: 0.2.1
2023-02-03 15:11:05,149:INFO:         statsmodels: 0.13.5
2023-02-03 15:11:05,149:INFO:              sktime: 0.16.0
2023-02-03 15:11:05,149:INFO:               tbats: 1.1.2
2023-02-03 15:11:05,150:INFO:            pmdarima: 2.0.2
2023-02-03 15:11:05,150:INFO:              psutil: 5.9.0
2023-02-03 15:11:05,150:INFO:PyCaret optional dependencies:
2023-02-03 15:11:05,189:INFO:                shap: Not installed
2023-02-03 15:11:05,189:INFO:           interpret: Not installed
2023-02-03 15:11:05,190:INFO:                umap: Not installed
2023-02-03 15:11:05,190:INFO:    pandas_profiling: Not installed
2023-02-03 15:11:05,190:INFO:  explainerdashboard: Not installed
2023-02-03 15:11:05,190:INFO:             autoviz: Not installed
2023-02-03 15:11:05,190:INFO:           fairlearn: Not installed
2023-02-03 15:11:05,190:INFO:             xgboost: Not installed
2023-02-03 15:11:05,190:INFO:            catboost: Not installed
2023-02-03 15:11:05,191:INFO:              kmodes: Not installed
2023-02-03 15:11:05,191:INFO:             mlxtend: Not installed
2023-02-03 15:11:05,191:INFO:       statsforecast: Not installed
2023-02-03 15:11:05,191:INFO:        tune_sklearn: Not installed
2023-02-03 15:11:05,192:INFO:                 ray: Not installed
2023-02-03 15:11:05,192:INFO:            hyperopt: Not installed
2023-02-03 15:11:05,192:INFO:              optuna: Not installed
2023-02-03 15:11:05,193:INFO:               skopt: Not installed
2023-02-03 15:11:05,193:INFO:              mlflow: Not installed
2023-02-03 15:11:05,193:INFO:              gradio: Not installed
2023-02-03 15:11:05,193:INFO:             fastapi: Not installed
2023-02-03 15:11:05,193:INFO:             uvicorn: Not installed
2023-02-03 15:11:05,194:INFO:              m2cgen: Not installed
2023-02-03 15:11:05,194:INFO:           evidently: Not installed
2023-02-03 15:11:05,194:INFO:                nltk: Not installed
2023-02-03 15:11:05,194:INFO:            pyLDAvis: Not installed
2023-02-03 15:11:05,194:INFO:              gensim: Not installed
2023-02-03 15:11:05,194:INFO:               spacy: Not installed
2023-02-03 15:11:05,194:INFO:           wordcloud: Not installed
2023-02-03 15:11:05,194:INFO:            textblob: Not installed
2023-02-03 15:11:05,194:INFO:               fugue: Not installed
2023-02-03 15:11:05,195:INFO:           streamlit: Not installed
2023-02-03 15:11:05,195:INFO:             prophet: Not installed
2023-02-03 15:11:05,195:INFO:None
2023-02-03 15:11:05,195:INFO:Set up GPU usage.
2023-02-03 15:11:05,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:05,195:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-02-03 15:11:05,195:INFO:Set up data.
2023-02-03 15:11:05,205:INFO:Set up train/test split.
2023-02-03 15:11:05,209:INFO:Set up index.
2023-02-03 15:11:05,210:INFO:Set up folding strategy.
2023-02-03 15:11:05,210:INFO:Assigning column types.
2023-02-03 15:11:05,215:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-03 15:11:05,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:05,216:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-03 15:11:05,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:05,221:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-03 15:11:05,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:05,228:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:11:05,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:05,323:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:05,323:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:05,402:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:11:05,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:05,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:05,404:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:13,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:13,645:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:13,645:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-03 15:11:13,646:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:13,660:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-03 15:11:13,660:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:13,675:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:11:13,675:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:13,788:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:13,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:13,848:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:11:13,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:13,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:13,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:14,210:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:14,211:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-03 15:11:14,211:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,211:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,228:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-03 15:11:14,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,246:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:11:14,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,383:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:14,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,452:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:11:14,452:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,453:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:14,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:14,611:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,611:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,625:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-03 15:11:14,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,639:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:11:14,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,757:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:14,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,819:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:11:14,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,820:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:14,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:14,995:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-03 15:11:14,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:14,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,023:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:11:15,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,142:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:15,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,212:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:11:15,212:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,212:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,213:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:15,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:15,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,393:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,407:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:11:15,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,524:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:15,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,581:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:11:15,582:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,582:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:15,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:15,756:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-03 15:11:15,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,771:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,911:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:15,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,977:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:11:15,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:15,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:16,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:16,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,155:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,286:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:16,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,347:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:11:16,347:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,347:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,348:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:16,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:16,524:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-03 15:11:16,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,676:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:16,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,740:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,740:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:16,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:16,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:16,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,115:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:11:17,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,193:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:17,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:17,370:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-03 15:11:17,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,388:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,532:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:17,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:17,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,791:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:17,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:18,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:18,146:INFO:Preparing preprocessing pipeline...
2023-02-03 15:11:18,148:INFO:Set up simple imputation.
2023-02-03 15:11:18,208:INFO:Finished creating preprocessing pipeline.
2023-02-03 15:11:18,219:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-02-03 15:11:18,219:INFO:Creating final display dataframe.
2023-02-03 15:11:18,402:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape          (648, 2)
4        Transformed data shape          (648, 2)
5   Transformed train set shape          (453, 2)
6    Transformed test set shape          (195, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              b860
2023-02-03 15:11:18,412:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,423:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,428:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,522:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,586:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,587:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:18,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:18,755:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,783:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:11:18,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:19,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:11:19,116:INFO:setup() successfully completed in 13.98s...............
2023-02-03 15:12:03,091:INFO:PyCaret RegressionExperiment
2023-02-03 15:12:03,091:INFO:Logging name: reg-default-name
2023-02-03 15:12:03,091:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-03 15:12:03,091:INFO:version 3.0.0.rc8
2023-02-03 15:12:03,091:INFO:Initializing setup()
2023-02-03 15:12:03,092:INFO:self.USI: 42b7
2023-02-03 15:12:03,092:INFO:self._variable_keys: {'_available_plots', 'n_jobs_param', '_ml_usecase', 'exp_id', 'logging_param', 'fold_generator', 'html_param', 'USI', 'gpu_param', 'fold_groups_param', 'exp_name_log', 'idx', 'memory', 'fold_shuffle_param', 'seed', 'gpu_n_jobs_param', 'y', 'y_train', 'X_train', 'X', 'X_test', 'pipeline', 'log_plots_param', 'data', 'transform_target_param', 'y_test', 'target_param'}
2023-02-03 15:12:03,092:INFO:Checking environment
2023-02-03 15:12:03,092:INFO:python_version: 3.10.9
2023-02-03 15:12:03,092:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-02-03 15:12:03,092:INFO:machine: AMD64
2023-02-03 15:12:03,092:INFO:platform: Windows-10-10.0.19045-SP0
2023-02-03 15:12:03,092:INFO:Memory: svmem(total=17090879488, available=5927350272, percent=65.3, used=11163529216, free=5927350272)
2023-02-03 15:12:03,093:INFO:Physical Core: 4
2023-02-03 15:12:03,093:INFO:Logical Core: 8
2023-02-03 15:12:03,093:INFO:Checking libraries
2023-02-03 15:12:03,093:INFO:System:
2023-02-03 15:12:03,093:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-02-03 15:12:03,093:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-02-03 15:12:03,093:INFO:   machine: Windows-10-10.0.19045-SP0
2023-02-03 15:12:03,093:INFO:PyCaret required dependencies:
2023-02-03 15:12:03,094:INFO:                 pip: 23.0
2023-02-03 15:12:03,094:INFO:          setuptools: 67.1.0
2023-02-03 15:12:03,094:INFO:             pycaret: 3.0.0rc8
2023-02-03 15:12:03,094:INFO:             IPython: 8.8.0
2023-02-03 15:12:03,094:INFO:          ipywidgets: 8.0.4
2023-02-03 15:12:03,094:INFO:                tqdm: 4.64.1
2023-02-03 15:12:03,094:INFO:               numpy: 1.23.5
2023-02-03 15:12:03,094:INFO:              pandas: 1.5.3
2023-02-03 15:12:03,094:INFO:              jinja2: 3.1.2
2023-02-03 15:12:03,094:INFO:               scipy: 1.10.0
2023-02-03 15:12:03,095:INFO:              joblib: 1.2.0
2023-02-03 15:12:03,095:INFO:             sklearn: 1.1.3
2023-02-03 15:12:03,095:INFO:                pyod: 1.0.7
2023-02-03 15:12:03,095:INFO:            imblearn: 0.10.1
2023-02-03 15:12:03,095:INFO:   category_encoders: 2.6.0
2023-02-03 15:12:03,095:INFO:            lightgbm: 3.3.5
2023-02-03 15:12:03,095:INFO:               numba: 0.56.4
2023-02-03 15:12:03,095:INFO:            requests: 2.28.2
2023-02-03 15:12:03,095:INFO:          matplotlib: 3.6.3
2023-02-03 15:12:03,095:INFO:          scikitplot: 0.3.7
2023-02-03 15:12:03,096:INFO:         yellowbrick: 1.5
2023-02-03 15:12:03,096:INFO:              plotly: 5.13.0
2023-02-03 15:12:03,096:INFO:             kaleido: 0.2.1
2023-02-03 15:12:03,096:INFO:         statsmodels: 0.13.5
2023-02-03 15:12:03,096:INFO:              sktime: 0.16.0
2023-02-03 15:12:03,096:INFO:               tbats: 1.1.2
2023-02-03 15:12:03,096:INFO:            pmdarima: 2.0.2
2023-02-03 15:12:03,096:INFO:              psutil: 5.9.0
2023-02-03 15:12:03,096:INFO:PyCaret optional dependencies:
2023-02-03 15:12:03,096:INFO:                shap: Not installed
2023-02-03 15:12:03,096:INFO:           interpret: Not installed
2023-02-03 15:12:03,096:INFO:                umap: Not installed
2023-02-03 15:12:03,096:INFO:    pandas_profiling: Not installed
2023-02-03 15:12:03,097:INFO:  explainerdashboard: Not installed
2023-02-03 15:12:03,097:INFO:             autoviz: Not installed
2023-02-03 15:12:03,097:INFO:           fairlearn: Not installed
2023-02-03 15:12:03,097:INFO:             xgboost: Not installed
2023-02-03 15:12:03,097:INFO:            catboost: Not installed
2023-02-03 15:12:03,097:INFO:              kmodes: Not installed
2023-02-03 15:12:03,097:INFO:             mlxtend: Not installed
2023-02-03 15:12:03,097:INFO:       statsforecast: Not installed
2023-02-03 15:12:03,097:INFO:        tune_sklearn: Not installed
2023-02-03 15:12:03,098:INFO:                 ray: Not installed
2023-02-03 15:12:03,098:INFO:            hyperopt: Not installed
2023-02-03 15:12:03,098:INFO:              optuna: Not installed
2023-02-03 15:12:03,098:INFO:               skopt: Not installed
2023-02-03 15:12:03,098:INFO:              mlflow: Not installed
2023-02-03 15:12:03,098:INFO:              gradio: Not installed
2023-02-03 15:12:03,098:INFO:             fastapi: Not installed
2023-02-03 15:12:03,098:INFO:             uvicorn: Not installed
2023-02-03 15:12:03,098:INFO:              m2cgen: Not installed
2023-02-03 15:12:03,098:INFO:           evidently: Not installed
2023-02-03 15:12:03,099:INFO:                nltk: Not installed
2023-02-03 15:12:03,099:INFO:            pyLDAvis: Not installed
2023-02-03 15:12:03,099:INFO:              gensim: Not installed
2023-02-03 15:12:03,099:INFO:               spacy: Not installed
2023-02-03 15:12:03,099:INFO:           wordcloud: Not installed
2023-02-03 15:12:03,099:INFO:            textblob: Not installed
2023-02-03 15:12:03,100:INFO:               fugue: Not installed
2023-02-03 15:12:03,100:INFO:           streamlit: Not installed
2023-02-03 15:12:03,100:INFO:             prophet: Not installed
2023-02-03 15:12:03,100:INFO:None
2023-02-03 15:12:03,100:INFO:Set up GPU usage.
2023-02-03 15:12:03,100:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,100:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-02-03 15:12:03,100:INFO:Set up data.
2023-02-03 15:12:03,105:INFO:Set up train/test split.
2023-02-03 15:12:03,109:INFO:Set up index.
2023-02-03 15:12:03,109:INFO:Set up folding strategy.
2023-02-03 15:12:03,109:INFO:Assigning column types.
2023-02-03 15:12:03,113:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-03 15:12:03,114:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,114:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,114:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,120:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,120:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,129:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,214:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,277:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,278:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:03,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:03,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,455:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,468:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,483:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,603:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,669:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,669:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,669:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,670:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:03,836:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:03,837:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-03 15:12:03,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,851:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,861:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:03,969:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:03,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,026:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,027:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:04,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:04,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,216:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,229:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,343:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,343:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,409:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,409:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:04,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:04,563:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-03 15:12:04,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,577:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,591:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,702:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,702:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,759:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,759:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,759:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,760:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:04,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:04,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,931:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:04,941:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-03 15:12:04,941:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,055:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:05,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:12:05,121:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,121:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:05,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:05,273:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-03 15:12:05,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,299:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,420:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:05,420:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,485:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:12:05,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:05,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:05,650:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,651:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,665:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,795:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:05,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,862:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-03 15:12:05,862:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,862:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:05,863:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:06,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:06,031:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-03 15:12:06,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,059:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,175:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:06,175:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,239:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:06,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:06,396:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,411:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,425:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,546:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-03 15:12:06,546:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,609:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,609:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:06,763:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:06,764:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-03 15:12:06,764:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,764:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,792:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,909:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,971:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,972:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:06,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:07,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:07,134:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,134:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,279:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,339:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:07,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:07,499:INFO:Preparing preprocessing pipeline...
2023-02-03 15:12:07,500:INFO:Set up simple imputation.
2023-02-03 15:12:07,549:INFO:Finished creating preprocessing pipeline.
2023-02-03 15:12:07,556:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-02-03 15:12:07,556:INFO:Creating final display dataframe.
2023-02-03 15:12:07,760:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape          (959, 2)
4        Transformed data shape          (959, 2)
5   Transformed train set shape          (671, 2)
6    Transformed test set shape          (288, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              42b7
2023-02-03 15:12:07,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,783:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,925:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:07,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:08,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:08,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:08,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:08,154:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:08,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:08,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:08,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:08,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-03 15:12:08,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:08,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-03 15:12:08,497:INFO:setup() successfully completed in 5.41s...............
2023-02-03 15:14:56,207:INFO:Initializing compare_models()
2023-02-03 15:14:56,207:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, include=None, fold=None, round=4, cross_validation=True, sort=r2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'r2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-03 15:14:56,207:INFO:Checking exceptions
2023-02-03 15:14:56,214:INFO:Preparing display monitor
2023-02-03 15:14:56,263:INFO:Initializing Linear Regression
2023-02-03 15:14:56,263:INFO:Total runtime is 0.0 minutes
2023-02-03 15:14:56,273:INFO:SubProcess create_model() called ==================================
2023-02-03 15:14:56,274:INFO:Initializing create_model()
2023-02-03 15:14:56,274:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:14:56,275:INFO:Checking exceptions
2023-02-03 15:14:56,275:INFO:Importing libraries
2023-02-03 15:14:56,275:INFO:Copying training dataset
2023-02-03 15:14:56,282:INFO:Defining folds
2023-02-03 15:14:56,282:INFO:Declaring metric variables
2023-02-03 15:14:56,292:INFO:Importing untrained model
2023-02-03 15:14:56,298:INFO:Linear Regression Imported successfully
2023-02-03 15:14:56,313:INFO:Starting cross validation
2023-02-03 15:14:56,339:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:14:57,776:INFO:Calculating mean and std
2023-02-03 15:14:57,777:INFO:Creating metrics dataframe
2023-02-03 15:14:57,785:INFO:Uploading results into container
2023-02-03 15:14:57,786:INFO:Uploading model into container now
2023-02-03 15:14:57,787:INFO:_master_model_container: 1
2023-02-03 15:14:57,787:INFO:_display_container: 2
2023-02-03 15:14:57,787:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:14:57,787:INFO:create_model() successfully completed......................................
2023-02-03 15:14:57,913:INFO:SubProcess create_model() end ==================================
2023-02-03 15:14:57,913:INFO:Creating metrics dataframe
2023-02-03 15:14:57,923:INFO:Initializing Lasso Regression
2023-02-03 15:14:57,924:INFO:Total runtime is 0.0276871124903361 minutes
2023-02-03 15:14:57,932:INFO:SubProcess create_model() called ==================================
2023-02-03 15:14:57,933:INFO:Initializing create_model()
2023-02-03 15:14:57,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:14:57,934:INFO:Checking exceptions
2023-02-03 15:14:57,934:INFO:Importing libraries
2023-02-03 15:14:57,935:INFO:Copying training dataset
2023-02-03 15:14:57,942:INFO:Defining folds
2023-02-03 15:14:57,943:INFO:Declaring metric variables
2023-02-03 15:14:57,949:INFO:Importing untrained model
2023-02-03 15:14:57,954:INFO:Lasso Regression Imported successfully
2023-02-03 15:14:57,969:INFO:Starting cross validation
2023-02-03 15:14:57,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:14:58,035:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.653e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,091:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.713e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,208:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.832e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,270:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,324:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.826e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,370:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,425:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,480:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,541:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,589:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.356e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:58,609:INFO:Calculating mean and std
2023-02-03 15:14:58,611:INFO:Creating metrics dataframe
2023-02-03 15:14:58,617:INFO:Uploading results into container
2023-02-03 15:14:58,618:INFO:Uploading model into container now
2023-02-03 15:14:58,618:INFO:_master_model_container: 2
2023-02-03 15:14:58,619:INFO:_display_container: 2
2023-02-03 15:14:58,619:INFO:Lasso(random_state=123)
2023-02-03 15:14:58,619:INFO:create_model() successfully completed......................................
2023-02-03 15:14:58,723:INFO:SubProcess create_model() end ==================================
2023-02-03 15:14:58,725:INFO:Creating metrics dataframe
2023-02-03 15:14:58,738:INFO:Initializing Ridge Regression
2023-02-03 15:14:58,739:INFO:Total runtime is 0.04126158555348714 minutes
2023-02-03 15:14:58,747:INFO:SubProcess create_model() called ==================================
2023-02-03 15:14:58,748:INFO:Initializing create_model()
2023-02-03 15:14:58,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:14:58,749:INFO:Checking exceptions
2023-02-03 15:14:58,750:INFO:Importing libraries
2023-02-03 15:14:58,751:INFO:Copying training dataset
2023-02-03 15:14:58,761:INFO:Defining folds
2023-02-03 15:14:58,761:INFO:Declaring metric variables
2023-02-03 15:14:58,768:INFO:Importing untrained model
2023-02-03 15:14:58,775:INFO:Ridge Regression Imported successfully
2023-02-03 15:14:58,788:INFO:Starting cross validation
2023-02-03 15:14:58,790:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:14:59,025:INFO:Calculating mean and std
2023-02-03 15:14:59,026:INFO:Creating metrics dataframe
2023-02-03 15:14:59,030:INFO:Uploading results into container
2023-02-03 15:14:59,030:INFO:Uploading model into container now
2023-02-03 15:14:59,031:INFO:_master_model_container: 3
2023-02-03 15:14:59,031:INFO:_display_container: 2
2023-02-03 15:14:59,032:INFO:Ridge(random_state=123)
2023-02-03 15:14:59,032:INFO:create_model() successfully completed......................................
2023-02-03 15:14:59,115:INFO:SubProcess create_model() end ==================================
2023-02-03 15:14:59,115:INFO:Creating metrics dataframe
2023-02-03 15:14:59,129:INFO:Initializing Elastic Net
2023-02-03 15:14:59,130:INFO:Total runtime is 0.04778089920679728 minutes
2023-02-03 15:14:59,135:INFO:SubProcess create_model() called ==================================
2023-02-03 15:14:59,135:INFO:Initializing create_model()
2023-02-03 15:14:59,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:14:59,136:INFO:Checking exceptions
2023-02-03 15:14:59,136:INFO:Importing libraries
2023-02-03 15:14:59,136:INFO:Copying training dataset
2023-02-03 15:14:59,140:INFO:Defining folds
2023-02-03 15:14:59,140:INFO:Declaring metric variables
2023-02-03 15:14:59,147:INFO:Importing untrained model
2023-02-03 15:14:59,152:INFO:Elastic Net Imported successfully
2023-02-03 15:14:59,165:INFO:Starting cross validation
2023-02-03 15:14:59,166:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:14:59,188:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,213:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.982e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,234:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,256:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,278:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.646e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,300:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.039e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,322:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.999e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,342:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,364:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.979e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,388:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:14:59,398:INFO:Calculating mean and std
2023-02-03 15:14:59,399:INFO:Creating metrics dataframe
2023-02-03 15:14:59,403:INFO:Uploading results into container
2023-02-03 15:14:59,404:INFO:Uploading model into container now
2023-02-03 15:14:59,405:INFO:_master_model_container: 4
2023-02-03 15:14:59,405:INFO:_display_container: 2
2023-02-03 15:14:59,405:INFO:ElasticNet(random_state=123)
2023-02-03 15:14:59,405:INFO:create_model() successfully completed......................................
2023-02-03 15:14:59,490:INFO:SubProcess create_model() end ==================================
2023-02-03 15:14:59,490:INFO:Creating metrics dataframe
2023-02-03 15:14:59,502:INFO:Initializing Least Angle Regression
2023-02-03 15:14:59,503:INFO:Total runtime is 0.05399715503056844 minutes
2023-02-03 15:14:59,508:INFO:SubProcess create_model() called ==================================
2023-02-03 15:14:59,509:INFO:Initializing create_model()
2023-02-03 15:14:59,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:14:59,509:INFO:Checking exceptions
2023-02-03 15:14:59,510:INFO:Importing libraries
2023-02-03 15:14:59,510:INFO:Copying training dataset
2023-02-03 15:14:59,515:INFO:Defining folds
2023-02-03 15:14:59,515:INFO:Declaring metric variables
2023-02-03 15:14:59,520:INFO:Importing untrained model
2023-02-03 15:14:59,527:INFO:Least Angle Regression Imported successfully
2023-02-03 15:14:59,539:INFO:Starting cross validation
2023-02-03 15:14:59,541:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:14:59,568:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,597:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,618:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,642:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,662:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,684:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,708:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,730:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,750:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,771:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:14:59,782:INFO:Calculating mean and std
2023-02-03 15:14:59,783:INFO:Creating metrics dataframe
2023-02-03 15:14:59,787:INFO:Uploading results into container
2023-02-03 15:14:59,788:INFO:Uploading model into container now
2023-02-03 15:14:59,788:INFO:_master_model_container: 5
2023-02-03 15:14:59,788:INFO:_display_container: 2
2023-02-03 15:14:59,789:INFO:Lars(random_state=123)
2023-02-03 15:14:59,789:INFO:create_model() successfully completed......................................
2023-02-03 15:14:59,871:INFO:SubProcess create_model() end ==================================
2023-02-03 15:14:59,871:INFO:Creating metrics dataframe
2023-02-03 15:14:59,887:INFO:Initializing Lasso Least Angle Regression
2023-02-03 15:14:59,888:INFO:Total runtime is 0.06040764252344767 minutes
2023-02-03 15:14:59,893:INFO:SubProcess create_model() called ==================================
2023-02-03 15:14:59,894:INFO:Initializing create_model()
2023-02-03 15:14:59,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:14:59,894:INFO:Checking exceptions
2023-02-03 15:14:59,895:INFO:Importing libraries
2023-02-03 15:14:59,895:INFO:Copying training dataset
2023-02-03 15:14:59,900:INFO:Defining folds
2023-02-03 15:14:59,901:INFO:Declaring metric variables
2023-02-03 15:14:59,907:INFO:Importing untrained model
2023-02-03 15:14:59,914:INFO:Lasso Least Angle Regression Imported successfully
2023-02-03 15:14:59,926:INFO:Starting cross validation
2023-02-03 15:14:59,928:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:14:59,954:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:14:59,978:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,002:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,029:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,050:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,071:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,092:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,113:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,133:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,152:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:15:00,161:INFO:Calculating mean and std
2023-02-03 15:15:00,162:INFO:Creating metrics dataframe
2023-02-03 15:15:00,166:INFO:Uploading results into container
2023-02-03 15:15:00,167:INFO:Uploading model into container now
2023-02-03 15:15:00,168:INFO:_master_model_container: 6
2023-02-03 15:15:00,168:INFO:_display_container: 2
2023-02-03 15:15:00,168:INFO:LassoLars(random_state=123)
2023-02-03 15:15:00,168:INFO:create_model() successfully completed......................................
2023-02-03 15:15:00,250:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:00,250:INFO:Creating metrics dataframe
2023-02-03 15:15:00,266:INFO:Initializing Orthogonal Matching Pursuit
2023-02-03 15:15:00,266:INFO:Total runtime is 0.066716468334198 minutes
2023-02-03 15:15:00,272:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:00,272:INFO:Initializing create_model()
2023-02-03 15:15:00,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:00,272:INFO:Checking exceptions
2023-02-03 15:15:00,272:INFO:Importing libraries
2023-02-03 15:15:00,273:INFO:Copying training dataset
2023-02-03 15:15:00,278:INFO:Defining folds
2023-02-03 15:15:00,278:INFO:Declaring metric variables
2023-02-03 15:15:00,286:INFO:Importing untrained model
2023-02-03 15:15:00,293:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-03 15:15:00,306:INFO:Starting cross validation
2023-02-03 15:15:00,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:00,328:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,352:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,376:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,396:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,417:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,437:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,458:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,479:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,500:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,520:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:15:00,532:INFO:Calculating mean and std
2023-02-03 15:15:00,533:INFO:Creating metrics dataframe
2023-02-03 15:15:00,537:INFO:Uploading results into container
2023-02-03 15:15:00,538:INFO:Uploading model into container now
2023-02-03 15:15:00,539:INFO:_master_model_container: 7
2023-02-03 15:15:00,539:INFO:_display_container: 2
2023-02-03 15:15:00,540:INFO:OrthogonalMatchingPursuit()
2023-02-03 15:15:00,541:INFO:create_model() successfully completed......................................
2023-02-03 15:15:00,623:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:00,623:INFO:Creating metrics dataframe
2023-02-03 15:15:00,639:INFO:Initializing Bayesian Ridge
2023-02-03 15:15:00,639:INFO:Total runtime is 0.07292533318201701 minutes
2023-02-03 15:15:00,645:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:00,646:INFO:Initializing create_model()
2023-02-03 15:15:00,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:00,646:INFO:Checking exceptions
2023-02-03 15:15:00,646:INFO:Importing libraries
2023-02-03 15:15:00,646:INFO:Copying training dataset
2023-02-03 15:15:00,651:INFO:Defining folds
2023-02-03 15:15:00,651:INFO:Declaring metric variables
2023-02-03 15:15:00,656:INFO:Importing untrained model
2023-02-03 15:15:00,664:INFO:Bayesian Ridge Imported successfully
2023-02-03 15:15:00,680:INFO:Starting cross validation
2023-02-03 15:15:00,682:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:00,945:INFO:Calculating mean and std
2023-02-03 15:15:00,945:INFO:Creating metrics dataframe
2023-02-03 15:15:00,949:INFO:Uploading results into container
2023-02-03 15:15:00,950:INFO:Uploading model into container now
2023-02-03 15:15:00,951:INFO:_master_model_container: 8
2023-02-03 15:15:00,951:INFO:_display_container: 2
2023-02-03 15:15:00,952:INFO:BayesianRidge()
2023-02-03 15:15:00,952:INFO:create_model() successfully completed......................................
2023-02-03 15:15:01,039:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:01,039:INFO:Creating metrics dataframe
2023-02-03 15:15:01,053:INFO:Initializing Passive Aggressive Regressor
2023-02-03 15:15:01,053:INFO:Total runtime is 0.07983566919962565 minutes
2023-02-03 15:15:01,058:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:01,058:INFO:Initializing create_model()
2023-02-03 15:15:01,059:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:01,059:INFO:Checking exceptions
2023-02-03 15:15:01,059:INFO:Importing libraries
2023-02-03 15:15:01,059:INFO:Copying training dataset
2023-02-03 15:15:01,063:INFO:Defining folds
2023-02-03 15:15:01,063:INFO:Declaring metric variables
2023-02-03 15:15:01,070:INFO:Importing untrained model
2023-02-03 15:15:01,075:INFO:Passive Aggressive Regressor Imported successfully
2023-02-03 15:15:01,086:INFO:Starting cross validation
2023-02-03 15:15:01,087:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:01,308:INFO:Calculating mean and std
2023-02-03 15:15:01,310:INFO:Creating metrics dataframe
2023-02-03 15:15:01,314:INFO:Uploading results into container
2023-02-03 15:15:01,315:INFO:Uploading model into container now
2023-02-03 15:15:01,316:INFO:_master_model_container: 9
2023-02-03 15:15:01,316:INFO:_display_container: 2
2023-02-03 15:15:01,316:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-03 15:15:01,316:INFO:create_model() successfully completed......................................
2023-02-03 15:15:01,400:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:01,401:INFO:Creating metrics dataframe
2023-02-03 15:15:01,415:INFO:Initializing Huber Regressor
2023-02-03 15:15:01,415:INFO:Total runtime is 0.08587079842885335 minutes
2023-02-03 15:15:01,420:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:01,421:INFO:Initializing create_model()
2023-02-03 15:15:01,421:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:01,421:INFO:Checking exceptions
2023-02-03 15:15:01,421:INFO:Importing libraries
2023-02-03 15:15:01,421:INFO:Copying training dataset
2023-02-03 15:15:01,425:INFO:Defining folds
2023-02-03 15:15:01,425:INFO:Declaring metric variables
2023-02-03 15:15:01,431:INFO:Importing untrained model
2023-02-03 15:15:01,437:INFO:Huber Regressor Imported successfully
2023-02-03 15:15:01,451:INFO:Starting cross validation
2023-02-03 15:15:01,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:01,765:INFO:Calculating mean and std
2023-02-03 15:15:01,766:INFO:Creating metrics dataframe
2023-02-03 15:15:01,771:INFO:Uploading results into container
2023-02-03 15:15:01,772:INFO:Uploading model into container now
2023-02-03 15:15:01,773:INFO:_master_model_container: 10
2023-02-03 15:15:01,773:INFO:_display_container: 2
2023-02-03 15:15:01,774:INFO:HuberRegressor()
2023-02-03 15:15:01,774:INFO:create_model() successfully completed......................................
2023-02-03 15:15:01,857:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:01,857:INFO:Creating metrics dataframe
2023-02-03 15:15:01,874:INFO:Initializing K Neighbors Regressor
2023-02-03 15:15:01,874:INFO:Total runtime is 0.09351608753204346 minutes
2023-02-03 15:15:01,880:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:01,880:INFO:Initializing create_model()
2023-02-03 15:15:01,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:01,880:INFO:Checking exceptions
2023-02-03 15:15:01,880:INFO:Importing libraries
2023-02-03 15:15:01,880:INFO:Copying training dataset
2023-02-03 15:15:01,885:INFO:Defining folds
2023-02-03 15:15:01,885:INFO:Declaring metric variables
2023-02-03 15:15:01,890:INFO:Importing untrained model
2023-02-03 15:15:01,898:INFO:K Neighbors Regressor Imported successfully
2023-02-03 15:15:01,917:INFO:Starting cross validation
2023-02-03 15:15:01,919:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:07,209:INFO:Calculating mean and std
2023-02-03 15:15:07,210:INFO:Creating metrics dataframe
2023-02-03 15:15:07,214:INFO:Uploading results into container
2023-02-03 15:15:07,216:INFO:Uploading model into container now
2023-02-03 15:15:07,217:INFO:_master_model_container: 11
2023-02-03 15:15:07,217:INFO:_display_container: 2
2023-02-03 15:15:07,218:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-03 15:15:07,218:INFO:create_model() successfully completed......................................
2023-02-03 15:15:07,309:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:07,309:INFO:Creating metrics dataframe
2023-02-03 15:15:07,327:INFO:Initializing Decision Tree Regressor
2023-02-03 15:15:07,328:INFO:Total runtime is 0.18439719676971436 minutes
2023-02-03 15:15:07,332:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:07,333:INFO:Initializing create_model()
2023-02-03 15:15:07,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:07,335:INFO:Checking exceptions
2023-02-03 15:15:07,335:INFO:Importing libraries
2023-02-03 15:15:07,335:INFO:Copying training dataset
2023-02-03 15:15:07,340:INFO:Defining folds
2023-02-03 15:15:07,341:INFO:Declaring metric variables
2023-02-03 15:15:07,346:INFO:Importing untrained model
2023-02-03 15:15:07,355:INFO:Decision Tree Regressor Imported successfully
2023-02-03 15:15:07,371:INFO:Starting cross validation
2023-02-03 15:15:07,372:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:07,612:INFO:Calculating mean and std
2023-02-03 15:15:07,614:INFO:Creating metrics dataframe
2023-02-03 15:15:07,620:INFO:Uploading results into container
2023-02-03 15:15:07,620:INFO:Uploading model into container now
2023-02-03 15:15:07,621:INFO:_master_model_container: 12
2023-02-03 15:15:07,621:INFO:_display_container: 2
2023-02-03 15:15:07,622:INFO:DecisionTreeRegressor(random_state=123)
2023-02-03 15:15:07,624:INFO:create_model() successfully completed......................................
2023-02-03 15:15:07,708:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:07,708:INFO:Creating metrics dataframe
2023-02-03 15:15:07,724:INFO:Initializing Random Forest Regressor
2023-02-03 15:15:07,724:INFO:Total runtime is 0.19100876649220785 minutes
2023-02-03 15:15:07,729:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:07,729:INFO:Initializing create_model()
2023-02-03 15:15:07,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:07,730:INFO:Checking exceptions
2023-02-03 15:15:07,730:INFO:Importing libraries
2023-02-03 15:15:07,730:INFO:Copying training dataset
2023-02-03 15:15:07,735:INFO:Defining folds
2023-02-03 15:15:07,735:INFO:Declaring metric variables
2023-02-03 15:15:07,742:INFO:Importing untrained model
2023-02-03 15:15:07,747:INFO:Random Forest Regressor Imported successfully
2023-02-03 15:15:07,760:INFO:Starting cross validation
2023-02-03 15:15:07,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:10,341:INFO:Calculating mean and std
2023-02-03 15:15:10,343:INFO:Creating metrics dataframe
2023-02-03 15:15:10,347:INFO:Uploading results into container
2023-02-03 15:15:10,347:INFO:Uploading model into container now
2023-02-03 15:15:10,348:INFO:_master_model_container: 13
2023-02-03 15:15:10,348:INFO:_display_container: 2
2023-02-03 15:15:10,348:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:15:10,349:INFO:create_model() successfully completed......................................
2023-02-03 15:15:10,440:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:10,440:INFO:Creating metrics dataframe
2023-02-03 15:15:10,459:INFO:Initializing Extra Trees Regressor
2023-02-03 15:15:10,459:INFO:Total runtime is 0.23660185337066653 minutes
2023-02-03 15:15:10,465:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:10,466:INFO:Initializing create_model()
2023-02-03 15:15:10,466:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:10,466:INFO:Checking exceptions
2023-02-03 15:15:10,466:INFO:Importing libraries
2023-02-03 15:15:10,467:INFO:Copying training dataset
2023-02-03 15:15:10,472:INFO:Defining folds
2023-02-03 15:15:10,473:INFO:Declaring metric variables
2023-02-03 15:15:10,477:INFO:Importing untrained model
2023-02-03 15:15:10,486:INFO:Extra Trees Regressor Imported successfully
2023-02-03 15:15:10,501:INFO:Starting cross validation
2023-02-03 15:15:10,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:12,813:INFO:Calculating mean and std
2023-02-03 15:15:12,815:INFO:Creating metrics dataframe
2023-02-03 15:15:12,821:INFO:Uploading results into container
2023-02-03 15:15:12,823:INFO:Uploading model into container now
2023-02-03 15:15:12,824:INFO:_master_model_container: 14
2023-02-03 15:15:12,824:INFO:_display_container: 2
2023-02-03 15:15:12,825:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:15:12,825:INFO:create_model() successfully completed......................................
2023-02-03 15:15:12,925:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:12,926:INFO:Creating metrics dataframe
2023-02-03 15:15:12,946:INFO:Initializing AdaBoost Regressor
2023-02-03 15:15:12,946:INFO:Total runtime is 0.2780460238456726 minutes
2023-02-03 15:15:12,951:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:12,951:INFO:Initializing create_model()
2023-02-03 15:15:12,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:12,952:INFO:Checking exceptions
2023-02-03 15:15:12,952:INFO:Importing libraries
2023-02-03 15:15:12,952:INFO:Copying training dataset
2023-02-03 15:15:12,959:INFO:Defining folds
2023-02-03 15:15:12,959:INFO:Declaring metric variables
2023-02-03 15:15:12,966:INFO:Importing untrained model
2023-02-03 15:15:12,973:INFO:AdaBoost Regressor Imported successfully
2023-02-03 15:15:12,985:INFO:Starting cross validation
2023-02-03 15:15:12,987:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:13,658:INFO:Calculating mean and std
2023-02-03 15:15:13,660:INFO:Creating metrics dataframe
2023-02-03 15:15:13,666:INFO:Uploading results into container
2023-02-03 15:15:13,667:INFO:Uploading model into container now
2023-02-03 15:15:13,667:INFO:_master_model_container: 15
2023-02-03 15:15:13,668:INFO:_display_container: 2
2023-02-03 15:15:13,668:INFO:AdaBoostRegressor(random_state=123)
2023-02-03 15:15:13,668:INFO:create_model() successfully completed......................................
2023-02-03 15:15:13,763:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:13,763:INFO:Creating metrics dataframe
2023-02-03 15:15:13,783:INFO:Initializing Gradient Boosting Regressor
2023-02-03 15:15:13,784:INFO:Total runtime is 0.29201157887776696 minutes
2023-02-03 15:15:13,789:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:13,790:INFO:Initializing create_model()
2023-02-03 15:15:13,790:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:13,791:INFO:Checking exceptions
2023-02-03 15:15:13,791:INFO:Importing libraries
2023-02-03 15:15:13,792:INFO:Copying training dataset
2023-02-03 15:15:13,796:INFO:Defining folds
2023-02-03 15:15:13,797:INFO:Declaring metric variables
2023-02-03 15:15:13,805:INFO:Importing untrained model
2023-02-03 15:15:13,813:INFO:Gradient Boosting Regressor Imported successfully
2023-02-03 15:15:13,829:INFO:Starting cross validation
2023-02-03 15:15:13,830:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:14,571:INFO:Calculating mean and std
2023-02-03 15:15:14,572:INFO:Creating metrics dataframe
2023-02-03 15:15:14,580:INFO:Uploading results into container
2023-02-03 15:15:14,580:INFO:Uploading model into container now
2023-02-03 15:15:14,581:INFO:_master_model_container: 16
2023-02-03 15:15:14,581:INFO:_display_container: 2
2023-02-03 15:15:14,582:INFO:GradientBoostingRegressor(random_state=123)
2023-02-03 15:15:14,582:INFO:create_model() successfully completed......................................
2023-02-03 15:15:14,695:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:14,695:INFO:Creating metrics dataframe
2023-02-03 15:15:14,719:INFO:Initializing Light Gradient Boosting Machine
2023-02-03 15:15:14,719:INFO:Total runtime is 0.30760041475296024 minutes
2023-02-03 15:15:14,729:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:14,729:INFO:Initializing create_model()
2023-02-03 15:15:14,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:14,730:INFO:Checking exceptions
2023-02-03 15:15:14,730:INFO:Importing libraries
2023-02-03 15:15:14,730:INFO:Copying training dataset
2023-02-03 15:15:14,736:INFO:Defining folds
2023-02-03 15:15:14,736:INFO:Declaring metric variables
2023-02-03 15:15:14,747:INFO:Importing untrained model
2023-02-03 15:15:14,754:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-03 15:15:14,777:INFO:Starting cross validation
2023-02-03 15:15:14,779:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:29,715:INFO:Calculating mean and std
2023-02-03 15:15:29,717:INFO:Creating metrics dataframe
2023-02-03 15:15:29,726:INFO:Uploading results into container
2023-02-03 15:15:29,727:INFO:Uploading model into container now
2023-02-03 15:15:29,729:INFO:_master_model_container: 17
2023-02-03 15:15:29,729:INFO:_display_container: 2
2023-02-03 15:15:29,730:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-02-03 15:15:29,730:INFO:create_model() successfully completed......................................
2023-02-03 15:15:29,855:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:29,856:INFO:Creating metrics dataframe
2023-02-03 15:15:29,873:INFO:Initializing Dummy Regressor
2023-02-03 15:15:29,874:INFO:Total runtime is 0.5601612011591593 minutes
2023-02-03 15:15:29,879:INFO:SubProcess create_model() called ==================================
2023-02-03 15:15:29,879:INFO:Initializing create_model()
2023-02-03 15:15:29,879:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:29,880:INFO:Checking exceptions
2023-02-03 15:15:29,880:INFO:Importing libraries
2023-02-03 15:15:29,880:INFO:Copying training dataset
2023-02-03 15:15:29,884:INFO:Defining folds
2023-02-03 15:15:29,884:INFO:Declaring metric variables
2023-02-03 15:15:29,890:INFO:Importing untrained model
2023-02-03 15:15:29,896:INFO:Dummy Regressor Imported successfully
2023-02-03 15:15:29,906:INFO:Starting cross validation
2023-02-03 15:15:29,908:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:15:30,144:INFO:Calculating mean and std
2023-02-03 15:15:30,145:INFO:Creating metrics dataframe
2023-02-03 15:15:30,149:INFO:Uploading results into container
2023-02-03 15:15:30,149:INFO:Uploading model into container now
2023-02-03 15:15:30,151:INFO:_master_model_container: 18
2023-02-03 15:15:30,151:INFO:_display_container: 2
2023-02-03 15:15:30,152:INFO:DummyRegressor()
2023-02-03 15:15:30,152:INFO:create_model() successfully completed......................................
2023-02-03 15:15:30,236:INFO:SubProcess create_model() end ==================================
2023-02-03 15:15:30,237:INFO:Creating metrics dataframe
2023-02-03 15:15:30,273:INFO:Initializing create_model()
2023-02-03 15:15:30,273:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:15:30,273:INFO:Checking exceptions
2023-02-03 15:15:30,277:INFO:Importing libraries
2023-02-03 15:15:30,277:INFO:Copying training dataset
2023-02-03 15:15:30,280:INFO:Defining folds
2023-02-03 15:15:30,280:INFO:Declaring metric variables
2023-02-03 15:15:30,280:INFO:Importing untrained model
2023-02-03 15:15:30,280:INFO:Declaring custom model
2023-02-03 15:15:30,281:INFO:Linear Regression Imported successfully
2023-02-03 15:15:30,281:INFO:Cross validation set to False
2023-02-03 15:15:30,281:INFO:Fitting Model
2023-02-03 15:15:30,317:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:15:30,317:INFO:create_model() successfully completed......................................
2023-02-03 15:15:30,463:INFO:_master_model_container: 18
2023-02-03 15:15:30,464:INFO:_display_container: 2
2023-02-03 15:15:30,464:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:15:30,465:INFO:compare_models() successfully completed......................................
2023-02-03 15:16:47,655:INFO:Initializing compare_models()
2023-02-03 15:16:47,656:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, include=None, fold=None, round=4, cross_validation=True, sort=r2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'r2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-03 15:16:47,656:INFO:Checking exceptions
2023-02-03 15:16:47,661:INFO:Preparing display monitor
2023-02-03 15:16:47,712:INFO:Initializing Linear Regression
2023-02-03 15:16:47,713:INFO:Total runtime is 1.6661485036214194e-05 minutes
2023-02-03 15:16:47,722:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:47,723:INFO:Initializing create_model()
2023-02-03 15:16:47,723:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:47,724:INFO:Checking exceptions
2023-02-03 15:16:47,724:INFO:Importing libraries
2023-02-03 15:16:47,724:INFO:Copying training dataset
2023-02-03 15:16:47,736:INFO:Defining folds
2023-02-03 15:16:47,737:INFO:Declaring metric variables
2023-02-03 15:16:47,748:INFO:Importing untrained model
2023-02-03 15:16:47,755:INFO:Linear Regression Imported successfully
2023-02-03 15:16:47,770:INFO:Starting cross validation
2023-02-03 15:16:47,773:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:48,167:INFO:Calculating mean and std
2023-02-03 15:16:48,168:INFO:Creating metrics dataframe
2023-02-03 15:16:48,174:INFO:Uploading results into container
2023-02-03 15:16:48,174:INFO:Uploading model into container now
2023-02-03 15:16:48,175:INFO:_master_model_container: 19
2023-02-03 15:16:48,175:INFO:_display_container: 3
2023-02-03 15:16:48,176:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:16:48,176:INFO:create_model() successfully completed......................................
2023-02-03 15:16:48,266:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:48,266:INFO:Creating metrics dataframe
2023-02-03 15:16:48,284:INFO:Initializing Lasso Regression
2023-02-03 15:16:48,284:INFO:Total runtime is 0.009527858098347981 minutes
2023-02-03 15:16:48,290:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:48,291:INFO:Initializing create_model()
2023-02-03 15:16:48,291:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:48,291:INFO:Checking exceptions
2023-02-03 15:16:48,291:INFO:Importing libraries
2023-02-03 15:16:48,291:INFO:Copying training dataset
2023-02-03 15:16:48,294:INFO:Defining folds
2023-02-03 15:16:48,294:INFO:Declaring metric variables
2023-02-03 15:16:48,299:INFO:Importing untrained model
2023-02-03 15:16:48,304:INFO:Lasso Regression Imported successfully
2023-02-03 15:16:48,320:INFO:Starting cross validation
2023-02-03 15:16:48,321:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:48,346:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.653e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,379:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.713e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,406:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.832e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,431:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,456:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.826e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,478:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,502:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,527:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,556:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,577:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.356e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:48,587:INFO:Calculating mean and std
2023-02-03 15:16:48,588:INFO:Creating metrics dataframe
2023-02-03 15:16:48,591:INFO:Uploading results into container
2023-02-03 15:16:48,592:INFO:Uploading model into container now
2023-02-03 15:16:48,593:INFO:_master_model_container: 20
2023-02-03 15:16:48,593:INFO:_display_container: 3
2023-02-03 15:16:48,594:INFO:Lasso(random_state=123)
2023-02-03 15:16:48,594:INFO:create_model() successfully completed......................................
2023-02-03 15:16:48,695:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:48,695:INFO:Creating metrics dataframe
2023-02-03 15:16:48,710:INFO:Initializing Ridge Regression
2023-02-03 15:16:48,710:INFO:Total runtime is 0.016623783111572265 minutes
2023-02-03 15:16:48,715:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:48,716:INFO:Initializing create_model()
2023-02-03 15:16:48,716:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:48,716:INFO:Checking exceptions
2023-02-03 15:16:48,716:INFO:Importing libraries
2023-02-03 15:16:48,717:INFO:Copying training dataset
2023-02-03 15:16:48,722:INFO:Defining folds
2023-02-03 15:16:48,722:INFO:Declaring metric variables
2023-02-03 15:16:48,728:INFO:Importing untrained model
2023-02-03 15:16:48,735:INFO:Ridge Regression Imported successfully
2023-02-03 15:16:48,748:INFO:Starting cross validation
2023-02-03 15:16:48,750:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:48,996:INFO:Calculating mean and std
2023-02-03 15:16:48,997:INFO:Creating metrics dataframe
2023-02-03 15:16:49,002:INFO:Uploading results into container
2023-02-03 15:16:49,003:INFO:Uploading model into container now
2023-02-03 15:16:49,003:INFO:_master_model_container: 21
2023-02-03 15:16:49,004:INFO:_display_container: 3
2023-02-03 15:16:49,004:INFO:Ridge(random_state=123)
2023-02-03 15:16:49,004:INFO:create_model() successfully completed......................................
2023-02-03 15:16:49,095:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:49,095:INFO:Creating metrics dataframe
2023-02-03 15:16:49,109:INFO:Initializing Elastic Net
2023-02-03 15:16:49,109:INFO:Total runtime is 0.023270229498545326 minutes
2023-02-03 15:16:49,114:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:49,114:INFO:Initializing create_model()
2023-02-03 15:16:49,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:49,115:INFO:Checking exceptions
2023-02-03 15:16:49,115:INFO:Importing libraries
2023-02-03 15:16:49,115:INFO:Copying training dataset
2023-02-03 15:16:49,120:INFO:Defining folds
2023-02-03 15:16:49,120:INFO:Declaring metric variables
2023-02-03 15:16:49,125:INFO:Importing untrained model
2023-02-03 15:16:49,132:INFO:Elastic Net Imported successfully
2023-02-03 15:16:49,147:INFO:Starting cross validation
2023-02-03 15:16:49,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:49,171:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,195:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.982e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,219:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,240:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,262:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.646e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,287:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.039e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,312:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.999e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,333:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,358:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.979e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,383:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:16:49,392:INFO:Calculating mean and std
2023-02-03 15:16:49,393:INFO:Creating metrics dataframe
2023-02-03 15:16:49,397:INFO:Uploading results into container
2023-02-03 15:16:49,397:INFO:Uploading model into container now
2023-02-03 15:16:49,399:INFO:_master_model_container: 22
2023-02-03 15:16:49,399:INFO:_display_container: 3
2023-02-03 15:16:49,400:INFO:ElasticNet(random_state=123)
2023-02-03 15:16:49,400:INFO:create_model() successfully completed......................................
2023-02-03 15:16:49,488:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:49,488:INFO:Creating metrics dataframe
2023-02-03 15:16:49,502:INFO:Initializing Least Angle Regression
2023-02-03 15:16:49,502:INFO:Total runtime is 0.029832891623179116 minutes
2023-02-03 15:16:49,508:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:49,508:INFO:Initializing create_model()
2023-02-03 15:16:49,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:49,508:INFO:Checking exceptions
2023-02-03 15:16:49,509:INFO:Importing libraries
2023-02-03 15:16:49,509:INFO:Copying training dataset
2023-02-03 15:16:49,513:INFO:Defining folds
2023-02-03 15:16:49,513:INFO:Declaring metric variables
2023-02-03 15:16:49,520:INFO:Importing untrained model
2023-02-03 15:16:49,528:INFO:Least Angle Regression Imported successfully
2023-02-03 15:16:49,543:INFO:Starting cross validation
2023-02-03 15:16:49,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:49,567:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,592:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,614:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,635:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,658:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,678:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,698:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,719:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,739:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,759:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:49,769:INFO:Calculating mean and std
2023-02-03 15:16:49,771:INFO:Creating metrics dataframe
2023-02-03 15:16:49,777:INFO:Uploading results into container
2023-02-03 15:16:49,778:INFO:Uploading model into container now
2023-02-03 15:16:49,778:INFO:_master_model_container: 23
2023-02-03 15:16:49,779:INFO:_display_container: 3
2023-02-03 15:16:49,779:INFO:Lars(random_state=123)
2023-02-03 15:16:49,780:INFO:create_model() successfully completed......................................
2023-02-03 15:16:49,860:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:49,861:INFO:Creating metrics dataframe
2023-02-03 15:16:49,873:INFO:Initializing Lasso Least Angle Regression
2023-02-03 15:16:49,874:INFO:Total runtime is 0.03602958520253499 minutes
2023-02-03 15:16:49,879:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:49,880:INFO:Initializing create_model()
2023-02-03 15:16:49,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:49,880:INFO:Checking exceptions
2023-02-03 15:16:49,880:INFO:Importing libraries
2023-02-03 15:16:49,880:INFO:Copying training dataset
2023-02-03 15:16:49,885:INFO:Defining folds
2023-02-03 15:16:49,885:INFO:Declaring metric variables
2023-02-03 15:16:49,891:INFO:Importing untrained model
2023-02-03 15:16:49,895:INFO:Lasso Least Angle Regression Imported successfully
2023-02-03 15:16:49,911:INFO:Starting cross validation
2023-02-03 15:16:49,913:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:49,930:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:49,961:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,004:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,033:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,073:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,102:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,133:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,163:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,247:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,282:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:16:50,296:INFO:Calculating mean and std
2023-02-03 15:16:50,298:INFO:Creating metrics dataframe
2023-02-03 15:16:50,306:INFO:Uploading results into container
2023-02-03 15:16:50,307:INFO:Uploading model into container now
2023-02-03 15:16:50,307:INFO:_master_model_container: 24
2023-02-03 15:16:50,307:INFO:_display_container: 3
2023-02-03 15:16:50,308:INFO:LassoLars(random_state=123)
2023-02-03 15:16:50,308:INFO:create_model() successfully completed......................................
2023-02-03 15:16:50,398:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:50,398:INFO:Creating metrics dataframe
2023-02-03 15:16:50,412:INFO:Initializing Orthogonal Matching Pursuit
2023-02-03 15:16:50,412:INFO:Total runtime is 0.044984956582387284 minutes
2023-02-03 15:16:50,416:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:50,417:INFO:Initializing create_model()
2023-02-03 15:16:50,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:50,418:INFO:Checking exceptions
2023-02-03 15:16:50,418:INFO:Importing libraries
2023-02-03 15:16:50,418:INFO:Copying training dataset
2023-02-03 15:16:50,424:INFO:Defining folds
2023-02-03 15:16:50,425:INFO:Declaring metric variables
2023-02-03 15:16:50,429:INFO:Importing untrained model
2023-02-03 15:16:50,434:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-03 15:16:50,447:INFO:Starting cross validation
2023-02-03 15:16:50,448:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:50,464:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,496:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,517:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,539:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,561:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,582:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,605:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,626:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,647:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,671:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:16:50,681:INFO:Calculating mean and std
2023-02-03 15:16:50,683:INFO:Creating metrics dataframe
2023-02-03 15:16:50,689:INFO:Uploading results into container
2023-02-03 15:16:50,690:INFO:Uploading model into container now
2023-02-03 15:16:50,691:INFO:_master_model_container: 25
2023-02-03 15:16:50,691:INFO:_display_container: 3
2023-02-03 15:16:50,692:INFO:OrthogonalMatchingPursuit()
2023-02-03 15:16:50,693:INFO:create_model() successfully completed......................................
2023-02-03 15:16:50,783:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:50,783:INFO:Creating metrics dataframe
2023-02-03 15:16:50,799:INFO:Initializing Bayesian Ridge
2023-02-03 15:16:50,799:INFO:Total runtime is 0.05144790808359782 minutes
2023-02-03 15:16:50,806:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:50,806:INFO:Initializing create_model()
2023-02-03 15:16:50,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:50,806:INFO:Checking exceptions
2023-02-03 15:16:50,806:INFO:Importing libraries
2023-02-03 15:16:50,807:INFO:Copying training dataset
2023-02-03 15:16:50,811:INFO:Defining folds
2023-02-03 15:16:50,812:INFO:Declaring metric variables
2023-02-03 15:16:50,817:INFO:Importing untrained model
2023-02-03 15:16:50,825:INFO:Bayesian Ridge Imported successfully
2023-02-03 15:16:50,838:INFO:Starting cross validation
2023-02-03 15:16:50,841:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:51,084:INFO:Calculating mean and std
2023-02-03 15:16:51,089:INFO:Creating metrics dataframe
2023-02-03 15:16:51,094:INFO:Uploading results into container
2023-02-03 15:16:51,095:INFO:Uploading model into container now
2023-02-03 15:16:51,096:INFO:_master_model_container: 26
2023-02-03 15:16:51,096:INFO:_display_container: 3
2023-02-03 15:16:51,097:INFO:BayesianRidge()
2023-02-03 15:16:51,097:INFO:create_model() successfully completed......................................
2023-02-03 15:16:51,189:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:51,189:INFO:Creating metrics dataframe
2023-02-03 15:16:51,206:INFO:Initializing Passive Aggressive Regressor
2023-02-03 15:16:51,207:INFO:Total runtime is 0.05824400981267293 minutes
2023-02-03 15:16:51,211:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:51,212:INFO:Initializing create_model()
2023-02-03 15:16:51,212:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:51,212:INFO:Checking exceptions
2023-02-03 15:16:51,212:INFO:Importing libraries
2023-02-03 15:16:51,213:INFO:Copying training dataset
2023-02-03 15:16:51,217:INFO:Defining folds
2023-02-03 15:16:51,217:INFO:Declaring metric variables
2023-02-03 15:16:51,225:INFO:Importing untrained model
2023-02-03 15:16:51,234:INFO:Passive Aggressive Regressor Imported successfully
2023-02-03 15:16:51,273:INFO:Starting cross validation
2023-02-03 15:16:51,277:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:51,515:INFO:Calculating mean and std
2023-02-03 15:16:51,516:INFO:Creating metrics dataframe
2023-02-03 15:16:51,521:INFO:Uploading results into container
2023-02-03 15:16:51,523:INFO:Uploading model into container now
2023-02-03 15:16:51,523:INFO:_master_model_container: 27
2023-02-03 15:16:51,523:INFO:_display_container: 3
2023-02-03 15:16:51,524:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-03 15:16:51,524:INFO:create_model() successfully completed......................................
2023-02-03 15:16:51,610:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:51,610:INFO:Creating metrics dataframe
2023-02-03 15:16:51,629:INFO:Initializing Huber Regressor
2023-02-03 15:16:51,629:INFO:Total runtime is 0.0652733047803243 minutes
2023-02-03 15:16:51,634:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:51,635:INFO:Initializing create_model()
2023-02-03 15:16:51,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:51,635:INFO:Checking exceptions
2023-02-03 15:16:51,635:INFO:Importing libraries
2023-02-03 15:16:51,635:INFO:Copying training dataset
2023-02-03 15:16:51,642:INFO:Defining folds
2023-02-03 15:16:51,642:INFO:Declaring metric variables
2023-02-03 15:16:51,647:INFO:Importing untrained model
2023-02-03 15:16:51,654:INFO:Huber Regressor Imported successfully
2023-02-03 15:16:51,666:INFO:Starting cross validation
2023-02-03 15:16:51,667:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:51,945:INFO:Calculating mean and std
2023-02-03 15:16:51,946:INFO:Creating metrics dataframe
2023-02-03 15:16:51,950:INFO:Uploading results into container
2023-02-03 15:16:51,951:INFO:Uploading model into container now
2023-02-03 15:16:51,952:INFO:_master_model_container: 28
2023-02-03 15:16:51,952:INFO:_display_container: 3
2023-02-03 15:16:51,953:INFO:HuberRegressor()
2023-02-03 15:16:51,953:INFO:create_model() successfully completed......................................
2023-02-03 15:16:52,047:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:52,047:INFO:Creating metrics dataframe
2023-02-03 15:16:52,065:INFO:Initializing K Neighbors Regressor
2023-02-03 15:16:52,065:INFO:Total runtime is 0.07253581285476685 minutes
2023-02-03 15:16:52,073:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:52,074:INFO:Initializing create_model()
2023-02-03 15:16:52,074:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:52,075:INFO:Checking exceptions
2023-02-03 15:16:52,075:INFO:Importing libraries
2023-02-03 15:16:52,075:INFO:Copying training dataset
2023-02-03 15:16:52,079:INFO:Defining folds
2023-02-03 15:16:52,079:INFO:Declaring metric variables
2023-02-03 15:16:52,085:INFO:Importing untrained model
2023-02-03 15:16:52,094:INFO:K Neighbors Regressor Imported successfully
2023-02-03 15:16:52,112:INFO:Starting cross validation
2023-02-03 15:16:52,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:52,481:INFO:Calculating mean and std
2023-02-03 15:16:52,482:INFO:Creating metrics dataframe
2023-02-03 15:16:52,486:INFO:Uploading results into container
2023-02-03 15:16:52,488:INFO:Uploading model into container now
2023-02-03 15:16:52,488:INFO:_master_model_container: 29
2023-02-03 15:16:52,488:INFO:_display_container: 3
2023-02-03 15:16:52,489:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-03 15:16:52,489:INFO:create_model() successfully completed......................................
2023-02-03 15:16:52,569:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:52,570:INFO:Creating metrics dataframe
2023-02-03 15:16:52,588:INFO:Initializing Decision Tree Regressor
2023-02-03 15:16:52,589:INFO:Total runtime is 0.08128010034561158 minutes
2023-02-03 15:16:52,594:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:52,595:INFO:Initializing create_model()
2023-02-03 15:16:52,595:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:52,595:INFO:Checking exceptions
2023-02-03 15:16:52,595:INFO:Importing libraries
2023-02-03 15:16:52,596:INFO:Copying training dataset
2023-02-03 15:16:52,601:INFO:Defining folds
2023-02-03 15:16:52,601:INFO:Declaring metric variables
2023-02-03 15:16:52,609:INFO:Importing untrained model
2023-02-03 15:16:52,614:INFO:Decision Tree Regressor Imported successfully
2023-02-03 15:16:52,626:INFO:Starting cross validation
2023-02-03 15:16:52,627:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:52,861:INFO:Calculating mean and std
2023-02-03 15:16:52,862:INFO:Creating metrics dataframe
2023-02-03 15:16:52,866:INFO:Uploading results into container
2023-02-03 15:16:52,867:INFO:Uploading model into container now
2023-02-03 15:16:52,868:INFO:_master_model_container: 30
2023-02-03 15:16:52,868:INFO:_display_container: 3
2023-02-03 15:16:52,868:INFO:DecisionTreeRegressor(random_state=123)
2023-02-03 15:16:52,868:INFO:create_model() successfully completed......................................
2023-02-03 15:16:52,951:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:52,952:INFO:Creating metrics dataframe
2023-02-03 15:16:52,967:INFO:Initializing Random Forest Regressor
2023-02-03 15:16:52,968:INFO:Total runtime is 0.08757672707239787 minutes
2023-02-03 15:16:52,974:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:52,975:INFO:Initializing create_model()
2023-02-03 15:16:52,975:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:52,975:INFO:Checking exceptions
2023-02-03 15:16:52,975:INFO:Importing libraries
2023-02-03 15:16:52,975:INFO:Copying training dataset
2023-02-03 15:16:52,981:INFO:Defining folds
2023-02-03 15:16:52,981:INFO:Declaring metric variables
2023-02-03 15:16:52,988:INFO:Importing untrained model
2023-02-03 15:16:52,996:INFO:Random Forest Regressor Imported successfully
2023-02-03 15:16:53,012:INFO:Starting cross validation
2023-02-03 15:16:53,013:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:54,900:INFO:Calculating mean and std
2023-02-03 15:16:54,901:INFO:Creating metrics dataframe
2023-02-03 15:16:54,907:INFO:Uploading results into container
2023-02-03 15:16:54,908:INFO:Uploading model into container now
2023-02-03 15:16:54,909:INFO:_master_model_container: 31
2023-02-03 15:16:54,909:INFO:_display_container: 3
2023-02-03 15:16:54,910:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:16:54,910:INFO:create_model() successfully completed......................................
2023-02-03 15:16:55,004:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:55,004:INFO:Creating metrics dataframe
2023-02-03 15:16:55,021:INFO:Initializing Extra Trees Regressor
2023-02-03 15:16:55,022:INFO:Total runtime is 0.12183132568995159 minutes
2023-02-03 15:16:55,028:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:55,029:INFO:Initializing create_model()
2023-02-03 15:16:55,029:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:55,030:INFO:Checking exceptions
2023-02-03 15:16:55,030:INFO:Importing libraries
2023-02-03 15:16:55,030:INFO:Copying training dataset
2023-02-03 15:16:55,034:INFO:Defining folds
2023-02-03 15:16:55,034:INFO:Declaring metric variables
2023-02-03 15:16:55,039:INFO:Importing untrained model
2023-02-03 15:16:55,048:INFO:Extra Trees Regressor Imported successfully
2023-02-03 15:16:55,062:INFO:Starting cross validation
2023-02-03 15:16:55,063:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:57,056:INFO:Calculating mean and std
2023-02-03 15:16:57,058:INFO:Creating metrics dataframe
2023-02-03 15:16:57,063:INFO:Uploading results into container
2023-02-03 15:16:57,063:INFO:Uploading model into container now
2023-02-03 15:16:57,064:INFO:_master_model_container: 32
2023-02-03 15:16:57,064:INFO:_display_container: 3
2023-02-03 15:16:57,065:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:16:57,065:INFO:create_model() successfully completed......................................
2023-02-03 15:16:57,155:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:57,155:INFO:Creating metrics dataframe
2023-02-03 15:16:57,171:INFO:Initializing AdaBoost Regressor
2023-02-03 15:16:57,171:INFO:Total runtime is 0.15764414469401042 minutes
2023-02-03 15:16:57,179:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:57,180:INFO:Initializing create_model()
2023-02-03 15:16:57,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:57,180:INFO:Checking exceptions
2023-02-03 15:16:57,180:INFO:Importing libraries
2023-02-03 15:16:57,180:INFO:Copying training dataset
2023-02-03 15:16:57,184:INFO:Defining folds
2023-02-03 15:16:57,185:INFO:Declaring metric variables
2023-02-03 15:16:57,191:INFO:Importing untrained model
2023-02-03 15:16:57,196:INFO:AdaBoost Regressor Imported successfully
2023-02-03 15:16:57,212:INFO:Starting cross validation
2023-02-03 15:16:57,213:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:57,817:INFO:Calculating mean and std
2023-02-03 15:16:57,819:INFO:Creating metrics dataframe
2023-02-03 15:16:57,823:INFO:Uploading results into container
2023-02-03 15:16:57,824:INFO:Uploading model into container now
2023-02-03 15:16:57,824:INFO:_master_model_container: 33
2023-02-03 15:16:57,824:INFO:_display_container: 3
2023-02-03 15:16:57,825:INFO:AdaBoostRegressor(random_state=123)
2023-02-03 15:16:57,825:INFO:create_model() successfully completed......................................
2023-02-03 15:16:57,911:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:57,911:INFO:Creating metrics dataframe
2023-02-03 15:16:57,932:INFO:Initializing Gradient Boosting Regressor
2023-02-03 15:16:57,933:INFO:Total runtime is 0.1703368385632833 minutes
2023-02-03 15:16:57,939:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:57,940:INFO:Initializing create_model()
2023-02-03 15:16:57,940:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:57,940:INFO:Checking exceptions
2023-02-03 15:16:57,940:INFO:Importing libraries
2023-02-03 15:16:57,940:INFO:Copying training dataset
2023-02-03 15:16:57,945:INFO:Defining folds
2023-02-03 15:16:57,945:INFO:Declaring metric variables
2023-02-03 15:16:57,951:INFO:Importing untrained model
2023-02-03 15:16:57,956:INFO:Gradient Boosting Regressor Imported successfully
2023-02-03 15:16:57,970:INFO:Starting cross validation
2023-02-03 15:16:57,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:16:58,725:INFO:Calculating mean and std
2023-02-03 15:16:58,729:INFO:Creating metrics dataframe
2023-02-03 15:16:58,733:INFO:Uploading results into container
2023-02-03 15:16:58,734:INFO:Uploading model into container now
2023-02-03 15:16:58,735:INFO:_master_model_container: 34
2023-02-03 15:16:58,735:INFO:_display_container: 3
2023-02-03 15:16:58,736:INFO:GradientBoostingRegressor(random_state=123)
2023-02-03 15:16:58,736:INFO:create_model() successfully completed......................................
2023-02-03 15:16:58,823:INFO:SubProcess create_model() end ==================================
2023-02-03 15:16:58,823:INFO:Creating metrics dataframe
2023-02-03 15:16:58,842:INFO:Initializing Light Gradient Boosting Machine
2023-02-03 15:16:58,843:INFO:Total runtime is 0.18551145394643148 minutes
2023-02-03 15:16:58,849:INFO:SubProcess create_model() called ==================================
2023-02-03 15:16:58,849:INFO:Initializing create_model()
2023-02-03 15:16:58,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:16:58,850:INFO:Checking exceptions
2023-02-03 15:16:58,850:INFO:Importing libraries
2023-02-03 15:16:58,850:INFO:Copying training dataset
2023-02-03 15:16:58,854:INFO:Defining folds
2023-02-03 15:16:58,855:INFO:Declaring metric variables
2023-02-03 15:16:58,863:INFO:Importing untrained model
2023-02-03 15:16:58,868:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-03 15:16:58,881:INFO:Starting cross validation
2023-02-03 15:16:58,883:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:06,317:INFO:Calculating mean and std
2023-02-03 15:17:06,319:INFO:Creating metrics dataframe
2023-02-03 15:17:06,329:INFO:Uploading results into container
2023-02-03 15:17:06,330:INFO:Uploading model into container now
2023-02-03 15:17:06,331:INFO:_master_model_container: 35
2023-02-03 15:17:06,331:INFO:_display_container: 3
2023-02-03 15:17:06,332:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-02-03 15:17:06,332:INFO:create_model() successfully completed......................................
2023-02-03 15:17:06,455:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:06,455:INFO:Creating metrics dataframe
2023-02-03 15:17:06,477:INFO:Initializing Dummy Regressor
2023-02-03 15:17:06,477:INFO:Total runtime is 0.31273931662241616 minutes
2023-02-03 15:17:06,482:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:06,482:INFO:Initializing create_model()
2023-02-03 15:17:06,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F58F18D0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:06,483:INFO:Checking exceptions
2023-02-03 15:17:06,483:INFO:Importing libraries
2023-02-03 15:17:06,484:INFO:Copying training dataset
2023-02-03 15:17:06,490:INFO:Defining folds
2023-02-03 15:17:06,490:INFO:Declaring metric variables
2023-02-03 15:17:06,495:INFO:Importing untrained model
2023-02-03 15:17:06,502:INFO:Dummy Regressor Imported successfully
2023-02-03 15:17:06,513:INFO:Starting cross validation
2023-02-03 15:17:06,516:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:06,720:INFO:Calculating mean and std
2023-02-03 15:17:06,722:INFO:Creating metrics dataframe
2023-02-03 15:17:06,726:INFO:Uploading results into container
2023-02-03 15:17:06,727:INFO:Uploading model into container now
2023-02-03 15:17:06,728:INFO:_master_model_container: 36
2023-02-03 15:17:06,728:INFO:_display_container: 3
2023-02-03 15:17:06,728:INFO:DummyRegressor()
2023-02-03 15:17:06,729:INFO:create_model() successfully completed......................................
2023-02-03 15:17:06,821:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:06,821:INFO:Creating metrics dataframe
2023-02-03 15:17:06,856:INFO:Initializing create_model()
2023-02-03 15:17:06,857:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:06,857:INFO:Checking exceptions
2023-02-03 15:17:06,859:INFO:Importing libraries
2023-02-03 15:17:06,859:INFO:Copying training dataset
2023-02-03 15:17:06,862:INFO:Defining folds
2023-02-03 15:17:06,862:INFO:Declaring metric variables
2023-02-03 15:17:06,862:INFO:Importing untrained model
2023-02-03 15:17:06,862:INFO:Declaring custom model
2023-02-03 15:17:06,863:INFO:Linear Regression Imported successfully
2023-02-03 15:17:06,864:INFO:Cross validation set to False
2023-02-03 15:17:06,864:INFO:Fitting Model
2023-02-03 15:17:06,883:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:17:06,883:INFO:create_model() successfully completed......................................
2023-02-03 15:17:07,040:INFO:_master_model_container: 36
2023-02-03 15:17:07,041:INFO:_display_container: 3
2023-02-03 15:17:07,041:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:17:07,041:INFO:compare_models() successfully completed......................................
2023-02-03 15:17:18,979:INFO:Initializing compare_models()
2023-02-03 15:17:18,979:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, include=None, fold=None, round=4, cross_validation=True, sort=r2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'r2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-03 15:17:18,980:INFO:Checking exceptions
2023-02-03 15:17:18,985:INFO:Preparing display monitor
2023-02-03 15:17:19,034:INFO:Initializing Linear Regression
2023-02-03 15:17:19,035:INFO:Total runtime is 1.660585403442383e-05 minutes
2023-02-03 15:17:19,043:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:19,043:INFO:Initializing create_model()
2023-02-03 15:17:19,044:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:19,044:INFO:Checking exceptions
2023-02-03 15:17:19,044:INFO:Importing libraries
2023-02-03 15:17:19,045:INFO:Copying training dataset
2023-02-03 15:17:19,053:INFO:Defining folds
2023-02-03 15:17:19,054:INFO:Declaring metric variables
2023-02-03 15:17:19,061:INFO:Importing untrained model
2023-02-03 15:17:19,069:INFO:Linear Regression Imported successfully
2023-02-03 15:17:19,084:INFO:Starting cross validation
2023-02-03 15:17:19,086:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:19,358:INFO:Calculating mean and std
2023-02-03 15:17:19,358:INFO:Creating metrics dataframe
2023-02-03 15:17:19,362:INFO:Uploading results into container
2023-02-03 15:17:19,362:INFO:Uploading model into container now
2023-02-03 15:17:19,363:INFO:_master_model_container: 37
2023-02-03 15:17:19,363:INFO:_display_container: 4
2023-02-03 15:17:19,363:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:17:19,363:INFO:create_model() successfully completed......................................
2023-02-03 15:17:19,454:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:19,454:INFO:Creating metrics dataframe
2023-02-03 15:17:19,466:INFO:Initializing Lasso Regression
2023-02-03 15:17:19,466:INFO:Total runtime is 0.007212615013122559 minutes
2023-02-03 15:17:19,471:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:19,472:INFO:Initializing create_model()
2023-02-03 15:17:19,472:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:19,472:INFO:Checking exceptions
2023-02-03 15:17:19,472:INFO:Importing libraries
2023-02-03 15:17:19,473:INFO:Copying training dataset
2023-02-03 15:17:19,477:INFO:Defining folds
2023-02-03 15:17:19,477:INFO:Declaring metric variables
2023-02-03 15:17:19,482:INFO:Importing untrained model
2023-02-03 15:17:19,487:INFO:Lasso Regression Imported successfully
2023-02-03 15:17:19,499:INFO:Starting cross validation
2023-02-03 15:17:19,500:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:19,523:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.653e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,553:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.713e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,575:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.832e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,599:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,625:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.826e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,651:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,675:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,699:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,722:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,745:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.356e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:19,755:INFO:Calculating mean and std
2023-02-03 15:17:19,755:INFO:Creating metrics dataframe
2023-02-03 15:17:19,759:INFO:Uploading results into container
2023-02-03 15:17:19,760:INFO:Uploading model into container now
2023-02-03 15:17:19,760:INFO:_master_model_container: 38
2023-02-03 15:17:19,760:INFO:_display_container: 4
2023-02-03 15:17:19,761:INFO:Lasso(random_state=123)
2023-02-03 15:17:19,761:INFO:create_model() successfully completed......................................
2023-02-03 15:17:19,842:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:19,842:INFO:Creating metrics dataframe
2023-02-03 15:17:19,857:INFO:Initializing Ridge Regression
2023-02-03 15:17:19,858:INFO:Total runtime is 0.013742069403330486 minutes
2023-02-03 15:17:19,862:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:19,863:INFO:Initializing create_model()
2023-02-03 15:17:19,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:19,863:INFO:Checking exceptions
2023-02-03 15:17:19,863:INFO:Importing libraries
2023-02-03 15:17:19,863:INFO:Copying training dataset
2023-02-03 15:17:19,868:INFO:Defining folds
2023-02-03 15:17:19,868:INFO:Declaring metric variables
2023-02-03 15:17:19,873:INFO:Importing untrained model
2023-02-03 15:17:19,892:INFO:Ridge Regression Imported successfully
2023-02-03 15:17:19,912:INFO:Starting cross validation
2023-02-03 15:17:19,913:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:20,162:INFO:Calculating mean and std
2023-02-03 15:17:20,163:INFO:Creating metrics dataframe
2023-02-03 15:17:20,170:INFO:Uploading results into container
2023-02-03 15:17:20,170:INFO:Uploading model into container now
2023-02-03 15:17:20,171:INFO:_master_model_container: 39
2023-02-03 15:17:20,171:INFO:_display_container: 4
2023-02-03 15:17:20,172:INFO:Ridge(random_state=123)
2023-02-03 15:17:20,172:INFO:create_model() successfully completed......................................
2023-02-03 15:17:20,272:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:20,272:INFO:Creating metrics dataframe
2023-02-03 15:17:20,288:INFO:Initializing Elastic Net
2023-02-03 15:17:20,288:INFO:Total runtime is 0.020902458826700845 minutes
2023-02-03 15:17:20,294:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:20,294:INFO:Initializing create_model()
2023-02-03 15:17:20,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:20,294:INFO:Checking exceptions
2023-02-03 15:17:20,295:INFO:Importing libraries
2023-02-03 15:17:20,295:INFO:Copying training dataset
2023-02-03 15:17:20,301:INFO:Defining folds
2023-02-03 15:17:20,301:INFO:Declaring metric variables
2023-02-03 15:17:20,307:INFO:Importing untrained model
2023-02-03 15:17:20,314:INFO:Elastic Net Imported successfully
2023-02-03 15:17:20,329:INFO:Starting cross validation
2023-02-03 15:17:20,331:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:20,357:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,384:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.982e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,408:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,429:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,452:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.646e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,474:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.039e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,495:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.999e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,517:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,538:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.979e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,563:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:17:20,573:INFO:Calculating mean and std
2023-02-03 15:17:20,575:INFO:Creating metrics dataframe
2023-02-03 15:17:20,579:INFO:Uploading results into container
2023-02-03 15:17:20,579:INFO:Uploading model into container now
2023-02-03 15:17:20,580:INFO:_master_model_container: 40
2023-02-03 15:17:20,580:INFO:_display_container: 4
2023-02-03 15:17:20,581:INFO:ElasticNet(random_state=123)
2023-02-03 15:17:20,581:INFO:create_model() successfully completed......................................
2023-02-03 15:17:20,663:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:20,663:INFO:Creating metrics dataframe
2023-02-03 15:17:20,677:INFO:Initializing Least Angle Regression
2023-02-03 15:17:20,677:INFO:Total runtime is 0.02738208770751953 minutes
2023-02-03 15:17:20,682:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:20,683:INFO:Initializing create_model()
2023-02-03 15:17:20,683:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:20,684:INFO:Checking exceptions
2023-02-03 15:17:20,684:INFO:Importing libraries
2023-02-03 15:17:20,684:INFO:Copying training dataset
2023-02-03 15:17:20,689:INFO:Defining folds
2023-02-03 15:17:20,689:INFO:Declaring metric variables
2023-02-03 15:17:20,695:INFO:Importing untrained model
2023-02-03 15:17:20,703:INFO:Least Angle Regression Imported successfully
2023-02-03 15:17:20,717:INFO:Starting cross validation
2023-02-03 15:17:20,719:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:20,741:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,762:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,785:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,805:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,826:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,848:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,873:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,894:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,915:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,936:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:20,950:INFO:Calculating mean and std
2023-02-03 15:17:20,951:INFO:Creating metrics dataframe
2023-02-03 15:17:20,956:INFO:Uploading results into container
2023-02-03 15:17:20,957:INFO:Uploading model into container now
2023-02-03 15:17:20,958:INFO:_master_model_container: 41
2023-02-03 15:17:20,958:INFO:_display_container: 4
2023-02-03 15:17:20,958:INFO:Lars(random_state=123)
2023-02-03 15:17:20,959:INFO:create_model() successfully completed......................................
2023-02-03 15:17:21,050:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:21,050:INFO:Creating metrics dataframe
2023-02-03 15:17:21,062:INFO:Initializing Lasso Least Angle Regression
2023-02-03 15:17:21,063:INFO:Total runtime is 0.03382838169733683 minutes
2023-02-03 15:17:21,069:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:21,070:INFO:Initializing create_model()
2023-02-03 15:17:21,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:21,070:INFO:Checking exceptions
2023-02-03 15:17:21,070:INFO:Importing libraries
2023-02-03 15:17:21,070:INFO:Copying training dataset
2023-02-03 15:17:21,074:INFO:Defining folds
2023-02-03 15:17:21,074:INFO:Declaring metric variables
2023-02-03 15:17:21,081:INFO:Importing untrained model
2023-02-03 15:17:21,087:INFO:Lasso Least Angle Regression Imported successfully
2023-02-03 15:17:21,099:INFO:Starting cross validation
2023-02-03 15:17:21,101:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:21,123:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,146:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,168:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,190:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,212:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,234:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,257:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,277:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,297:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,320:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:17:21,330:INFO:Calculating mean and std
2023-02-03 15:17:21,334:INFO:Creating metrics dataframe
2023-02-03 15:17:21,340:INFO:Uploading results into container
2023-02-03 15:17:21,341:INFO:Uploading model into container now
2023-02-03 15:17:21,341:INFO:_master_model_container: 42
2023-02-03 15:17:21,342:INFO:_display_container: 4
2023-02-03 15:17:21,342:INFO:LassoLars(random_state=123)
2023-02-03 15:17:21,342:INFO:create_model() successfully completed......................................
2023-02-03 15:17:21,428:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:21,428:INFO:Creating metrics dataframe
2023-02-03 15:17:21,443:INFO:Initializing Orthogonal Matching Pursuit
2023-02-03 15:17:21,443:INFO:Total runtime is 0.040146406491597494 minutes
2023-02-03 15:17:21,447:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:21,447:INFO:Initializing create_model()
2023-02-03 15:17:21,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:21,448:INFO:Checking exceptions
2023-02-03 15:17:21,448:INFO:Importing libraries
2023-02-03 15:17:21,449:INFO:Copying training dataset
2023-02-03 15:17:21,455:INFO:Defining folds
2023-02-03 15:17:21,456:INFO:Declaring metric variables
2023-02-03 15:17:21,461:INFO:Importing untrained model
2023-02-03 15:17:21,468:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-03 15:17:21,484:INFO:Starting cross validation
2023-02-03 15:17:21,487:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:21,504:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,530:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,552:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,572:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,592:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,613:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,636:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,658:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,680:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,702:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:17:21,712:INFO:Calculating mean and std
2023-02-03 15:17:21,714:INFO:Creating metrics dataframe
2023-02-03 15:17:21,719:INFO:Uploading results into container
2023-02-03 15:17:21,719:INFO:Uploading model into container now
2023-02-03 15:17:21,720:INFO:_master_model_container: 43
2023-02-03 15:17:21,721:INFO:_display_container: 4
2023-02-03 15:17:21,721:INFO:OrthogonalMatchingPursuit()
2023-02-03 15:17:21,722:INFO:create_model() successfully completed......................................
2023-02-03 15:17:21,809:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:21,809:INFO:Creating metrics dataframe
2023-02-03 15:17:21,823:INFO:Initializing Bayesian Ridge
2023-02-03 15:17:21,823:INFO:Total runtime is 0.046492513020833334 minutes
2023-02-03 15:17:21,829:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:21,829:INFO:Initializing create_model()
2023-02-03 15:17:21,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:21,830:INFO:Checking exceptions
2023-02-03 15:17:21,830:INFO:Importing libraries
2023-02-03 15:17:21,830:INFO:Copying training dataset
2023-02-03 15:17:21,836:INFO:Defining folds
2023-02-03 15:17:21,836:INFO:Declaring metric variables
2023-02-03 15:17:21,842:INFO:Importing untrained model
2023-02-03 15:17:21,848:INFO:Bayesian Ridge Imported successfully
2023-02-03 15:17:21,865:INFO:Starting cross validation
2023-02-03 15:17:21,866:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:22,106:INFO:Calculating mean and std
2023-02-03 15:17:22,107:INFO:Creating metrics dataframe
2023-02-03 15:17:22,111:INFO:Uploading results into container
2023-02-03 15:17:22,112:INFO:Uploading model into container now
2023-02-03 15:17:22,112:INFO:_master_model_container: 44
2023-02-03 15:17:22,113:INFO:_display_container: 4
2023-02-03 15:17:22,113:INFO:BayesianRidge()
2023-02-03 15:17:22,114:INFO:create_model() successfully completed......................................
2023-02-03 15:17:22,204:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:22,204:INFO:Creating metrics dataframe
2023-02-03 15:17:22,218:INFO:Initializing Passive Aggressive Regressor
2023-02-03 15:17:22,219:INFO:Total runtime is 0.053088982899983726 minutes
2023-02-03 15:17:22,223:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:22,223:INFO:Initializing create_model()
2023-02-03 15:17:22,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:22,224:INFO:Checking exceptions
2023-02-03 15:17:22,224:INFO:Importing libraries
2023-02-03 15:17:22,224:INFO:Copying training dataset
2023-02-03 15:17:22,228:INFO:Defining folds
2023-02-03 15:17:22,229:INFO:Declaring metric variables
2023-02-03 15:17:22,234:INFO:Importing untrained model
2023-02-03 15:17:22,244:INFO:Passive Aggressive Regressor Imported successfully
2023-02-03 15:17:22,262:INFO:Starting cross validation
2023-02-03 15:17:22,264:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:22,496:INFO:Calculating mean and std
2023-02-03 15:17:22,498:INFO:Creating metrics dataframe
2023-02-03 15:17:22,503:INFO:Uploading results into container
2023-02-03 15:17:22,504:INFO:Uploading model into container now
2023-02-03 15:17:22,504:INFO:_master_model_container: 45
2023-02-03 15:17:22,504:INFO:_display_container: 4
2023-02-03 15:17:22,505:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-03 15:17:22,505:INFO:create_model() successfully completed......................................
2023-02-03 15:17:22,590:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:22,591:INFO:Creating metrics dataframe
2023-02-03 15:17:22,607:INFO:Initializing Huber Regressor
2023-02-03 15:17:22,608:INFO:Total runtime is 0.059568393230438235 minutes
2023-02-03 15:17:22,614:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:22,615:INFO:Initializing create_model()
2023-02-03 15:17:22,615:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:22,615:INFO:Checking exceptions
2023-02-03 15:17:22,615:INFO:Importing libraries
2023-02-03 15:17:22,615:INFO:Copying training dataset
2023-02-03 15:17:22,622:INFO:Defining folds
2023-02-03 15:17:22,622:INFO:Declaring metric variables
2023-02-03 15:17:22,629:INFO:Importing untrained model
2023-02-03 15:17:22,635:INFO:Huber Regressor Imported successfully
2023-02-03 15:17:22,649:INFO:Starting cross validation
2023-02-03 15:17:22,651:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:22,925:INFO:Calculating mean and std
2023-02-03 15:17:22,928:INFO:Creating metrics dataframe
2023-02-03 15:17:22,940:INFO:Uploading results into container
2023-02-03 15:17:22,942:INFO:Uploading model into container now
2023-02-03 15:17:22,942:INFO:_master_model_container: 46
2023-02-03 15:17:22,943:INFO:_display_container: 4
2023-02-03 15:17:22,943:INFO:HuberRegressor()
2023-02-03 15:17:22,943:INFO:create_model() successfully completed......................................
2023-02-03 15:17:23,057:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:23,057:INFO:Creating metrics dataframe
2023-02-03 15:17:23,075:INFO:Initializing K Neighbors Regressor
2023-02-03 15:17:23,076:INFO:Total runtime is 0.06736389001210531 minutes
2023-02-03 15:17:23,081:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:23,082:INFO:Initializing create_model()
2023-02-03 15:17:23,082:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:23,082:INFO:Checking exceptions
2023-02-03 15:17:23,082:INFO:Importing libraries
2023-02-03 15:17:23,083:INFO:Copying training dataset
2023-02-03 15:17:23,090:INFO:Defining folds
2023-02-03 15:17:23,091:INFO:Declaring metric variables
2023-02-03 15:17:23,097:INFO:Importing untrained model
2023-02-03 15:17:23,104:INFO:K Neighbors Regressor Imported successfully
2023-02-03 15:17:23,120:INFO:Starting cross validation
2023-02-03 15:17:23,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:23,478:INFO:Calculating mean and std
2023-02-03 15:17:23,479:INFO:Creating metrics dataframe
2023-02-03 15:17:23,483:INFO:Uploading results into container
2023-02-03 15:17:23,485:INFO:Uploading model into container now
2023-02-03 15:17:23,486:INFO:_master_model_container: 47
2023-02-03 15:17:23,486:INFO:_display_container: 4
2023-02-03 15:17:23,487:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-03 15:17:23,487:INFO:create_model() successfully completed......................................
2023-02-03 15:17:23,573:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:23,574:INFO:Creating metrics dataframe
2023-02-03 15:17:23,591:INFO:Initializing Decision Tree Regressor
2023-02-03 15:17:23,591:INFO:Total runtime is 0.07595900297164918 minutes
2023-02-03 15:17:23,597:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:23,597:INFO:Initializing create_model()
2023-02-03 15:17:23,597:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:23,597:INFO:Checking exceptions
2023-02-03 15:17:23,598:INFO:Importing libraries
2023-02-03 15:17:23,598:INFO:Copying training dataset
2023-02-03 15:17:23,602:INFO:Defining folds
2023-02-03 15:17:23,603:INFO:Declaring metric variables
2023-02-03 15:17:23,611:INFO:Importing untrained model
2023-02-03 15:17:23,616:INFO:Decision Tree Regressor Imported successfully
2023-02-03 15:17:23,626:INFO:Starting cross validation
2023-02-03 15:17:23,628:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:23,864:INFO:Calculating mean and std
2023-02-03 15:17:23,865:INFO:Creating metrics dataframe
2023-02-03 15:17:23,870:INFO:Uploading results into container
2023-02-03 15:17:23,871:INFO:Uploading model into container now
2023-02-03 15:17:23,872:INFO:_master_model_container: 48
2023-02-03 15:17:23,872:INFO:_display_container: 4
2023-02-03 15:17:23,873:INFO:DecisionTreeRegressor(random_state=123)
2023-02-03 15:17:23,873:INFO:create_model() successfully completed......................................
2023-02-03 15:17:23,955:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:23,955:INFO:Creating metrics dataframe
2023-02-03 15:17:23,971:INFO:Initializing Random Forest Regressor
2023-02-03 15:17:23,971:INFO:Total runtime is 0.08228869438171388 minutes
2023-02-03 15:17:23,976:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:23,977:INFO:Initializing create_model()
2023-02-03 15:17:23,977:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:23,977:INFO:Checking exceptions
2023-02-03 15:17:23,977:INFO:Importing libraries
2023-02-03 15:17:23,978:INFO:Copying training dataset
2023-02-03 15:17:23,981:INFO:Defining folds
2023-02-03 15:17:23,982:INFO:Declaring metric variables
2023-02-03 15:17:23,988:INFO:Importing untrained model
2023-02-03 15:17:23,994:INFO:Random Forest Regressor Imported successfully
2023-02-03 15:17:24,009:INFO:Starting cross validation
2023-02-03 15:17:24,011:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:25,842:INFO:Calculating mean and std
2023-02-03 15:17:25,844:INFO:Creating metrics dataframe
2023-02-03 15:17:25,848:INFO:Uploading results into container
2023-02-03 15:17:25,849:INFO:Uploading model into container now
2023-02-03 15:17:25,850:INFO:_master_model_container: 49
2023-02-03 15:17:25,850:INFO:_display_container: 4
2023-02-03 15:17:25,851:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:17:25,851:INFO:create_model() successfully completed......................................
2023-02-03 15:17:25,944:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:25,944:INFO:Creating metrics dataframe
2023-02-03 15:17:25,961:INFO:Initializing Extra Trees Regressor
2023-02-03 15:17:25,961:INFO:Total runtime is 0.11545761028925579 minutes
2023-02-03 15:17:25,965:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:25,966:INFO:Initializing create_model()
2023-02-03 15:17:25,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:25,966:INFO:Checking exceptions
2023-02-03 15:17:25,967:INFO:Importing libraries
2023-02-03 15:17:25,967:INFO:Copying training dataset
2023-02-03 15:17:25,971:INFO:Defining folds
2023-02-03 15:17:25,971:INFO:Declaring metric variables
2023-02-03 15:17:25,977:INFO:Importing untrained model
2023-02-03 15:17:25,983:INFO:Extra Trees Regressor Imported successfully
2023-02-03 15:17:25,992:INFO:Starting cross validation
2023-02-03 15:17:25,994:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:27,928:INFO:Calculating mean and std
2023-02-03 15:17:27,930:INFO:Creating metrics dataframe
2023-02-03 15:17:27,935:INFO:Uploading results into container
2023-02-03 15:17:27,936:INFO:Uploading model into container now
2023-02-03 15:17:27,936:INFO:_master_model_container: 50
2023-02-03 15:17:27,936:INFO:_display_container: 4
2023-02-03 15:17:27,937:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:17:27,937:INFO:create_model() successfully completed......................................
2023-02-03 15:17:28,021:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:28,021:INFO:Creating metrics dataframe
2023-02-03 15:17:28,038:INFO:Initializing AdaBoost Regressor
2023-02-03 15:17:28,038:INFO:Total runtime is 0.15007108052571616 minutes
2023-02-03 15:17:28,044:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:28,044:INFO:Initializing create_model()
2023-02-03 15:17:28,044:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:28,044:INFO:Checking exceptions
2023-02-03 15:17:28,044:INFO:Importing libraries
2023-02-03 15:17:28,044:INFO:Copying training dataset
2023-02-03 15:17:28,049:INFO:Defining folds
2023-02-03 15:17:28,049:INFO:Declaring metric variables
2023-02-03 15:17:28,054:INFO:Importing untrained model
2023-02-03 15:17:28,062:INFO:AdaBoost Regressor Imported successfully
2023-02-03 15:17:28,074:INFO:Starting cross validation
2023-02-03 15:17:28,075:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:28,691:INFO:Calculating mean and std
2023-02-03 15:17:28,693:INFO:Creating metrics dataframe
2023-02-03 15:17:28,697:INFO:Uploading results into container
2023-02-03 15:17:28,698:INFO:Uploading model into container now
2023-02-03 15:17:28,699:INFO:_master_model_container: 51
2023-02-03 15:17:28,699:INFO:_display_container: 4
2023-02-03 15:17:28,700:INFO:AdaBoostRegressor(random_state=123)
2023-02-03 15:17:28,700:INFO:create_model() successfully completed......................................
2023-02-03 15:17:28,787:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:28,787:INFO:Creating metrics dataframe
2023-02-03 15:17:28,804:INFO:Initializing Gradient Boosting Regressor
2023-02-03 15:17:28,804:INFO:Total runtime is 0.16283047993977867 minutes
2023-02-03 15:17:28,810:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:28,810:INFO:Initializing create_model()
2023-02-03 15:17:28,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:28,811:INFO:Checking exceptions
2023-02-03 15:17:28,811:INFO:Importing libraries
2023-02-03 15:17:28,811:INFO:Copying training dataset
2023-02-03 15:17:28,815:INFO:Defining folds
2023-02-03 15:17:28,815:INFO:Declaring metric variables
2023-02-03 15:17:28,821:INFO:Importing untrained model
2023-02-03 15:17:28,830:INFO:Gradient Boosting Regressor Imported successfully
2023-02-03 15:17:28,845:INFO:Starting cross validation
2023-02-03 15:17:28,847:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:29,569:INFO:Calculating mean and std
2023-02-03 15:17:29,571:INFO:Creating metrics dataframe
2023-02-03 15:17:29,580:INFO:Uploading results into container
2023-02-03 15:17:29,581:INFO:Uploading model into container now
2023-02-03 15:17:29,582:INFO:_master_model_container: 52
2023-02-03 15:17:29,582:INFO:_display_container: 4
2023-02-03 15:17:29,583:INFO:GradientBoostingRegressor(random_state=123)
2023-02-03 15:17:29,583:INFO:create_model() successfully completed......................................
2023-02-03 15:17:29,684:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:29,684:INFO:Creating metrics dataframe
2023-02-03 15:17:29,704:INFO:Initializing Light Gradient Boosting Machine
2023-02-03 15:17:29,704:INFO:Total runtime is 0.1778382460276286 minutes
2023-02-03 15:17:29,713:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:29,713:INFO:Initializing create_model()
2023-02-03 15:17:29,714:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:29,714:INFO:Checking exceptions
2023-02-03 15:17:29,714:INFO:Importing libraries
2023-02-03 15:17:29,715:INFO:Copying training dataset
2023-02-03 15:17:29,721:INFO:Defining folds
2023-02-03 15:17:29,721:INFO:Declaring metric variables
2023-02-03 15:17:29,730:INFO:Importing untrained model
2023-02-03 15:17:29,736:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-03 15:17:29,758:INFO:Starting cross validation
2023-02-03 15:17:29,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:37,210:INFO:Calculating mean and std
2023-02-03 15:17:37,213:INFO:Creating metrics dataframe
2023-02-03 15:17:37,222:INFO:Uploading results into container
2023-02-03 15:17:37,224:INFO:Uploading model into container now
2023-02-03 15:17:37,225:INFO:_master_model_container: 53
2023-02-03 15:17:37,225:INFO:_display_container: 4
2023-02-03 15:17:37,226:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-02-03 15:17:37,226:INFO:create_model() successfully completed......................................
2023-02-03 15:17:37,349:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:37,350:INFO:Creating metrics dataframe
2023-02-03 15:17:37,368:INFO:Initializing Dummy Regressor
2023-02-03 15:17:37,369:INFO:Total runtime is 0.30558565457661946 minutes
2023-02-03 15:17:37,374:INFO:SubProcess create_model() called ==================================
2023-02-03 15:17:37,374:INFO:Initializing create_model()
2023-02-03 15:17:37,374:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:37,375:INFO:Checking exceptions
2023-02-03 15:17:37,375:INFO:Importing libraries
2023-02-03 15:17:37,375:INFO:Copying training dataset
2023-02-03 15:17:37,379:INFO:Defining folds
2023-02-03 15:17:37,379:INFO:Declaring metric variables
2023-02-03 15:17:37,385:INFO:Importing untrained model
2023-02-03 15:17:37,391:INFO:Dummy Regressor Imported successfully
2023-02-03 15:17:37,401:INFO:Starting cross validation
2023-02-03 15:17:37,403:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:17:37,606:INFO:Calculating mean and std
2023-02-03 15:17:37,607:INFO:Creating metrics dataframe
2023-02-03 15:17:37,612:INFO:Uploading results into container
2023-02-03 15:17:37,613:INFO:Uploading model into container now
2023-02-03 15:17:37,614:INFO:_master_model_container: 54
2023-02-03 15:17:37,614:INFO:_display_container: 4
2023-02-03 15:17:37,615:INFO:DummyRegressor()
2023-02-03 15:17:37,615:INFO:create_model() successfully completed......................................
2023-02-03 15:17:37,704:INFO:SubProcess create_model() end ==================================
2023-02-03 15:17:37,704:INFO:Creating metrics dataframe
2023-02-03 15:17:37,739:INFO:Initializing create_model()
2023-02-03 15:17:37,740:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:17:37,740:INFO:Checking exceptions
2023-02-03 15:17:37,742:INFO:Importing libraries
2023-02-03 15:17:37,742:INFO:Copying training dataset
2023-02-03 15:17:37,746:INFO:Defining folds
2023-02-03 15:17:37,746:INFO:Declaring metric variables
2023-02-03 15:17:37,746:INFO:Importing untrained model
2023-02-03 15:17:37,746:INFO:Declaring custom model
2023-02-03 15:17:37,747:INFO:Linear Regression Imported successfully
2023-02-03 15:17:37,747:INFO:Cross validation set to False
2023-02-03 15:17:37,747:INFO:Fitting Model
2023-02-03 15:17:37,758:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:17:37,758:INFO:create_model() successfully completed......................................
2023-02-03 15:17:37,902:INFO:_master_model_container: 54
2023-02-03 15:17:37,903:INFO:_display_container: 4
2023-02-03 15:17:37,903:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:17:37,903:INFO:compare_models() successfully completed......................................
2023-02-03 15:19:00,284:INFO:Initializing create_model()
2023-02-03 15:19:00,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:00,284:INFO:Checking exceptions
2023-02-03 15:19:00,326:INFO:Importing libraries
2023-02-03 15:19:00,327:INFO:Copying training dataset
2023-02-03 15:19:00,340:INFO:Defining folds
2023-02-03 15:19:00,340:INFO:Declaring metric variables
2023-02-03 15:19:00,352:INFO:Importing untrained model
2023-02-03 15:19:00,352:INFO:Declaring custom model
2023-02-03 15:19:00,360:INFO:Linear Regression Imported successfully
2023-02-03 15:19:00,377:INFO:Starting cross validation
2023-02-03 15:19:00,380:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:00,745:INFO:Calculating mean and std
2023-02-03 15:19:00,746:INFO:Creating metrics dataframe
2023-02-03 15:19:00,754:INFO:Finalizing model
2023-02-03 15:19:00,776:INFO:Uploading results into container
2023-02-03 15:19:00,778:INFO:Uploading model into container now
2023-02-03 15:19:00,804:INFO:_master_model_container: 55
2023-02-03 15:19:00,804:INFO:_display_container: 5
2023-02-03 15:19:00,804:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:19:00,805:INFO:create_model() successfully completed......................................
2023-02-03 15:19:20,909:INFO:Initializing compare_models()
2023-02-03 15:19:20,910:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-03 15:19:20,910:INFO:Checking exceptions
2023-02-03 15:19:20,913:INFO:Preparing display monitor
2023-02-03 15:19:20,966:INFO:Initializing Linear Regression
2023-02-03 15:19:20,967:INFO:Total runtime is 1.6669432322184246e-05 minutes
2023-02-03 15:19:20,977:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:20,978:INFO:Initializing create_model()
2023-02-03 15:19:20,978:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:20,978:INFO:Checking exceptions
2023-02-03 15:19:20,979:INFO:Importing libraries
2023-02-03 15:19:20,980:INFO:Copying training dataset
2023-02-03 15:19:20,992:INFO:Defining folds
2023-02-03 15:19:20,992:INFO:Declaring metric variables
2023-02-03 15:19:20,999:INFO:Importing untrained model
2023-02-03 15:19:21,010:INFO:Linear Regression Imported successfully
2023-02-03 15:19:21,024:INFO:Starting cross validation
2023-02-03 15:19:21,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:21,315:INFO:Calculating mean and std
2023-02-03 15:19:21,315:INFO:Creating metrics dataframe
2023-02-03 15:19:21,319:INFO:Uploading results into container
2023-02-03 15:19:21,320:INFO:Uploading model into container now
2023-02-03 15:19:21,320:INFO:_master_model_container: 56
2023-02-03 15:19:21,320:INFO:_display_container: 6
2023-02-03 15:19:21,320:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:19:21,321:INFO:create_model() successfully completed......................................
2023-02-03 15:19:21,404:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:21,404:INFO:Creating metrics dataframe
2023-02-03 15:19:21,416:INFO:Initializing Lasso Regression
2023-02-03 15:19:21,416:INFO:Total runtime is 0.007495677471160889 minutes
2023-02-03 15:19:21,423:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:21,423:INFO:Initializing create_model()
2023-02-03 15:19:21,424:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:21,424:INFO:Checking exceptions
2023-02-03 15:19:21,424:INFO:Importing libraries
2023-02-03 15:19:21,424:INFO:Copying training dataset
2023-02-03 15:19:21,427:INFO:Defining folds
2023-02-03 15:19:21,427:INFO:Declaring metric variables
2023-02-03 15:19:21,433:INFO:Importing untrained model
2023-02-03 15:19:21,440:INFO:Lasso Regression Imported successfully
2023-02-03 15:19:21,451:INFO:Starting cross validation
2023-02-03 15:19:21,452:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:21,471:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.653e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,501:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.713e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,525:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.832e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,545:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,566:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.826e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,587:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,612:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,633:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,655:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,676:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.356e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:21,685:INFO:Calculating mean and std
2023-02-03 15:19:21,686:INFO:Creating metrics dataframe
2023-02-03 15:19:21,691:INFO:Uploading results into container
2023-02-03 15:19:21,691:INFO:Uploading model into container now
2023-02-03 15:19:21,692:INFO:_master_model_container: 57
2023-02-03 15:19:21,692:INFO:_display_container: 6
2023-02-03 15:19:21,692:INFO:Lasso(random_state=123)
2023-02-03 15:19:21,692:INFO:create_model() successfully completed......................................
2023-02-03 15:19:21,776:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:21,776:INFO:Creating metrics dataframe
2023-02-03 15:19:21,788:INFO:Initializing Ridge Regression
2023-02-03 15:19:21,788:INFO:Total runtime is 0.013692132631937663 minutes
2023-02-03 15:19:21,794:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:21,794:INFO:Initializing create_model()
2023-02-03 15:19:21,794:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:21,794:INFO:Checking exceptions
2023-02-03 15:19:21,794:INFO:Importing libraries
2023-02-03 15:19:21,795:INFO:Copying training dataset
2023-02-03 15:19:21,798:INFO:Defining folds
2023-02-03 15:19:21,798:INFO:Declaring metric variables
2023-02-03 15:19:21,802:INFO:Importing untrained model
2023-02-03 15:19:21,808:INFO:Ridge Regression Imported successfully
2023-02-03 15:19:21,819:INFO:Starting cross validation
2023-02-03 15:19:21,822:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:22,054:INFO:Calculating mean and std
2023-02-03 15:19:22,055:INFO:Creating metrics dataframe
2023-02-03 15:19:22,060:INFO:Uploading results into container
2023-02-03 15:19:22,061:INFO:Uploading model into container now
2023-02-03 15:19:22,062:INFO:_master_model_container: 58
2023-02-03 15:19:22,062:INFO:_display_container: 6
2023-02-03 15:19:22,063:INFO:Ridge(random_state=123)
2023-02-03 15:19:22,063:INFO:create_model() successfully completed......................................
2023-02-03 15:19:22,145:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:22,145:INFO:Creating metrics dataframe
2023-02-03 15:19:22,157:INFO:Initializing Elastic Net
2023-02-03 15:19:22,158:INFO:Total runtime is 0.019855419794718426 minutes
2023-02-03 15:19:22,162:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:22,163:INFO:Initializing create_model()
2023-02-03 15:19:22,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:22,163:INFO:Checking exceptions
2023-02-03 15:19:22,163:INFO:Importing libraries
2023-02-03 15:19:22,163:INFO:Copying training dataset
2023-02-03 15:19:22,167:INFO:Defining folds
2023-02-03 15:19:22,167:INFO:Declaring metric variables
2023-02-03 15:19:22,174:INFO:Importing untrained model
2023-02-03 15:19:22,182:INFO:Elastic Net Imported successfully
2023-02-03 15:19:22,194:INFO:Starting cross validation
2023-02-03 15:19:22,195:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:22,218:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,245:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.982e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,266:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,286:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,307:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.646e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,329:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.039e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,350:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.999e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,372:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,394:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.979e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,413:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:22,422:INFO:Calculating mean and std
2023-02-03 15:19:22,423:INFO:Creating metrics dataframe
2023-02-03 15:19:22,427:INFO:Uploading results into container
2023-02-03 15:19:22,428:INFO:Uploading model into container now
2023-02-03 15:19:22,429:INFO:_master_model_container: 59
2023-02-03 15:19:22,430:INFO:_display_container: 6
2023-02-03 15:19:22,430:INFO:ElasticNet(random_state=123)
2023-02-03 15:19:22,430:INFO:create_model() successfully completed......................................
2023-02-03 15:19:22,526:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:22,526:INFO:Creating metrics dataframe
2023-02-03 15:19:22,541:INFO:Initializing Least Angle Regression
2023-02-03 15:19:22,541:INFO:Total runtime is 0.02625157435735067 minutes
2023-02-03 15:19:22,547:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:22,547:INFO:Initializing create_model()
2023-02-03 15:19:22,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:22,548:INFO:Checking exceptions
2023-02-03 15:19:22,548:INFO:Importing libraries
2023-02-03 15:19:22,548:INFO:Copying training dataset
2023-02-03 15:19:22,555:INFO:Defining folds
2023-02-03 15:19:22,555:INFO:Declaring metric variables
2023-02-03 15:19:22,560:INFO:Importing untrained model
2023-02-03 15:19:22,568:INFO:Least Angle Regression Imported successfully
2023-02-03 15:19:22,589:INFO:Starting cross validation
2023-02-03 15:19:22,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:22,624:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,650:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,673:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,695:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,719:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,746:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,767:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,790:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,810:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,833:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:22,845:INFO:Calculating mean and std
2023-02-03 15:19:22,846:INFO:Creating metrics dataframe
2023-02-03 15:19:22,851:INFO:Uploading results into container
2023-02-03 15:19:22,852:INFO:Uploading model into container now
2023-02-03 15:19:22,852:INFO:_master_model_container: 60
2023-02-03 15:19:22,852:INFO:_display_container: 6
2023-02-03 15:19:22,853:INFO:Lars(random_state=123)
2023-02-03 15:19:22,853:INFO:create_model() successfully completed......................................
2023-02-03 15:19:22,943:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:22,943:INFO:Creating metrics dataframe
2023-02-03 15:19:22,958:INFO:Initializing Lasso Least Angle Regression
2023-02-03 15:19:22,958:INFO:Total runtime is 0.03319758176803589 minutes
2023-02-03 15:19:22,963:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:22,963:INFO:Initializing create_model()
2023-02-03 15:19:22,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:22,964:INFO:Checking exceptions
2023-02-03 15:19:22,964:INFO:Importing libraries
2023-02-03 15:19:22,964:INFO:Copying training dataset
2023-02-03 15:19:22,968:INFO:Defining folds
2023-02-03 15:19:22,968:INFO:Declaring metric variables
2023-02-03 15:19:22,976:INFO:Importing untrained model
2023-02-03 15:19:22,983:INFO:Lasso Least Angle Regression Imported successfully
2023-02-03 15:19:22,998:INFO:Starting cross validation
2023-02-03 15:19:22,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:23,017:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,044:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,066:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,087:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,111:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,133:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,156:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,177:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,198:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,220:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:23,230:INFO:Calculating mean and std
2023-02-03 15:19:23,231:INFO:Creating metrics dataframe
2023-02-03 15:19:23,235:INFO:Uploading results into container
2023-02-03 15:19:23,236:INFO:Uploading model into container now
2023-02-03 15:19:23,237:INFO:_master_model_container: 61
2023-02-03 15:19:23,237:INFO:_display_container: 6
2023-02-03 15:19:23,239:INFO:LassoLars(random_state=123)
2023-02-03 15:19:23,239:INFO:create_model() successfully completed......................................
2023-02-03 15:19:23,330:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:23,330:INFO:Creating metrics dataframe
2023-02-03 15:19:23,346:INFO:Initializing Orthogonal Matching Pursuit
2023-02-03 15:19:23,347:INFO:Total runtime is 0.039677258332570395 minutes
2023-02-03 15:19:23,352:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:23,352:INFO:Initializing create_model()
2023-02-03 15:19:23,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:23,353:INFO:Checking exceptions
2023-02-03 15:19:23,353:INFO:Importing libraries
2023-02-03 15:19:23,354:INFO:Copying training dataset
2023-02-03 15:19:23,362:INFO:Defining folds
2023-02-03 15:19:23,362:INFO:Declaring metric variables
2023-02-03 15:19:23,370:INFO:Importing untrained model
2023-02-03 15:19:23,380:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-03 15:19:23,394:INFO:Starting cross validation
2023-02-03 15:19:23,396:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:23,414:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,441:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,464:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,488:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,509:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,530:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,551:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,575:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,596:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,616:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:23,627:INFO:Calculating mean and std
2023-02-03 15:19:23,628:INFO:Creating metrics dataframe
2023-02-03 15:19:23,632:INFO:Uploading results into container
2023-02-03 15:19:23,633:INFO:Uploading model into container now
2023-02-03 15:19:23,633:INFO:_master_model_container: 62
2023-02-03 15:19:23,633:INFO:_display_container: 6
2023-02-03 15:19:23,634:INFO:OrthogonalMatchingPursuit()
2023-02-03 15:19:23,634:INFO:create_model() successfully completed......................................
2023-02-03 15:19:23,729:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:23,730:INFO:Creating metrics dataframe
2023-02-03 15:19:23,745:INFO:Initializing Bayesian Ridge
2023-02-03 15:19:23,745:INFO:Total runtime is 0.04630675713221232 minutes
2023-02-03 15:19:23,751:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:23,751:INFO:Initializing create_model()
2023-02-03 15:19:23,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:23,752:INFO:Checking exceptions
2023-02-03 15:19:23,752:INFO:Importing libraries
2023-02-03 15:19:23,752:INFO:Copying training dataset
2023-02-03 15:19:23,758:INFO:Defining folds
2023-02-03 15:19:23,758:INFO:Declaring metric variables
2023-02-03 15:19:23,764:INFO:Importing untrained model
2023-02-03 15:19:23,770:INFO:Bayesian Ridge Imported successfully
2023-02-03 15:19:23,788:INFO:Starting cross validation
2023-02-03 15:19:23,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:24,026:INFO:Calculating mean and std
2023-02-03 15:19:24,027:INFO:Creating metrics dataframe
2023-02-03 15:19:24,032:INFO:Uploading results into container
2023-02-03 15:19:24,033:INFO:Uploading model into container now
2023-02-03 15:19:24,033:INFO:_master_model_container: 63
2023-02-03 15:19:24,034:INFO:_display_container: 6
2023-02-03 15:19:24,034:INFO:BayesianRidge()
2023-02-03 15:19:24,035:INFO:create_model() successfully completed......................................
2023-02-03 15:19:24,126:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:24,126:INFO:Creating metrics dataframe
2023-02-03 15:19:24,142:INFO:Initializing Passive Aggressive Regressor
2023-02-03 15:19:24,142:INFO:Total runtime is 0.05291986068089803 minutes
2023-02-03 15:19:24,146:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:24,148:INFO:Initializing create_model()
2023-02-03 15:19:24,148:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:24,148:INFO:Checking exceptions
2023-02-03 15:19:24,148:INFO:Importing libraries
2023-02-03 15:19:24,148:INFO:Copying training dataset
2023-02-03 15:19:24,151:INFO:Defining folds
2023-02-03 15:19:24,152:INFO:Declaring metric variables
2023-02-03 15:19:24,159:INFO:Importing untrained model
2023-02-03 15:19:24,167:INFO:Passive Aggressive Regressor Imported successfully
2023-02-03 15:19:24,182:INFO:Starting cross validation
2023-02-03 15:19:24,183:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:24,458:INFO:Calculating mean and std
2023-02-03 15:19:24,460:INFO:Creating metrics dataframe
2023-02-03 15:19:24,464:INFO:Uploading results into container
2023-02-03 15:19:24,465:INFO:Uploading model into container now
2023-02-03 15:19:24,465:INFO:_master_model_container: 64
2023-02-03 15:19:24,466:INFO:_display_container: 6
2023-02-03 15:19:24,466:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-03 15:19:24,467:INFO:create_model() successfully completed......................................
2023-02-03 15:19:24,559:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:24,559:INFO:Creating metrics dataframe
2023-02-03 15:19:24,576:INFO:Initializing Huber Regressor
2023-02-03 15:19:24,576:INFO:Total runtime is 0.06016546885172526 minutes
2023-02-03 15:19:24,581:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:24,581:INFO:Initializing create_model()
2023-02-03 15:19:24,582:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:24,582:INFO:Checking exceptions
2023-02-03 15:19:24,582:INFO:Importing libraries
2023-02-03 15:19:24,582:INFO:Copying training dataset
2023-02-03 15:19:24,586:INFO:Defining folds
2023-02-03 15:19:24,587:INFO:Declaring metric variables
2023-02-03 15:19:24,595:INFO:Importing untrained model
2023-02-03 15:19:24,600:INFO:Huber Regressor Imported successfully
2023-02-03 15:19:24,613:INFO:Starting cross validation
2023-02-03 15:19:24,615:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:24,899:INFO:Calculating mean and std
2023-02-03 15:19:24,900:INFO:Creating metrics dataframe
2023-02-03 15:19:24,904:INFO:Uploading results into container
2023-02-03 15:19:24,905:INFO:Uploading model into container now
2023-02-03 15:19:24,907:INFO:_master_model_container: 65
2023-02-03 15:19:24,907:INFO:_display_container: 6
2023-02-03 15:19:24,908:INFO:HuberRegressor()
2023-02-03 15:19:24,908:INFO:create_model() successfully completed......................................
2023-02-03 15:19:24,999:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:24,999:INFO:Creating metrics dataframe
2023-02-03 15:19:25,017:INFO:Initializing K Neighbors Regressor
2023-02-03 15:19:25,017:INFO:Total runtime is 0.06751126448313395 minutes
2023-02-03 15:19:25,022:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:25,023:INFO:Initializing create_model()
2023-02-03 15:19:25,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:25,024:INFO:Checking exceptions
2023-02-03 15:19:25,025:INFO:Importing libraries
2023-02-03 15:19:25,025:INFO:Copying training dataset
2023-02-03 15:19:25,030:INFO:Defining folds
2023-02-03 15:19:25,031:INFO:Declaring metric variables
2023-02-03 15:19:25,038:INFO:Importing untrained model
2023-02-03 15:19:25,045:INFO:K Neighbors Regressor Imported successfully
2023-02-03 15:19:25,064:INFO:Starting cross validation
2023-02-03 15:19:25,065:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:25,428:INFO:Calculating mean and std
2023-02-03 15:19:25,429:INFO:Creating metrics dataframe
2023-02-03 15:19:25,433:INFO:Uploading results into container
2023-02-03 15:19:25,434:INFO:Uploading model into container now
2023-02-03 15:19:25,435:INFO:_master_model_container: 66
2023-02-03 15:19:25,435:INFO:_display_container: 6
2023-02-03 15:19:25,436:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-03 15:19:25,436:INFO:create_model() successfully completed......................................
2023-02-03 15:19:25,524:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:25,524:INFO:Creating metrics dataframe
2023-02-03 15:19:25,542:INFO:Initializing Decision Tree Regressor
2023-02-03 15:19:25,542:INFO:Total runtime is 0.07626235882441203 minutes
2023-02-03 15:19:25,548:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:25,548:INFO:Initializing create_model()
2023-02-03 15:19:25,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:25,549:INFO:Checking exceptions
2023-02-03 15:19:25,549:INFO:Importing libraries
2023-02-03 15:19:25,549:INFO:Copying training dataset
2023-02-03 15:19:25,554:INFO:Defining folds
2023-02-03 15:19:25,554:INFO:Declaring metric variables
2023-02-03 15:19:25,564:INFO:Importing untrained model
2023-02-03 15:19:25,569:INFO:Decision Tree Regressor Imported successfully
2023-02-03 15:19:25,582:INFO:Starting cross validation
2023-02-03 15:19:25,584:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:25,819:INFO:Calculating mean and std
2023-02-03 15:19:25,821:INFO:Creating metrics dataframe
2023-02-03 15:19:25,830:INFO:Uploading results into container
2023-02-03 15:19:25,831:INFO:Uploading model into container now
2023-02-03 15:19:25,832:INFO:_master_model_container: 67
2023-02-03 15:19:25,832:INFO:_display_container: 6
2023-02-03 15:19:25,832:INFO:DecisionTreeRegressor(random_state=123)
2023-02-03 15:19:25,832:INFO:create_model() successfully completed......................................
2023-02-03 15:19:25,915:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:25,915:INFO:Creating metrics dataframe
2023-02-03 15:19:25,932:INFO:Initializing Random Forest Regressor
2023-02-03 15:19:25,932:INFO:Total runtime is 0.08275857766469319 minutes
2023-02-03 15:19:25,939:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:25,939:INFO:Initializing create_model()
2023-02-03 15:19:25,939:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:25,940:INFO:Checking exceptions
2023-02-03 15:19:25,940:INFO:Importing libraries
2023-02-03 15:19:25,940:INFO:Copying training dataset
2023-02-03 15:19:25,945:INFO:Defining folds
2023-02-03 15:19:25,945:INFO:Declaring metric variables
2023-02-03 15:19:25,951:INFO:Importing untrained model
2023-02-03 15:19:25,957:INFO:Random Forest Regressor Imported successfully
2023-02-03 15:19:25,968:INFO:Starting cross validation
2023-02-03 15:19:25,969:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:27,868:INFO:Calculating mean and std
2023-02-03 15:19:27,869:INFO:Creating metrics dataframe
2023-02-03 15:19:27,873:INFO:Uploading results into container
2023-02-03 15:19:27,874:INFO:Uploading model into container now
2023-02-03 15:19:27,874:INFO:_master_model_container: 68
2023-02-03 15:19:27,874:INFO:_display_container: 6
2023-02-03 15:19:27,875:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:19:27,876:INFO:create_model() successfully completed......................................
2023-02-03 15:19:27,980:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:27,980:INFO:Creating metrics dataframe
2023-02-03 15:19:28,003:INFO:Initializing Extra Trees Regressor
2023-02-03 15:19:28,003:INFO:Total runtime is 0.11727210680643717 minutes
2023-02-03 15:19:28,013:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:28,013:INFO:Initializing create_model()
2023-02-03 15:19:28,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:28,014:INFO:Checking exceptions
2023-02-03 15:19:28,014:INFO:Importing libraries
2023-02-03 15:19:28,014:INFO:Copying training dataset
2023-02-03 15:19:28,022:INFO:Defining folds
2023-02-03 15:19:28,022:INFO:Declaring metric variables
2023-02-03 15:19:28,031:INFO:Importing untrained model
2023-02-03 15:19:28,041:INFO:Extra Trees Regressor Imported successfully
2023-02-03 15:19:28,066:INFO:Starting cross validation
2023-02-03 15:19:28,068:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:29,967:INFO:Calculating mean and std
2023-02-03 15:19:29,968:INFO:Creating metrics dataframe
2023-02-03 15:19:29,972:INFO:Uploading results into container
2023-02-03 15:19:29,973:INFO:Uploading model into container now
2023-02-03 15:19:29,973:INFO:_master_model_container: 69
2023-02-03 15:19:29,974:INFO:_display_container: 6
2023-02-03 15:19:29,974:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:19:29,975:INFO:create_model() successfully completed......................................
2023-02-03 15:19:30,060:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:30,061:INFO:Creating metrics dataframe
2023-02-03 15:19:30,077:INFO:Initializing AdaBoost Regressor
2023-02-03 15:19:30,077:INFO:Total runtime is 0.15183955430984497 minutes
2023-02-03 15:19:30,084:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:30,084:INFO:Initializing create_model()
2023-02-03 15:19:30,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:30,085:INFO:Checking exceptions
2023-02-03 15:19:30,085:INFO:Importing libraries
2023-02-03 15:19:30,085:INFO:Copying training dataset
2023-02-03 15:19:30,089:INFO:Defining folds
2023-02-03 15:19:30,089:INFO:Declaring metric variables
2023-02-03 15:19:30,095:INFO:Importing untrained model
2023-02-03 15:19:30,102:INFO:AdaBoost Regressor Imported successfully
2023-02-03 15:19:30,112:INFO:Starting cross validation
2023-02-03 15:19:30,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:30,786:INFO:Calculating mean and std
2023-02-03 15:19:30,788:INFO:Creating metrics dataframe
2023-02-03 15:19:30,792:INFO:Uploading results into container
2023-02-03 15:19:30,793:INFO:Uploading model into container now
2023-02-03 15:19:30,793:INFO:_master_model_container: 70
2023-02-03 15:19:30,794:INFO:_display_container: 6
2023-02-03 15:19:30,795:INFO:AdaBoostRegressor(random_state=123)
2023-02-03 15:19:30,796:INFO:create_model() successfully completed......................................
2023-02-03 15:19:30,887:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:30,888:INFO:Creating metrics dataframe
2023-02-03 15:19:30,905:INFO:Initializing Gradient Boosting Regressor
2023-02-03 15:19:30,906:INFO:Total runtime is 0.16566501458485922 minutes
2023-02-03 15:19:30,913:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:30,913:INFO:Initializing create_model()
2023-02-03 15:19:30,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:30,914:INFO:Checking exceptions
2023-02-03 15:19:30,914:INFO:Importing libraries
2023-02-03 15:19:30,914:INFO:Copying training dataset
2023-02-03 15:19:30,919:INFO:Defining folds
2023-02-03 15:19:30,919:INFO:Declaring metric variables
2023-02-03 15:19:30,926:INFO:Importing untrained model
2023-02-03 15:19:30,932:INFO:Gradient Boosting Regressor Imported successfully
2023-02-03 15:19:30,945:INFO:Starting cross validation
2023-02-03 15:19:30,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:31,714:INFO:Calculating mean and std
2023-02-03 15:19:31,717:INFO:Creating metrics dataframe
2023-02-03 15:19:31,722:INFO:Uploading results into container
2023-02-03 15:19:31,724:INFO:Uploading model into container now
2023-02-03 15:19:31,725:INFO:_master_model_container: 71
2023-02-03 15:19:31,726:INFO:_display_container: 6
2023-02-03 15:19:31,727:INFO:GradientBoostingRegressor(random_state=123)
2023-02-03 15:19:31,727:INFO:create_model() successfully completed......................................
2023-02-03 15:19:31,842:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:31,842:INFO:Creating metrics dataframe
2023-02-03 15:19:31,874:INFO:Initializing Light Gradient Boosting Machine
2023-02-03 15:19:31,874:INFO:Total runtime is 0.18178909619649253 minutes
2023-02-03 15:19:31,884:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:31,885:INFO:Initializing create_model()
2023-02-03 15:19:31,885:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:31,885:INFO:Checking exceptions
2023-02-03 15:19:31,885:INFO:Importing libraries
2023-02-03 15:19:31,885:INFO:Copying training dataset
2023-02-03 15:19:31,899:INFO:Defining folds
2023-02-03 15:19:31,899:INFO:Declaring metric variables
2023-02-03 15:19:31,910:INFO:Importing untrained model
2023-02-03 15:19:31,923:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-03 15:19:31,944:INFO:Starting cross validation
2023-02-03 15:19:31,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:39,600:INFO:Calculating mean and std
2023-02-03 15:19:39,605:INFO:Creating metrics dataframe
2023-02-03 15:19:39,612:INFO:Uploading results into container
2023-02-03 15:19:39,613:INFO:Uploading model into container now
2023-02-03 15:19:39,613:INFO:_master_model_container: 72
2023-02-03 15:19:39,613:INFO:_display_container: 6
2023-02-03 15:19:39,614:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-02-03 15:19:39,615:INFO:create_model() successfully completed......................................
2023-02-03 15:19:39,726:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:39,726:INFO:Creating metrics dataframe
2023-02-03 15:19:39,746:INFO:Initializing Dummy Regressor
2023-02-03 15:19:39,747:INFO:Total runtime is 0.3130154967308044 minutes
2023-02-03 15:19:39,752:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:39,752:INFO:Initializing create_model()
2023-02-03 15:19:39,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1F8B7F0>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:39,753:INFO:Checking exceptions
2023-02-03 15:19:39,753:INFO:Importing libraries
2023-02-03 15:19:39,754:INFO:Copying training dataset
2023-02-03 15:19:39,759:INFO:Defining folds
2023-02-03 15:19:39,760:INFO:Declaring metric variables
2023-02-03 15:19:39,766:INFO:Importing untrained model
2023-02-03 15:19:39,773:INFO:Dummy Regressor Imported successfully
2023-02-03 15:19:39,786:INFO:Starting cross validation
2023-02-03 15:19:39,787:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:40,024:INFO:Calculating mean and std
2023-02-03 15:19:40,025:INFO:Creating metrics dataframe
2023-02-03 15:19:40,029:INFO:Uploading results into container
2023-02-03 15:19:40,030:INFO:Uploading model into container now
2023-02-03 15:19:40,030:INFO:_master_model_container: 73
2023-02-03 15:19:40,031:INFO:_display_container: 6
2023-02-03 15:19:40,031:INFO:DummyRegressor()
2023-02-03 15:19:40,031:INFO:create_model() successfully completed......................................
2023-02-03 15:19:40,129:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:40,130:INFO:Creating metrics dataframe
2023-02-03 15:19:40,164:INFO:Initializing create_model()
2023-02-03 15:19:40,164:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:40,164:INFO:Checking exceptions
2023-02-03 15:19:40,167:INFO:Importing libraries
2023-02-03 15:19:40,167:INFO:Copying training dataset
2023-02-03 15:19:40,173:INFO:Defining folds
2023-02-03 15:19:40,173:INFO:Declaring metric variables
2023-02-03 15:19:40,174:INFO:Importing untrained model
2023-02-03 15:19:40,174:INFO:Declaring custom model
2023-02-03 15:19:40,174:INFO:Linear Regression Imported successfully
2023-02-03 15:19:40,175:INFO:Cross validation set to False
2023-02-03 15:19:40,175:INFO:Fitting Model
2023-02-03 15:19:40,187:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:19:40,187:INFO:create_model() successfully completed......................................
2023-02-03 15:19:40,362:INFO:_master_model_container: 73
2023-02-03 15:19:40,362:INFO:_display_container: 6
2023-02-03 15:19:40,363:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:19:40,363:INFO:compare_models() successfully completed......................................
2023-02-03 15:19:48,854:INFO:Initializing compare_models()
2023-02-03 15:19:48,855:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, include=None, fold=None, round=4, cross_validation=True, sort=r2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'r2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-03 15:19:48,855:INFO:Checking exceptions
2023-02-03 15:19:48,859:INFO:Preparing display monitor
2023-02-03 15:19:48,912:INFO:Initializing Linear Regression
2023-02-03 15:19:48,912:INFO:Total runtime is 0.0 minutes
2023-02-03 15:19:48,920:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:48,921:INFO:Initializing create_model()
2023-02-03 15:19:48,921:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:48,921:INFO:Checking exceptions
2023-02-03 15:19:48,922:INFO:Importing libraries
2023-02-03 15:19:48,922:INFO:Copying training dataset
2023-02-03 15:19:48,929:INFO:Defining folds
2023-02-03 15:19:48,930:INFO:Declaring metric variables
2023-02-03 15:19:48,939:INFO:Importing untrained model
2023-02-03 15:19:48,950:INFO:Linear Regression Imported successfully
2023-02-03 15:19:48,967:INFO:Starting cross validation
2023-02-03 15:19:48,969:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:49,359:INFO:Calculating mean and std
2023-02-03 15:19:49,359:INFO:Creating metrics dataframe
2023-02-03 15:19:49,364:INFO:Uploading results into container
2023-02-03 15:19:49,366:INFO:Uploading model into container now
2023-02-03 15:19:49,367:INFO:_master_model_container: 74
2023-02-03 15:19:49,367:INFO:_display_container: 7
2023-02-03 15:19:49,367:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:19:49,367:INFO:create_model() successfully completed......................................
2023-02-03 15:19:49,452:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:49,452:INFO:Creating metrics dataframe
2023-02-03 15:19:49,463:INFO:Initializing Lasso Regression
2023-02-03 15:19:49,463:INFO:Total runtime is 0.00917805035909017 minutes
2023-02-03 15:19:49,468:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:49,469:INFO:Initializing create_model()
2023-02-03 15:19:49,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:49,470:INFO:Checking exceptions
2023-02-03 15:19:49,470:INFO:Importing libraries
2023-02-03 15:19:49,470:INFO:Copying training dataset
2023-02-03 15:19:49,474:INFO:Defining folds
2023-02-03 15:19:49,474:INFO:Declaring metric variables
2023-02-03 15:19:49,479:INFO:Importing untrained model
2023-02-03 15:19:49,484:INFO:Lasso Regression Imported successfully
2023-02-03 15:19:49,495:INFO:Starting cross validation
2023-02-03 15:19:49,497:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:49,524:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.653e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,559:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.713e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,584:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.832e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,605:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,631:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.826e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,660:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,683:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,705:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,726:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,748:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.356e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:49,757:INFO:Calculating mean and std
2023-02-03 15:19:49,758:INFO:Creating metrics dataframe
2023-02-03 15:19:49,761:INFO:Uploading results into container
2023-02-03 15:19:49,762:INFO:Uploading model into container now
2023-02-03 15:19:49,763:INFO:_master_model_container: 75
2023-02-03 15:19:49,763:INFO:_display_container: 7
2023-02-03 15:19:49,763:INFO:Lasso(random_state=123)
2023-02-03 15:19:49,763:INFO:create_model() successfully completed......................................
2023-02-03 15:19:49,877:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:49,877:INFO:Creating metrics dataframe
2023-02-03 15:19:49,906:INFO:Initializing Ridge Regression
2023-02-03 15:19:49,907:INFO:Total runtime is 0.016573814551035564 minutes
2023-02-03 15:19:49,920:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:49,922:INFO:Initializing create_model()
2023-02-03 15:19:49,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:49,922:INFO:Checking exceptions
2023-02-03 15:19:49,922:INFO:Importing libraries
2023-02-03 15:19:49,922:INFO:Copying training dataset
2023-02-03 15:19:49,928:INFO:Defining folds
2023-02-03 15:19:49,928:INFO:Declaring metric variables
2023-02-03 15:19:49,941:INFO:Importing untrained model
2023-02-03 15:19:49,953:INFO:Ridge Regression Imported successfully
2023-02-03 15:19:49,988:INFO:Starting cross validation
2023-02-03 15:19:49,990:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:50,256:INFO:Calculating mean and std
2023-02-03 15:19:50,258:INFO:Creating metrics dataframe
2023-02-03 15:19:50,262:INFO:Uploading results into container
2023-02-03 15:19:50,263:INFO:Uploading model into container now
2023-02-03 15:19:50,265:INFO:_master_model_container: 76
2023-02-03 15:19:50,266:INFO:_display_container: 7
2023-02-03 15:19:50,267:INFO:Ridge(random_state=123)
2023-02-03 15:19:50,267:INFO:create_model() successfully completed......................................
2023-02-03 15:19:50,362:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:50,362:INFO:Creating metrics dataframe
2023-02-03 15:19:50,376:INFO:Initializing Elastic Net
2023-02-03 15:19:50,376:INFO:Total runtime is 0.02440266211827596 minutes
2023-02-03 15:19:50,384:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:50,384:INFO:Initializing create_model()
2023-02-03 15:19:50,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:50,385:INFO:Checking exceptions
2023-02-03 15:19:50,385:INFO:Importing libraries
2023-02-03 15:19:50,385:INFO:Copying training dataset
2023-02-03 15:19:50,390:INFO:Defining folds
2023-02-03 15:19:50,390:INFO:Declaring metric variables
2023-02-03 15:19:50,396:INFO:Importing untrained model
2023-02-03 15:19:50,403:INFO:Elastic Net Imported successfully
2023-02-03 15:19:50,417:INFO:Starting cross validation
2023-02-03 15:19:50,418:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:50,441:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,478:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.982e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,503:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,526:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,548:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.646e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,571:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.039e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,593:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.999e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,616:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,637:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.979e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,668:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:19:50,682:INFO:Calculating mean and std
2023-02-03 15:19:50,684:INFO:Creating metrics dataframe
2023-02-03 15:19:50,688:INFO:Uploading results into container
2023-02-03 15:19:50,689:INFO:Uploading model into container now
2023-02-03 15:19:50,690:INFO:_master_model_container: 77
2023-02-03 15:19:50,691:INFO:_display_container: 7
2023-02-03 15:19:50,691:INFO:ElasticNet(random_state=123)
2023-02-03 15:19:50,692:INFO:create_model() successfully completed......................................
2023-02-03 15:19:50,777:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:50,777:INFO:Creating metrics dataframe
2023-02-03 15:19:50,790:INFO:Initializing Least Angle Regression
2023-02-03 15:19:50,790:INFO:Total runtime is 0.03129870494206746 minutes
2023-02-03 15:19:50,794:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:50,795:INFO:Initializing create_model()
2023-02-03 15:19:50,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:50,795:INFO:Checking exceptions
2023-02-03 15:19:50,796:INFO:Importing libraries
2023-02-03 15:19:50,796:INFO:Copying training dataset
2023-02-03 15:19:50,801:INFO:Defining folds
2023-02-03 15:19:50,802:INFO:Declaring metric variables
2023-02-03 15:19:50,810:INFO:Importing untrained model
2023-02-03 15:19:50,822:INFO:Least Angle Regression Imported successfully
2023-02-03 15:19:50,833:INFO:Starting cross validation
2023-02-03 15:19:50,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:50,857:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:50,888:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:50,922:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:50,947:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:50,978:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,001:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,023:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,043:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,067:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,090:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,104:INFO:Calculating mean and std
2023-02-03 15:19:51,105:INFO:Creating metrics dataframe
2023-02-03 15:19:51,110:INFO:Uploading results into container
2023-02-03 15:19:51,110:INFO:Uploading model into container now
2023-02-03 15:19:51,111:INFO:_master_model_container: 78
2023-02-03 15:19:51,111:INFO:_display_container: 7
2023-02-03 15:19:51,112:INFO:Lars(random_state=123)
2023-02-03 15:19:51,112:INFO:create_model() successfully completed......................................
2023-02-03 15:19:51,196:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:51,196:INFO:Creating metrics dataframe
2023-02-03 15:19:51,211:INFO:Initializing Lasso Least Angle Regression
2023-02-03 15:19:51,211:INFO:Total runtime is 0.03831135829289754 minutes
2023-02-03 15:19:51,219:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:51,220:INFO:Initializing create_model()
2023-02-03 15:19:51,220:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:51,220:INFO:Checking exceptions
2023-02-03 15:19:51,220:INFO:Importing libraries
2023-02-03 15:19:51,220:INFO:Copying training dataset
2023-02-03 15:19:51,226:INFO:Defining folds
2023-02-03 15:19:51,226:INFO:Declaring metric variables
2023-02-03 15:19:51,235:INFO:Importing untrained model
2023-02-03 15:19:51,244:INFO:Lasso Least Angle Regression Imported successfully
2023-02-03 15:19:51,263:INFO:Starting cross validation
2023-02-03 15:19:51,264:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:51,289:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,320:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,345:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,371:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,407:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,429:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,455:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,478:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,502:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,526:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:19:51,538:INFO:Calculating mean and std
2023-02-03 15:19:51,539:INFO:Creating metrics dataframe
2023-02-03 15:19:51,545:INFO:Uploading results into container
2023-02-03 15:19:51,546:INFO:Uploading model into container now
2023-02-03 15:19:51,547:INFO:_master_model_container: 79
2023-02-03 15:19:51,547:INFO:_display_container: 7
2023-02-03 15:19:51,547:INFO:LassoLars(random_state=123)
2023-02-03 15:19:51,547:INFO:create_model() successfully completed......................................
2023-02-03 15:19:51,644:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:51,645:INFO:Creating metrics dataframe
2023-02-03 15:19:51,660:INFO:Initializing Orthogonal Matching Pursuit
2023-02-03 15:19:51,660:INFO:Total runtime is 0.045790394147237144 minutes
2023-02-03 15:19:51,665:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:51,665:INFO:Initializing create_model()
2023-02-03 15:19:51,666:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:51,666:INFO:Checking exceptions
2023-02-03 15:19:51,666:INFO:Importing libraries
2023-02-03 15:19:51,667:INFO:Copying training dataset
2023-02-03 15:19:51,673:INFO:Defining folds
2023-02-03 15:19:51,673:INFO:Declaring metric variables
2023-02-03 15:19:51,682:INFO:Importing untrained model
2023-02-03 15:19:51,690:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-03 15:19:51,709:INFO:Starting cross validation
2023-02-03 15:19:51,710:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:51,730:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,764:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,791:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,818:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,842:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,869:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,896:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,922:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,951:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,975:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:19:51,987:INFO:Calculating mean and std
2023-02-03 15:19:51,989:INFO:Creating metrics dataframe
2023-02-03 15:19:51,993:INFO:Uploading results into container
2023-02-03 15:19:51,994:INFO:Uploading model into container now
2023-02-03 15:19:51,994:INFO:_master_model_container: 80
2023-02-03 15:19:51,994:INFO:_display_container: 7
2023-02-03 15:19:51,995:INFO:OrthogonalMatchingPursuit()
2023-02-03 15:19:51,995:INFO:create_model() successfully completed......................................
2023-02-03 15:19:52,097:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:52,097:INFO:Creating metrics dataframe
2023-02-03 15:19:52,114:INFO:Initializing Bayesian Ridge
2023-02-03 15:19:52,114:INFO:Total runtime is 0.05336937904357911 minutes
2023-02-03 15:19:52,123:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:52,124:INFO:Initializing create_model()
2023-02-03 15:19:52,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:52,124:INFO:Checking exceptions
2023-02-03 15:19:52,125:INFO:Importing libraries
2023-02-03 15:19:52,125:INFO:Copying training dataset
2023-02-03 15:19:52,129:INFO:Defining folds
2023-02-03 15:19:52,130:INFO:Declaring metric variables
2023-02-03 15:19:52,137:INFO:Importing untrained model
2023-02-03 15:19:52,142:INFO:Bayesian Ridge Imported successfully
2023-02-03 15:19:52,158:INFO:Starting cross validation
2023-02-03 15:19:52,160:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:52,409:INFO:Calculating mean and std
2023-02-03 15:19:52,410:INFO:Creating metrics dataframe
2023-02-03 15:19:52,414:INFO:Uploading results into container
2023-02-03 15:19:52,415:INFO:Uploading model into container now
2023-02-03 15:19:52,415:INFO:_master_model_container: 81
2023-02-03 15:19:52,416:INFO:_display_container: 7
2023-02-03 15:19:52,417:INFO:BayesianRidge()
2023-02-03 15:19:52,417:INFO:create_model() successfully completed......................................
2023-02-03 15:19:52,508:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:52,508:INFO:Creating metrics dataframe
2023-02-03 15:19:52,527:INFO:Initializing Passive Aggressive Regressor
2023-02-03 15:19:52,527:INFO:Total runtime is 0.06024888753890992 minutes
2023-02-03 15:19:52,534:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:52,535:INFO:Initializing create_model()
2023-02-03 15:19:52,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:52,536:INFO:Checking exceptions
2023-02-03 15:19:52,536:INFO:Importing libraries
2023-02-03 15:19:52,536:INFO:Copying training dataset
2023-02-03 15:19:52,543:INFO:Defining folds
2023-02-03 15:19:52,543:INFO:Declaring metric variables
2023-02-03 15:19:52,554:INFO:Importing untrained model
2023-02-03 15:19:52,560:INFO:Passive Aggressive Regressor Imported successfully
2023-02-03 15:19:52,575:INFO:Starting cross validation
2023-02-03 15:19:52,576:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:52,910:INFO:Calculating mean and std
2023-02-03 15:19:52,912:INFO:Creating metrics dataframe
2023-02-03 15:19:52,916:INFO:Uploading results into container
2023-02-03 15:19:52,917:INFO:Uploading model into container now
2023-02-03 15:19:52,919:INFO:_master_model_container: 82
2023-02-03 15:19:52,919:INFO:_display_container: 7
2023-02-03 15:19:52,920:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-03 15:19:52,921:INFO:create_model() successfully completed......................................
2023-02-03 15:19:53,027:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:53,027:INFO:Creating metrics dataframe
2023-02-03 15:19:53,048:INFO:Initializing Huber Regressor
2023-02-03 15:19:53,048:INFO:Total runtime is 0.0689271132151286 minutes
2023-02-03 15:19:53,057:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:53,057:INFO:Initializing create_model()
2023-02-03 15:19:53,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:53,057:INFO:Checking exceptions
2023-02-03 15:19:53,057:INFO:Importing libraries
2023-02-03 15:19:53,057:INFO:Copying training dataset
2023-02-03 15:19:53,062:INFO:Defining folds
2023-02-03 15:19:53,062:INFO:Declaring metric variables
2023-02-03 15:19:53,070:INFO:Importing untrained model
2023-02-03 15:19:53,075:INFO:Huber Regressor Imported successfully
2023-02-03 15:19:53,092:INFO:Starting cross validation
2023-02-03 15:19:53,094:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:53,444:INFO:Calculating mean and std
2023-02-03 15:19:53,445:INFO:Creating metrics dataframe
2023-02-03 15:19:53,449:INFO:Uploading results into container
2023-02-03 15:19:53,450:INFO:Uploading model into container now
2023-02-03 15:19:53,450:INFO:_master_model_container: 83
2023-02-03 15:19:53,450:INFO:_display_container: 7
2023-02-03 15:19:53,454:INFO:HuberRegressor()
2023-02-03 15:19:53,455:INFO:create_model() successfully completed......................................
2023-02-03 15:19:53,566:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:53,566:INFO:Creating metrics dataframe
2023-02-03 15:19:53,588:INFO:Initializing K Neighbors Regressor
2023-02-03 15:19:53,588:INFO:Total runtime is 0.07793862422307334 minutes
2023-02-03 15:19:53,593:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:53,594:INFO:Initializing create_model()
2023-02-03 15:19:53,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:53,594:INFO:Checking exceptions
2023-02-03 15:19:53,594:INFO:Importing libraries
2023-02-03 15:19:53,595:INFO:Copying training dataset
2023-02-03 15:19:53,598:INFO:Defining folds
2023-02-03 15:19:53,598:INFO:Declaring metric variables
2023-02-03 15:19:53,607:INFO:Importing untrained model
2023-02-03 15:19:53,613:INFO:K Neighbors Regressor Imported successfully
2023-02-03 15:19:53,630:INFO:Starting cross validation
2023-02-03 15:19:53,632:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:54,042:INFO:Calculating mean and std
2023-02-03 15:19:54,044:INFO:Creating metrics dataframe
2023-02-03 15:19:54,048:INFO:Uploading results into container
2023-02-03 15:19:54,049:INFO:Uploading model into container now
2023-02-03 15:19:54,050:INFO:_master_model_container: 84
2023-02-03 15:19:54,050:INFO:_display_container: 7
2023-02-03 15:19:54,050:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-03 15:19:54,050:INFO:create_model() successfully completed......................................
2023-02-03 15:19:54,146:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:54,146:INFO:Creating metrics dataframe
2023-02-03 15:19:54,165:INFO:Initializing Decision Tree Regressor
2023-02-03 15:19:54,165:INFO:Total runtime is 0.08754975398381552 minutes
2023-02-03 15:19:54,175:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:54,175:INFO:Initializing create_model()
2023-02-03 15:19:54,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:54,176:INFO:Checking exceptions
2023-02-03 15:19:54,176:INFO:Importing libraries
2023-02-03 15:19:54,176:INFO:Copying training dataset
2023-02-03 15:19:54,180:INFO:Defining folds
2023-02-03 15:19:54,180:INFO:Declaring metric variables
2023-02-03 15:19:54,190:INFO:Importing untrained model
2023-02-03 15:19:54,198:INFO:Decision Tree Regressor Imported successfully
2023-02-03 15:19:54,213:INFO:Starting cross validation
2023-02-03 15:19:54,214:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:54,458:INFO:Calculating mean and std
2023-02-03 15:19:54,460:INFO:Creating metrics dataframe
2023-02-03 15:19:54,464:INFO:Uploading results into container
2023-02-03 15:19:54,465:INFO:Uploading model into container now
2023-02-03 15:19:54,466:INFO:_master_model_container: 85
2023-02-03 15:19:54,466:INFO:_display_container: 7
2023-02-03 15:19:54,467:INFO:DecisionTreeRegressor(random_state=123)
2023-02-03 15:19:54,467:INFO:create_model() successfully completed......................................
2023-02-03 15:19:54,548:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:54,548:INFO:Creating metrics dataframe
2023-02-03 15:19:54,567:INFO:Initializing Random Forest Regressor
2023-02-03 15:19:54,567:INFO:Total runtime is 0.09424591461817425 minutes
2023-02-03 15:19:54,573:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:54,574:INFO:Initializing create_model()
2023-02-03 15:19:54,574:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:54,574:INFO:Checking exceptions
2023-02-03 15:19:54,575:INFO:Importing libraries
2023-02-03 15:19:54,575:INFO:Copying training dataset
2023-02-03 15:19:54,578:INFO:Defining folds
2023-02-03 15:19:54,579:INFO:Declaring metric variables
2023-02-03 15:19:54,586:INFO:Importing untrained model
2023-02-03 15:19:54,591:INFO:Random Forest Regressor Imported successfully
2023-02-03 15:19:54,608:INFO:Starting cross validation
2023-02-03 15:19:54,610:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:56,918:INFO:Calculating mean and std
2023-02-03 15:19:56,920:INFO:Creating metrics dataframe
2023-02-03 15:19:56,927:INFO:Uploading results into container
2023-02-03 15:19:56,928:INFO:Uploading model into container now
2023-02-03 15:19:56,929:INFO:_master_model_container: 86
2023-02-03 15:19:56,929:INFO:_display_container: 7
2023-02-03 15:19:56,929:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:19:56,930:INFO:create_model() successfully completed......................................
2023-02-03 15:19:57,024:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:57,024:INFO:Creating metrics dataframe
2023-02-03 15:19:57,043:INFO:Initializing Extra Trees Regressor
2023-02-03 15:19:57,043:INFO:Total runtime is 0.13552223443984987 minutes
2023-02-03 15:19:57,048:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:57,048:INFO:Initializing create_model()
2023-02-03 15:19:57,049:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:57,049:INFO:Checking exceptions
2023-02-03 15:19:57,049:INFO:Importing libraries
2023-02-03 15:19:57,049:INFO:Copying training dataset
2023-02-03 15:19:57,053:INFO:Defining folds
2023-02-03 15:19:57,053:INFO:Declaring metric variables
2023-02-03 15:19:57,062:INFO:Importing untrained model
2023-02-03 15:19:57,067:INFO:Extra Trees Regressor Imported successfully
2023-02-03 15:19:57,081:INFO:Starting cross validation
2023-02-03 15:19:57,082:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:59,041:INFO:Calculating mean and std
2023-02-03 15:19:59,043:INFO:Creating metrics dataframe
2023-02-03 15:19:59,046:INFO:Uploading results into container
2023-02-03 15:19:59,047:INFO:Uploading model into container now
2023-02-03 15:19:59,047:INFO:_master_model_container: 87
2023-02-03 15:19:59,048:INFO:_display_container: 7
2023-02-03 15:19:59,048:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:19:59,048:INFO:create_model() successfully completed......................................
2023-02-03 15:19:59,132:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:59,132:INFO:Creating metrics dataframe
2023-02-03 15:19:59,150:INFO:Initializing AdaBoost Regressor
2023-02-03 15:19:59,150:INFO:Total runtime is 0.1706383268038432 minutes
2023-02-03 15:19:59,155:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:59,155:INFO:Initializing create_model()
2023-02-03 15:19:59,156:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:59,156:INFO:Checking exceptions
2023-02-03 15:19:59,157:INFO:Importing libraries
2023-02-03 15:19:59,157:INFO:Copying training dataset
2023-02-03 15:19:59,161:INFO:Defining folds
2023-02-03 15:19:59,161:INFO:Declaring metric variables
2023-02-03 15:19:59,166:INFO:Importing untrained model
2023-02-03 15:19:59,171:INFO:AdaBoost Regressor Imported successfully
2023-02-03 15:19:59,184:INFO:Starting cross validation
2023-02-03 15:19:59,185:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:19:59,852:INFO:Calculating mean and std
2023-02-03 15:19:59,853:INFO:Creating metrics dataframe
2023-02-03 15:19:59,860:INFO:Uploading results into container
2023-02-03 15:19:59,860:INFO:Uploading model into container now
2023-02-03 15:19:59,861:INFO:_master_model_container: 88
2023-02-03 15:19:59,862:INFO:_display_container: 7
2023-02-03 15:19:59,862:INFO:AdaBoostRegressor(random_state=123)
2023-02-03 15:19:59,862:INFO:create_model() successfully completed......................................
2023-02-03 15:19:59,955:INFO:SubProcess create_model() end ==================================
2023-02-03 15:19:59,955:INFO:Creating metrics dataframe
2023-02-03 15:19:59,972:INFO:Initializing Gradient Boosting Regressor
2023-02-03 15:19:59,973:INFO:Total runtime is 0.18434717257817587 minutes
2023-02-03 15:19:59,981:INFO:SubProcess create_model() called ==================================
2023-02-03 15:19:59,982:INFO:Initializing create_model()
2023-02-03 15:19:59,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:19:59,983:INFO:Checking exceptions
2023-02-03 15:19:59,983:INFO:Importing libraries
2023-02-03 15:19:59,983:INFO:Copying training dataset
2023-02-03 15:19:59,987:INFO:Defining folds
2023-02-03 15:19:59,987:INFO:Declaring metric variables
2023-02-03 15:19:59,994:INFO:Importing untrained model
2023-02-03 15:19:59,999:INFO:Gradient Boosting Regressor Imported successfully
2023-02-03 15:20:00,011:INFO:Starting cross validation
2023-02-03 15:20:00,014:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:20:00,806:INFO:Calculating mean and std
2023-02-03 15:20:00,810:INFO:Creating metrics dataframe
2023-02-03 15:20:00,816:INFO:Uploading results into container
2023-02-03 15:20:00,817:INFO:Uploading model into container now
2023-02-03 15:20:00,817:INFO:_master_model_container: 89
2023-02-03 15:20:00,817:INFO:_display_container: 7
2023-02-03 15:20:00,818:INFO:GradientBoostingRegressor(random_state=123)
2023-02-03 15:20:00,818:INFO:create_model() successfully completed......................................
2023-02-03 15:20:00,919:INFO:SubProcess create_model() end ==================================
2023-02-03 15:20:00,919:INFO:Creating metrics dataframe
2023-02-03 15:20:00,941:INFO:Initializing Light Gradient Boosting Machine
2023-02-03 15:20:00,942:INFO:Total runtime is 0.20050466060638428 minutes
2023-02-03 15:20:00,949:INFO:SubProcess create_model() called ==================================
2023-02-03 15:20:00,950:INFO:Initializing create_model()
2023-02-03 15:20:00,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:20:00,951:INFO:Checking exceptions
2023-02-03 15:20:00,951:INFO:Importing libraries
2023-02-03 15:20:00,951:INFO:Copying training dataset
2023-02-03 15:20:00,955:INFO:Defining folds
2023-02-03 15:20:00,955:INFO:Declaring metric variables
2023-02-03 15:20:00,965:INFO:Importing untrained model
2023-02-03 15:20:00,971:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-03 15:20:00,987:INFO:Starting cross validation
2023-02-03 15:20:00,988:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:20:08,856:INFO:Calculating mean and std
2023-02-03 15:20:08,857:INFO:Creating metrics dataframe
2023-02-03 15:20:08,868:INFO:Uploading results into container
2023-02-03 15:20:08,870:INFO:Uploading model into container now
2023-02-03 15:20:08,871:INFO:_master_model_container: 90
2023-02-03 15:20:08,871:INFO:_display_container: 7
2023-02-03 15:20:08,872:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-02-03 15:20:08,872:INFO:create_model() successfully completed......................................
2023-02-03 15:20:09,012:INFO:SubProcess create_model() end ==================================
2023-02-03 15:20:09,012:INFO:Creating metrics dataframe
2023-02-03 15:20:09,035:INFO:Initializing Dummy Regressor
2023-02-03 15:20:09,036:INFO:Total runtime is 0.33540481328964233 minutes
2023-02-03 15:20:09,041:INFO:SubProcess create_model() called ==================================
2023-02-03 15:20:09,041:INFO:Initializing create_model()
2023-02-03 15:20:09,041:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1618E50>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:20:09,041:INFO:Checking exceptions
2023-02-03 15:20:09,042:INFO:Importing libraries
2023-02-03 15:20:09,042:INFO:Copying training dataset
2023-02-03 15:20:09,047:INFO:Defining folds
2023-02-03 15:20:09,047:INFO:Declaring metric variables
2023-02-03 15:20:09,055:INFO:Importing untrained model
2023-02-03 15:20:09,061:INFO:Dummy Regressor Imported successfully
2023-02-03 15:20:09,075:INFO:Starting cross validation
2023-02-03 15:20:09,076:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:20:09,329:INFO:Calculating mean and std
2023-02-03 15:20:09,330:INFO:Creating metrics dataframe
2023-02-03 15:20:09,338:INFO:Uploading results into container
2023-02-03 15:20:09,339:INFO:Uploading model into container now
2023-02-03 15:20:09,340:INFO:_master_model_container: 91
2023-02-03 15:20:09,340:INFO:_display_container: 7
2023-02-03 15:20:09,340:INFO:DummyRegressor()
2023-02-03 15:20:09,341:INFO:create_model() successfully completed......................................
2023-02-03 15:20:09,430:INFO:SubProcess create_model() end ==================================
2023-02-03 15:20:09,430:INFO:Creating metrics dataframe
2023-02-03 15:20:09,464:INFO:Initializing create_model()
2023-02-03 15:20:09,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:20:09,465:INFO:Checking exceptions
2023-02-03 15:20:09,470:INFO:Importing libraries
2023-02-03 15:20:09,471:INFO:Copying training dataset
2023-02-03 15:20:09,474:INFO:Defining folds
2023-02-03 15:20:09,474:INFO:Declaring metric variables
2023-02-03 15:20:09,474:INFO:Importing untrained model
2023-02-03 15:20:09,474:INFO:Declaring custom model
2023-02-03 15:20:09,475:INFO:Linear Regression Imported successfully
2023-02-03 15:20:09,475:INFO:Cross validation set to False
2023-02-03 15:20:09,475:INFO:Fitting Model
2023-02-03 15:20:09,491:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:20:09,491:INFO:create_model() successfully completed......................................
2023-02-03 15:20:09,656:INFO:_master_model_container: 91
2023-02-03 15:20:09,656:INFO:_display_container: 7
2023-02-03 15:20:09,656:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:20:09,656:INFO:compare_models() successfully completed......................................
2023-02-03 15:20:26,315:INFO:Initializing create_model()
2023-02-03 15:20:26,316:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:20:26,316:INFO:Checking exceptions
2023-02-03 15:20:26,347:INFO:Importing libraries
2023-02-03 15:20:26,348:INFO:Copying training dataset
2023-02-03 15:20:26,357:INFO:Defining folds
2023-02-03 15:20:26,358:INFO:Declaring metric variables
2023-02-03 15:20:26,365:INFO:Importing untrained model
2023-02-03 15:20:26,365:INFO:Declaring custom model
2023-02-03 15:20:26,374:INFO:Linear Regression Imported successfully
2023-02-03 15:20:26,388:INFO:Starting cross validation
2023-02-03 15:20:26,390:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:20:26,678:INFO:Calculating mean and std
2023-02-03 15:20:26,679:INFO:Creating metrics dataframe
2023-02-03 15:20:26,685:INFO:Finalizing model
2023-02-03 15:20:26,709:INFO:Uploading results into container
2023-02-03 15:20:26,710:INFO:Uploading model into container now
2023-02-03 15:20:26,726:INFO:_master_model_container: 92
2023-02-03 15:20:26,726:INFO:_display_container: 8
2023-02-03 15:20:26,726:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:20:26,727:INFO:create_model() successfully completed......................................
2023-02-03 15:22:19,811:INFO:Initializing create_model()
2023-02-03 15:22:19,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:19,811:INFO:Checking exceptions
2023-02-03 15:22:19,849:INFO:Importing libraries
2023-02-03 15:22:19,850:INFO:Copying training dataset
2023-02-03 15:22:19,862:INFO:Defining folds
2023-02-03 15:22:19,863:INFO:Declaring metric variables
2023-02-03 15:22:19,871:INFO:Importing untrained model
2023-02-03 15:22:19,881:INFO:Huber Regressor Imported successfully
2023-02-03 15:22:19,898:INFO:Starting cross validation
2023-02-03 15:22:19,899:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:20,335:INFO:Calculating mean and std
2023-02-03 15:22:20,335:INFO:Creating metrics dataframe
2023-02-03 15:22:20,344:INFO:Finalizing model
2023-02-03 15:22:20,370:INFO:Uploading results into container
2023-02-03 15:22:20,372:INFO:Uploading model into container now
2023-02-03 15:22:20,390:INFO:_master_model_container: 93
2023-02-03 15:22:20,390:INFO:_display_container: 9
2023-02-03 15:22:20,391:INFO:HuberRegressor()
2023-02-03 15:22:20,391:INFO:create_model() successfully completed......................................
2023-02-03 15:22:38,501:INFO:Initializing compare_models()
2023-02-03 15:22:38,502:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-03 15:22:38,502:INFO:Checking exceptions
2023-02-03 15:22:38,506:INFO:Preparing display monitor
2023-02-03 15:22:38,560:INFO:Initializing Linear Regression
2023-02-03 15:22:38,560:INFO:Total runtime is 0.0 minutes
2023-02-03 15:22:38,569:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:38,570:INFO:Initializing create_model()
2023-02-03 15:22:38,571:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:38,571:INFO:Checking exceptions
2023-02-03 15:22:38,572:INFO:Importing libraries
2023-02-03 15:22:38,572:INFO:Copying training dataset
2023-02-03 15:22:38,579:INFO:Defining folds
2023-02-03 15:22:38,579:INFO:Declaring metric variables
2023-02-03 15:22:38,588:INFO:Importing untrained model
2023-02-03 15:22:38,597:INFO:Linear Regression Imported successfully
2023-02-03 15:22:38,613:INFO:Starting cross validation
2023-02-03 15:22:38,615:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:39,011:INFO:Calculating mean and std
2023-02-03 15:22:39,012:INFO:Creating metrics dataframe
2023-02-03 15:22:39,017:INFO:Uploading results into container
2023-02-03 15:22:39,018:INFO:Uploading model into container now
2023-02-03 15:22:39,019:INFO:_master_model_container: 94
2023-02-03 15:22:39,019:INFO:_display_container: 10
2023-02-03 15:22:39,019:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:22:39,019:INFO:create_model() successfully completed......................................
2023-02-03 15:22:39,135:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:39,135:INFO:Creating metrics dataframe
2023-02-03 15:22:39,154:INFO:Initializing Lasso Regression
2023-02-03 15:22:39,154:INFO:Total runtime is 0.009894271691640219 minutes
2023-02-03 15:22:39,161:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:39,162:INFO:Initializing create_model()
2023-02-03 15:22:39,162:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:39,162:INFO:Checking exceptions
2023-02-03 15:22:39,162:INFO:Importing libraries
2023-02-03 15:22:39,163:INFO:Copying training dataset
2023-02-03 15:22:39,169:INFO:Defining folds
2023-02-03 15:22:39,169:INFO:Declaring metric variables
2023-02-03 15:22:39,174:INFO:Importing untrained model
2023-02-03 15:22:39,180:INFO:Lasso Regression Imported successfully
2023-02-03 15:22:39,193:INFO:Starting cross validation
2023-02-03 15:22:39,195:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:39,219:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.653e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,260:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.713e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,285:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.832e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,307:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,330:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.826e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,360:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,386:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,421:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,454:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,487:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.356e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:39,499:INFO:Calculating mean and std
2023-02-03 15:22:39,499:INFO:Creating metrics dataframe
2023-02-03 15:22:39,505:INFO:Uploading results into container
2023-02-03 15:22:39,506:INFO:Uploading model into container now
2023-02-03 15:22:39,506:INFO:_master_model_container: 95
2023-02-03 15:22:39,506:INFO:_display_container: 10
2023-02-03 15:22:39,507:INFO:Lasso(random_state=123)
2023-02-03 15:22:39,507:INFO:create_model() successfully completed......................................
2023-02-03 15:22:39,620:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:39,620:INFO:Creating metrics dataframe
2023-02-03 15:22:39,636:INFO:Initializing Ridge Regression
2023-02-03 15:22:39,636:INFO:Total runtime is 0.017922989527384442 minutes
2023-02-03 15:22:39,642:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:39,642:INFO:Initializing create_model()
2023-02-03 15:22:39,643:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:39,643:INFO:Checking exceptions
2023-02-03 15:22:39,643:INFO:Importing libraries
2023-02-03 15:22:39,643:INFO:Copying training dataset
2023-02-03 15:22:39,648:INFO:Defining folds
2023-02-03 15:22:39,648:INFO:Declaring metric variables
2023-02-03 15:22:39,657:INFO:Importing untrained model
2023-02-03 15:22:39,665:INFO:Ridge Regression Imported successfully
2023-02-03 15:22:39,682:INFO:Starting cross validation
2023-02-03 15:22:39,685:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:39,959:INFO:Calculating mean and std
2023-02-03 15:22:39,961:INFO:Creating metrics dataframe
2023-02-03 15:22:39,966:INFO:Uploading results into container
2023-02-03 15:22:39,967:INFO:Uploading model into container now
2023-02-03 15:22:39,969:INFO:_master_model_container: 96
2023-02-03 15:22:39,969:INFO:_display_container: 10
2023-02-03 15:22:39,970:INFO:Ridge(random_state=123)
2023-02-03 15:22:39,970:INFO:create_model() successfully completed......................................
2023-02-03 15:22:40,067:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:40,068:INFO:Creating metrics dataframe
2023-02-03 15:22:40,088:INFO:Initializing Elastic Net
2023-02-03 15:22:40,088:INFO:Total runtime is 0.025468671321868898 minutes
2023-02-03 15:22:40,094:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:40,094:INFO:Initializing create_model()
2023-02-03 15:22:40,094:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:40,095:INFO:Checking exceptions
2023-02-03 15:22:40,095:INFO:Importing libraries
2023-02-03 15:22:40,095:INFO:Copying training dataset
2023-02-03 15:22:40,101:INFO:Defining folds
2023-02-03 15:22:40,102:INFO:Declaring metric variables
2023-02-03 15:22:40,109:INFO:Importing untrained model
2023-02-03 15:22:40,117:INFO:Elastic Net Imported successfully
2023-02-03 15:22:40,133:INFO:Starting cross validation
2023-02-03 15:22:40,135:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:40,163:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+08, tolerance: 1.937e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,194:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.982e+08, tolerance: 1.916e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,221:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+08, tolerance: 1.902e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,247:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e+08, tolerance: 1.967e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,280:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.646e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,307:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.039e+08, tolerance: 1.944e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,339:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.999e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,373:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.416e+08, tolerance: 1.931e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,406:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.979e+08, tolerance: 1.924e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,442:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e+08, tolerance: 1.958e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-03 15:22:40,454:INFO:Calculating mean and std
2023-02-03 15:22:40,456:INFO:Creating metrics dataframe
2023-02-03 15:22:40,461:INFO:Uploading results into container
2023-02-03 15:22:40,462:INFO:Uploading model into container now
2023-02-03 15:22:40,463:INFO:_master_model_container: 97
2023-02-03 15:22:40,463:INFO:_display_container: 10
2023-02-03 15:22:40,464:INFO:ElasticNet(random_state=123)
2023-02-03 15:22:40,464:INFO:create_model() successfully completed......................................
2023-02-03 15:22:40,567:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:40,567:INFO:Creating metrics dataframe
2023-02-03 15:22:40,583:INFO:Initializing Least Angle Regression
2023-02-03 15:22:40,584:INFO:Total runtime is 0.03373061815897624 minutes
2023-02-03 15:22:40,593:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:40,594:INFO:Initializing create_model()
2023-02-03 15:22:40,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:40,594:INFO:Checking exceptions
2023-02-03 15:22:40,594:INFO:Importing libraries
2023-02-03 15:22:40,594:INFO:Copying training dataset
2023-02-03 15:22:40,599:INFO:Defining folds
2023-02-03 15:22:40,599:INFO:Declaring metric variables
2023-02-03 15:22:40,606:INFO:Importing untrained model
2023-02-03 15:22:40,613:INFO:Least Angle Regression Imported successfully
2023-02-03 15:22:40,628:INFO:Starting cross validation
2023-02-03 15:22:40,630:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:40,652:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,690:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,721:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,747:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,781:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,808:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,833:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,857:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,881:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,903:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:40,914:INFO:Calculating mean and std
2023-02-03 15:22:40,915:INFO:Creating metrics dataframe
2023-02-03 15:22:40,923:INFO:Uploading results into container
2023-02-03 15:22:40,924:INFO:Uploading model into container now
2023-02-03 15:22:40,925:INFO:_master_model_container: 98
2023-02-03 15:22:40,925:INFO:_display_container: 10
2023-02-03 15:22:40,926:INFO:Lars(random_state=123)
2023-02-03 15:22:40,926:INFO:create_model() successfully completed......................................
2023-02-03 15:22:41,033:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:41,034:INFO:Creating metrics dataframe
2023-02-03 15:22:41,054:INFO:Initializing Lasso Least Angle Regression
2023-02-03 15:22:41,054:INFO:Total runtime is 0.04155953327814738 minutes
2023-02-03 15:22:41,059:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:41,060:INFO:Initializing create_model()
2023-02-03 15:22:41,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:41,060:INFO:Checking exceptions
2023-02-03 15:22:41,061:INFO:Importing libraries
2023-02-03 15:22:41,061:INFO:Copying training dataset
2023-02-03 15:22:41,065:INFO:Defining folds
2023-02-03 15:22:41,065:INFO:Declaring metric variables
2023-02-03 15:22:41,073:INFO:Importing untrained model
2023-02-03 15:22:41,082:INFO:Lasso Least Angle Regression Imported successfully
2023-02-03 15:22:41,095:INFO:Starting cross validation
2023-02-03 15:22:41,096:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:41,120:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,157:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,182:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,210:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,234:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,265:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,293:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,317:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,347:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,374:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-03 15:22:41,383:INFO:Calculating mean and std
2023-02-03 15:22:41,385:INFO:Creating metrics dataframe
2023-02-03 15:22:41,392:INFO:Uploading results into container
2023-02-03 15:22:41,393:INFO:Uploading model into container now
2023-02-03 15:22:41,393:INFO:_master_model_container: 99
2023-02-03 15:22:41,393:INFO:_display_container: 10
2023-02-03 15:22:41,394:INFO:LassoLars(random_state=123)
2023-02-03 15:22:41,394:INFO:create_model() successfully completed......................................
2023-02-03 15:22:41,506:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:41,506:INFO:Creating metrics dataframe
2023-02-03 15:22:41,522:INFO:Initializing Orthogonal Matching Pursuit
2023-02-03 15:22:41,522:INFO:Total runtime is 0.049355045954386396 minutes
2023-02-03 15:22:41,528:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:41,529:INFO:Initializing create_model()
2023-02-03 15:22:41,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:41,529:INFO:Checking exceptions
2023-02-03 15:22:41,529:INFO:Importing libraries
2023-02-03 15:22:41,529:INFO:Copying training dataset
2023-02-03 15:22:41,534:INFO:Defining folds
2023-02-03 15:22:41,535:INFO:Declaring metric variables
2023-02-03 15:22:41,545:INFO:Importing untrained model
2023-02-03 15:22:41,550:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-03 15:22:41,567:INFO:Starting cross validation
2023-02-03 15:22:41,569:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:41,594:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,626:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,650:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,676:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,701:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,726:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,757:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,781:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,805:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,828:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-03 15:22:41,840:INFO:Calculating mean and std
2023-02-03 15:22:41,842:INFO:Creating metrics dataframe
2023-02-03 15:22:41,848:INFO:Uploading results into container
2023-02-03 15:22:41,849:INFO:Uploading model into container now
2023-02-03 15:22:41,849:INFO:_master_model_container: 100
2023-02-03 15:22:41,850:INFO:_display_container: 10
2023-02-03 15:22:41,850:INFO:OrthogonalMatchingPursuit()
2023-02-03 15:22:41,851:INFO:create_model() successfully completed......................................
2023-02-03 15:22:41,956:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:41,956:INFO:Creating metrics dataframe
2023-02-03 15:22:41,979:INFO:Initializing Bayesian Ridge
2023-02-03 15:22:41,979:INFO:Total runtime is 0.056983943780263266 minutes
2023-02-03 15:22:41,984:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:41,985:INFO:Initializing create_model()
2023-02-03 15:22:41,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:41,987:INFO:Checking exceptions
2023-02-03 15:22:41,988:INFO:Importing libraries
2023-02-03 15:22:41,988:INFO:Copying training dataset
2023-02-03 15:22:41,993:INFO:Defining folds
2023-02-03 15:22:41,993:INFO:Declaring metric variables
2023-02-03 15:22:41,999:INFO:Importing untrained model
2023-02-03 15:22:42,005:INFO:Bayesian Ridge Imported successfully
2023-02-03 15:22:42,023:INFO:Starting cross validation
2023-02-03 15:22:42,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:42,304:INFO:Calculating mean and std
2023-02-03 15:22:42,306:INFO:Creating metrics dataframe
2023-02-03 15:22:42,310:INFO:Uploading results into container
2023-02-03 15:22:42,311:INFO:Uploading model into container now
2023-02-03 15:22:42,311:INFO:_master_model_container: 101
2023-02-03 15:22:42,311:INFO:_display_container: 10
2023-02-03 15:22:42,312:INFO:BayesianRidge()
2023-02-03 15:22:42,312:INFO:create_model() successfully completed......................................
2023-02-03 15:22:42,424:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:42,425:INFO:Creating metrics dataframe
2023-02-03 15:22:42,443:INFO:Initializing Passive Aggressive Regressor
2023-02-03 15:22:42,443:INFO:Total runtime is 0.06471283038457235 minutes
2023-02-03 15:22:42,449:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:42,450:INFO:Initializing create_model()
2023-02-03 15:22:42,450:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:42,450:INFO:Checking exceptions
2023-02-03 15:22:42,450:INFO:Importing libraries
2023-02-03 15:22:42,450:INFO:Copying training dataset
2023-02-03 15:22:42,457:INFO:Defining folds
2023-02-03 15:22:42,457:INFO:Declaring metric variables
2023-02-03 15:22:42,462:INFO:Importing untrained model
2023-02-03 15:22:42,469:INFO:Passive Aggressive Regressor Imported successfully
2023-02-03 15:22:42,488:INFO:Starting cross validation
2023-02-03 15:22:42,490:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:42,850:INFO:Calculating mean and std
2023-02-03 15:22:42,851:INFO:Creating metrics dataframe
2023-02-03 15:22:42,859:INFO:Uploading results into container
2023-02-03 15:22:42,860:INFO:Uploading model into container now
2023-02-03 15:22:42,861:INFO:_master_model_container: 102
2023-02-03 15:22:42,861:INFO:_display_container: 10
2023-02-03 15:22:42,862:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-03 15:22:42,862:INFO:create_model() successfully completed......................................
2023-02-03 15:22:42,967:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:42,968:INFO:Creating metrics dataframe
2023-02-03 15:22:42,994:INFO:Initializing Huber Regressor
2023-02-03 15:22:42,994:INFO:Total runtime is 0.07389095624287922 minutes
2023-02-03 15:22:43,000:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:43,000:INFO:Initializing create_model()
2023-02-03 15:22:43,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:43,001:INFO:Checking exceptions
2023-02-03 15:22:43,001:INFO:Importing libraries
2023-02-03 15:22:43,001:INFO:Copying training dataset
2023-02-03 15:22:43,007:INFO:Defining folds
2023-02-03 15:22:43,007:INFO:Declaring metric variables
2023-02-03 15:22:43,015:INFO:Importing untrained model
2023-02-03 15:22:43,022:INFO:Huber Regressor Imported successfully
2023-02-03 15:22:43,050:INFO:Starting cross validation
2023-02-03 15:22:43,051:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:43,390:INFO:Calculating mean and std
2023-02-03 15:22:43,392:INFO:Creating metrics dataframe
2023-02-03 15:22:43,400:INFO:Uploading results into container
2023-02-03 15:22:43,401:INFO:Uploading model into container now
2023-02-03 15:22:43,401:INFO:_master_model_container: 103
2023-02-03 15:22:43,401:INFO:_display_container: 10
2023-02-03 15:22:43,402:INFO:HuberRegressor()
2023-02-03 15:22:43,402:INFO:create_model() successfully completed......................................
2023-02-03 15:22:43,489:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:43,489:INFO:Creating metrics dataframe
2023-02-03 15:22:43,509:INFO:Initializing K Neighbors Regressor
2023-02-03 15:22:43,509:INFO:Total runtime is 0.08248596986134846 minutes
2023-02-03 15:22:43,514:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:43,514:INFO:Initializing create_model()
2023-02-03 15:22:43,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:43,515:INFO:Checking exceptions
2023-02-03 15:22:43,515:INFO:Importing libraries
2023-02-03 15:22:43,516:INFO:Copying training dataset
2023-02-03 15:22:43,522:INFO:Defining folds
2023-02-03 15:22:43,522:INFO:Declaring metric variables
2023-02-03 15:22:43,530:INFO:Importing untrained model
2023-02-03 15:22:43,536:INFO:K Neighbors Regressor Imported successfully
2023-02-03 15:22:43,550:INFO:Starting cross validation
2023-02-03 15:22:43,552:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:43,943:INFO:Calculating mean and std
2023-02-03 15:22:43,944:INFO:Creating metrics dataframe
2023-02-03 15:22:43,949:INFO:Uploading results into container
2023-02-03 15:22:43,950:INFO:Uploading model into container now
2023-02-03 15:22:43,951:INFO:_master_model_container: 104
2023-02-03 15:22:43,951:INFO:_display_container: 10
2023-02-03 15:22:43,952:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-03 15:22:43,952:INFO:create_model() successfully completed......................................
2023-02-03 15:22:44,061:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:44,061:INFO:Creating metrics dataframe
2023-02-03 15:22:44,083:INFO:Initializing Decision Tree Regressor
2023-02-03 15:22:44,084:INFO:Total runtime is 0.09206384420394896 minutes
2023-02-03 15:22:44,093:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:44,094:INFO:Initializing create_model()
2023-02-03 15:22:44,094:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:44,094:INFO:Checking exceptions
2023-02-03 15:22:44,094:INFO:Importing libraries
2023-02-03 15:22:44,095:INFO:Copying training dataset
2023-02-03 15:22:44,101:INFO:Defining folds
2023-02-03 15:22:44,101:INFO:Declaring metric variables
2023-02-03 15:22:44,112:INFO:Importing untrained model
2023-02-03 15:22:44,124:INFO:Decision Tree Regressor Imported successfully
2023-02-03 15:22:44,146:INFO:Starting cross validation
2023-02-03 15:22:44,148:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:44,502:INFO:Calculating mean and std
2023-02-03 15:22:44,504:INFO:Creating metrics dataframe
2023-02-03 15:22:44,512:INFO:Uploading results into container
2023-02-03 15:22:44,513:INFO:Uploading model into container now
2023-02-03 15:22:44,514:INFO:_master_model_container: 105
2023-02-03 15:22:44,514:INFO:_display_container: 10
2023-02-03 15:22:44,515:INFO:DecisionTreeRegressor(random_state=123)
2023-02-03 15:22:44,516:INFO:create_model() successfully completed......................................
2023-02-03 15:22:44,641:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:44,641:INFO:Creating metrics dataframe
2023-02-03 15:22:44,658:INFO:Initializing Random Forest Regressor
2023-02-03 15:22:44,658:INFO:Total runtime is 0.10162502129872639 minutes
2023-02-03 15:22:44,662:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:44,663:INFO:Initializing create_model()
2023-02-03 15:22:44,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:44,663:INFO:Checking exceptions
2023-02-03 15:22:44,664:INFO:Importing libraries
2023-02-03 15:22:44,664:INFO:Copying training dataset
2023-02-03 15:22:44,669:INFO:Defining folds
2023-02-03 15:22:44,669:INFO:Declaring metric variables
2023-02-03 15:22:44,677:INFO:Importing untrained model
2023-02-03 15:22:44,686:INFO:Random Forest Regressor Imported successfully
2023-02-03 15:22:44,707:INFO:Starting cross validation
2023-02-03 15:22:44,709:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:47,038:INFO:Calculating mean and std
2023-02-03 15:22:47,039:INFO:Creating metrics dataframe
2023-02-03 15:22:47,047:INFO:Uploading results into container
2023-02-03 15:22:47,048:INFO:Uploading model into container now
2023-02-03 15:22:47,049:INFO:_master_model_container: 106
2023-02-03 15:22:47,049:INFO:_display_container: 10
2023-02-03 15:22:47,050:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:22:47,050:INFO:create_model() successfully completed......................................
2023-02-03 15:22:47,155:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:47,155:INFO:Creating metrics dataframe
2023-02-03 15:22:47,175:INFO:Initializing Extra Trees Regressor
2023-02-03 15:22:47,176:INFO:Total runtime is 0.14360103607177732 minutes
2023-02-03 15:22:47,180:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:47,181:INFO:Initializing create_model()
2023-02-03 15:22:47,181:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:47,181:INFO:Checking exceptions
2023-02-03 15:22:47,181:INFO:Importing libraries
2023-02-03 15:22:47,181:INFO:Copying training dataset
2023-02-03 15:22:47,186:INFO:Defining folds
2023-02-03 15:22:47,186:INFO:Declaring metric variables
2023-02-03 15:22:47,194:INFO:Importing untrained model
2023-02-03 15:22:47,203:INFO:Extra Trees Regressor Imported successfully
2023-02-03 15:22:47,218:INFO:Starting cross validation
2023-02-03 15:22:47,220:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:49,458:INFO:Calculating mean and std
2023-02-03 15:22:49,461:INFO:Creating metrics dataframe
2023-02-03 15:22:49,467:INFO:Uploading results into container
2023-02-03 15:22:49,468:INFO:Uploading model into container now
2023-02-03 15:22:49,468:INFO:_master_model_container: 107
2023-02-03 15:22:49,469:INFO:_display_container: 10
2023-02-03 15:22:49,469:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-03 15:22:49,469:INFO:create_model() successfully completed......................................
2023-02-03 15:22:49,573:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:49,573:INFO:Creating metrics dataframe
2023-02-03 15:22:49,593:INFO:Initializing AdaBoost Regressor
2023-02-03 15:22:49,594:INFO:Total runtime is 0.1838779052098592 minutes
2023-02-03 15:22:49,600:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:49,601:INFO:Initializing create_model()
2023-02-03 15:22:49,601:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:49,601:INFO:Checking exceptions
2023-02-03 15:22:49,601:INFO:Importing libraries
2023-02-03 15:22:49,601:INFO:Copying training dataset
2023-02-03 15:22:49,605:INFO:Defining folds
2023-02-03 15:22:49,606:INFO:Declaring metric variables
2023-02-03 15:22:49,613:INFO:Importing untrained model
2023-02-03 15:22:49,621:INFO:AdaBoost Regressor Imported successfully
2023-02-03 15:22:49,636:INFO:Starting cross validation
2023-02-03 15:22:49,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:50,383:INFO:Calculating mean and std
2023-02-03 15:22:50,384:INFO:Creating metrics dataframe
2023-02-03 15:22:50,388:INFO:Uploading results into container
2023-02-03 15:22:50,389:INFO:Uploading model into container now
2023-02-03 15:22:50,390:INFO:_master_model_container: 108
2023-02-03 15:22:50,390:INFO:_display_container: 10
2023-02-03 15:22:50,390:INFO:AdaBoostRegressor(random_state=123)
2023-02-03 15:22:50,390:INFO:create_model() successfully completed......................................
2023-02-03 15:22:50,514:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:50,515:INFO:Creating metrics dataframe
2023-02-03 15:22:50,536:INFO:Initializing Gradient Boosting Regressor
2023-02-03 15:22:50,536:INFO:Total runtime is 0.19960221846898396 minutes
2023-02-03 15:22:50,543:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:50,545:INFO:Initializing create_model()
2023-02-03 15:22:50,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:50,547:INFO:Checking exceptions
2023-02-03 15:22:50,547:INFO:Importing libraries
2023-02-03 15:22:50,547:INFO:Copying training dataset
2023-02-03 15:22:50,555:INFO:Defining folds
2023-02-03 15:22:50,555:INFO:Declaring metric variables
2023-02-03 15:22:50,566:INFO:Importing untrained model
2023-02-03 15:22:50,575:INFO:Gradient Boosting Regressor Imported successfully
2023-02-03 15:22:50,601:INFO:Starting cross validation
2023-02-03 15:22:50,603:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:51,447:INFO:Calculating mean and std
2023-02-03 15:22:51,449:INFO:Creating metrics dataframe
2023-02-03 15:22:51,455:INFO:Uploading results into container
2023-02-03 15:22:51,456:INFO:Uploading model into container now
2023-02-03 15:22:51,457:INFO:_master_model_container: 109
2023-02-03 15:22:51,457:INFO:_display_container: 10
2023-02-03 15:22:51,458:INFO:GradientBoostingRegressor(random_state=123)
2023-02-03 15:22:51,458:INFO:create_model() successfully completed......................................
2023-02-03 15:22:51,561:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:51,561:INFO:Creating metrics dataframe
2023-02-03 15:22:51,589:INFO:Initializing Light Gradient Boosting Machine
2023-02-03 15:22:51,589:INFO:Total runtime is 0.21714218854904174 minutes
2023-02-03 15:22:51,598:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:51,598:INFO:Initializing create_model()
2023-02-03 15:22:51,599:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:51,600:INFO:Checking exceptions
2023-02-03 15:22:51,600:INFO:Importing libraries
2023-02-03 15:22:51,600:INFO:Copying training dataset
2023-02-03 15:22:51,609:INFO:Defining folds
2023-02-03 15:22:51,609:INFO:Declaring metric variables
2023-02-03 15:22:51,617:INFO:Importing untrained model
2023-02-03 15:22:51,628:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-03 15:22:51,655:INFO:Starting cross validation
2023-02-03 15:22:51,657:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:22:59,521:INFO:Calculating mean and std
2023-02-03 15:22:59,524:INFO:Creating metrics dataframe
2023-02-03 15:22:59,532:INFO:Uploading results into container
2023-02-03 15:22:59,534:INFO:Uploading model into container now
2023-02-03 15:22:59,535:INFO:_master_model_container: 110
2023-02-03 15:22:59,535:INFO:_display_container: 10
2023-02-03 15:22:59,537:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-02-03 15:22:59,538:INFO:create_model() successfully completed......................................
2023-02-03 15:22:59,683:INFO:SubProcess create_model() end ==================================
2023-02-03 15:22:59,683:INFO:Creating metrics dataframe
2023-02-03 15:22:59,716:INFO:Initializing Dummy Regressor
2023-02-03 15:22:59,716:INFO:Total runtime is 0.35259779294331867 minutes
2023-02-03 15:22:59,726:INFO:SubProcess create_model() called ==================================
2023-02-03 15:22:59,727:INFO:Initializing create_model()
2023-02-03 15:22:59,727:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000181F1AEE890>, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:22:59,728:INFO:Checking exceptions
2023-02-03 15:22:59,728:INFO:Importing libraries
2023-02-03 15:22:59,728:INFO:Copying training dataset
2023-02-03 15:22:59,734:INFO:Defining folds
2023-02-03 15:22:59,736:INFO:Declaring metric variables
2023-02-03 15:22:59,743:INFO:Importing untrained model
2023-02-03 15:22:59,754:INFO:Dummy Regressor Imported successfully
2023-02-03 15:22:59,774:INFO:Starting cross validation
2023-02-03 15:22:59,776:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:23:00,119:INFO:Calculating mean and std
2023-02-03 15:23:00,123:INFO:Creating metrics dataframe
2023-02-03 15:23:00,129:INFO:Uploading results into container
2023-02-03 15:23:00,130:INFO:Uploading model into container now
2023-02-03 15:23:00,131:INFO:_master_model_container: 111
2023-02-03 15:23:00,131:INFO:_display_container: 10
2023-02-03 15:23:00,132:INFO:DummyRegressor()
2023-02-03 15:23:00,132:INFO:create_model() successfully completed......................................
2023-02-03 15:23:00,231:INFO:SubProcess create_model() end ==================================
2023-02-03 15:23:00,232:INFO:Creating metrics dataframe
2023-02-03 15:23:00,267:INFO:Initializing create_model()
2023-02-03 15:23:00,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:23:00,267:INFO:Checking exceptions
2023-02-03 15:23:00,270:INFO:Importing libraries
2023-02-03 15:23:00,270:INFO:Copying training dataset
2023-02-03 15:23:00,278:INFO:Defining folds
2023-02-03 15:23:00,278:INFO:Declaring metric variables
2023-02-03 15:23:00,279:INFO:Importing untrained model
2023-02-03 15:23:00,279:INFO:Declaring custom model
2023-02-03 15:23:00,279:INFO:Linear Regression Imported successfully
2023-02-03 15:23:00,280:INFO:Cross validation set to False
2023-02-03 15:23:00,280:INFO:Fitting Model
2023-02-03 15:23:00,292:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:23:00,292:INFO:create_model() successfully completed......................................
2023-02-03 15:23:00,458:INFO:_master_model_container: 111
2023-02-03 15:23:00,458:INFO:_display_container: 10
2023-02-03 15:23:00,459:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:23:00,459:INFO:compare_models() successfully completed......................................
2023-02-03 15:24:08,358:INFO:Initializing evaluate_model()
2023-02-03 15:24:08,359:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-03 15:24:08,391:INFO:Initializing plot_model()
2023-02-03 15:24:08,392:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:24:08,392:INFO:Checking exceptions
2023-02-03 15:24:08,396:INFO:Preloading libraries
2023-02-03 15:24:08,396:INFO:Copying training dataset
2023-02-03 15:24:08,397:INFO:Plot type: pipeline
2023-02-03 15:24:08,720:INFO:Visual Rendered Successfully
2023-02-03 15:24:08,952:INFO:plot_model() successfully completed......................................
2023-02-03 15:24:19,888:INFO:Initializing plot_model()
2023-02-03 15:24:19,888:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:24:19,888:INFO:Checking exceptions
2023-02-03 15:24:19,894:INFO:Preloading libraries
2023-02-03 15:24:19,894:INFO:Copying training dataset
2023-02-03 15:24:19,895:INFO:Plot type: residuals
2023-02-03 15:24:20,045:INFO:Fitting Model
2023-02-03 15:24:20,046:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2023-02-03 15:24:20,128:INFO:Scoring test/hold-out set
2023-02-03 15:24:20,912:INFO:Visual Rendered Successfully
2023-02-03 15:24:21,004:INFO:plot_model() successfully completed......................................
2023-02-03 15:24:36,254:INFO:Initializing plot_model()
2023-02-03 15:24:36,255:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:24:36,256:INFO:Checking exceptions
2023-02-03 15:24:36,261:INFO:Preloading libraries
2023-02-03 15:24:36,261:INFO:Copying training dataset
2023-02-03 15:24:36,261:INFO:Plot type: error
2023-02-03 15:24:36,320:INFO:Fitting Model
2023-02-03 15:24:36,320:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2023-02-03 15:24:36,320:INFO:Scoring test/hold-out set
2023-02-03 15:24:36,661:INFO:Visual Rendered Successfully
2023-02-03 15:24:36,769:INFO:plot_model() successfully completed......................................
2023-02-03 15:24:44,864:INFO:Initializing plot_model()
2023-02-03 15:24:44,865:INFO:plot_model(plot=tree, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:24:44,865:INFO:Checking exceptions
2023-02-03 15:24:49,464:INFO:Initializing plot_model()
2023-02-03 15:24:49,465:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:24:49,465:INFO:Checking exceptions
2023-02-03 15:24:49,471:INFO:Preloading libraries
2023-02-03 15:24:49,471:INFO:Copying training dataset
2023-02-03 15:24:49,471:INFO:Plot type: pipeline
2023-02-03 15:24:49,566:INFO:Visual Rendered Successfully
2023-02-03 15:24:49,668:INFO:plot_model() successfully completed......................................
2023-02-03 15:24:51,444:INFO:Initializing plot_model()
2023-02-03 15:24:51,444:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:24:51,444:INFO:Checking exceptions
2023-02-03 15:24:51,451:INFO:Preloading libraries
2023-02-03 15:24:51,452:INFO:Copying training dataset
2023-02-03 15:24:51,452:INFO:Plot type: feature
2023-02-03 15:24:51,591:INFO:Visual Rendered Successfully
2023-02-03 15:24:51,709:INFO:plot_model() successfully completed......................................
2023-02-03 15:24:58,498:INFO:Initializing plot_model()
2023-02-03 15:24:58,499:INFO:plot_model(plot=residuals_interactive, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:24:58,499:INFO:Checking exceptions
2023-02-03 15:24:58,504:INFO:Preloading libraries
2023-02-03 15:24:58,504:INFO:Copying training dataset
2023-02-03 15:24:58,504:INFO:Plot type: residuals_interactive
2023-02-03 15:24:58,554:INFO:Calculated model residuals
2023-02-03 15:24:59,413:INFO:Calculated Tunkey-Anscombe Plot
2023-02-03 15:24:59,591:INFO:Calculated Normal QQ Plot
2023-02-03 15:24:59,979:INFO:Calculated Scale-Location Plot
2023-02-03 15:25:00,316:INFO:Calculated Residual vs Leverage Plot inc. Cook's distance
2023-02-03 15:25:00,713:INFO:Visual Rendered Successfully
2023-02-03 15:25:00,826:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:01,197:INFO:Initializing plot_model()
2023-02-03 15:25:01,197:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:01,197:INFO:Checking exceptions
2023-02-03 15:25:01,204:INFO:Preloading libraries
2023-02-03 15:25:01,204:INFO:Copying training dataset
2023-02-03 15:25:01,204:INFO:Plot type: cooks
2023-02-03 15:25:01,248:INFO:Fitting Model
2023-02-03 15:25:01,517:INFO:Visual Rendered Successfully
2023-02-03 15:25:01,626:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:10,511:INFO:Initializing plot_model()
2023-02-03 15:25:10,512:INFO:plot_model(plot=learning, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:10,512:INFO:Checking exceptions
2023-02-03 15:25:10,518:INFO:Preloading libraries
2023-02-03 15:25:10,518:INFO:Copying training dataset
2023-02-03 15:25:10,518:INFO:Plot type: learning
2023-02-03 15:25:10,563:INFO:Fitting Model
2023-02-03 15:25:11,889:INFO:Visual Rendered Successfully
2023-02-03 15:25:12,004:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:28,816:INFO:Initializing plot_model()
2023-02-03 15:25:28,816:INFO:plot_model(plot=vc, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:28,817:INFO:Checking exceptions
2023-02-03 15:25:28,821:INFO:Preloading libraries
2023-02-03 15:25:28,822:INFO:Copying training dataset
2023-02-03 15:25:28,822:INFO:Plot type: vc
2023-02-03 15:25:28,822:INFO:Determining param_name
2023-02-03 15:25:28,823:INFO:param_name: alpha
2023-02-03 15:25:28,865:INFO:Fitting Model
2023-02-03 15:25:30,023:INFO:Visual Rendered Successfully
2023-02-03 15:25:30,126:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:34,070:INFO:Initializing plot_model()
2023-02-03 15:25:34,071:INFO:plot_model(plot=manifold, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:34,071:INFO:Checking exceptions
2023-02-03 15:25:34,076:INFO:Preloading libraries
2023-02-03 15:25:34,076:INFO:Copying training dataset
2023-02-03 15:25:34,077:INFO:Plot type: manifold
2023-02-03 15:25:34,150:INFO:Fitting & Transforming Model
2023-02-03 15:25:34,151:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\manifold\_t_sne.py:810: FutureWarning:

The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.


2023-02-03 15:25:37,039:INFO:Initializing plot_model()
2023-02-03 15:25:37,040:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:37,040:INFO:Checking exceptions
2023-02-03 15:25:37,045:INFO:Preloading libraries
2023-02-03 15:25:37,046:INFO:Copying training dataset
2023-02-03 15:25:37,046:INFO:Plot type: error
2023-02-03 15:25:37,087:INFO:Fitting Model
2023-02-03 15:25:37,088:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2023-02-03 15:25:37,088:INFO:Scoring test/hold-out set
2023-02-03 15:25:37,437:INFO:Visual Rendered Successfully
2023-02-03 15:25:37,614:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:38,954:INFO:Initializing plot_model()
2023-02-03 15:25:38,954:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:38,954:INFO:Checking exceptions
2023-02-03 15:25:38,961:INFO:Preloading libraries
2023-02-03 15:25:38,961:INFO:Copying training dataset
2023-02-03 15:25:38,961:INFO:Plot type: residuals
2023-02-03 15:25:39,027:INFO:Fitting Model
2023-02-03 15:25:39,027:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2023-02-03 15:25:39,087:INFO:Scoring test/hold-out set
2023-02-03 15:25:39,710:INFO:Visual Rendered Successfully
2023-02-03 15:25:39,857:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:40,336:INFO:Initializing plot_model()
2023-02-03 15:25:40,338:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:40,338:INFO:Checking exceptions
2023-02-03 15:25:40,341:INFO:Preloading libraries
2023-02-03 15:25:40,342:INFO:Copying training dataset
2023-02-03 15:25:40,342:INFO:Plot type: parameter
2023-02-03 15:25:40,348:INFO:Visual Rendered Successfully
2023-02-03 15:25:40,469:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:45,771:INFO:Initializing plot_model()
2023-02-03 15:25:45,771:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:45,772:INFO:Checking exceptions
2023-02-03 15:25:45,775:INFO:Preloading libraries
2023-02-03 15:25:45,776:INFO:Copying training dataset
2023-02-03 15:25:45,776:INFO:Plot type: residuals
2023-02-03 15:25:45,850:INFO:Fitting Model
2023-02-03 15:25:45,850:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2023-02-03 15:25:45,915:INFO:Scoring test/hold-out set
2023-02-03 15:25:46,418:INFO:Visual Rendered Successfully
2023-02-03 15:25:46,525:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:47,797:INFO:Initializing plot_model()
2023-02-03 15:25:47,798:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:47,798:INFO:Checking exceptions
2023-02-03 15:25:47,803:INFO:Preloading libraries
2023-02-03 15:25:47,804:INFO:Copying training dataset
2023-02-03 15:25:47,806:INFO:Plot type: error
2023-02-03 15:25:47,843:INFO:Fitting Model
2023-02-03 15:25:47,844:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2023-02-03 15:25:47,844:INFO:Scoring test/hold-out set
2023-02-03 15:25:48,188:INFO:Visual Rendered Successfully
2023-02-03 15:25:48,332:INFO:plot_model() successfully completed......................................
2023-02-03 15:25:49,776:INFO:Initializing plot_model()
2023-02-03 15:25:49,776:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:25:49,777:INFO:Checking exceptions
2023-02-03 15:25:49,783:INFO:Preloading libraries
2023-02-03 15:25:49,783:INFO:Copying training dataset
2023-02-03 15:25:49,784:INFO:Plot type: residuals
2023-02-03 15:25:49,867:INFO:Fitting Model
2023-02-03 15:25:49,867:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2023-02-03 15:25:49,948:INFO:Scoring test/hold-out set
2023-02-03 15:25:51,020:INFO:Visual Rendered Successfully
2023-02-03 15:25:51,200:INFO:plot_model() successfully completed......................................
2023-02-03 15:26:04,075:INFO:Initializing create_model()
2023-02-03 15:26:04,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:26:04,076:INFO:Checking exceptions
2023-02-03 15:26:04,113:INFO:Importing libraries
2023-02-03 15:26:04,113:INFO:Copying training dataset
2023-02-03 15:26:04,120:INFO:Defining folds
2023-02-03 15:26:04,120:INFO:Declaring metric variables
2023-02-03 15:26:04,131:INFO:Importing untrained model
2023-02-03 15:26:04,131:INFO:Declaring custom model
2023-02-03 15:26:04,140:INFO:Linear Regression Imported successfully
2023-02-03 15:26:04,158:INFO:Starting cross validation
2023-02-03 15:26:04,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:26:04,492:INFO:Calculating mean and std
2023-02-03 15:26:04,493:INFO:Creating metrics dataframe
2023-02-03 15:26:04,501:INFO:Finalizing model
2023-02-03 15:26:04,521:INFO:Uploading results into container
2023-02-03 15:26:04,523:INFO:Uploading model into container now
2023-02-03 15:26:04,540:INFO:_master_model_container: 112
2023-02-03 15:26:04,540:INFO:_display_container: 11
2023-02-03 15:26:04,540:INFO:LinearRegression(n_jobs=-1)
2023-02-03 15:26:04,541:INFO:create_model() successfully completed......................................
2023-02-03 15:26:08,157:INFO:Initializing evaluate_model()
2023-02-03 15:26:08,158:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-03 15:26:08,182:INFO:Initializing plot_model()
2023-02-03 15:26:08,182:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:26:08,182:INFO:Checking exceptions
2023-02-03 15:26:08,187:INFO:Preloading libraries
2023-02-03 15:26:08,187:INFO:Copying training dataset
2023-02-03 15:26:08,188:INFO:Plot type: pipeline
2023-02-03 15:26:08,337:INFO:Visual Rendered Successfully
2023-02-03 15:26:08,478:INFO:plot_model() successfully completed......................................
2023-02-03 15:26:10,431:INFO:Initializing plot_model()
2023-02-03 15:26:10,432:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:26:10,432:INFO:Checking exceptions
2023-02-03 15:26:10,436:INFO:Preloading libraries
2023-02-03 15:26:10,436:INFO:Copying training dataset
2023-02-03 15:26:10,436:INFO:Plot type: residuals
2023-02-03 15:26:10,517:INFO:Fitting Model
2023-02-03 15:26:10,517:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but LinearRegression was fitted with feature names


2023-02-03 15:26:10,574:INFO:Scoring test/hold-out set
2023-02-03 15:26:11,075:INFO:Visual Rendered Successfully
2023-02-03 15:26:11,198:INFO:plot_model() successfully completed......................................
2023-02-03 15:26:16,584:INFO:Initializing plot_model()
2023-02-03 15:26:16,584:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:26:16,584:INFO:Checking exceptions
2023-02-03 15:26:16,590:INFO:Preloading libraries
2023-02-03 15:26:16,591:INFO:Copying training dataset
2023-02-03 15:26:16,591:INFO:Plot type: error
2023-02-03 15:26:16,623:INFO:Fitting Model
2023-02-03 15:26:16,623:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but LinearRegression was fitted with feature names


2023-02-03 15:26:16,623:INFO:Scoring test/hold-out set
2023-02-03 15:26:16,868:INFO:Visual Rendered Successfully
2023-02-03 15:26:16,988:INFO:plot_model() successfully completed......................................
2023-02-03 15:26:19,746:INFO:Initializing plot_model()
2023-02-03 15:26:19,747:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:26:19,747:INFO:Checking exceptions
2023-02-03 15:26:19,752:INFO:Preloading libraries
2023-02-03 15:26:19,753:INFO:Copying training dataset
2023-02-03 15:26:19,753:INFO:Plot type: residuals
2023-02-03 15:26:19,818:INFO:Fitting Model
2023-02-03 15:26:19,818:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but LinearRegression was fitted with feature names


2023-02-03 15:26:19,872:INFO:Scoring test/hold-out set
2023-02-03 15:26:20,379:INFO:Visual Rendered Successfully
2023-02-03 15:26:20,496:INFO:plot_model() successfully completed......................................
2023-02-03 15:26:21,252:INFO:Initializing plot_model()
2023-02-03 15:26:21,253:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:26:21,253:INFO:Checking exceptions
2023-02-03 15:26:21,258:INFO:Preloading libraries
2023-02-03 15:26:21,259:INFO:Copying training dataset
2023-02-03 15:26:21,259:INFO:Plot type: parameter
2023-02-03 15:26:21,265:INFO:Visual Rendered Successfully
2023-02-03 15:26:21,367:INFO:plot_model() successfully completed......................................
2023-02-03 15:26:22,525:INFO:Initializing plot_model()
2023-02-03 15:26:22,525:INFO:plot_model(plot=learning, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:26:22,526:INFO:Checking exceptions
2023-02-03 15:26:22,532:INFO:Preloading libraries
2023-02-03 15:26:22,533:INFO:Copying training dataset
2023-02-03 15:26:22,533:INFO:Plot type: learning
2023-02-03 15:26:22,570:INFO:Fitting Model
2023-02-03 15:26:24,085:INFO:Visual Rendered Successfully
2023-02-03 15:26:24,196:INFO:plot_model() successfully completed......................................
2023-02-03 15:26:34,189:INFO:Initializing create_model()
2023-02-03 15:26:34,189:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-03 15:26:34,189:INFO:Checking exceptions
2023-02-03 15:26:34,217:INFO:Importing libraries
2023-02-03 15:26:34,218:INFO:Copying training dataset
2023-02-03 15:26:34,227:INFO:Defining folds
2023-02-03 15:26:34,228:INFO:Declaring metric variables
2023-02-03 15:26:34,235:INFO:Importing untrained model
2023-02-03 15:26:34,248:INFO:Huber Regressor Imported successfully
2023-02-03 15:26:34,266:INFO:Starting cross validation
2023-02-03 15:26:34,268:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-03 15:26:34,717:INFO:Calculating mean and std
2023-02-03 15:26:34,718:INFO:Creating metrics dataframe
2023-02-03 15:26:34,726:INFO:Finalizing model
2023-02-03 15:26:34,753:INFO:Uploading results into container
2023-02-03 15:26:34,756:INFO:Uploading model into container now
2023-02-03 15:26:34,769:INFO:_master_model_container: 113
2023-02-03 15:26:34,769:INFO:_display_container: 12
2023-02-03 15:26:34,770:INFO:HuberRegressor()
2023-02-03 15:26:34,770:INFO:create_model() successfully completed......................................
2023-02-03 15:26:37,151:INFO:Initializing evaluate_model()
2023-02-03 15:26:37,151:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-03 15:26:37,171:INFO:Initializing plot_model()
2023-02-03 15:26:37,171:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:26:37,172:INFO:Checking exceptions
2023-02-03 15:26:37,177:INFO:Preloading libraries
2023-02-03 15:26:37,177:INFO:Copying training dataset
2023-02-03 15:26:37,178:INFO:Plot type: pipeline
2023-02-03 15:26:37,291:INFO:Visual Rendered Successfully
2023-02-03 15:26:37,408:INFO:plot_model() successfully completed......................................
2023-02-03 15:26:39,040:INFO:Initializing plot_model()
2023-02-03 15:26:39,040:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, system=True)
2023-02-03 15:26:39,040:INFO:Checking exceptions
2023-02-03 15:26:39,046:INFO:Preloading libraries
2023-02-03 15:26:39,046:INFO:Copying training dataset
2023-02-03 15:26:39,047:INFO:Plot type: residuals
2023-02-03 15:26:39,136:INFO:Fitting Model
2023-02-03 15:26:39,137:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2023-02-03 15:26:39,198:INFO:Scoring test/hold-out set
2023-02-03 15:26:40,035:INFO:Visual Rendered Successfully
2023-02-03 15:26:40,232:INFO:plot_model() successfully completed......................................
2023-02-03 15:28:14,375:INFO:Initializing predict_model()
2023-02-03 15:28:14,375:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000181F5E82D70>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000181F972FF40>)
2023-02-03 15:28:14,376:INFO:Checking exceptions
2023-02-03 15:28:14,376:INFO:Preloading libraries
2023-02-03 15:28:14,379:INFO:Set up data.
2023-02-03 15:28:14,388:INFO:Set up index.
2023-02-06 13:22:24,349:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:22:24,350:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:22:24,351:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:22:24,351:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:22:26,038:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-06 13:23:41,469:INFO:PyCaret RegressionExperiment
2023-02-06 13:23:41,470:INFO:Logging name: reg-default-name
2023-02-06 13:23:41,470:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-06 13:23:41,470:INFO:version 3.0.0.rc8
2023-02-06 13:23:41,471:INFO:Initializing setup()
2023-02-06 13:23:41,471:INFO:self.USI: 8710
2023-02-06 13:23:41,471:INFO:self._variable_keys: {'log_plots_param', 'n_jobs_param', '_available_plots', 'y', 'exp_name_log', 'USI', 'html_param', 'logging_param', 'fold_shuffle_param', 'y_test', 'memory', 'seed', 'idx', 'fold_generator', 'X', '_ml_usecase', 'data', 'exp_id', 'X_train', 'gpu_n_jobs_param', 'pipeline', 'fold_groups_param', 'gpu_param', 'target_param', 'y_train', 'transform_target_param', 'X_test'}
2023-02-06 13:23:41,472:INFO:Checking environment
2023-02-06 13:23:41,472:INFO:python_version: 3.10.9
2023-02-06 13:23:41,473:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-02-06 13:23:41,473:INFO:machine: AMD64
2023-02-06 13:23:41,474:INFO:platform: Windows-10-10.0.19045-SP0
2023-02-06 13:23:41,475:INFO:Memory: svmem(total=17090879488, available=6704939008, percent=60.8, used=10385940480, free=6704939008)
2023-02-06 13:23:41,476:INFO:Physical Core: 4
2023-02-06 13:23:41,477:INFO:Logical Core: 8
2023-02-06 13:23:41,478:INFO:Checking libraries
2023-02-06 13:23:41,479:INFO:System:
2023-02-06 13:23:41,479:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-02-06 13:23:41,480:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-02-06 13:23:41,480:INFO:   machine: Windows-10-10.0.19045-SP0
2023-02-06 13:23:41,481:INFO:PyCaret required dependencies:
2023-02-06 13:23:41,482:INFO:                 pip: 23.0
2023-02-06 13:23:41,482:INFO:          setuptools: 67.1.0
2023-02-06 13:23:41,483:INFO:             pycaret: 3.0.0rc8
2023-02-06 13:23:41,483:INFO:             IPython: 8.8.0
2023-02-06 13:23:41,483:INFO:          ipywidgets: 8.0.4
2023-02-06 13:23:41,484:INFO:                tqdm: 4.64.1
2023-02-06 13:23:41,484:INFO:               numpy: 1.23.5
2023-02-06 13:23:41,484:INFO:              pandas: 1.5.3
2023-02-06 13:23:41,485:INFO:              jinja2: 3.1.2
2023-02-06 13:23:41,485:INFO:               scipy: 1.10.0
2023-02-06 13:23:41,485:INFO:              joblib: 1.2.0
2023-02-06 13:23:41,486:INFO:             sklearn: 1.1.3
2023-02-06 13:23:41,486:INFO:                pyod: 1.0.7
2023-02-06 13:23:41,486:INFO:            imblearn: 0.10.1
2023-02-06 13:23:41,486:INFO:   category_encoders: 2.6.0
2023-02-06 13:23:41,486:INFO:            lightgbm: 3.3.5
2023-02-06 13:23:41,486:INFO:               numba: 0.56.4
2023-02-06 13:23:41,487:INFO:            requests: 2.28.2
2023-02-06 13:23:41,487:INFO:          matplotlib: 3.6.3
2023-02-06 13:23:41,487:INFO:          scikitplot: 0.3.7
2023-02-06 13:23:41,487:INFO:         yellowbrick: 1.5
2023-02-06 13:23:41,487:INFO:              plotly: 5.13.0
2023-02-06 13:23:41,487:INFO:             kaleido: 0.2.1
2023-02-06 13:23:41,487:INFO:         statsmodels: 0.13.5
2023-02-06 13:23:41,487:INFO:              sktime: 0.16.0
2023-02-06 13:23:41,487:INFO:               tbats: 1.1.2
2023-02-06 13:23:41,487:INFO:            pmdarima: 2.0.2
2023-02-06 13:23:41,487:INFO:              psutil: 5.9.0
2023-02-06 13:23:41,487:INFO:PyCaret optional dependencies:
2023-02-06 13:23:41,526:INFO:                shap: Not installed
2023-02-06 13:23:41,527:INFO:           interpret: Not installed
2023-02-06 13:23:41,527:INFO:                umap: Not installed
2023-02-06 13:23:41,527:INFO:    pandas_profiling: Not installed
2023-02-06 13:23:41,527:INFO:  explainerdashboard: Not installed
2023-02-06 13:23:41,527:INFO:             autoviz: Not installed
2023-02-06 13:23:41,527:INFO:           fairlearn: Not installed
2023-02-06 13:23:41,527:INFO:             xgboost: 1.7.3
2023-02-06 13:23:41,527:INFO:            catboost: Not installed
2023-02-06 13:23:41,527:INFO:              kmodes: Not installed
2023-02-06 13:23:41,527:INFO:             mlxtend: Not installed
2023-02-06 13:23:41,527:INFO:       statsforecast: Not installed
2023-02-06 13:23:41,527:INFO:        tune_sklearn: Not installed
2023-02-06 13:23:41,527:INFO:                 ray: Not installed
2023-02-06 13:23:41,527:INFO:            hyperopt: Not installed
2023-02-06 13:23:41,527:INFO:              optuna: Not installed
2023-02-06 13:23:41,528:INFO:               skopt: Not installed
2023-02-06 13:23:41,528:INFO:              mlflow: Not installed
2023-02-06 13:23:41,528:INFO:              gradio: Not installed
2023-02-06 13:23:41,528:INFO:             fastapi: Not installed
2023-02-06 13:23:41,528:INFO:             uvicorn: Not installed
2023-02-06 13:23:41,528:INFO:              m2cgen: Not installed
2023-02-06 13:23:41,528:INFO:           evidently: Not installed
2023-02-06 13:23:41,528:INFO:                nltk: Not installed
2023-02-06 13:23:41,528:INFO:            pyLDAvis: Not installed
2023-02-06 13:23:41,528:INFO:              gensim: Not installed
2023-02-06 13:23:41,528:INFO:               spacy: Not installed
2023-02-06 13:23:41,528:INFO:           wordcloud: Not installed
2023-02-06 13:23:41,528:INFO:            textblob: Not installed
2023-02-06 13:23:41,528:INFO:               fugue: Not installed
2023-02-06 13:23:41,528:INFO:           streamlit: Not installed
2023-02-06 13:23:41,528:INFO:             prophet: Not installed
2023-02-06 13:23:41,529:INFO:None
2023-02-06 13:23:41,529:INFO:Set up GPU usage.
2023-02-06 13:23:41,529:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:41,529:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-02-06 13:23:41,529:INFO:Set up data.
2023-02-06 13:23:41,535:INFO:Set up train/test split.
2023-02-06 13:23:41,540:INFO:Set up index.
2023-02-06 13:23:41,541:INFO:Set up folding strategy.
2023-02-06 13:23:41,542:INFO:Assigning column types.
2023-02-06 13:23:41,548:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-06 13:23:41,548:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:41,548:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-06 13:23:41,548:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:41,554:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-06 13:23:41,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:41,561:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 13:23:41,561:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:41,635:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:41,635:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:41,693:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 13:23:41,694:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:41,694:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:41,694:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:42,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:42,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:42,668:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-06 13:23:42,668:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:42,681:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-06 13:23:42,681:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:42,693:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 13:23:42,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:42,834:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:42,835:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:42,917:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 13:23:42,917:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:42,917:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:42,918:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:43,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:43,131:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-06 13:23:43,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,145:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,159:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,285:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,285:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,360:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,360:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,361:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:43,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:43,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,557:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,557:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,569:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,570:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,684:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,746:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,746:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,746:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,747:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:43,938:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:43,940:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-06 13:23:43,940:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,940:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:43,966:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 13:23:43,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,086:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:44,086:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,143:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 13:23:44,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,144:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:44,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:44,317:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,317:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,344:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 13:23:44,344:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,462:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:44,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,519:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 13:23:44,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,520:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:44,699:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:44,700:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-06 13:23:44,701:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,701:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,715:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,729:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,839:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:44,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,895:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 13:23:44,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,896:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:44,896:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:45,080:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:45,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,107:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,221:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:45,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,275:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 13:23:45,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,276:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:45,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:45,442:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-06 13:23:45,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,442:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,471:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:45,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,639:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:45,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:45,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:45,968:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 13:23:45,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,025:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,025:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,026:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:46,206:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:46,207:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-06 13:23:46,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,234:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,405:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:46,579:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:46,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,606:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,718:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:46,777:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:46,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:46,954:INFO:Preparing preprocessing pipeline...
2023-02-06 13:23:46,956:INFO:Set up simple imputation.
2023-02-06 13:23:47,040:INFO:Finished creating preprocessing pipeline.
2023-02-06 13:23:47,049:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-02-06 13:23:47,049:INFO:Creating final display dataframe.
2023-02-06 13:23:47,263:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape          (962, 2)
4        Transformed data shape          (962, 2)
5   Transformed train set shape          (673, 2)
6    Transformed test set shape          (289, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              8710
2023-02-06 13:23:47,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,428:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,428:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,429:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:47,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:47,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 13:23:47,807:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 13:23:47,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 13:23:47,990:INFO:setup() successfully completed in 6.52s...............
2023-02-06 13:23:51,353:INFO:Initializing compare_models()
2023-02-06 13:23:51,353:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-06 13:23:51,354:INFO:Checking exceptions
2023-02-06 13:23:51,356:INFO:Preparing display monitor
2023-02-06 13:23:51,412:INFO:Initializing Linear Regression
2023-02-06 13:23:51,413:INFO:Total runtime is 1.6669432322184246e-05 minutes
2023-02-06 13:23:51,421:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:51,421:INFO:Initializing create_model()
2023-02-06 13:23:51,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:51,424:INFO:Checking exceptions
2023-02-06 13:23:51,426:INFO:Importing libraries
2023-02-06 13:23:51,427:INFO:Copying training dataset
2023-02-06 13:23:51,434:INFO:Defining folds
2023-02-06 13:23:51,434:INFO:Declaring metric variables
2023-02-06 13:23:51,442:INFO:Importing untrained model
2023-02-06 13:23:51,449:INFO:Linear Regression Imported successfully
2023-02-06 13:23:51,464:INFO:Starting cross validation
2023-02-06 13:23:51,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:52,720:INFO:Calculating mean and std
2023-02-06 13:23:52,726:INFO:Creating metrics dataframe
2023-02-06 13:23:52,732:INFO:Uploading results into container
2023-02-06 13:23:52,733:INFO:Uploading model into container now
2023-02-06 13:23:52,734:INFO:_master_model_container: 1
2023-02-06 13:23:52,734:INFO:_display_container: 2
2023-02-06 13:23:52,735:INFO:LinearRegression(n_jobs=-1)
2023-02-06 13:23:52,735:INFO:create_model() successfully completed......................................
2023-02-06 13:23:52,848:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:52,849:INFO:Creating metrics dataframe
2023-02-06 13:23:52,862:INFO:Initializing Lasso Regression
2023-02-06 13:23:52,862:INFO:Total runtime is 0.024169143040974936 minutes
2023-02-06 13:23:52,866:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:52,867:INFO:Initializing create_model()
2023-02-06 13:23:52,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:52,867:INFO:Checking exceptions
2023-02-06 13:23:52,867:INFO:Importing libraries
2023-02-06 13:23:52,868:INFO:Copying training dataset
2023-02-06 13:23:52,875:INFO:Defining folds
2023-02-06 13:23:52,876:INFO:Declaring metric variables
2023-02-06 13:23:52,881:INFO:Importing untrained model
2023-02-06 13:23:52,889:INFO:Lasso Regression Imported successfully
2023-02-06 13:23:52,906:INFO:Starting cross validation
2023-02-06 13:23:52,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:52,962:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.632e+08, tolerance: 1.978e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,012:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+08, tolerance: 1.993e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,063:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.045e+08, tolerance: 1.929e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,109:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.157e+08, tolerance: 2.040e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,159:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.967e+08, tolerance: 1.980e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,205:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.866e+08, tolerance: 2.009e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,252:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.263e+07, tolerance: 2.011e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,298:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.086e+08, tolerance: 2.004e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,347:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.600e+08, tolerance: 1.990e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,393:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.602e+08, tolerance: 2.033e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:53,411:INFO:Calculating mean and std
2023-02-06 13:23:53,413:INFO:Creating metrics dataframe
2023-02-06 13:23:53,417:INFO:Uploading results into container
2023-02-06 13:23:53,417:INFO:Uploading model into container now
2023-02-06 13:23:53,418:INFO:_master_model_container: 2
2023-02-06 13:23:53,418:INFO:_display_container: 2
2023-02-06 13:23:53,418:INFO:Lasso(random_state=123)
2023-02-06 13:23:53,418:INFO:create_model() successfully completed......................................
2023-02-06 13:23:53,518:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:53,519:INFO:Creating metrics dataframe
2023-02-06 13:23:53,535:INFO:Initializing Ridge Regression
2023-02-06 13:23:53,535:INFO:Total runtime is 0.03536992073059082 minutes
2023-02-06 13:23:53,542:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:53,542:INFO:Initializing create_model()
2023-02-06 13:23:53,542:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:53,542:INFO:Checking exceptions
2023-02-06 13:23:53,542:INFO:Importing libraries
2023-02-06 13:23:53,543:INFO:Copying training dataset
2023-02-06 13:23:53,546:INFO:Defining folds
2023-02-06 13:23:53,546:INFO:Declaring metric variables
2023-02-06 13:23:53,554:INFO:Importing untrained model
2023-02-06 13:23:53,563:INFO:Ridge Regression Imported successfully
2023-02-06 13:23:53,580:INFO:Starting cross validation
2023-02-06 13:23:53,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:53,903:INFO:Calculating mean and std
2023-02-06 13:23:53,905:INFO:Creating metrics dataframe
2023-02-06 13:23:53,909:INFO:Uploading results into container
2023-02-06 13:23:53,910:INFO:Uploading model into container now
2023-02-06 13:23:53,910:INFO:_master_model_container: 3
2023-02-06 13:23:53,911:INFO:_display_container: 2
2023-02-06 13:23:53,911:INFO:Ridge(random_state=123)
2023-02-06 13:23:53,911:INFO:create_model() successfully completed......................................
2023-02-06 13:23:54,010:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:54,011:INFO:Creating metrics dataframe
2023-02-06 13:23:54,026:INFO:Initializing Elastic Net
2023-02-06 13:23:54,026:INFO:Total runtime is 0.0435551921526591 minutes
2023-02-06 13:23:54,031:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:54,032:INFO:Initializing create_model()
2023-02-06 13:23:54,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:54,032:INFO:Checking exceptions
2023-02-06 13:23:54,032:INFO:Importing libraries
2023-02-06 13:23:54,033:INFO:Copying training dataset
2023-02-06 13:23:54,040:INFO:Defining folds
2023-02-06 13:23:54,040:INFO:Declaring metric variables
2023-02-06 13:23:54,048:INFO:Importing untrained model
2023-02-06 13:23:54,057:INFO:Elastic Net Imported successfully
2023-02-06 13:23:54,071:INFO:Starting cross validation
2023-02-06 13:23:54,073:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:54,100:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.823e+08, tolerance: 1.978e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,132:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.675e+08, tolerance: 1.993e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,162:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.480e+08, tolerance: 1.929e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,190:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.003e+08, tolerance: 2.040e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,217:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.984e+08, tolerance: 1.980e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,245:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.855e+08, tolerance: 2.009e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,273:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e+08, tolerance: 2.011e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,300:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.619e+08, tolerance: 2.004e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,328:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.329e+08, tolerance: 1.990e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,355:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.757e+08, tolerance: 2.033e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 13:23:54,366:INFO:Calculating mean and std
2023-02-06 13:23:54,367:INFO:Creating metrics dataframe
2023-02-06 13:23:54,372:INFO:Uploading results into container
2023-02-06 13:23:54,373:INFO:Uploading model into container now
2023-02-06 13:23:54,373:INFO:_master_model_container: 4
2023-02-06 13:23:54,373:INFO:_display_container: 2
2023-02-06 13:23:54,374:INFO:ElasticNet(random_state=123)
2023-02-06 13:23:54,374:INFO:create_model() successfully completed......................................
2023-02-06 13:23:54,472:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:54,473:INFO:Creating metrics dataframe
2023-02-06 13:23:54,485:INFO:Initializing Least Angle Regression
2023-02-06 13:23:54,486:INFO:Total runtime is 0.051221716403961184 minutes
2023-02-06 13:23:54,491:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:54,492:INFO:Initializing create_model()
2023-02-06 13:23:54,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:54,492:INFO:Checking exceptions
2023-02-06 13:23:54,492:INFO:Importing libraries
2023-02-06 13:23:54,492:INFO:Copying training dataset
2023-02-06 13:23:54,496:INFO:Defining folds
2023-02-06 13:23:54,496:INFO:Declaring metric variables
2023-02-06 13:23:54,503:INFO:Importing untrained model
2023-02-06 13:23:54,509:INFO:Least Angle Regression Imported successfully
2023-02-06 13:23:54,526:INFO:Starting cross validation
2023-02-06 13:23:54,528:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:54,601:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,646:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,673:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,698:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,724:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,748:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,775:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,800:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,826:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,856:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:54,868:INFO:Calculating mean and std
2023-02-06 13:23:54,870:INFO:Creating metrics dataframe
2023-02-06 13:23:54,875:INFO:Uploading results into container
2023-02-06 13:23:54,876:INFO:Uploading model into container now
2023-02-06 13:23:54,876:INFO:_master_model_container: 5
2023-02-06 13:23:54,877:INFO:_display_container: 2
2023-02-06 13:23:54,877:INFO:Lars(random_state=123)
2023-02-06 13:23:54,877:INFO:create_model() successfully completed......................................
2023-02-06 13:23:54,975:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:54,975:INFO:Creating metrics dataframe
2023-02-06 13:23:54,988:INFO:Initializing Lasso Least Angle Regression
2023-02-06 13:23:54,989:INFO:Total runtime is 0.059607346852620445 minutes
2023-02-06 13:23:54,994:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:54,994:INFO:Initializing create_model()
2023-02-06 13:23:54,995:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:54,995:INFO:Checking exceptions
2023-02-06 13:23:54,995:INFO:Importing libraries
2023-02-06 13:23:54,995:INFO:Copying training dataset
2023-02-06 13:23:54,999:INFO:Defining folds
2023-02-06 13:23:54,999:INFO:Declaring metric variables
2023-02-06 13:23:55,008:INFO:Importing untrained model
2023-02-06 13:23:55,014:INFO:Lasso Least Angle Regression Imported successfully
2023-02-06 13:23:55,032:INFO:Starting cross validation
2023-02-06 13:23:55,035:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:55,061:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,091:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,120:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,144:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,170:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,201:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,227:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,252:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,279:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,306:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 13:23:55,319:INFO:Calculating mean and std
2023-02-06 13:23:55,320:INFO:Creating metrics dataframe
2023-02-06 13:23:55,324:INFO:Uploading results into container
2023-02-06 13:23:55,325:INFO:Uploading model into container now
2023-02-06 13:23:55,326:INFO:_master_model_container: 6
2023-02-06 13:23:55,326:INFO:_display_container: 2
2023-02-06 13:23:55,327:INFO:LassoLars(random_state=123)
2023-02-06 13:23:55,327:INFO:create_model() successfully completed......................................
2023-02-06 13:23:55,420:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:55,421:INFO:Creating metrics dataframe
2023-02-06 13:23:55,434:INFO:Initializing Orthogonal Matching Pursuit
2023-02-06 13:23:55,434:INFO:Total runtime is 0.06702644427617391 minutes
2023-02-06 13:23:55,440:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:55,441:INFO:Initializing create_model()
2023-02-06 13:23:55,441:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:55,441:INFO:Checking exceptions
2023-02-06 13:23:55,441:INFO:Importing libraries
2023-02-06 13:23:55,442:INFO:Copying training dataset
2023-02-06 13:23:55,446:INFO:Defining folds
2023-02-06 13:23:55,446:INFO:Declaring metric variables
2023-02-06 13:23:55,454:INFO:Importing untrained model
2023-02-06 13:23:55,461:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-06 13:23:55,476:INFO:Starting cross validation
2023-02-06 13:23:55,477:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:55,504:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,543:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,571:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,600:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,628:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,656:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,682:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,715:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,741:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,767:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 13:23:55,779:INFO:Calculating mean and std
2023-02-06 13:23:55,781:INFO:Creating metrics dataframe
2023-02-06 13:23:55,786:INFO:Uploading results into container
2023-02-06 13:23:55,787:INFO:Uploading model into container now
2023-02-06 13:23:55,788:INFO:_master_model_container: 7
2023-02-06 13:23:55,788:INFO:_display_container: 2
2023-02-06 13:23:55,789:INFO:OrthogonalMatchingPursuit()
2023-02-06 13:23:55,789:INFO:create_model() successfully completed......................................
2023-02-06 13:23:55,883:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:55,884:INFO:Creating metrics dataframe
2023-02-06 13:23:55,900:INFO:Initializing Bayesian Ridge
2023-02-06 13:23:55,900:INFO:Total runtime is 0.07478955586751301 minutes
2023-02-06 13:23:55,905:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:55,905:INFO:Initializing create_model()
2023-02-06 13:23:55,905:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:55,905:INFO:Checking exceptions
2023-02-06 13:23:55,905:INFO:Importing libraries
2023-02-06 13:23:55,906:INFO:Copying training dataset
2023-02-06 13:23:55,911:INFO:Defining folds
2023-02-06 13:23:55,911:INFO:Declaring metric variables
2023-02-06 13:23:55,919:INFO:Importing untrained model
2023-02-06 13:23:55,926:INFO:Bayesian Ridge Imported successfully
2023-02-06 13:23:55,941:INFO:Starting cross validation
2023-02-06 13:23:55,942:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:56,236:INFO:Calculating mean and std
2023-02-06 13:23:56,237:INFO:Creating metrics dataframe
2023-02-06 13:23:56,242:INFO:Uploading results into container
2023-02-06 13:23:56,242:INFO:Uploading model into container now
2023-02-06 13:23:56,243:INFO:_master_model_container: 8
2023-02-06 13:23:56,243:INFO:_display_container: 2
2023-02-06 13:23:56,244:INFO:BayesianRidge()
2023-02-06 13:23:56,244:INFO:create_model() successfully completed......................................
2023-02-06 13:23:56,342:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:56,342:INFO:Creating metrics dataframe
2023-02-06 13:23:56,358:INFO:Initializing Passive Aggressive Regressor
2023-02-06 13:23:56,358:INFO:Total runtime is 0.08243235747019449 minutes
2023-02-06 13:23:56,363:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:56,364:INFO:Initializing create_model()
2023-02-06 13:23:56,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:56,364:INFO:Checking exceptions
2023-02-06 13:23:56,364:INFO:Importing libraries
2023-02-06 13:23:56,365:INFO:Copying training dataset
2023-02-06 13:23:56,370:INFO:Defining folds
2023-02-06 13:23:56,370:INFO:Declaring metric variables
2023-02-06 13:23:56,376:INFO:Importing untrained model
2023-02-06 13:23:56,384:INFO:Passive Aggressive Regressor Imported successfully
2023-02-06 13:23:56,396:INFO:Starting cross validation
2023-02-06 13:23:56,398:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:56,726:INFO:Calculating mean and std
2023-02-06 13:23:56,727:INFO:Creating metrics dataframe
2023-02-06 13:23:56,732:INFO:Uploading results into container
2023-02-06 13:23:56,732:INFO:Uploading model into container now
2023-02-06 13:23:56,734:INFO:_master_model_container: 9
2023-02-06 13:23:56,734:INFO:_display_container: 2
2023-02-06 13:23:56,735:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-06 13:23:56,735:INFO:create_model() successfully completed......................................
2023-02-06 13:23:56,829:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:56,830:INFO:Creating metrics dataframe
2023-02-06 13:23:56,845:INFO:Initializing Huber Regressor
2023-02-06 13:23:56,845:INFO:Total runtime is 0.09054499069849649 minutes
2023-02-06 13:23:56,852:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:56,853:INFO:Initializing create_model()
2023-02-06 13:23:56,853:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:56,853:INFO:Checking exceptions
2023-02-06 13:23:56,854:INFO:Importing libraries
2023-02-06 13:23:56,854:INFO:Copying training dataset
2023-02-06 13:23:56,859:INFO:Defining folds
2023-02-06 13:23:56,859:INFO:Declaring metric variables
2023-02-06 13:23:56,866:INFO:Importing untrained model
2023-02-06 13:23:56,872:INFO:Huber Regressor Imported successfully
2023-02-06 13:23:56,888:INFO:Starting cross validation
2023-02-06 13:23:56,889:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:23:57,240:INFO:Calculating mean and std
2023-02-06 13:23:57,241:INFO:Creating metrics dataframe
2023-02-06 13:23:57,245:INFO:Uploading results into container
2023-02-06 13:23:57,245:INFO:Uploading model into container now
2023-02-06 13:23:57,246:INFO:_master_model_container: 10
2023-02-06 13:23:57,246:INFO:_display_container: 2
2023-02-06 13:23:57,247:INFO:HuberRegressor()
2023-02-06 13:23:57,248:INFO:create_model() successfully completed......................................
2023-02-06 13:23:57,343:INFO:SubProcess create_model() end ==================================
2023-02-06 13:23:57,343:INFO:Creating metrics dataframe
2023-02-06 13:23:57,358:INFO:Initializing K Neighbors Regressor
2023-02-06 13:23:57,359:INFO:Total runtime is 0.0991073727607727 minutes
2023-02-06 13:23:57,364:INFO:SubProcess create_model() called ==================================
2023-02-06 13:23:57,365:INFO:Initializing create_model()
2023-02-06 13:23:57,365:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:23:57,365:INFO:Checking exceptions
2023-02-06 13:23:57,366:INFO:Importing libraries
2023-02-06 13:23:57,366:INFO:Copying training dataset
2023-02-06 13:23:57,370:INFO:Defining folds
2023-02-06 13:23:57,370:INFO:Declaring metric variables
2023-02-06 13:23:57,376:INFO:Importing untrained model
2023-02-06 13:23:57,383:INFO:K Neighbors Regressor Imported successfully
2023-02-06 13:23:57,394:INFO:Starting cross validation
2023-02-06 13:23:57,397:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:03,290:INFO:Calculating mean and std
2023-02-06 13:24:03,291:INFO:Creating metrics dataframe
2023-02-06 13:24:03,295:INFO:Uploading results into container
2023-02-06 13:24:03,295:INFO:Uploading model into container now
2023-02-06 13:24:03,296:INFO:_master_model_container: 11
2023-02-06 13:24:03,296:INFO:_display_container: 2
2023-02-06 13:24:03,297:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-06 13:24:03,297:INFO:create_model() successfully completed......................................
2023-02-06 13:24:03,392:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:03,392:INFO:Creating metrics dataframe
2023-02-06 13:24:03,406:INFO:Initializing Decision Tree Regressor
2023-02-06 13:24:03,406:INFO:Total runtime is 0.19990280469258626 minutes
2023-02-06 13:24:03,412:INFO:SubProcess create_model() called ==================================
2023-02-06 13:24:03,412:INFO:Initializing create_model()
2023-02-06 13:24:03,412:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:03,413:INFO:Checking exceptions
2023-02-06 13:24:03,413:INFO:Importing libraries
2023-02-06 13:24:03,413:INFO:Copying training dataset
2023-02-06 13:24:03,417:INFO:Defining folds
2023-02-06 13:24:03,417:INFO:Declaring metric variables
2023-02-06 13:24:03,424:INFO:Importing untrained model
2023-02-06 13:24:03,430:INFO:Decision Tree Regressor Imported successfully
2023-02-06 13:24:03,445:INFO:Starting cross validation
2023-02-06 13:24:03,447:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:03,744:INFO:Calculating mean and std
2023-02-06 13:24:03,745:INFO:Creating metrics dataframe
2023-02-06 13:24:03,749:INFO:Uploading results into container
2023-02-06 13:24:03,750:INFO:Uploading model into container now
2023-02-06 13:24:03,750:INFO:_master_model_container: 12
2023-02-06 13:24:03,751:INFO:_display_container: 2
2023-02-06 13:24:03,751:INFO:DecisionTreeRegressor(random_state=123)
2023-02-06 13:24:03,752:INFO:create_model() successfully completed......................................
2023-02-06 13:24:03,847:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:03,847:INFO:Creating metrics dataframe
2023-02-06 13:24:03,864:INFO:Initializing Random Forest Regressor
2023-02-06 13:24:03,864:INFO:Total runtime is 0.20753448009490966 minutes
2023-02-06 13:24:03,870:INFO:SubProcess create_model() called ==================================
2023-02-06 13:24:03,871:INFO:Initializing create_model()
2023-02-06 13:24:03,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:03,871:INFO:Checking exceptions
2023-02-06 13:24:03,872:INFO:Importing libraries
2023-02-06 13:24:03,872:INFO:Copying training dataset
2023-02-06 13:24:03,876:INFO:Defining folds
2023-02-06 13:24:03,876:INFO:Declaring metric variables
2023-02-06 13:24:03,884:INFO:Importing untrained model
2023-02-06 13:24:03,892:INFO:Random Forest Regressor Imported successfully
2023-02-06 13:24:03,912:INFO:Starting cross validation
2023-02-06 13:24:03,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:06,226:INFO:Calculating mean and std
2023-02-06 13:24:06,228:INFO:Creating metrics dataframe
2023-02-06 13:24:06,236:INFO:Uploading results into container
2023-02-06 13:24:06,237:INFO:Uploading model into container now
2023-02-06 13:24:06,238:INFO:_master_model_container: 13
2023-02-06 13:24:06,238:INFO:_display_container: 2
2023-02-06 13:24:06,238:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-06 13:24:06,239:INFO:create_model() successfully completed......................................
2023-02-06 13:24:06,345:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:06,345:INFO:Creating metrics dataframe
2023-02-06 13:24:06,367:INFO:Initializing Extra Trees Regressor
2023-02-06 13:24:06,368:INFO:Total runtime is 0.24925457239151 minutes
2023-02-06 13:24:06,372:INFO:SubProcess create_model() called ==================================
2023-02-06 13:24:06,372:INFO:Initializing create_model()
2023-02-06 13:24:06,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:06,373:INFO:Checking exceptions
2023-02-06 13:24:06,373:INFO:Importing libraries
2023-02-06 13:24:06,373:INFO:Copying training dataset
2023-02-06 13:24:06,378:INFO:Defining folds
2023-02-06 13:24:06,378:INFO:Declaring metric variables
2023-02-06 13:24:06,387:INFO:Importing untrained model
2023-02-06 13:24:06,396:INFO:Extra Trees Regressor Imported successfully
2023-02-06 13:24:06,411:INFO:Starting cross validation
2023-02-06 13:24:06,412:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:08,584:INFO:Calculating mean and std
2023-02-06 13:24:08,586:INFO:Creating metrics dataframe
2023-02-06 13:24:08,591:INFO:Uploading results into container
2023-02-06 13:24:08,592:INFO:Uploading model into container now
2023-02-06 13:24:08,592:INFO:_master_model_container: 14
2023-02-06 13:24:08,592:INFO:_display_container: 2
2023-02-06 13:24:08,593:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-06 13:24:08,594:INFO:create_model() successfully completed......................................
2023-02-06 13:24:08,696:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:08,696:INFO:Creating metrics dataframe
2023-02-06 13:24:08,713:INFO:Initializing AdaBoost Regressor
2023-02-06 13:24:08,714:INFO:Total runtime is 0.2883580684661865 minutes
2023-02-06 13:24:08,720:INFO:SubProcess create_model() called ==================================
2023-02-06 13:24:08,721:INFO:Initializing create_model()
2023-02-06 13:24:08,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:08,722:INFO:Checking exceptions
2023-02-06 13:24:08,722:INFO:Importing libraries
2023-02-06 13:24:08,722:INFO:Copying training dataset
2023-02-06 13:24:08,728:INFO:Defining folds
2023-02-06 13:24:08,730:INFO:Declaring metric variables
2023-02-06 13:24:08,739:INFO:Importing untrained model
2023-02-06 13:24:08,747:INFO:AdaBoost Regressor Imported successfully
2023-02-06 13:24:08,760:INFO:Starting cross validation
2023-02-06 13:24:08,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:09,437:INFO:Calculating mean and std
2023-02-06 13:24:09,439:INFO:Creating metrics dataframe
2023-02-06 13:24:09,446:INFO:Uploading results into container
2023-02-06 13:24:09,447:INFO:Uploading model into container now
2023-02-06 13:24:09,448:INFO:_master_model_container: 15
2023-02-06 13:24:09,448:INFO:_display_container: 2
2023-02-06 13:24:09,449:INFO:AdaBoostRegressor(random_state=123)
2023-02-06 13:24:09,449:INFO:create_model() successfully completed......................................
2023-02-06 13:24:09,550:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:09,550:INFO:Creating metrics dataframe
2023-02-06 13:24:09,569:INFO:Initializing Gradient Boosting Regressor
2023-02-06 13:24:09,570:INFO:Total runtime is 0.3026328881581624 minutes
2023-02-06 13:24:09,576:INFO:SubProcess create_model() called ==================================
2023-02-06 13:24:09,577:INFO:Initializing create_model()
2023-02-06 13:24:09,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:09,577:INFO:Checking exceptions
2023-02-06 13:24:09,577:INFO:Importing libraries
2023-02-06 13:24:09,578:INFO:Copying training dataset
2023-02-06 13:24:09,581:INFO:Defining folds
2023-02-06 13:24:09,581:INFO:Declaring metric variables
2023-02-06 13:24:09,588:INFO:Importing untrained model
2023-02-06 13:24:09,596:INFO:Gradient Boosting Regressor Imported successfully
2023-02-06 13:24:09,608:INFO:Starting cross validation
2023-02-06 13:24:09,611:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:10,382:INFO:Calculating mean and std
2023-02-06 13:24:10,383:INFO:Creating metrics dataframe
2023-02-06 13:24:10,388:INFO:Uploading results into container
2023-02-06 13:24:10,389:INFO:Uploading model into container now
2023-02-06 13:24:10,391:INFO:_master_model_container: 16
2023-02-06 13:24:10,391:INFO:_display_container: 2
2023-02-06 13:24:10,392:INFO:GradientBoostingRegressor(random_state=123)
2023-02-06 13:24:10,392:INFO:create_model() successfully completed......................................
2023-02-06 13:24:10,491:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:10,491:INFO:Creating metrics dataframe
2023-02-06 13:24:10,510:INFO:Initializing Extreme Gradient Boosting
2023-02-06 13:24:10,511:INFO:Total runtime is 0.3183120290438334 minutes
2023-02-06 13:24:10,518:INFO:SubProcess create_model() called ==================================
2023-02-06 13:24:10,518:INFO:Initializing create_model()
2023-02-06 13:24:10,519:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:10,519:INFO:Checking exceptions
2023-02-06 13:24:10,519:INFO:Importing libraries
2023-02-06 13:24:10,519:INFO:Copying training dataset
2023-02-06 13:24:10,524:INFO:Defining folds
2023-02-06 13:24:10,524:INFO:Declaring metric variables
2023-02-06 13:24:10,532:INFO:Importing untrained model
2023-02-06 13:24:10,538:INFO:Extreme Gradient Boosting Imported successfully
2023-02-06 13:24:10,552:INFO:Starting cross validation
2023-02-06 13:24:10,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:16,073:INFO:Calculating mean and std
2023-02-06 13:24:16,077:INFO:Creating metrics dataframe
2023-02-06 13:24:16,085:INFO:Uploading results into container
2023-02-06 13:24:16,086:INFO:Uploading model into container now
2023-02-06 13:24:16,087:INFO:_master_model_container: 17
2023-02-06 13:24:16,088:INFO:_display_container: 2
2023-02-06 13:24:16,090:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-02-06 13:24:16,090:INFO:create_model() successfully completed......................................
2023-02-06 13:24:16,227:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:16,227:INFO:Creating metrics dataframe
2023-02-06 13:24:16,245:INFO:Initializing Light Gradient Boosting Machine
2023-02-06 13:24:16,245:INFO:Total runtime is 0.41387817064921056 minutes
2023-02-06 13:24:16,253:INFO:SubProcess create_model() called ==================================
2023-02-06 13:24:16,254:INFO:Initializing create_model()
2023-02-06 13:24:16,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:16,254:INFO:Checking exceptions
2023-02-06 13:24:16,255:INFO:Importing libraries
2023-02-06 13:24:16,255:INFO:Copying training dataset
2023-02-06 13:24:16,258:INFO:Defining folds
2023-02-06 13:24:16,259:INFO:Declaring metric variables
2023-02-06 13:24:16,265:INFO:Importing untrained model
2023-02-06 13:24:16,274:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-06 13:24:16,287:INFO:Starting cross validation
2023-02-06 13:24:16,288:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:24,303:INFO:Calculating mean and std
2023-02-06 13:24:24,305:INFO:Creating metrics dataframe
2023-02-06 13:24:24,312:INFO:Uploading results into container
2023-02-06 13:24:24,314:INFO:Uploading model into container now
2023-02-06 13:24:24,315:INFO:_master_model_container: 18
2023-02-06 13:24:24,315:INFO:_display_container: 2
2023-02-06 13:24:24,316:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-02-06 13:24:24,317:INFO:create_model() successfully completed......................................
2023-02-06 13:24:24,442:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:24,442:INFO:Creating metrics dataframe
2023-02-06 13:24:24,461:INFO:Initializing Dummy Regressor
2023-02-06 13:24:24,461:INFO:Total runtime is 0.5508141994476318 minutes
2023-02-06 13:24:24,468:INFO:SubProcess create_model() called ==================================
2023-02-06 13:24:24,469:INFO:Initializing create_model()
2023-02-06 13:24:24,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B4FF0F7730>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:24,469:INFO:Checking exceptions
2023-02-06 13:24:24,469:INFO:Importing libraries
2023-02-06 13:24:24,469:INFO:Copying training dataset
2023-02-06 13:24:24,474:INFO:Defining folds
2023-02-06 13:24:24,474:INFO:Declaring metric variables
2023-02-06 13:24:24,480:INFO:Importing untrained model
2023-02-06 13:24:24,489:INFO:Dummy Regressor Imported successfully
2023-02-06 13:24:24,508:INFO:Starting cross validation
2023-02-06 13:24:24,509:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:24,798:INFO:Calculating mean and std
2023-02-06 13:24:24,801:INFO:Creating metrics dataframe
2023-02-06 13:24:24,806:INFO:Uploading results into container
2023-02-06 13:24:24,807:INFO:Uploading model into container now
2023-02-06 13:24:24,807:INFO:_master_model_container: 19
2023-02-06 13:24:24,807:INFO:_display_container: 2
2023-02-06 13:24:24,808:INFO:DummyRegressor()
2023-02-06 13:24:24,808:INFO:create_model() successfully completed......................................
2023-02-06 13:24:24,916:INFO:SubProcess create_model() end ==================================
2023-02-06 13:24:24,916:INFO:Creating metrics dataframe
2023-02-06 13:24:24,955:INFO:Initializing create_model()
2023-02-06 13:24:24,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:24,955:INFO:Checking exceptions
2023-02-06 13:24:24,960:INFO:Importing libraries
2023-02-06 13:24:24,960:INFO:Copying training dataset
2023-02-06 13:24:24,968:INFO:Defining folds
2023-02-06 13:24:24,969:INFO:Declaring metric variables
2023-02-06 13:24:24,969:INFO:Importing untrained model
2023-02-06 13:24:24,970:INFO:Declaring custom model
2023-02-06 13:24:24,971:INFO:Linear Regression Imported successfully
2023-02-06 13:24:24,973:INFO:Cross validation set to False
2023-02-06 13:24:24,973:INFO:Fitting Model
2023-02-06 13:24:25,011:INFO:LinearRegression(n_jobs=-1)
2023-02-06 13:24:25,012:INFO:create_model() successfully completed......................................
2023-02-06 13:24:25,178:INFO:_master_model_container: 19
2023-02-06 13:24:25,178:INFO:_display_container: 2
2023-02-06 13:24:25,178:INFO:LinearRegression(n_jobs=-1)
2023-02-06 13:24:25,179:INFO:compare_models() successfully completed......................................
2023-02-06 13:24:31,697:INFO:Initializing create_model()
2023-02-06 13:24:31,698:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-06 13:24:31,698:INFO:Checking exceptions
2023-02-06 13:24:31,741:INFO:Importing libraries
2023-02-06 13:24:31,741:INFO:Copying training dataset
2023-02-06 13:24:31,751:INFO:Defining folds
2023-02-06 13:24:31,751:INFO:Declaring metric variables
2023-02-06 13:24:31,761:INFO:Importing untrained model
2023-02-06 13:24:31,766:INFO:Huber Regressor Imported successfully
2023-02-06 13:24:31,783:INFO:Starting cross validation
2023-02-06 13:24:31,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 13:24:32,360:INFO:Calculating mean and std
2023-02-06 13:24:32,361:INFO:Creating metrics dataframe
2023-02-06 13:24:32,367:INFO:Finalizing model
2023-02-06 13:24:32,417:INFO:Uploading results into container
2023-02-06 13:24:32,420:INFO:Uploading model into container now
2023-02-06 13:24:32,437:INFO:_master_model_container: 20
2023-02-06 13:24:32,437:INFO:_display_container: 3
2023-02-06 13:24:32,438:INFO:HuberRegressor()
2023-02-06 13:24:32,438:INFO:create_model() successfully completed......................................
2023-02-06 13:24:36,800:INFO:Initializing evaluate_model()
2023-02-06 13:24:36,800:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-06 13:24:36,828:INFO:Initializing plot_model()
2023-02-06 13:24:36,829:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, system=True)
2023-02-06 13:24:36,829:INFO:Checking exceptions
2023-02-06 13:24:36,836:INFO:Preloading libraries
2023-02-06 13:24:36,837:INFO:Copying training dataset
2023-02-06 13:24:36,837:INFO:Plot type: pipeline
2023-02-06 13:24:37,174:INFO:Visual Rendered Successfully
2023-02-06 13:24:37,291:INFO:plot_model() successfully completed......................................
2023-02-06 13:24:41,034:INFO:Initializing plot_model()
2023-02-06 13:24:41,035:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, system=True)
2023-02-06 13:24:41,035:INFO:Checking exceptions
2023-02-06 13:24:41,041:INFO:Preloading libraries
2023-02-06 13:24:41,041:INFO:Copying training dataset
2023-02-06 13:24:41,042:INFO:Plot type: parameter
2023-02-06 13:24:41,049:INFO:Visual Rendered Successfully
2023-02-06 13:24:41,174:INFO:plot_model() successfully completed......................................
2023-02-06 13:24:41,895:INFO:Initializing plot_model()
2023-02-06 13:24:41,896:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, system=True)
2023-02-06 13:24:41,896:INFO:Checking exceptions
2023-02-06 13:24:41,902:INFO:Preloading libraries
2023-02-06 13:24:41,903:INFO:Copying training dataset
2023-02-06 13:24:41,904:INFO:Plot type: residuals
2023-02-06 13:24:42,045:INFO:Fitting Model
2023-02-06 13:24:42,046:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2023-02-06 13:24:42,104:INFO:Scoring test/hold-out set
2023-02-06 13:24:42,889:INFO:Visual Rendered Successfully
2023-02-06 13:24:43,005:INFO:plot_model() successfully completed......................................
2023-02-06 13:24:46,748:INFO:Initializing predict_model()
2023-02-06 13:24:46,748:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4DA3251B0>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001B4836C3520>)
2023-02-06 13:24:46,749:INFO:Checking exceptions
2023-02-06 13:24:46,749:INFO:Preloading libraries
2023-02-06 13:24:46,753:INFO:Set up data.
2023-02-06 13:24:46,761:INFO:Set up index.
2023-02-06 16:33:30,803:INFO:PyCaret RegressionExperiment
2023-02-06 16:33:30,804:INFO:Logging name: reg-default-name
2023-02-06 16:33:30,805:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-06 16:33:30,805:INFO:version 3.0.0.rc8
2023-02-06 16:33:30,806:INFO:Initializing setup()
2023-02-06 16:33:30,806:INFO:self.USI: 120e
2023-02-06 16:33:30,807:INFO:self._variable_keys: {'log_plots_param', 'n_jobs_param', '_available_plots', 'y', 'exp_name_log', 'USI', 'html_param', 'logging_param', 'fold_shuffle_param', 'y_test', 'memory', 'seed', 'idx', 'fold_generator', 'X', '_ml_usecase', 'data', 'exp_id', 'X_train', 'gpu_n_jobs_param', 'pipeline', 'fold_groups_param', 'gpu_param', 'target_param', 'y_train', 'transform_target_param', 'X_test'}
2023-02-06 16:33:30,808:INFO:Checking environment
2023-02-06 16:33:30,808:INFO:python_version: 3.10.9
2023-02-06 16:33:30,809:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-02-06 16:33:30,810:INFO:machine: AMD64
2023-02-06 16:33:30,811:INFO:platform: Windows-10-10.0.19045-SP0
2023-02-06 16:33:30,812:INFO:Memory: svmem(total=17090879488, available=6271623168, percent=63.3, used=10819256320, free=6271623168)
2023-02-06 16:33:30,813:INFO:Physical Core: 4
2023-02-06 16:33:30,814:INFO:Logical Core: 8
2023-02-06 16:33:30,815:INFO:Checking libraries
2023-02-06 16:33:30,816:INFO:System:
2023-02-06 16:33:30,816:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-02-06 16:33:30,817:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-02-06 16:33:30,818:INFO:   machine: Windows-10-10.0.19045-SP0
2023-02-06 16:33:30,818:INFO:PyCaret required dependencies:
2023-02-06 16:33:30,820:INFO:                 pip: 23.0
2023-02-06 16:33:30,821:INFO:          setuptools: 67.1.0
2023-02-06 16:33:30,822:INFO:             pycaret: 3.0.0rc8
2023-02-06 16:33:30,823:INFO:             IPython: 8.8.0
2023-02-06 16:33:30,823:INFO:          ipywidgets: 8.0.4
2023-02-06 16:33:30,824:INFO:                tqdm: 4.64.1
2023-02-06 16:33:30,824:INFO:               numpy: 1.23.5
2023-02-06 16:33:30,825:INFO:              pandas: 1.5.3
2023-02-06 16:33:30,825:INFO:              jinja2: 3.1.2
2023-02-06 16:33:30,826:INFO:               scipy: 1.10.0
2023-02-06 16:33:30,827:INFO:              joblib: 1.2.0
2023-02-06 16:33:30,828:INFO:             sklearn: 1.1.3
2023-02-06 16:33:30,829:INFO:                pyod: 1.0.7
2023-02-06 16:33:30,830:INFO:            imblearn: 0.10.1
2023-02-06 16:33:30,831:INFO:   category_encoders: 2.6.0
2023-02-06 16:33:30,832:INFO:            lightgbm: 3.3.5
2023-02-06 16:33:30,832:INFO:               numba: 0.56.4
2023-02-06 16:33:30,833:INFO:            requests: 2.28.2
2023-02-06 16:33:30,833:INFO:          matplotlib: 3.6.3
2023-02-06 16:33:30,834:INFO:          scikitplot: 0.3.7
2023-02-06 16:33:30,835:INFO:         yellowbrick: 1.5
2023-02-06 16:33:30,835:INFO:              plotly: 5.13.0
2023-02-06 16:33:30,836:INFO:             kaleido: 0.2.1
2023-02-06 16:33:30,836:INFO:         statsmodels: 0.13.5
2023-02-06 16:33:30,837:INFO:              sktime: 0.16.0
2023-02-06 16:33:30,837:INFO:               tbats: 1.1.2
2023-02-06 16:33:30,838:INFO:            pmdarima: 2.0.2
2023-02-06 16:33:30,838:INFO:              psutil: 5.9.0
2023-02-06 16:33:30,838:INFO:PyCaret optional dependencies:
2023-02-06 16:33:30,838:INFO:                shap: Not installed
2023-02-06 16:33:30,839:INFO:           interpret: Not installed
2023-02-06 16:33:30,839:INFO:                umap: Not installed
2023-02-06 16:33:30,839:INFO:    pandas_profiling: Not installed
2023-02-06 16:33:30,839:INFO:  explainerdashboard: Not installed
2023-02-06 16:33:30,839:INFO:             autoviz: Not installed
2023-02-06 16:33:30,840:INFO:           fairlearn: Not installed
2023-02-06 16:33:30,840:INFO:             xgboost: 1.7.3
2023-02-06 16:33:30,840:INFO:            catboost: Not installed
2023-02-06 16:33:30,841:INFO:              kmodes: Not installed
2023-02-06 16:33:30,842:INFO:             mlxtend: Not installed
2023-02-06 16:33:30,842:INFO:       statsforecast: Not installed
2023-02-06 16:33:30,842:INFO:        tune_sklearn: Not installed
2023-02-06 16:33:30,843:INFO:                 ray: Not installed
2023-02-06 16:33:30,843:INFO:            hyperopt: Not installed
2023-02-06 16:33:30,844:INFO:              optuna: Not installed
2023-02-06 16:33:30,844:INFO:               skopt: Not installed
2023-02-06 16:33:30,844:INFO:              mlflow: Not installed
2023-02-06 16:33:30,845:INFO:              gradio: Not installed
2023-02-06 16:33:30,845:INFO:             fastapi: Not installed
2023-02-06 16:33:30,845:INFO:             uvicorn: Not installed
2023-02-06 16:33:30,845:INFO:              m2cgen: Not installed
2023-02-06 16:33:30,846:INFO:           evidently: Not installed
2023-02-06 16:33:30,847:INFO:                nltk: Not installed
2023-02-06 16:33:30,848:INFO:            pyLDAvis: Not installed
2023-02-06 16:33:30,849:INFO:              gensim: Not installed
2023-02-06 16:33:30,849:INFO:               spacy: Not installed
2023-02-06 16:33:30,849:INFO:           wordcloud: Not installed
2023-02-06 16:33:30,849:INFO:            textblob: Not installed
2023-02-06 16:33:30,850:INFO:               fugue: Not installed
2023-02-06 16:33:30,850:INFO:           streamlit: Not installed
2023-02-06 16:33:30,850:INFO:             prophet: Not installed
2023-02-06 16:33:30,850:INFO:None
2023-02-06 16:33:30,851:INFO:Set up GPU usage.
2023-02-06 16:33:30,852:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:30,852:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-02-06 16:33:30,853:INFO:Set up data.
2023-02-06 16:33:30,865:INFO:Set up train/test split.
2023-02-06 16:33:30,877:INFO:Set up index.
2023-02-06 16:33:30,877:INFO:Set up folding strategy.
2023-02-06 16:33:30,878:INFO:Assigning column types.
2023-02-06 16:33:30,887:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-06 16:33:30,888:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:30,889:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-06 16:33:30,890:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:30,899:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-06 16:33:30,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:30,908:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 16:33:30,908:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:30,992:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:30,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,053:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 16:33:31,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,056:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:31,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:31,586:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,586:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-06 16:33:31,587:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,600:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-06 16:33:31,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,613:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 16:33:31,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,739:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:31,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,816:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 16:33:31,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:31,818:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:32,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:32,012:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-06 16:33:32,012:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,012:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,022:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,038:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,151:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,151:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,214:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,215:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:32,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:32,433:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,433:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,446:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,469:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,470:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,594:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,672:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,673:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,673:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,675:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:32,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:32,841:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-06 16:33:32,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,868:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,868:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:32,993:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:32,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,065:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 16:33:33,065:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,065:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,066:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:33,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:33,230:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,230:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,257:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-06 16:33:33,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,376:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:33,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,437:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 16:33:33,437:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,437:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,438:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:33,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:33,613:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-06 16:33:33,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,646:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,770:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:33,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,836:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 16:33:33,836:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,836:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:33,837:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:34,010:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:34,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,040:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,158:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:34,158:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-06 16:33:34,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,216:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:34,381:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:34,382:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-06 16:33:34,382:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,395:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,537:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:34,537:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,611:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,611:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:34,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:34,777:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,777:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,807:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,932:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-06 16:33:34,932:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:34,996:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:35,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:35,157:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-06 16:33:35,158:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,158:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,172:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,308:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,399:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:35,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:35,571:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,571:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,717:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:35,776:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:35,953:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:35,956:INFO:Preparing preprocessing pipeline...
2023-02-06 16:33:35,958:INFO:Set up simple imputation.
2023-02-06 16:33:35,982:INFO:Finished creating preprocessing pipeline.
2023-02-06 16:33:35,996:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-02-06 16:33:35,996:INFO:Creating final display dataframe.
2023-02-06 16:33:36,112:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape          (962, 2)
4        Transformed data shape          (962, 2)
5   Transformed train set shape          (673, 2)
6    Transformed test set shape          (289, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              120e
2023-02-06 16:33:36,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,139:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,278:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:36,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:36,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,454:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,480:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,658:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,658:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-06 16:33:36,658:INFO:Soft dependency imported: xgboost: 1.7.3
2023-02-06 16:33:36,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-06 16:33:36,832:INFO:setup() successfully completed in 6.04s...............
2023-02-06 16:33:43,922:INFO:Initializing compare_models()
2023-02-06 16:33:43,923:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-06 16:33:43,923:INFO:Checking exceptions
2023-02-06 16:33:43,926:INFO:Preparing display monitor
2023-02-06 16:33:44,007:INFO:Initializing Linear Regression
2023-02-06 16:33:44,007:INFO:Total runtime is 0.0 minutes
2023-02-06 16:33:44,016:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:44,017:INFO:Initializing create_model()
2023-02-06 16:33:44,017:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:44,018:INFO:Checking exceptions
2023-02-06 16:33:44,018:INFO:Importing libraries
2023-02-06 16:33:44,019:INFO:Copying training dataset
2023-02-06 16:33:44,026:INFO:Defining folds
2023-02-06 16:33:44,026:INFO:Declaring metric variables
2023-02-06 16:33:44,034:INFO:Importing untrained model
2023-02-06 16:33:44,045:INFO:Linear Regression Imported successfully
2023-02-06 16:33:44,063:INFO:Starting cross validation
2023-02-06 16:33:44,066:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:44,478:INFO:Calculating mean and std
2023-02-06 16:33:44,479:INFO:Creating metrics dataframe
2023-02-06 16:33:44,483:INFO:Uploading results into container
2023-02-06 16:33:44,484:INFO:Uploading model into container now
2023-02-06 16:33:44,484:INFO:_master_model_container: 1
2023-02-06 16:33:44,484:INFO:_display_container: 2
2023-02-06 16:33:44,485:INFO:LinearRegression(n_jobs=-1)
2023-02-06 16:33:44,485:INFO:create_model() successfully completed......................................
2023-02-06 16:33:44,732:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:44,732:INFO:Creating metrics dataframe
2023-02-06 16:33:44,748:INFO:Initializing Lasso Regression
2023-02-06 16:33:44,748:INFO:Total runtime is 0.012342242399851482 minutes
2023-02-06 16:33:44,755:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:44,756:INFO:Initializing create_model()
2023-02-06 16:33:44,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:44,756:INFO:Checking exceptions
2023-02-06 16:33:44,757:INFO:Importing libraries
2023-02-06 16:33:44,757:INFO:Copying training dataset
2023-02-06 16:33:44,761:INFO:Defining folds
2023-02-06 16:33:44,761:INFO:Declaring metric variables
2023-02-06 16:33:44,767:INFO:Importing untrained model
2023-02-06 16:33:44,780:INFO:Lasso Regression Imported successfully
2023-02-06 16:33:44,800:INFO:Starting cross validation
2023-02-06 16:33:44,801:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:44,832:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.632e+08, tolerance: 1.978e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:44,883:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+08, tolerance: 1.993e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:44,921:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.045e+08, tolerance: 1.929e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:44,955:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.157e+08, tolerance: 2.040e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:44,993:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.967e+08, tolerance: 1.980e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:45,028:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.866e+08, tolerance: 2.009e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:45,063:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.263e+07, tolerance: 2.011e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:45,096:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.086e+08, tolerance: 2.004e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:45,132:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.600e+08, tolerance: 1.990e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:45,165:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.602e+08, tolerance: 2.033e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:45,180:INFO:Calculating mean and std
2023-02-06 16:33:45,182:INFO:Creating metrics dataframe
2023-02-06 16:33:45,191:INFO:Uploading results into container
2023-02-06 16:33:45,192:INFO:Uploading model into container now
2023-02-06 16:33:45,192:INFO:_master_model_container: 2
2023-02-06 16:33:45,193:INFO:_display_container: 2
2023-02-06 16:33:45,194:INFO:Lasso(random_state=123)
2023-02-06 16:33:45,194:INFO:create_model() successfully completed......................................
2023-02-06 16:33:45,325:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:45,325:INFO:Creating metrics dataframe
2023-02-06 16:33:45,341:INFO:Initializing Ridge Regression
2023-02-06 16:33:45,342:INFO:Total runtime is 0.022249281406402588 minutes
2023-02-06 16:33:45,347:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:45,348:INFO:Initializing create_model()
2023-02-06 16:33:45,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:45,348:INFO:Checking exceptions
2023-02-06 16:33:45,348:INFO:Importing libraries
2023-02-06 16:33:45,348:INFO:Copying training dataset
2023-02-06 16:33:45,356:INFO:Defining folds
2023-02-06 16:33:45,356:INFO:Declaring metric variables
2023-02-06 16:33:45,362:INFO:Importing untrained model
2023-02-06 16:33:45,369:INFO:Ridge Regression Imported successfully
2023-02-06 16:33:45,388:INFO:Starting cross validation
2023-02-06 16:33:45,390:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:45,692:INFO:Calculating mean and std
2023-02-06 16:33:45,694:INFO:Creating metrics dataframe
2023-02-06 16:33:45,698:INFO:Uploading results into container
2023-02-06 16:33:45,698:INFO:Uploading model into container now
2023-02-06 16:33:45,699:INFO:_master_model_container: 3
2023-02-06 16:33:45,699:INFO:_display_container: 2
2023-02-06 16:33:45,699:INFO:Ridge(random_state=123)
2023-02-06 16:33:45,699:INFO:create_model() successfully completed......................................
2023-02-06 16:33:45,813:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:45,813:INFO:Creating metrics dataframe
2023-02-06 16:33:45,829:INFO:Initializing Elastic Net
2023-02-06 16:33:45,829:INFO:Total runtime is 0.030365554491678874 minutes
2023-02-06 16:33:45,836:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:45,837:INFO:Initializing create_model()
2023-02-06 16:33:45,837:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:45,837:INFO:Checking exceptions
2023-02-06 16:33:45,837:INFO:Importing libraries
2023-02-06 16:33:45,837:INFO:Copying training dataset
2023-02-06 16:33:45,841:INFO:Defining folds
2023-02-06 16:33:45,842:INFO:Declaring metric variables
2023-02-06 16:33:45,847:INFO:Importing untrained model
2023-02-06 16:33:45,856:INFO:Elastic Net Imported successfully
2023-02-06 16:33:45,874:INFO:Starting cross validation
2023-02-06 16:33:45,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:45,901:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.823e+08, tolerance: 1.978e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:45,937:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.675e+08, tolerance: 1.993e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:45,970:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.480e+08, tolerance: 1.929e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:46,003:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.003e+08, tolerance: 2.040e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:46,033:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.984e+08, tolerance: 1.980e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:46,062:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.855e+08, tolerance: 2.009e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:46,100:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e+08, tolerance: 2.011e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:46,141:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.619e+08, tolerance: 2.004e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:46,180:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.329e+08, tolerance: 1.990e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:46,213:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.757e+08, tolerance: 2.033e+07
  model = cd_fast.enet_coordinate_descent(

2023-02-06 16:33:46,226:INFO:Calculating mean and std
2023-02-06 16:33:46,228:INFO:Creating metrics dataframe
2023-02-06 16:33:46,231:INFO:Uploading results into container
2023-02-06 16:33:46,232:INFO:Uploading model into container now
2023-02-06 16:33:46,233:INFO:_master_model_container: 4
2023-02-06 16:33:46,234:INFO:_display_container: 2
2023-02-06 16:33:46,235:INFO:ElasticNet(random_state=123)
2023-02-06 16:33:46,235:INFO:create_model() successfully completed......................................
2023-02-06 16:33:46,347:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:46,347:INFO:Creating metrics dataframe
2023-02-06 16:33:46,363:INFO:Initializing Least Angle Regression
2023-02-06 16:33:46,364:INFO:Total runtime is 0.0392874002456665 minutes
2023-02-06 16:33:46,375:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:46,375:INFO:Initializing create_model()
2023-02-06 16:33:46,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:46,376:INFO:Checking exceptions
2023-02-06 16:33:46,376:INFO:Importing libraries
2023-02-06 16:33:46,376:INFO:Copying training dataset
2023-02-06 16:33:46,381:INFO:Defining folds
2023-02-06 16:33:46,383:INFO:Declaring metric variables
2023-02-06 16:33:46,393:INFO:Importing untrained model
2023-02-06 16:33:46,398:INFO:Least Angle Regression Imported successfully
2023-02-06 16:33:46,418:INFO:Starting cross validation
2023-02-06 16:33:46,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:46,450:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,509:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,571:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,602:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,630:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,658:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,688:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,718:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,747:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,777:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:46,794:INFO:Calculating mean and std
2023-02-06 16:33:46,796:INFO:Creating metrics dataframe
2023-02-06 16:33:46,804:INFO:Uploading results into container
2023-02-06 16:33:46,805:INFO:Uploading model into container now
2023-02-06 16:33:46,806:INFO:_master_model_container: 5
2023-02-06 16:33:46,806:INFO:_display_container: 2
2023-02-06 16:33:46,807:INFO:Lars(random_state=123)
2023-02-06 16:33:46,807:INFO:create_model() successfully completed......................................
2023-02-06 16:33:46,931:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:46,931:INFO:Creating metrics dataframe
2023-02-06 16:33:46,947:INFO:Initializing Lasso Least Angle Regression
2023-02-06 16:33:46,947:INFO:Total runtime is 0.04899345239003499 minutes
2023-02-06 16:33:46,957:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:46,958:INFO:Initializing create_model()
2023-02-06 16:33:46,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:46,958:INFO:Checking exceptions
2023-02-06 16:33:46,958:INFO:Importing libraries
2023-02-06 16:33:46,959:INFO:Copying training dataset
2023-02-06 16:33:46,963:INFO:Defining folds
2023-02-06 16:33:46,963:INFO:Declaring metric variables
2023-02-06 16:33:46,972:INFO:Importing untrained model
2023-02-06 16:33:46,978:INFO:Lasso Least Angle Regression Imported successfully
2023-02-06 16:33:46,992:INFO:Starting cross validation
2023-02-06 16:33:46,993:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:47,019:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,054:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,080:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,110:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,138:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,166:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,196:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,235:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,273:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,309:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-02-06 16:33:47,324:INFO:Calculating mean and std
2023-02-06 16:33:47,325:INFO:Creating metrics dataframe
2023-02-06 16:33:47,330:INFO:Uploading results into container
2023-02-06 16:33:47,336:INFO:Uploading model into container now
2023-02-06 16:33:47,337:INFO:_master_model_container: 6
2023-02-06 16:33:47,338:INFO:_display_container: 2
2023-02-06 16:33:47,338:INFO:LassoLars(random_state=123)
2023-02-06 16:33:47,338:INFO:create_model() successfully completed......................................
2023-02-06 16:33:47,438:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:47,438:INFO:Creating metrics dataframe
2023-02-06 16:33:47,454:INFO:Initializing Orthogonal Matching Pursuit
2023-02-06 16:33:47,454:INFO:Total runtime is 0.057446106274922686 minutes
2023-02-06 16:33:47,459:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:47,459:INFO:Initializing create_model()
2023-02-06 16:33:47,459:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:47,460:INFO:Checking exceptions
2023-02-06 16:33:47,460:INFO:Importing libraries
2023-02-06 16:33:47,460:INFO:Copying training dataset
2023-02-06 16:33:47,464:INFO:Defining folds
2023-02-06 16:33:47,464:INFO:Declaring metric variables
2023-02-06 16:33:47,471:INFO:Importing untrained model
2023-02-06 16:33:47,475:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-06 16:33:47,487:INFO:Starting cross validation
2023-02-06 16:33:47,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:47,505:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,533:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,560:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,588:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,617:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,643:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,673:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,700:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,725:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,753:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-02-06 16:33:47,767:INFO:Calculating mean and std
2023-02-06 16:33:47,769:INFO:Creating metrics dataframe
2023-02-06 16:33:47,775:INFO:Uploading results into container
2023-02-06 16:33:47,775:INFO:Uploading model into container now
2023-02-06 16:33:47,776:INFO:_master_model_container: 7
2023-02-06 16:33:47,776:INFO:_display_container: 2
2023-02-06 16:33:47,776:INFO:OrthogonalMatchingPursuit()
2023-02-06 16:33:47,777:INFO:create_model() successfully completed......................................
2023-02-06 16:33:47,883:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:47,883:INFO:Creating metrics dataframe
2023-02-06 16:33:47,895:INFO:Initializing Bayesian Ridge
2023-02-06 16:33:47,896:INFO:Total runtime is 0.06480961243311564 minutes
2023-02-06 16:33:47,903:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:47,904:INFO:Initializing create_model()
2023-02-06 16:33:47,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:47,904:INFO:Checking exceptions
2023-02-06 16:33:47,904:INFO:Importing libraries
2023-02-06 16:33:47,904:INFO:Copying training dataset
2023-02-06 16:33:47,908:INFO:Defining folds
2023-02-06 16:33:47,909:INFO:Declaring metric variables
2023-02-06 16:33:47,915:INFO:Importing untrained model
2023-02-06 16:33:47,923:INFO:Bayesian Ridge Imported successfully
2023-02-06 16:33:47,935:INFO:Starting cross validation
2023-02-06 16:33:47,936:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:48,210:INFO:Calculating mean and std
2023-02-06 16:33:48,211:INFO:Creating metrics dataframe
2023-02-06 16:33:48,219:INFO:Uploading results into container
2023-02-06 16:33:48,220:INFO:Uploading model into container now
2023-02-06 16:33:48,220:INFO:_master_model_container: 8
2023-02-06 16:33:48,221:INFO:_display_container: 2
2023-02-06 16:33:48,221:INFO:BayesianRidge()
2023-02-06 16:33:48,221:INFO:create_model() successfully completed......................................
2023-02-06 16:33:48,320:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:48,320:INFO:Creating metrics dataframe
2023-02-06 16:33:48,337:INFO:Initializing Passive Aggressive Regressor
2023-02-06 16:33:48,337:INFO:Total runtime is 0.07216133673985799 minutes
2023-02-06 16:33:48,342:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:48,342:INFO:Initializing create_model()
2023-02-06 16:33:48,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:48,343:INFO:Checking exceptions
2023-02-06 16:33:48,343:INFO:Importing libraries
2023-02-06 16:33:48,343:INFO:Copying training dataset
2023-02-06 16:33:48,349:INFO:Defining folds
2023-02-06 16:33:48,349:INFO:Declaring metric variables
2023-02-06 16:33:48,356:INFO:Importing untrained model
2023-02-06 16:33:48,361:INFO:Passive Aggressive Regressor Imported successfully
2023-02-06 16:33:48,372:INFO:Starting cross validation
2023-02-06 16:33:48,373:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:48,677:INFO:Calculating mean and std
2023-02-06 16:33:48,681:INFO:Creating metrics dataframe
2023-02-06 16:33:48,688:INFO:Uploading results into container
2023-02-06 16:33:48,689:INFO:Uploading model into container now
2023-02-06 16:33:48,690:INFO:_master_model_container: 9
2023-02-06 16:33:48,690:INFO:_display_container: 2
2023-02-06 16:33:48,690:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-06 16:33:48,691:INFO:create_model() successfully completed......................................
2023-02-06 16:33:48,806:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:48,806:INFO:Creating metrics dataframe
2023-02-06 16:33:48,822:INFO:Initializing Huber Regressor
2023-02-06 16:33:48,822:INFO:Total runtime is 0.08025193214416504 minutes
2023-02-06 16:33:48,827:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:48,829:INFO:Initializing create_model()
2023-02-06 16:33:48,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:48,829:INFO:Checking exceptions
2023-02-06 16:33:48,829:INFO:Importing libraries
2023-02-06 16:33:48,829:INFO:Copying training dataset
2023-02-06 16:33:48,833:INFO:Defining folds
2023-02-06 16:33:48,834:INFO:Declaring metric variables
2023-02-06 16:33:48,840:INFO:Importing untrained model
2023-02-06 16:33:48,846:INFO:Huber Regressor Imported successfully
2023-02-06 16:33:48,859:INFO:Starting cross validation
2023-02-06 16:33:48,861:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:49,354:INFO:Calculating mean and std
2023-02-06 16:33:49,355:INFO:Creating metrics dataframe
2023-02-06 16:33:49,360:INFO:Uploading results into container
2023-02-06 16:33:49,362:INFO:Uploading model into container now
2023-02-06 16:33:49,363:INFO:_master_model_container: 10
2023-02-06 16:33:49,363:INFO:_display_container: 2
2023-02-06 16:33:49,365:INFO:HuberRegressor()
2023-02-06 16:33:49,365:INFO:create_model() successfully completed......................................
2023-02-06 16:33:49,502:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:49,502:INFO:Creating metrics dataframe
2023-02-06 16:33:49,520:INFO:Initializing K Neighbors Regressor
2023-02-06 16:33:49,520:INFO:Total runtime is 0.09188435077667237 minutes
2023-02-06 16:33:49,524:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:49,525:INFO:Initializing create_model()
2023-02-06 16:33:49,525:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:49,525:INFO:Checking exceptions
2023-02-06 16:33:49,525:INFO:Importing libraries
2023-02-06 16:33:49,526:INFO:Copying training dataset
2023-02-06 16:33:49,533:INFO:Defining folds
2023-02-06 16:33:49,533:INFO:Declaring metric variables
2023-02-06 16:33:49,541:INFO:Importing untrained model
2023-02-06 16:33:49,550:INFO:K Neighbors Regressor Imported successfully
2023-02-06 16:33:49,570:INFO:Starting cross validation
2023-02-06 16:33:49,572:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:55,658:INFO:Calculating mean and std
2023-02-06 16:33:55,659:INFO:Creating metrics dataframe
2023-02-06 16:33:55,663:INFO:Uploading results into container
2023-02-06 16:33:55,664:INFO:Uploading model into container now
2023-02-06 16:33:55,665:INFO:_master_model_container: 11
2023-02-06 16:33:55,665:INFO:_display_container: 2
2023-02-06 16:33:55,666:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-06 16:33:55,666:INFO:create_model() successfully completed......................................
2023-02-06 16:33:55,772:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:55,772:INFO:Creating metrics dataframe
2023-02-06 16:33:55,788:INFO:Initializing Decision Tree Regressor
2023-02-06 16:33:55,788:INFO:Total runtime is 0.19634258349736533 minutes
2023-02-06 16:33:55,792:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:55,793:INFO:Initializing create_model()
2023-02-06 16:33:55,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:55,793:INFO:Checking exceptions
2023-02-06 16:33:55,794:INFO:Importing libraries
2023-02-06 16:33:55,794:INFO:Copying training dataset
2023-02-06 16:33:55,798:INFO:Defining folds
2023-02-06 16:33:55,799:INFO:Declaring metric variables
2023-02-06 16:33:55,805:INFO:Importing untrained model
2023-02-06 16:33:55,811:INFO:Decision Tree Regressor Imported successfully
2023-02-06 16:33:55,827:INFO:Starting cross validation
2023-02-06 16:33:55,828:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:56,113:INFO:Calculating mean and std
2023-02-06 16:33:56,115:INFO:Creating metrics dataframe
2023-02-06 16:33:56,121:INFO:Uploading results into container
2023-02-06 16:33:56,122:INFO:Uploading model into container now
2023-02-06 16:33:56,123:INFO:_master_model_container: 12
2023-02-06 16:33:56,123:INFO:_display_container: 2
2023-02-06 16:33:56,124:INFO:DecisionTreeRegressor(random_state=123)
2023-02-06 16:33:56,124:INFO:create_model() successfully completed......................................
2023-02-06 16:33:56,231:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:56,232:INFO:Creating metrics dataframe
2023-02-06 16:33:56,255:INFO:Initializing Random Forest Regressor
2023-02-06 16:33:56,256:INFO:Total runtime is 0.2041469653447469 minutes
2023-02-06 16:33:56,262:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:56,262:INFO:Initializing create_model()
2023-02-06 16:33:56,262:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:56,263:INFO:Checking exceptions
2023-02-06 16:33:56,263:INFO:Importing libraries
2023-02-06 16:33:56,263:INFO:Copying training dataset
2023-02-06 16:33:56,269:INFO:Defining folds
2023-02-06 16:33:56,270:INFO:Declaring metric variables
2023-02-06 16:33:56,278:INFO:Importing untrained model
2023-02-06 16:33:56,289:INFO:Random Forest Regressor Imported successfully
2023-02-06 16:33:56,306:INFO:Starting cross validation
2023-02-06 16:33:56,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:33:58,584:INFO:Calculating mean and std
2023-02-06 16:33:58,585:INFO:Creating metrics dataframe
2023-02-06 16:33:58,589:INFO:Uploading results into container
2023-02-06 16:33:58,590:INFO:Uploading model into container now
2023-02-06 16:33:58,590:INFO:_master_model_container: 13
2023-02-06 16:33:58,591:INFO:_display_container: 2
2023-02-06 16:33:58,591:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-06 16:33:58,591:INFO:create_model() successfully completed......................................
2023-02-06 16:33:58,700:INFO:SubProcess create_model() end ==================================
2023-02-06 16:33:58,701:INFO:Creating metrics dataframe
2023-02-06 16:33:58,719:INFO:Initializing Extra Trees Regressor
2023-02-06 16:33:58,719:INFO:Total runtime is 0.2451942523320516 minutes
2023-02-06 16:33:58,724:INFO:SubProcess create_model() called ==================================
2023-02-06 16:33:58,724:INFO:Initializing create_model()
2023-02-06 16:33:58,725:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:33:58,725:INFO:Checking exceptions
2023-02-06 16:33:58,725:INFO:Importing libraries
2023-02-06 16:33:58,725:INFO:Copying training dataset
2023-02-06 16:33:58,730:INFO:Defining folds
2023-02-06 16:33:58,731:INFO:Declaring metric variables
2023-02-06 16:33:58,738:INFO:Importing untrained model
2023-02-06 16:33:58,745:INFO:Extra Trees Regressor Imported successfully
2023-02-06 16:33:58,760:INFO:Starting cross validation
2023-02-06 16:33:58,763:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:34:00,970:INFO:Calculating mean and std
2023-02-06 16:34:00,972:INFO:Creating metrics dataframe
2023-02-06 16:34:00,980:INFO:Uploading results into container
2023-02-06 16:34:00,981:INFO:Uploading model into container now
2023-02-06 16:34:00,982:INFO:_master_model_container: 14
2023-02-06 16:34:00,982:INFO:_display_container: 2
2023-02-06 16:34:00,983:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-06 16:34:00,983:INFO:create_model() successfully completed......................................
2023-02-06 16:34:01,099:INFO:SubProcess create_model() end ==================================
2023-02-06 16:34:01,099:INFO:Creating metrics dataframe
2023-02-06 16:34:01,120:INFO:Initializing AdaBoost Regressor
2023-02-06 16:34:01,120:INFO:Total runtime is 0.28521345059076947 minutes
2023-02-06 16:34:01,127:INFO:SubProcess create_model() called ==================================
2023-02-06 16:34:01,127:INFO:Initializing create_model()
2023-02-06 16:34:01,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:34:01,127:INFO:Checking exceptions
2023-02-06 16:34:01,128:INFO:Importing libraries
2023-02-06 16:34:01,128:INFO:Copying training dataset
2023-02-06 16:34:01,132:INFO:Defining folds
2023-02-06 16:34:01,133:INFO:Declaring metric variables
2023-02-06 16:34:01,139:INFO:Importing untrained model
2023-02-06 16:34:01,151:INFO:AdaBoost Regressor Imported successfully
2023-02-06 16:34:01,166:INFO:Starting cross validation
2023-02-06 16:34:01,167:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:34:01,876:INFO:Calculating mean and std
2023-02-06 16:34:01,877:INFO:Creating metrics dataframe
2023-02-06 16:34:01,881:INFO:Uploading results into container
2023-02-06 16:34:01,882:INFO:Uploading model into container now
2023-02-06 16:34:01,883:INFO:_master_model_container: 15
2023-02-06 16:34:01,883:INFO:_display_container: 2
2023-02-06 16:34:01,884:INFO:AdaBoostRegressor(random_state=123)
2023-02-06 16:34:01,884:INFO:create_model() successfully completed......................................
2023-02-06 16:34:01,989:INFO:SubProcess create_model() end ==================================
2023-02-06 16:34:01,990:INFO:Creating metrics dataframe
2023-02-06 16:34:02,008:INFO:Initializing Gradient Boosting Regressor
2023-02-06 16:34:02,008:INFO:Total runtime is 0.3000239491462708 minutes
2023-02-06 16:34:02,013:INFO:SubProcess create_model() called ==================================
2023-02-06 16:34:02,014:INFO:Initializing create_model()
2023-02-06 16:34:02,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:34:02,014:INFO:Checking exceptions
2023-02-06 16:34:02,014:INFO:Importing libraries
2023-02-06 16:34:02,014:INFO:Copying training dataset
2023-02-06 16:34:02,018:INFO:Defining folds
2023-02-06 16:34:02,019:INFO:Declaring metric variables
2023-02-06 16:34:02,026:INFO:Importing untrained model
2023-02-06 16:34:02,033:INFO:Gradient Boosting Regressor Imported successfully
2023-02-06 16:34:02,049:INFO:Starting cross validation
2023-02-06 16:34:02,050:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:34:02,816:INFO:Calculating mean and std
2023-02-06 16:34:02,817:INFO:Creating metrics dataframe
2023-02-06 16:34:02,823:INFO:Uploading results into container
2023-02-06 16:34:02,824:INFO:Uploading model into container now
2023-02-06 16:34:02,825:INFO:_master_model_container: 16
2023-02-06 16:34:02,825:INFO:_display_container: 2
2023-02-06 16:34:02,826:INFO:GradientBoostingRegressor(random_state=123)
2023-02-06 16:34:02,826:INFO:create_model() successfully completed......................................
2023-02-06 16:34:02,926:INFO:SubProcess create_model() end ==================================
2023-02-06 16:34:02,927:INFO:Creating metrics dataframe
2023-02-06 16:34:02,944:INFO:Initializing Extreme Gradient Boosting
2023-02-06 16:34:02,944:INFO:Total runtime is 0.31561100085576377 minutes
2023-02-06 16:34:02,949:INFO:SubProcess create_model() called ==================================
2023-02-06 16:34:02,949:INFO:Initializing create_model()
2023-02-06 16:34:02,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:34:02,950:INFO:Checking exceptions
2023-02-06 16:34:02,950:INFO:Importing libraries
2023-02-06 16:34:02,950:INFO:Copying training dataset
2023-02-06 16:34:02,955:INFO:Defining folds
2023-02-06 16:34:02,955:INFO:Declaring metric variables
2023-02-06 16:34:02,962:INFO:Importing untrained model
2023-02-06 16:34:02,969:INFO:Extreme Gradient Boosting Imported successfully
2023-02-06 16:34:02,988:INFO:Starting cross validation
2023-02-06 16:34:02,989:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:34:09,937:INFO:Calculating mean and std
2023-02-06 16:34:09,940:INFO:Creating metrics dataframe
2023-02-06 16:34:09,950:INFO:Uploading results into container
2023-02-06 16:34:09,952:INFO:Uploading model into container now
2023-02-06 16:34:09,953:INFO:_master_model_container: 17
2023-02-06 16:34:09,953:INFO:_display_container: 2
2023-02-06 16:34:09,956:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-02-06 16:34:09,956:INFO:create_model() successfully completed......................................
2023-02-06 16:34:10,090:INFO:SubProcess create_model() end ==================================
2023-02-06 16:34:10,090:INFO:Creating metrics dataframe
2023-02-06 16:34:10,110:INFO:Initializing Light Gradient Boosting Machine
2023-02-06 16:34:10,111:INFO:Total runtime is 0.4350594798723857 minutes
2023-02-06 16:34:10,117:INFO:SubProcess create_model() called ==================================
2023-02-06 16:34:10,117:INFO:Initializing create_model()
2023-02-06 16:34:10,117:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:34:10,117:INFO:Checking exceptions
2023-02-06 16:34:10,118:INFO:Importing libraries
2023-02-06 16:34:10,118:INFO:Copying training dataset
2023-02-06 16:34:10,122:INFO:Defining folds
2023-02-06 16:34:10,122:INFO:Declaring metric variables
2023-02-06 16:34:10,131:INFO:Importing untrained model
2023-02-06 16:34:10,137:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-06 16:34:10,149:INFO:Starting cross validation
2023-02-06 16:34:10,151:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:34:17,872:INFO:Calculating mean and std
2023-02-06 16:34:17,875:INFO:Creating metrics dataframe
2023-02-06 16:34:17,887:INFO:Uploading results into container
2023-02-06 16:34:17,888:INFO:Uploading model into container now
2023-02-06 16:34:17,889:INFO:_master_model_container: 18
2023-02-06 16:34:17,889:INFO:_display_container: 2
2023-02-06 16:34:17,890:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-02-06 16:34:17,891:INFO:create_model() successfully completed......................................
2023-02-06 16:34:18,025:INFO:SubProcess create_model() end ==================================
2023-02-06 16:34:18,025:INFO:Creating metrics dataframe
2023-02-06 16:34:18,045:INFO:Initializing Dummy Regressor
2023-02-06 16:34:18,045:INFO:Total runtime is 0.5672948320706686 minutes
2023-02-06 16:34:18,051:INFO:SubProcess create_model() called ==================================
2023-02-06 16:34:18,052:INFO:Initializing create_model()
2023-02-06 16:34:18,052:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B48369EB30>, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:34:18,052:INFO:Checking exceptions
2023-02-06 16:34:18,052:INFO:Importing libraries
2023-02-06 16:34:18,052:INFO:Copying training dataset
2023-02-06 16:34:18,056:INFO:Defining folds
2023-02-06 16:34:18,057:INFO:Declaring metric variables
2023-02-06 16:34:18,063:INFO:Importing untrained model
2023-02-06 16:34:18,070:INFO:Dummy Regressor Imported successfully
2023-02-06 16:34:18,085:INFO:Starting cross validation
2023-02-06 16:34:18,087:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:34:18,340:INFO:Calculating mean and std
2023-02-06 16:34:18,342:INFO:Creating metrics dataframe
2023-02-06 16:34:18,348:INFO:Uploading results into container
2023-02-06 16:34:18,348:INFO:Uploading model into container now
2023-02-06 16:34:18,349:INFO:_master_model_container: 19
2023-02-06 16:34:18,349:INFO:_display_container: 2
2023-02-06 16:34:18,350:INFO:DummyRegressor()
2023-02-06 16:34:18,350:INFO:create_model() successfully completed......................................
2023-02-06 16:34:18,453:INFO:SubProcess create_model() end ==================================
2023-02-06 16:34:18,453:INFO:Creating metrics dataframe
2023-02-06 16:34:18,488:INFO:Initializing create_model()
2023-02-06 16:34:18,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:34:18,489:INFO:Checking exceptions
2023-02-06 16:34:18,491:INFO:Importing libraries
2023-02-06 16:34:18,491:INFO:Copying training dataset
2023-02-06 16:34:18,497:INFO:Defining folds
2023-02-06 16:34:18,497:INFO:Declaring metric variables
2023-02-06 16:34:18,498:INFO:Importing untrained model
2023-02-06 16:34:18,498:INFO:Declaring custom model
2023-02-06 16:34:18,499:INFO:Linear Regression Imported successfully
2023-02-06 16:34:18,501:INFO:Cross validation set to False
2023-02-06 16:34:18,501:INFO:Fitting Model
2023-02-06 16:34:18,518:INFO:LinearRegression(n_jobs=-1)
2023-02-06 16:34:18,518:INFO:create_model() successfully completed......................................
2023-02-06 16:34:18,686:INFO:_master_model_container: 19
2023-02-06 16:34:18,687:INFO:_display_container: 2
2023-02-06 16:34:18,687:INFO:LinearRegression(n_jobs=-1)
2023-02-06 16:34:18,688:INFO:compare_models() successfully completed......................................
2023-02-06 16:34:21,464:INFO:Initializing create_model()
2023-02-06 16:34:21,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-06 16:34:21,465:INFO:Checking exceptions
2023-02-06 16:34:21,508:INFO:Importing libraries
2023-02-06 16:34:21,508:INFO:Copying training dataset
2023-02-06 16:34:21,518:INFO:Defining folds
2023-02-06 16:34:21,519:INFO:Declaring metric variables
2023-02-06 16:34:21,527:INFO:Importing untrained model
2023-02-06 16:34:21,534:INFO:Huber Regressor Imported successfully
2023-02-06 16:34:21,551:INFO:Starting cross validation
2023-02-06 16:34:21,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-02-06 16:34:22,014:INFO:Calculating mean and std
2023-02-06 16:34:22,015:INFO:Creating metrics dataframe
2023-02-06 16:34:22,021:INFO:Finalizing model
2023-02-06 16:34:22,050:INFO:Uploading results into container
2023-02-06 16:34:22,052:INFO:Uploading model into container now
2023-02-06 16:34:22,076:INFO:_master_model_container: 20
2023-02-06 16:34:22,076:INFO:_display_container: 3
2023-02-06 16:34:22,077:INFO:HuberRegressor()
2023-02-06 16:34:22,078:INFO:create_model() successfully completed......................................
2023-02-06 16:34:26,335:INFO:Initializing predict_model()
2023-02-06 16:34:26,335:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B4FF418BE0>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001B483675CF0>)
2023-02-06 16:34:26,335:INFO:Checking exceptions
2023-02-06 16:34:26,335:INFO:Preloading libraries
2023-02-06 16:34:26,338:INFO:Set up data.
2023-02-06 16:34:26,344:INFO:Set up index.
2023-05-12 14:51:35,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:35,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:35,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:35,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:37,274:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-12 14:51:41,283:INFO:PyCaret RegressionExperiment
2023-05-12 14:51:41,284:INFO:Logging name: reg-default-name
2023-05-12 14:51:41,284:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-12 14:51:41,285:INFO:version 3.0.0.rc8
2023-05-12 14:51:41,285:INFO:Initializing setup()
2023-05-12 14:51:41,285:INFO:self.USI: 713a
2023-05-12 14:51:41,286:INFO:self._variable_keys: {'target_param', 'y', 'X_train', 'fold_generator', 'X', 'idx', 'n_jobs_param', 'y_test', 'X_test', 'memory', '_available_plots', 'logging_param', 'gpu_param', 'data', 'seed', 'exp_name_log', '_ml_usecase', 'exp_id', 'pipeline', 'fold_groups_param', 'y_train', 'html_param', 'gpu_n_jobs_param', 'USI', 'fold_shuffle_param', 'log_plots_param', 'transform_target_param'}
2023-05-12 14:51:41,286:INFO:Checking environment
2023-05-12 14:51:41,287:INFO:python_version: 3.10.9
2023-05-12 14:51:41,288:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-05-12 14:51:41,289:INFO:machine: AMD64
2023-05-12 14:51:41,289:INFO:platform: Windows-10-10.0.19045-SP0
2023-05-12 14:51:41,290:INFO:Memory: svmem(total=17090879488, available=3019161600, percent=82.3, used=14071717888, free=3019161600)
2023-05-12 14:51:41,290:INFO:Physical Core: 4
2023-05-12 14:51:41,290:INFO:Logical Core: 8
2023-05-12 14:51:41,291:INFO:Checking libraries
2023-05-12 14:51:41,291:INFO:System:
2023-05-12 14:51:41,291:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-05-12 14:51:41,292:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-05-12 14:51:41,292:INFO:   machine: Windows-10-10.0.19045-SP0
2023-05-12 14:51:41,292:INFO:PyCaret required dependencies:
2023-05-12 14:51:41,293:INFO:                 pip: 23.0
2023-05-12 14:51:41,293:INFO:          setuptools: 67.1.0
2023-05-12 14:51:41,294:INFO:             pycaret: 3.0.0rc8
2023-05-12 14:51:41,294:INFO:             IPython: 8.8.0
2023-05-12 14:51:41,294:INFO:          ipywidgets: 8.0.4
2023-05-12 14:51:41,295:INFO:                tqdm: 4.64.1
2023-05-12 14:51:41,295:INFO:               numpy: 1.23.5
2023-05-12 14:51:41,295:INFO:              pandas: 1.5.3
2023-05-12 14:51:41,296:INFO:              jinja2: 3.1.2
2023-05-12 14:51:41,296:INFO:               scipy: 1.10.0
2023-05-12 14:51:41,296:INFO:              joblib: 1.2.0
2023-05-12 14:51:41,297:INFO:             sklearn: 1.1.3
2023-05-12 14:51:41,297:INFO:                pyod: 1.0.7
2023-05-12 14:51:41,297:INFO:            imblearn: 0.10.1
2023-05-12 14:51:41,298:INFO:   category_encoders: 2.6.0
2023-05-12 14:51:41,298:INFO:            lightgbm: 3.3.5
2023-05-12 14:51:41,298:INFO:               numba: 0.56.4
2023-05-12 14:51:41,298:INFO:            requests: 2.28.2
2023-05-12 14:51:41,298:INFO:          matplotlib: 3.6.3
2023-05-12 14:51:41,298:INFO:          scikitplot: 0.3.7
2023-05-12 14:51:41,298:INFO:         yellowbrick: 1.5
2023-05-12 14:51:41,298:INFO:              plotly: 5.13.0
2023-05-12 14:51:41,298:INFO:             kaleido: 0.2.1
2023-05-12 14:51:41,299:INFO:         statsmodels: 0.13.5
2023-05-12 14:51:41,299:INFO:              sktime: 0.16.0
2023-05-12 14:51:41,299:INFO:               tbats: 1.1.2
2023-05-12 14:51:41,299:INFO:            pmdarima: 2.0.2
2023-05-12 14:51:41,299:INFO:              psutil: 5.9.0
2023-05-12 14:51:41,299:INFO:PyCaret optional dependencies:
2023-05-12 14:51:41,330:INFO:                shap: Not installed
2023-05-12 14:51:41,331:INFO:           interpret: Not installed
2023-05-12 14:51:41,331:INFO:                umap: Not installed
2023-05-12 14:51:41,331:INFO:    pandas_profiling: Not installed
2023-05-12 14:51:41,331:INFO:  explainerdashboard: Not installed
2023-05-12 14:51:41,331:INFO:             autoviz: Not installed
2023-05-12 14:51:41,331:INFO:           fairlearn: Not installed
2023-05-12 14:51:41,331:INFO:             xgboost: 1.7.3
2023-05-12 14:51:41,331:INFO:            catboost: Not installed
2023-05-12 14:51:41,331:INFO:              kmodes: Not installed
2023-05-12 14:51:41,331:INFO:             mlxtend: Not installed
2023-05-12 14:51:41,331:INFO:       statsforecast: Not installed
2023-05-12 14:51:41,331:INFO:        tune_sklearn: Not installed
2023-05-12 14:51:41,331:INFO:                 ray: Not installed
2023-05-12 14:51:41,331:INFO:            hyperopt: Not installed
2023-05-12 14:51:41,332:INFO:              optuna: Not installed
2023-05-12 14:51:41,332:INFO:               skopt: Not installed
2023-05-12 14:51:41,332:INFO:              mlflow: Not installed
2023-05-12 14:51:41,332:INFO:              gradio: Not installed
2023-05-12 14:51:41,332:INFO:             fastapi: Not installed
2023-05-12 14:51:41,332:INFO:             uvicorn: Not installed
2023-05-12 14:51:41,332:INFO:              m2cgen: Not installed
2023-05-12 14:51:41,332:INFO:           evidently: Not installed
2023-05-12 14:51:41,332:INFO:                nltk: Not installed
2023-05-12 14:51:41,332:INFO:            pyLDAvis: Not installed
2023-05-12 14:51:41,332:INFO:              gensim: Not installed
2023-05-12 14:51:41,332:INFO:               spacy: Not installed
2023-05-12 14:51:41,332:INFO:           wordcloud: Not installed
2023-05-12 14:51:41,332:INFO:            textblob: Not installed
2023-05-12 14:51:41,332:INFO:               fugue: Not installed
2023-05-12 14:51:41,332:INFO:           streamlit: Not installed
2023-05-12 14:51:41,333:INFO:             prophet: Not installed
2023-05-12 14:51:41,333:INFO:None
2023-05-12 14:51:41,333:INFO:Set up GPU usage.
2023-05-12 14:51:41,333:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:41,333:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-05-12 14:51:41,333:INFO:Set up data.
2023-05-12 14:51:41,339:INFO:Set up train/test split.
2023-05-12 14:51:41,343:INFO:Set up index.
2023-05-12 14:51:41,344:INFO:Set up folding strategy.
2023-05-12 14:51:41,344:INFO:Assigning column types.
2023-05-12 14:51:41,347:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-12 14:51:41,348:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:41,348:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 14:51:41,348:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:41,359:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 14:51:41,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:41,370:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:51:41,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:41,441:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:41,441:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:41,494:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:51:41,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:41,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:41,495:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:43,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:43,307:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,307:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,307:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,320:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,331:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,440:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,440:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,492:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,492:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,492:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,493:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:43,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:43,666:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-12 14:51:43,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,678:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,679:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,690:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,802:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,856:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:51:43,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,857:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:43,857:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:44,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:44,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,053:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,066:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,067:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,176:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,176:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,230:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,231:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,231:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,232:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:44,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:44,420:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-12 14:51:44,420:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,420:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,445:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,446:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,557:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,611:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,612:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:44,800:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:44,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,827:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,943:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,997:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:51:44,997:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,997:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:44,998:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:45,176:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:45,176:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-12 14:51:45,177:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,177:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,190:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,202:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,315:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:45,315:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,375:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:51:45,375:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,375:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,379:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:45,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:45,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,561:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,574:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,689:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:45,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,745:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:51:45,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,746:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:45,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:45,934:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-12 14:51:45,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,935:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:45,959:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,072:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:46,073:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,130:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:46,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:46,317:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,317:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,454:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:51:46,454:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,508:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,508:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,508:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:46,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:46,666:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-12 14:51:46,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,694:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:46,855:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:47,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:47,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,057:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,226:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,227:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:47,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:47,411:INFO:Preparing preprocessing pipeline...
2023-05-12 14:51:47,412:INFO:Set up simple imputation.
2023-05-12 14:51:47,472:INFO:Finished creating preprocessing pipeline.
2023-05-12 14:51:47,483:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-05-12 14:51:47,483:INFO:Creating final display dataframe.
2023-05-12 14:51:47,687:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape         (1042, 2)
4        Transformed data shape         (1042, 2)
5   Transformed train set shape          (729, 2)
6    Transformed test set shape          (313, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              713a
2023-05-12 14:51:47,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,704:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,777:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,830:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:47,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:47,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:47,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:48,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:48,020:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:48,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:48,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:48,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:51:48,186:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:51:48,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:51:48,362:INFO:setup() successfully completed in 7.08s...............
2023-05-12 14:51:48,414:INFO:Initializing compare_models()
2023-05-12 14:51:48,414:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-12 14:51:48,414:INFO:Checking exceptions
2023-05-12 14:51:48,419:INFO:Preparing display monitor
2023-05-12 14:51:48,479:INFO:Initializing Linear Regression
2023-05-12 14:51:48,479:INFO:Total runtime is 0.0 minutes
2023-05-12 14:51:48,487:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:48,488:INFO:Initializing create_model()
2023-05-12 14:51:48,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:48,488:INFO:Checking exceptions
2023-05-12 14:51:48,488:INFO:Importing libraries
2023-05-12 14:51:48,489:INFO:Copying training dataset
2023-05-12 14:51:48,492:INFO:Defining folds
2023-05-12 14:51:48,492:INFO:Declaring metric variables
2023-05-12 14:51:48,497:INFO:Importing untrained model
2023-05-12 14:51:48,503:INFO:Linear Regression Imported successfully
2023-05-12 14:51:48,515:INFO:Starting cross validation
2023-05-12 14:51:48,530:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:49,400:INFO:Calculating mean and std
2023-05-12 14:51:49,401:INFO:Creating metrics dataframe
2023-05-12 14:51:49,407:INFO:Uploading results into container
2023-05-12 14:51:49,408:INFO:Uploading model into container now
2023-05-12 14:51:49,408:INFO:_master_model_container: 1
2023-05-12 14:51:49,408:INFO:_display_container: 2
2023-05-12 14:51:49,408:INFO:LinearRegression(n_jobs=-1)
2023-05-12 14:51:49,408:INFO:create_model() successfully completed......................................
2023-05-12 14:51:49,511:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:49,512:INFO:Creating metrics dataframe
2023-05-12 14:51:49,527:INFO:Initializing Lasso Regression
2023-05-12 14:51:49,527:INFO:Total runtime is 0.01746841271718343 minutes
2023-05-12 14:51:49,534:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:49,535:INFO:Initializing create_model()
2023-05-12 14:51:49,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:49,536:INFO:Checking exceptions
2023-05-12 14:51:49,536:INFO:Importing libraries
2023-05-12 14:51:49,536:INFO:Copying training dataset
2023-05-12 14:51:49,540:INFO:Defining folds
2023-05-12 14:51:49,541:INFO:Declaring metric variables
2023-05-12 14:51:49,549:INFO:Importing untrained model
2023-05-12 14:51:49,559:INFO:Lasso Regression Imported successfully
2023-05-12 14:51:49,571:INFO:Starting cross validation
2023-05-12 14:51:49,572:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:49,608:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.228e+08, tolerance: 1.948e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,653:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.926e+08, tolerance: 1.970e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,696:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.543e+08, tolerance: 1.940e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,736:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.701e+08, tolerance: 1.938e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,775:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.060e+08, tolerance: 1.941e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,814:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.280e+08, tolerance: 1.951e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,859:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.429e+08, tolerance: 1.974e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,898:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.178e+08, tolerance: 1.907e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,938:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.602e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,978:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.286e+08, tolerance: 1.982e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:49,995:INFO:Calculating mean and std
2023-05-12 14:51:49,996:INFO:Creating metrics dataframe
2023-05-12 14:51:50,000:INFO:Uploading results into container
2023-05-12 14:51:50,001:INFO:Uploading model into container now
2023-05-12 14:51:50,002:INFO:_master_model_container: 2
2023-05-12 14:51:50,002:INFO:_display_container: 2
2023-05-12 14:51:50,002:INFO:Lasso(random_state=123)
2023-05-12 14:51:50,003:INFO:create_model() successfully completed......................................
2023-05-12 14:51:50,085:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:50,085:INFO:Creating metrics dataframe
2023-05-12 14:51:50,097:INFO:Initializing Ridge Regression
2023-05-12 14:51:50,097:INFO:Total runtime is 0.026957058906555177 minutes
2023-05-12 14:51:50,103:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:50,104:INFO:Initializing create_model()
2023-05-12 14:51:50,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:50,104:INFO:Checking exceptions
2023-05-12 14:51:50,104:INFO:Importing libraries
2023-05-12 14:51:50,104:INFO:Copying training dataset
2023-05-12 14:51:50,108:INFO:Defining folds
2023-05-12 14:51:50,108:INFO:Declaring metric variables
2023-05-12 14:51:50,114:INFO:Importing untrained model
2023-05-12 14:51:50,120:INFO:Ridge Regression Imported successfully
2023-05-12 14:51:50,130:INFO:Starting cross validation
2023-05-12 14:51:50,131:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:50,384:INFO:Calculating mean and std
2023-05-12 14:51:50,386:INFO:Creating metrics dataframe
2023-05-12 14:51:50,392:INFO:Uploading results into container
2023-05-12 14:51:50,393:INFO:Uploading model into container now
2023-05-12 14:51:50,394:INFO:_master_model_container: 3
2023-05-12 14:51:50,394:INFO:_display_container: 2
2023-05-12 14:51:50,395:INFO:Ridge(random_state=123)
2023-05-12 14:51:50,395:INFO:create_model() successfully completed......................................
2023-05-12 14:51:50,482:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:50,482:INFO:Creating metrics dataframe
2023-05-12 14:51:50,500:INFO:Initializing Elastic Net
2023-05-12 14:51:50,500:INFO:Total runtime is 0.03367509444554647 minutes
2023-05-12 14:51:50,506:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:50,506:INFO:Initializing create_model()
2023-05-12 14:51:50,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:50,507:INFO:Checking exceptions
2023-05-12 14:51:50,507:INFO:Importing libraries
2023-05-12 14:51:50,507:INFO:Copying training dataset
2023-05-12 14:51:50,512:INFO:Defining folds
2023-05-12 14:51:50,513:INFO:Declaring metric variables
2023-05-12 14:51:50,520:INFO:Importing untrained model
2023-05-12 14:51:50,527:INFO:Elastic Net Imported successfully
2023-05-12 14:51:50,538:INFO:Starting cross validation
2023-05-12 14:51:50,539:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:50,561:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.219e+08, tolerance: 1.948e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,589:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.152e+08, tolerance: 1.970e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,621:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.940e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,645:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.927e+08, tolerance: 1.938e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,669:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.434e+08, tolerance: 1.941e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,693:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.622e+08, tolerance: 1.951e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,717:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.840e+08, tolerance: 1.974e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,743:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.019e+08, tolerance: 1.907e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,766:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.858e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,790:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.022e+08, tolerance: 1.982e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:51:50,800:INFO:Calculating mean and std
2023-05-12 14:51:50,801:INFO:Creating metrics dataframe
2023-05-12 14:51:50,806:INFO:Uploading results into container
2023-05-12 14:51:50,807:INFO:Uploading model into container now
2023-05-12 14:51:50,807:INFO:_master_model_container: 4
2023-05-12 14:51:50,808:INFO:_display_container: 2
2023-05-12 14:51:50,808:INFO:ElasticNet(random_state=123)
2023-05-12 14:51:50,809:INFO:create_model() successfully completed......................................
2023-05-12 14:51:50,885:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:50,886:INFO:Creating metrics dataframe
2023-05-12 14:51:50,898:INFO:Initializing Least Angle Regression
2023-05-12 14:51:50,898:INFO:Total runtime is 0.04031027952829997 minutes
2023-05-12 14:51:50,903:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:50,904:INFO:Initializing create_model()
2023-05-12 14:51:50,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:50,904:INFO:Checking exceptions
2023-05-12 14:51:50,904:INFO:Importing libraries
2023-05-12 14:51:50,905:INFO:Copying training dataset
2023-05-12 14:51:50,908:INFO:Defining folds
2023-05-12 14:51:50,909:INFO:Declaring metric variables
2023-05-12 14:51:50,914:INFO:Importing untrained model
2023-05-12 14:51:50,920:INFO:Least Angle Regression Imported successfully
2023-05-12 14:51:50,929:INFO:Starting cross validation
2023-05-12 14:51:50,930:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:50,951:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:50,977:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,000:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,024:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,046:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,067:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,090:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,112:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,137:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,158:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,170:INFO:Calculating mean and std
2023-05-12 14:51:51,171:INFO:Creating metrics dataframe
2023-05-12 14:51:51,174:INFO:Uploading results into container
2023-05-12 14:51:51,175:INFO:Uploading model into container now
2023-05-12 14:51:51,176:INFO:_master_model_container: 5
2023-05-12 14:51:51,176:INFO:_display_container: 2
2023-05-12 14:51:51,177:INFO:Lars(random_state=123)
2023-05-12 14:51:51,177:INFO:create_model() successfully completed......................................
2023-05-12 14:51:51,255:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:51,255:INFO:Creating metrics dataframe
2023-05-12 14:51:51,268:INFO:Initializing Lasso Least Angle Regression
2023-05-12 14:51:51,268:INFO:Total runtime is 0.0464728315671285 minutes
2023-05-12 14:51:51,274:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:51,274:INFO:Initializing create_model()
2023-05-12 14:51:51,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:51,275:INFO:Checking exceptions
2023-05-12 14:51:51,275:INFO:Importing libraries
2023-05-12 14:51:51,275:INFO:Copying training dataset
2023-05-12 14:51:51,278:INFO:Defining folds
2023-05-12 14:51:51,279:INFO:Declaring metric variables
2023-05-12 14:51:51,284:INFO:Importing untrained model
2023-05-12 14:51:51,289:INFO:Lasso Least Angle Regression Imported successfully
2023-05-12 14:51:51,298:INFO:Starting cross validation
2023-05-12 14:51:51,299:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:51,312:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,333:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,360:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,382:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,405:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,427:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,450:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,473:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,495:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,517:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:51:51,528:INFO:Calculating mean and std
2023-05-12 14:51:51,529:INFO:Creating metrics dataframe
2023-05-12 14:51:51,532:INFO:Uploading results into container
2023-05-12 14:51:51,533:INFO:Uploading model into container now
2023-05-12 14:51:51,534:INFO:_master_model_container: 6
2023-05-12 14:51:51,534:INFO:_display_container: 2
2023-05-12 14:51:51,535:INFO:LassoLars(random_state=123)
2023-05-12 14:51:51,536:INFO:create_model() successfully completed......................................
2023-05-12 14:51:51,615:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:51,615:INFO:Creating metrics dataframe
2023-05-12 14:51:51,630:INFO:Initializing Orthogonal Matching Pursuit
2023-05-12 14:51:51,630:INFO:Total runtime is 0.05250598986943563 minutes
2023-05-12 14:51:51,635:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:51,636:INFO:Initializing create_model()
2023-05-12 14:51:51,636:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:51,636:INFO:Checking exceptions
2023-05-12 14:51:51,636:INFO:Importing libraries
2023-05-12 14:51:51,636:INFO:Copying training dataset
2023-05-12 14:51:51,640:INFO:Defining folds
2023-05-12 14:51:51,640:INFO:Declaring metric variables
2023-05-12 14:51:51,644:INFO:Importing untrained model
2023-05-12 14:51:51,652:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-12 14:51:51,680:INFO:Starting cross validation
2023-05-12 14:51:51,682:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:51,711:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,737:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,759:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,781:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,804:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,827:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,848:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,871:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,893:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,915:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:51:51,928:INFO:Calculating mean and std
2023-05-12 14:51:51,929:INFO:Creating metrics dataframe
2023-05-12 14:51:51,934:INFO:Uploading results into container
2023-05-12 14:51:51,935:INFO:Uploading model into container now
2023-05-12 14:51:51,936:INFO:_master_model_container: 7
2023-05-12 14:51:51,936:INFO:_display_container: 2
2023-05-12 14:51:51,936:INFO:OrthogonalMatchingPursuit()
2023-05-12 14:51:51,937:INFO:create_model() successfully completed......................................
2023-05-12 14:51:52,015:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:52,016:INFO:Creating metrics dataframe
2023-05-12 14:51:52,029:INFO:Initializing Bayesian Ridge
2023-05-12 14:51:52,029:INFO:Total runtime is 0.05916630029678345 minutes
2023-05-12 14:51:52,035:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:52,035:INFO:Initializing create_model()
2023-05-12 14:51:52,035:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:52,035:INFO:Checking exceptions
2023-05-12 14:51:52,036:INFO:Importing libraries
2023-05-12 14:51:52,036:INFO:Copying training dataset
2023-05-12 14:51:52,039:INFO:Defining folds
2023-05-12 14:51:52,040:INFO:Declaring metric variables
2023-05-12 14:51:52,045:INFO:Importing untrained model
2023-05-12 14:51:52,051:INFO:Bayesian Ridge Imported successfully
2023-05-12 14:51:52,060:INFO:Starting cross validation
2023-05-12 14:51:52,061:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:52,292:INFO:Calculating mean and std
2023-05-12 14:51:52,293:INFO:Creating metrics dataframe
2023-05-12 14:51:52,297:INFO:Uploading results into container
2023-05-12 14:51:52,298:INFO:Uploading model into container now
2023-05-12 14:51:52,298:INFO:_master_model_container: 8
2023-05-12 14:51:52,299:INFO:_display_container: 2
2023-05-12 14:51:52,299:INFO:BayesianRidge()
2023-05-12 14:51:52,300:INFO:create_model() successfully completed......................................
2023-05-12 14:51:52,380:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:52,380:INFO:Creating metrics dataframe
2023-05-12 14:51:52,395:INFO:Initializing Passive Aggressive Regressor
2023-05-12 14:51:52,396:INFO:Total runtime is 0.06528769731521607 minutes
2023-05-12 14:51:52,401:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:52,401:INFO:Initializing create_model()
2023-05-12 14:51:52,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:52,401:INFO:Checking exceptions
2023-05-12 14:51:52,401:INFO:Importing libraries
2023-05-12 14:51:52,402:INFO:Copying training dataset
2023-05-12 14:51:52,406:INFO:Defining folds
2023-05-12 14:51:52,406:INFO:Declaring metric variables
2023-05-12 14:51:52,411:INFO:Importing untrained model
2023-05-12 14:51:52,416:INFO:Passive Aggressive Regressor Imported successfully
2023-05-12 14:51:52,426:INFO:Starting cross validation
2023-05-12 14:51:52,427:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:52,644:INFO:Calculating mean and std
2023-05-12 14:51:52,646:INFO:Creating metrics dataframe
2023-05-12 14:51:52,649:INFO:Uploading results into container
2023-05-12 14:51:52,650:INFO:Uploading model into container now
2023-05-12 14:51:52,652:INFO:_master_model_container: 9
2023-05-12 14:51:52,652:INFO:_display_container: 2
2023-05-12 14:51:52,652:INFO:PassiveAggressiveRegressor(random_state=123)
2023-05-12 14:51:52,652:INFO:create_model() successfully completed......................................
2023-05-12 14:51:52,729:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:52,730:INFO:Creating metrics dataframe
2023-05-12 14:51:52,745:INFO:Initializing Huber Regressor
2023-05-12 14:51:52,745:INFO:Total runtime is 0.07110445102055868 minutes
2023-05-12 14:51:52,750:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:52,750:INFO:Initializing create_model()
2023-05-12 14:51:52,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:52,752:INFO:Checking exceptions
2023-05-12 14:51:52,752:INFO:Importing libraries
2023-05-12 14:51:52,752:INFO:Copying training dataset
2023-05-12 14:51:52,755:INFO:Defining folds
2023-05-12 14:51:52,755:INFO:Declaring metric variables
2023-05-12 14:51:52,760:INFO:Importing untrained model
2023-05-12 14:51:52,767:INFO:Huber Regressor Imported successfully
2023-05-12 14:51:52,775:INFO:Starting cross validation
2023-05-12 14:51:52,776:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:53,044:INFO:Calculating mean and std
2023-05-12 14:51:53,046:INFO:Creating metrics dataframe
2023-05-12 14:51:53,049:INFO:Uploading results into container
2023-05-12 14:51:53,050:INFO:Uploading model into container now
2023-05-12 14:51:53,051:INFO:_master_model_container: 10
2023-05-12 14:51:53,051:INFO:_display_container: 2
2023-05-12 14:51:53,052:INFO:HuberRegressor()
2023-05-12 14:51:53,052:INFO:create_model() successfully completed......................................
2023-05-12 14:51:53,129:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:53,129:INFO:Creating metrics dataframe
2023-05-12 14:51:53,143:INFO:Initializing K Neighbors Regressor
2023-05-12 14:51:53,143:INFO:Total runtime is 0.07772698799769084 minutes
2023-05-12 14:51:53,147:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:53,148:INFO:Initializing create_model()
2023-05-12 14:51:53,148:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:53,148:INFO:Checking exceptions
2023-05-12 14:51:53,148:INFO:Importing libraries
2023-05-12 14:51:53,149:INFO:Copying training dataset
2023-05-12 14:51:53,153:INFO:Defining folds
2023-05-12 14:51:53,153:INFO:Declaring metric variables
2023-05-12 14:51:53,171:INFO:Importing untrained model
2023-05-12 14:51:53,182:INFO:K Neighbors Regressor Imported successfully
2023-05-12 14:51:53,196:INFO:Starting cross validation
2023-05-12 14:51:53,198:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:58,476:INFO:Calculating mean and std
2023-05-12 14:51:58,477:INFO:Creating metrics dataframe
2023-05-12 14:51:58,481:INFO:Uploading results into container
2023-05-12 14:51:58,481:INFO:Uploading model into container now
2023-05-12 14:51:58,482:INFO:_master_model_container: 11
2023-05-12 14:51:58,483:INFO:_display_container: 2
2023-05-12 14:51:58,484:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-12 14:51:58,484:INFO:create_model() successfully completed......................................
2023-05-12 14:51:58,569:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:58,569:INFO:Creating metrics dataframe
2023-05-12 14:51:58,584:INFO:Initializing Decision Tree Regressor
2023-05-12 14:51:58,584:INFO:Total runtime is 0.16841310660044354 minutes
2023-05-12 14:51:58,588:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:58,589:INFO:Initializing create_model()
2023-05-12 14:51:58,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:58,589:INFO:Checking exceptions
2023-05-12 14:51:58,589:INFO:Importing libraries
2023-05-12 14:51:58,589:INFO:Copying training dataset
2023-05-12 14:51:58,593:INFO:Defining folds
2023-05-12 14:51:58,594:INFO:Declaring metric variables
2023-05-12 14:51:58,598:INFO:Importing untrained model
2023-05-12 14:51:58,605:INFO:Decision Tree Regressor Imported successfully
2023-05-12 14:51:58,615:INFO:Starting cross validation
2023-05-12 14:51:58,617:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:51:58,854:INFO:Calculating mean and std
2023-05-12 14:51:58,855:INFO:Creating metrics dataframe
2023-05-12 14:51:58,859:INFO:Uploading results into container
2023-05-12 14:51:58,860:INFO:Uploading model into container now
2023-05-12 14:51:58,861:INFO:_master_model_container: 12
2023-05-12 14:51:58,861:INFO:_display_container: 2
2023-05-12 14:51:58,861:INFO:DecisionTreeRegressor(random_state=123)
2023-05-12 14:51:58,862:INFO:create_model() successfully completed......................................
2023-05-12 14:51:58,941:INFO:SubProcess create_model() end ==================================
2023-05-12 14:51:58,941:INFO:Creating metrics dataframe
2023-05-12 14:51:58,957:INFO:Initializing Random Forest Regressor
2023-05-12 14:51:58,957:INFO:Total runtime is 0.17462968031565348 minutes
2023-05-12 14:51:58,962:INFO:SubProcess create_model() called ==================================
2023-05-12 14:51:58,963:INFO:Initializing create_model()
2023-05-12 14:51:58,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:51:58,963:INFO:Checking exceptions
2023-05-12 14:51:58,963:INFO:Importing libraries
2023-05-12 14:51:58,963:INFO:Copying training dataset
2023-05-12 14:51:58,968:INFO:Defining folds
2023-05-12 14:51:58,968:INFO:Declaring metric variables
2023-05-12 14:51:58,975:INFO:Importing untrained model
2023-05-12 14:51:58,980:INFO:Random Forest Regressor Imported successfully
2023-05-12 14:51:58,991:INFO:Starting cross validation
2023-05-12 14:51:58,992:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:52:01,406:INFO:Calculating mean and std
2023-05-12 14:52:01,407:INFO:Creating metrics dataframe
2023-05-12 14:52:01,411:INFO:Uploading results into container
2023-05-12 14:52:01,412:INFO:Uploading model into container now
2023-05-12 14:52:01,412:INFO:_master_model_container: 13
2023-05-12 14:52:01,412:INFO:_display_container: 2
2023-05-12 14:52:01,413:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-05-12 14:52:01,413:INFO:create_model() successfully completed......................................
2023-05-12 14:52:01,492:INFO:SubProcess create_model() end ==================================
2023-05-12 14:52:01,492:INFO:Creating metrics dataframe
2023-05-12 14:52:01,508:INFO:Initializing Extra Trees Regressor
2023-05-12 14:52:01,509:INFO:Total runtime is 0.21714743773142497 minutes
2023-05-12 14:52:01,514:INFO:SubProcess create_model() called ==================================
2023-05-12 14:52:01,514:INFO:Initializing create_model()
2023-05-12 14:52:01,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:52:01,514:INFO:Checking exceptions
2023-05-12 14:52:01,515:INFO:Importing libraries
2023-05-12 14:52:01,515:INFO:Copying training dataset
2023-05-12 14:52:01,518:INFO:Defining folds
2023-05-12 14:52:01,519:INFO:Declaring metric variables
2023-05-12 14:52:01,524:INFO:Importing untrained model
2023-05-12 14:52:01,530:INFO:Extra Trees Regressor Imported successfully
2023-05-12 14:52:01,539:INFO:Starting cross validation
2023-05-12 14:52:01,540:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:52:03,588:INFO:Calculating mean and std
2023-05-12 14:52:03,590:INFO:Creating metrics dataframe
2023-05-12 14:52:03,594:INFO:Uploading results into container
2023-05-12 14:52:03,596:INFO:Uploading model into container now
2023-05-12 14:52:03,597:INFO:_master_model_container: 14
2023-05-12 14:52:03,597:INFO:_display_container: 2
2023-05-12 14:52:03,598:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-05-12 14:52:03,599:INFO:create_model() successfully completed......................................
2023-05-12 14:52:03,681:INFO:SubProcess create_model() end ==================================
2023-05-12 14:52:03,682:INFO:Creating metrics dataframe
2023-05-12 14:52:03,705:INFO:Initializing AdaBoost Regressor
2023-05-12 14:52:03,705:INFO:Total runtime is 0.2537640929222107 minutes
2023-05-12 14:52:03,713:INFO:SubProcess create_model() called ==================================
2023-05-12 14:52:03,713:INFO:Initializing create_model()
2023-05-12 14:52:03,714:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:52:03,714:INFO:Checking exceptions
2023-05-12 14:52:03,714:INFO:Importing libraries
2023-05-12 14:52:03,714:INFO:Copying training dataset
2023-05-12 14:52:03,720:INFO:Defining folds
2023-05-12 14:52:03,721:INFO:Declaring metric variables
2023-05-12 14:52:03,729:INFO:Importing untrained model
2023-05-12 14:52:03,737:INFO:AdaBoost Regressor Imported successfully
2023-05-12 14:52:03,746:INFO:Starting cross validation
2023-05-12 14:52:03,748:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:52:04,546:INFO:Calculating mean and std
2023-05-12 14:52:04,548:INFO:Creating metrics dataframe
2023-05-12 14:52:04,555:INFO:Uploading results into container
2023-05-12 14:52:04,556:INFO:Uploading model into container now
2023-05-12 14:52:04,558:INFO:_master_model_container: 15
2023-05-12 14:52:04,558:INFO:_display_container: 2
2023-05-12 14:52:04,559:INFO:AdaBoostRegressor(random_state=123)
2023-05-12 14:52:04,559:INFO:create_model() successfully completed......................................
2023-05-12 14:52:04,667:INFO:SubProcess create_model() end ==================================
2023-05-12 14:52:04,667:INFO:Creating metrics dataframe
2023-05-12 14:52:04,690:INFO:Initializing Gradient Boosting Regressor
2023-05-12 14:52:04,691:INFO:Total runtime is 0.27019739548365274 minutes
2023-05-12 14:52:04,697:INFO:SubProcess create_model() called ==================================
2023-05-12 14:52:04,698:INFO:Initializing create_model()
2023-05-12 14:52:04,698:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:52:04,699:INFO:Checking exceptions
2023-05-12 14:52:04,699:INFO:Importing libraries
2023-05-12 14:52:04,699:INFO:Copying training dataset
2023-05-12 14:52:04,705:INFO:Defining folds
2023-05-12 14:52:04,705:INFO:Declaring metric variables
2023-05-12 14:52:04,713:INFO:Importing untrained model
2023-05-12 14:52:04,722:INFO:Gradient Boosting Regressor Imported successfully
2023-05-12 14:52:04,740:INFO:Starting cross validation
2023-05-12 14:52:04,742:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:52:05,977:INFO:Calculating mean and std
2023-05-12 14:52:05,982:INFO:Creating metrics dataframe
2023-05-12 14:52:05,991:INFO:Uploading results into container
2023-05-12 14:52:05,993:INFO:Uploading model into container now
2023-05-12 14:52:05,994:INFO:_master_model_container: 16
2023-05-12 14:52:05,994:INFO:_display_container: 2
2023-05-12 14:52:05,995:INFO:GradientBoostingRegressor(random_state=123)
2023-05-12 14:52:05,995:INFO:create_model() successfully completed......................................
2023-05-12 14:52:06,124:INFO:SubProcess create_model() end ==================================
2023-05-12 14:52:06,124:INFO:Creating metrics dataframe
2023-05-12 14:52:06,158:INFO:Initializing Extreme Gradient Boosting
2023-05-12 14:52:06,159:INFO:Total runtime is 0.29466408491134644 minutes
2023-05-12 14:52:06,169:INFO:SubProcess create_model() called ==================================
2023-05-12 14:52:06,170:INFO:Initializing create_model()
2023-05-12 14:52:06,170:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:52:06,170:INFO:Checking exceptions
2023-05-12 14:52:06,171:INFO:Importing libraries
2023-05-12 14:52:06,171:INFO:Copying training dataset
2023-05-12 14:52:06,180:INFO:Defining folds
2023-05-12 14:52:06,180:INFO:Declaring metric variables
2023-05-12 14:52:06,190:INFO:Importing untrained model
2023-05-12 14:52:06,200:INFO:Extreme Gradient Boosting Imported successfully
2023-05-12 14:52:06,217:INFO:Starting cross validation
2023-05-12 14:52:06,219:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:52:12,139:INFO:Calculating mean and std
2023-05-12 14:52:12,142:INFO:Creating metrics dataframe
2023-05-12 14:52:12,151:INFO:Uploading results into container
2023-05-12 14:52:12,152:INFO:Uploading model into container now
2023-05-12 14:52:12,153:INFO:_master_model_container: 17
2023-05-12 14:52:12,153:INFO:_display_container: 2
2023-05-12 14:52:12,156:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-05-12 14:52:12,156:INFO:create_model() successfully completed......................................
2023-05-12 14:52:12,271:INFO:SubProcess create_model() end ==================================
2023-05-12 14:52:12,271:INFO:Creating metrics dataframe
2023-05-12 14:52:12,290:INFO:Initializing Light Gradient Boosting Machine
2023-05-12 14:52:12,290:INFO:Total runtime is 0.3968480110168457 minutes
2023-05-12 14:52:12,296:INFO:SubProcess create_model() called ==================================
2023-05-12 14:52:12,297:INFO:Initializing create_model()
2023-05-12 14:52:12,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:52:12,297:INFO:Checking exceptions
2023-05-12 14:52:12,297:INFO:Importing libraries
2023-05-12 14:52:12,298:INFO:Copying training dataset
2023-05-12 14:52:12,303:INFO:Defining folds
2023-05-12 14:52:12,303:INFO:Declaring metric variables
2023-05-12 14:52:12,309:INFO:Importing untrained model
2023-05-12 14:52:12,316:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-12 14:52:12,327:INFO:Starting cross validation
2023-05-12 14:52:12,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:52:21,513:INFO:Calculating mean and std
2023-05-12 14:52:21,518:INFO:Creating metrics dataframe
2023-05-12 14:52:21,526:INFO:Uploading results into container
2023-05-12 14:52:21,528:INFO:Uploading model into container now
2023-05-12 14:52:21,529:INFO:_master_model_container: 18
2023-05-12 14:52:21,529:INFO:_display_container: 2
2023-05-12 14:52:21,530:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-05-12 14:52:21,530:INFO:create_model() successfully completed......................................
2023-05-12 14:52:21,645:INFO:SubProcess create_model() end ==================================
2023-05-12 14:52:21,645:INFO:Creating metrics dataframe
2023-05-12 14:52:21,661:INFO:Initializing Dummy Regressor
2023-05-12 14:52:21,661:INFO:Total runtime is 0.5530237158139546 minutes
2023-05-12 14:52:21,666:INFO:SubProcess create_model() called ==================================
2023-05-12 14:52:21,666:INFO:Initializing create_model()
2023-05-12 14:52:21,666:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025CCF46DC30>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:52:21,667:INFO:Checking exceptions
2023-05-12 14:52:21,667:INFO:Importing libraries
2023-05-12 14:52:21,667:INFO:Copying training dataset
2023-05-12 14:52:21,671:INFO:Defining folds
2023-05-12 14:52:21,671:INFO:Declaring metric variables
2023-05-12 14:52:21,677:INFO:Importing untrained model
2023-05-12 14:52:21,682:INFO:Dummy Regressor Imported successfully
2023-05-12 14:52:21,692:INFO:Starting cross validation
2023-05-12 14:52:21,694:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:52:21,887:INFO:Calculating mean and std
2023-05-12 14:52:21,888:INFO:Creating metrics dataframe
2023-05-12 14:52:21,892:INFO:Uploading results into container
2023-05-12 14:52:21,893:INFO:Uploading model into container now
2023-05-12 14:52:21,894:INFO:_master_model_container: 19
2023-05-12 14:52:21,894:INFO:_display_container: 2
2023-05-12 14:52:21,895:INFO:DummyRegressor()
2023-05-12 14:52:21,895:INFO:create_model() successfully completed......................................
2023-05-12 14:52:21,973:INFO:SubProcess create_model() end ==================================
2023-05-12 14:52:21,974:INFO:Creating metrics dataframe
2023-05-12 14:52:22,003:INFO:Initializing create_model()
2023-05-12 14:52:22,004:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:52:22,004:INFO:Checking exceptions
2023-05-12 14:52:22,006:INFO:Importing libraries
2023-05-12 14:52:22,007:INFO:Copying training dataset
2023-05-12 14:52:22,009:INFO:Defining folds
2023-05-12 14:52:22,009:INFO:Declaring metric variables
2023-05-12 14:52:22,010:INFO:Importing untrained model
2023-05-12 14:52:22,010:INFO:Declaring custom model
2023-05-12 14:52:22,010:INFO:Linear Regression Imported successfully
2023-05-12 14:52:22,011:INFO:Cross validation set to False
2023-05-12 14:52:22,011:INFO:Fitting Model
2023-05-12 14:52:22,040:INFO:LinearRegression(n_jobs=-1)
2023-05-12 14:52:22,040:INFO:create_model() successfully completed......................................
2023-05-12 14:52:22,168:INFO:_master_model_container: 19
2023-05-12 14:52:22,168:INFO:_display_container: 2
2023-05-12 14:52:22,168:INFO:LinearRegression(n_jobs=-1)
2023-05-12 14:52:22,169:INFO:compare_models() successfully completed......................................
2023-05-12 14:52:22,306:INFO:Initializing create_model()
2023-05-12 14:52:22,306:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:52:22,306:INFO:Checking exceptions
2023-05-12 14:52:22,364:INFO:Importing libraries
2023-05-12 14:52:22,364:INFO:Copying training dataset
2023-05-12 14:52:22,369:INFO:Defining folds
2023-05-12 14:52:22,370:INFO:Declaring metric variables
2023-05-12 14:52:22,376:INFO:Importing untrained model
2023-05-12 14:52:22,387:INFO:Huber Regressor Imported successfully
2023-05-12 14:52:22,404:INFO:Starting cross validation
2023-05-12 14:52:22,406:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:52:22,749:INFO:Calculating mean and std
2023-05-12 14:52:22,749:INFO:Creating metrics dataframe
2023-05-12 14:52:22,756:INFO:Finalizing model
2023-05-12 14:52:22,794:INFO:Uploading results into container
2023-05-12 14:52:22,796:INFO:Uploading model into container now
2023-05-12 14:52:22,809:INFO:_master_model_container: 20
2023-05-12 14:52:22,809:INFO:_display_container: 3
2023-05-12 14:52:22,810:INFO:HuberRegressor()
2023-05-12 14:52:22,810:INFO:create_model() successfully completed......................................
2023-05-12 14:52:23,024:INFO:Initializing evaluate_model()
2023-05-12 14:52:23,025:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-05-12 14:52:23,058:INFO:Initializing plot_model()
2023-05-12 14:52:23,058:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, system=True)
2023-05-12 14:52:23,059:INFO:Checking exceptions
2023-05-12 14:52:23,062:INFO:Preloading libraries
2023-05-12 14:52:23,062:INFO:Copying training dataset
2023-05-12 14:52:23,062:INFO:Plot type: pipeline
2023-05-12 14:52:23,321:INFO:Visual Rendered Successfully
2023-05-12 14:52:23,417:INFO:plot_model() successfully completed......................................
2023-05-12 14:52:23,518:INFO:Initializing predict_model()
2023-05-12 14:52:23,518:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025CF396ECE0>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000025CF781BEB0>)
2023-05-12 14:52:23,518:INFO:Checking exceptions
2023-05-12 14:52:23,518:INFO:Preloading libraries
2023-05-12 14:52:23,522:INFO:Set up data.
2023-05-12 14:52:23,532:INFO:Set up index.
2023-05-12 14:55:09,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:09,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:09,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:09,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:11,043:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-12 14:55:13,937:INFO:PyCaret RegressionExperiment
2023-05-12 14:55:13,938:INFO:Logging name: reg-default-name
2023-05-12 14:55:13,939:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-12 14:55:13,940:INFO:version 3.0.0.rc8
2023-05-12 14:55:13,941:INFO:Initializing setup()
2023-05-12 14:55:13,942:INFO:self.USI: 4fe9
2023-05-12 14:55:13,943:INFO:self._variable_keys: {'html_param', 'memory', '_available_plots', 'seed', 'idx', 'fold_groups_param', 'X', 'data', 'y_test', 'gpu_param', 'exp_name_log', 'exp_id', 'X_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'logging_param', 'USI', 'log_plots_param', 'y', 'n_jobs_param', '_ml_usecase', 'y_train', 'fold_generator', 'transform_target_param', 'pipeline', 'X_train', 'target_param'}
2023-05-12 14:55:13,944:INFO:Checking environment
2023-05-12 14:55:13,944:INFO:python_version: 3.10.9
2023-05-12 14:55:13,945:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-05-12 14:55:13,945:INFO:machine: AMD64
2023-05-12 14:55:13,945:INFO:platform: Windows-10-10.0.19045-SP0
2023-05-12 14:55:13,946:INFO:Memory: svmem(total=17090879488, available=2996797440, percent=82.5, used=14094082048, free=2996797440)
2023-05-12 14:55:13,946:INFO:Physical Core: 4
2023-05-12 14:55:13,946:INFO:Logical Core: 8
2023-05-12 14:55:13,946:INFO:Checking libraries
2023-05-12 14:55:13,947:INFO:System:
2023-05-12 14:55:13,947:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-05-12 14:55:13,947:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-05-12 14:55:13,947:INFO:   machine: Windows-10-10.0.19045-SP0
2023-05-12 14:55:13,948:INFO:PyCaret required dependencies:
2023-05-12 14:55:13,948:INFO:                 pip: 23.0
2023-05-12 14:55:13,948:INFO:          setuptools: 67.1.0
2023-05-12 14:55:13,948:INFO:             pycaret: 3.0.0rc8
2023-05-12 14:55:13,949:INFO:             IPython: 8.8.0
2023-05-12 14:55:13,949:INFO:          ipywidgets: 8.0.4
2023-05-12 14:55:13,949:INFO:                tqdm: 4.64.1
2023-05-12 14:55:13,949:INFO:               numpy: 1.23.5
2023-05-12 14:55:13,949:INFO:              pandas: 1.5.3
2023-05-12 14:55:13,949:INFO:              jinja2: 3.1.2
2023-05-12 14:55:13,949:INFO:               scipy: 1.10.0
2023-05-12 14:55:13,950:INFO:              joblib: 1.2.0
2023-05-12 14:55:13,950:INFO:             sklearn: 1.1.3
2023-05-12 14:55:13,950:INFO:                pyod: 1.0.7
2023-05-12 14:55:13,950:INFO:            imblearn: 0.10.1
2023-05-12 14:55:13,950:INFO:   category_encoders: 2.6.0
2023-05-12 14:55:13,950:INFO:            lightgbm: 3.3.5
2023-05-12 14:55:13,950:INFO:               numba: 0.56.4
2023-05-12 14:55:13,950:INFO:            requests: 2.28.2
2023-05-12 14:55:13,951:INFO:          matplotlib: 3.6.3
2023-05-12 14:55:13,951:INFO:          scikitplot: 0.3.7
2023-05-12 14:55:13,951:INFO:         yellowbrick: 1.5
2023-05-12 14:55:13,951:INFO:              plotly: 5.13.0
2023-05-12 14:55:13,951:INFO:             kaleido: 0.2.1
2023-05-12 14:55:13,951:INFO:         statsmodels: 0.13.5
2023-05-12 14:55:13,951:INFO:              sktime: 0.16.0
2023-05-12 14:55:13,951:INFO:               tbats: 1.1.2
2023-05-12 14:55:13,952:INFO:            pmdarima: 2.0.2
2023-05-12 14:55:13,952:INFO:              psutil: 5.9.0
2023-05-12 14:55:13,952:INFO:PyCaret optional dependencies:
2023-05-12 14:55:13,986:INFO:                shap: Not installed
2023-05-12 14:55:13,986:INFO:           interpret: Not installed
2023-05-12 14:55:13,986:INFO:                umap: Not installed
2023-05-12 14:55:13,986:INFO:    pandas_profiling: Not installed
2023-05-12 14:55:13,986:INFO:  explainerdashboard: Not installed
2023-05-12 14:55:13,986:INFO:             autoviz: Not installed
2023-05-12 14:55:13,986:INFO:           fairlearn: Not installed
2023-05-12 14:55:13,987:INFO:             xgboost: 1.7.3
2023-05-12 14:55:13,987:INFO:            catboost: Not installed
2023-05-12 14:55:13,987:INFO:              kmodes: Not installed
2023-05-12 14:55:13,987:INFO:             mlxtend: Not installed
2023-05-12 14:55:13,987:INFO:       statsforecast: Not installed
2023-05-12 14:55:13,987:INFO:        tune_sklearn: Not installed
2023-05-12 14:55:13,987:INFO:                 ray: Not installed
2023-05-12 14:55:13,987:INFO:            hyperopt: Not installed
2023-05-12 14:55:13,987:INFO:              optuna: Not installed
2023-05-12 14:55:13,987:INFO:               skopt: Not installed
2023-05-12 14:55:13,987:INFO:              mlflow: Not installed
2023-05-12 14:55:13,987:INFO:              gradio: Not installed
2023-05-12 14:55:13,987:INFO:             fastapi: Not installed
2023-05-12 14:55:13,987:INFO:             uvicorn: Not installed
2023-05-12 14:55:13,988:INFO:              m2cgen: Not installed
2023-05-12 14:55:13,988:INFO:           evidently: Not installed
2023-05-12 14:55:13,988:INFO:                nltk: Not installed
2023-05-12 14:55:13,988:INFO:            pyLDAvis: Not installed
2023-05-12 14:55:13,988:INFO:              gensim: Not installed
2023-05-12 14:55:13,988:INFO:               spacy: Not installed
2023-05-12 14:55:13,988:INFO:           wordcloud: Not installed
2023-05-12 14:55:13,988:INFO:            textblob: Not installed
2023-05-12 14:55:13,988:INFO:               fugue: Not installed
2023-05-12 14:55:13,988:INFO:           streamlit: Not installed
2023-05-12 14:55:13,988:INFO:             prophet: Not installed
2023-05-12 14:55:13,988:INFO:None
2023-05-12 14:55:13,988:INFO:Set up GPU usage.
2023-05-12 14:55:13,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:13,988:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-05-12 14:55:13,989:INFO:Set up data.
2023-05-12 14:55:13,993:INFO:Set up train/test split.
2023-05-12 14:55:13,995:INFO:Set up index.
2023-05-12 14:55:13,995:INFO:Set up folding strategy.
2023-05-12 14:55:13,996:INFO:Assigning column types.
2023-05-12 14:55:13,999:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-12 14:55:13,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:13,999:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 14:55:13,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,005:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,010:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,089:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,089:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,144:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,145:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:14,522:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:14,523:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,523:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,537:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,552:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,552:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,666:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,717:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,717:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,718:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,718:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:14,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:14,900:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-12 14:55:14,900:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,901:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,913:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,913:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:14,925:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:55:14,925:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,034:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,090:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,091:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:15,310:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:15,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,326:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,340:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,341:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,465:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,465:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,544:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,546:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:15,713:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:15,714:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-12 14:55:15,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,727:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,739:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,862:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,925:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:55:15,925:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,926:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:15,927:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:16,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:16,092:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,117:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 14:55:16,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,227:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:16,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,279:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:55:16,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,281:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:16,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:16,449:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-12 14:55:16,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,477:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,584:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:16,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,639:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:55:16,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,643:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:16,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:16,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,847:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:16,970:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:16,971:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,040:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 14:55:17,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,042:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:17,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:17,228:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-12 14:55:17,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,365:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:17,366:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,425:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,425:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,426:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:17,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:17,590:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,740:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 14:55:17,740:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,794:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:17,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:17,972:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-12 14:55:17,972:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:17,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,110:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,162:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,162:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,162:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:18,329:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:18,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,344:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,471:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,522:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,523:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,523:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:18,688:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:18,691:INFO:Preparing preprocessing pipeline...
2023-05-12 14:55:18,693:INFO:Set up simple imputation.
2023-05-12 14:55:18,759:INFO:Finished creating preprocessing pipeline.
2023-05-12 14:55:18,769:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-05-12 14:55:18,769:INFO:Creating final display dataframe.
2023-05-12 14:55:18,969:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape          (731, 2)
4        Transformed data shape          (731, 2)
5   Transformed train set shape          (511, 2)
6    Transformed test set shape          (220, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              4fe9
2023-05-12 14:55:18,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,978:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:18,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,120:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:19,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:19,312:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,340:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,450:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 14:55:19,506:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 14:55:19,679:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 14:55:19,681:INFO:setup() successfully completed in 5.75s...............
2023-05-12 14:55:19,719:INFO:Initializing compare_models()
2023-05-12 14:55:19,720:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-12 14:55:19,720:INFO:Checking exceptions
2023-05-12 14:55:19,724:INFO:Preparing display monitor
2023-05-12 14:55:19,795:INFO:Initializing Linear Regression
2023-05-12 14:55:19,795:INFO:Total runtime is 0.0 minutes
2023-05-12 14:55:19,803:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:19,803:INFO:Initializing create_model()
2023-05-12 14:55:19,804:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:19,804:INFO:Checking exceptions
2023-05-12 14:55:19,804:INFO:Importing libraries
2023-05-12 14:55:19,804:INFO:Copying training dataset
2023-05-12 14:55:19,808:INFO:Defining folds
2023-05-12 14:55:19,808:INFO:Declaring metric variables
2023-05-12 14:55:19,813:INFO:Importing untrained model
2023-05-12 14:55:19,819:INFO:Linear Regression Imported successfully
2023-05-12 14:55:19,830:INFO:Starting cross validation
2023-05-12 14:55:19,840:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:20,671:INFO:Calculating mean and std
2023-05-12 14:55:20,671:INFO:Creating metrics dataframe
2023-05-12 14:55:20,675:INFO:Uploading results into container
2023-05-12 14:55:20,676:INFO:Uploading model into container now
2023-05-12 14:55:20,677:INFO:_master_model_container: 1
2023-05-12 14:55:20,677:INFO:_display_container: 2
2023-05-12 14:55:20,677:INFO:LinearRegression(n_jobs=-1)
2023-05-12 14:55:20,677:INFO:create_model() successfully completed......................................
2023-05-12 14:55:20,762:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:20,762:INFO:Creating metrics dataframe
2023-05-12 14:55:20,774:INFO:Initializing Lasso Regression
2023-05-12 14:55:20,774:INFO:Total runtime is 0.016316898663838706 minutes
2023-05-12 14:55:20,778:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:20,779:INFO:Initializing create_model()
2023-05-12 14:55:20,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:20,779:INFO:Checking exceptions
2023-05-12 14:55:20,779:INFO:Importing libraries
2023-05-12 14:55:20,779:INFO:Copying training dataset
2023-05-12 14:55:20,783:INFO:Defining folds
2023-05-12 14:55:20,784:INFO:Declaring metric variables
2023-05-12 14:55:20,789:INFO:Importing untrained model
2023-05-12 14:55:20,795:INFO:Lasso Regression Imported successfully
2023-05-12 14:55:20,805:INFO:Starting cross validation
2023-05-12 14:55:20,806:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:20,878:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.814e+08, tolerance: 9.007e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:20,926:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.327e+08, tolerance: 9.082e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:20,967:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.914e+08, tolerance: 9.031e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:21,007:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.116e+08, tolerance: 9.143e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:21,047:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.606e+08, tolerance: 9.165e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:21,087:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.105e+08, tolerance: 8.948e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:21,127:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.059e+08, tolerance: 8.970e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:21,167:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.385e+08, tolerance: 9.263e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:21,207:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.838e+08, tolerance: 9.056e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:21,224:INFO:Calculating mean and std
2023-05-12 14:55:21,225:INFO:Creating metrics dataframe
2023-05-12 14:55:21,230:INFO:Uploading results into container
2023-05-12 14:55:21,231:INFO:Uploading model into container now
2023-05-12 14:55:21,231:INFO:_master_model_container: 2
2023-05-12 14:55:21,231:INFO:_display_container: 2
2023-05-12 14:55:21,232:INFO:Lasso(random_state=123)
2023-05-12 14:55:21,232:INFO:create_model() successfully completed......................................
2023-05-12 14:55:21,314:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:21,314:INFO:Creating metrics dataframe
2023-05-12 14:55:21,327:INFO:Initializing Ridge Regression
2023-05-12 14:55:21,327:INFO:Total runtime is 0.025526857376098635 minutes
2023-05-12 14:55:21,332:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:21,332:INFO:Initializing create_model()
2023-05-12 14:55:21,333:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:21,333:INFO:Checking exceptions
2023-05-12 14:55:21,333:INFO:Importing libraries
2023-05-12 14:55:21,333:INFO:Copying training dataset
2023-05-12 14:55:21,338:INFO:Defining folds
2023-05-12 14:55:21,338:INFO:Declaring metric variables
2023-05-12 14:55:21,344:INFO:Importing untrained model
2023-05-12 14:55:21,350:INFO:Ridge Regression Imported successfully
2023-05-12 14:55:21,360:INFO:Starting cross validation
2023-05-12 14:55:21,361:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:21,816:INFO:Calculating mean and std
2023-05-12 14:55:21,819:INFO:Creating metrics dataframe
2023-05-12 14:55:21,823:INFO:Uploading results into container
2023-05-12 14:55:21,824:INFO:Uploading model into container now
2023-05-12 14:55:21,825:INFO:_master_model_container: 3
2023-05-12 14:55:21,825:INFO:_display_container: 2
2023-05-12 14:55:21,826:INFO:Ridge(random_state=123)
2023-05-12 14:55:21,826:INFO:create_model() successfully completed......................................
2023-05-12 14:55:21,909:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:21,909:INFO:Creating metrics dataframe
2023-05-12 14:55:21,921:INFO:Initializing Elastic Net
2023-05-12 14:55:21,922:INFO:Total runtime is 0.035443580150604254 minutes
2023-05-12 14:55:21,928:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:21,928:INFO:Initializing create_model()
2023-05-12 14:55:21,928:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:21,928:INFO:Checking exceptions
2023-05-12 14:55:21,928:INFO:Importing libraries
2023-05-12 14:55:21,928:INFO:Copying training dataset
2023-05-12 14:55:21,932:INFO:Defining folds
2023-05-12 14:55:21,932:INFO:Declaring metric variables
2023-05-12 14:55:21,938:INFO:Importing untrained model
2023-05-12 14:55:21,944:INFO:Elastic Net Imported successfully
2023-05-12 14:55:21,955:INFO:Starting cross validation
2023-05-12 14:55:21,956:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:22,002:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.236e+08, tolerance: 9.007e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,030:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.542e+08, tolerance: 9.082e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,057:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.170e+08, tolerance: 9.031e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,080:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.308e+08, tolerance: 9.143e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,107:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.676e+08, tolerance: 9.165e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,136:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.372e+08, tolerance: 8.948e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,172:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.400e+08, tolerance: 8.970e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,197:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.545e+08, tolerance: 9.263e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,222:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.233e+08, tolerance: 9.056e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 14:55:22,232:INFO:Calculating mean and std
2023-05-12 14:55:22,233:INFO:Creating metrics dataframe
2023-05-12 14:55:22,238:INFO:Uploading results into container
2023-05-12 14:55:22,239:INFO:Uploading model into container now
2023-05-12 14:55:22,239:INFO:_master_model_container: 4
2023-05-12 14:55:22,239:INFO:_display_container: 2
2023-05-12 14:55:22,240:INFO:ElasticNet(random_state=123)
2023-05-12 14:55:22,240:INFO:create_model() successfully completed......................................
2023-05-12 14:55:22,319:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:22,319:INFO:Creating metrics dataframe
2023-05-12 14:55:22,332:INFO:Initializing Least Angle Regression
2023-05-12 14:55:22,332:INFO:Total runtime is 0.042277646064758305 minutes
2023-05-12 14:55:22,338:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:22,338:INFO:Initializing create_model()
2023-05-12 14:55:22,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:22,339:INFO:Checking exceptions
2023-05-12 14:55:22,339:INFO:Importing libraries
2023-05-12 14:55:22,339:INFO:Copying training dataset
2023-05-12 14:55:22,342:INFO:Defining folds
2023-05-12 14:55:22,343:INFO:Declaring metric variables
2023-05-12 14:55:22,348:INFO:Importing untrained model
2023-05-12 14:55:22,353:INFO:Least Angle Regression Imported successfully
2023-05-12 14:55:22,362:INFO:Starting cross validation
2023-05-12 14:55:22,363:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:22,380:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,404:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,428:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,451:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,477:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,500:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,524:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,553:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,582:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,612:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:22,625:INFO:Calculating mean and std
2023-05-12 14:55:22,626:INFO:Creating metrics dataframe
2023-05-12 14:55:22,630:INFO:Uploading results into container
2023-05-12 14:55:22,631:INFO:Uploading model into container now
2023-05-12 14:55:22,631:INFO:_master_model_container: 5
2023-05-12 14:55:22,631:INFO:_display_container: 2
2023-05-12 14:55:22,632:INFO:Lars(random_state=123)
2023-05-12 14:55:22,632:INFO:create_model() successfully completed......................................
2023-05-12 14:55:22,714:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:22,715:INFO:Creating metrics dataframe
2023-05-12 14:55:22,729:INFO:Initializing Lasso Least Angle Regression
2023-05-12 14:55:22,729:INFO:Total runtime is 0.04889397223790487 minutes
2023-05-12 14:55:22,735:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:22,736:INFO:Initializing create_model()
2023-05-12 14:55:22,737:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:22,737:INFO:Checking exceptions
2023-05-12 14:55:22,737:INFO:Importing libraries
2023-05-12 14:55:22,737:INFO:Copying training dataset
2023-05-12 14:55:22,741:INFO:Defining folds
2023-05-12 14:55:22,741:INFO:Declaring metric variables
2023-05-12 14:55:22,748:INFO:Importing untrained model
2023-05-12 14:55:22,754:INFO:Lasso Least Angle Regression Imported successfully
2023-05-12 14:55:22,765:INFO:Starting cross validation
2023-05-12 14:55:22,766:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:22,784:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:22,810:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:22,835:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:22,859:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:22,883:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:22,908:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:22,934:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:22,960:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:22,990:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:23,016:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 14:55:23,029:INFO:Calculating mean and std
2023-05-12 14:55:23,031:INFO:Creating metrics dataframe
2023-05-12 14:55:23,037:INFO:Uploading results into container
2023-05-12 14:55:23,038:INFO:Uploading model into container now
2023-05-12 14:55:23,039:INFO:_master_model_container: 6
2023-05-12 14:55:23,039:INFO:_display_container: 2
2023-05-12 14:55:23,040:INFO:LassoLars(random_state=123)
2023-05-12 14:55:23,040:INFO:create_model() successfully completed......................................
2023-05-12 14:55:23,130:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:23,130:INFO:Creating metrics dataframe
2023-05-12 14:55:23,145:INFO:Initializing Orthogonal Matching Pursuit
2023-05-12 14:55:23,146:INFO:Total runtime is 0.05584694147109986 minutes
2023-05-12 14:55:23,151:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:23,152:INFO:Initializing create_model()
2023-05-12 14:55:23,152:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:23,152:INFO:Checking exceptions
2023-05-12 14:55:23,153:INFO:Importing libraries
2023-05-12 14:55:23,153:INFO:Copying training dataset
2023-05-12 14:55:23,157:INFO:Defining folds
2023-05-12 14:55:23,157:INFO:Declaring metric variables
2023-05-12 14:55:23,162:INFO:Importing untrained model
2023-05-12 14:55:23,169:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-12 14:55:23,182:INFO:Starting cross validation
2023-05-12 14:55:23,183:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:23,199:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,226:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,250:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,274:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,297:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,321:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,345:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,372:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,398:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,428:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 14:55:23,443:INFO:Calculating mean and std
2023-05-12 14:55:23,445:INFO:Creating metrics dataframe
2023-05-12 14:55:23,451:INFO:Uploading results into container
2023-05-12 14:55:23,452:INFO:Uploading model into container now
2023-05-12 14:55:23,453:INFO:_master_model_container: 7
2023-05-12 14:55:23,453:INFO:_display_container: 2
2023-05-12 14:55:23,453:INFO:OrthogonalMatchingPursuit()
2023-05-12 14:55:23,453:INFO:create_model() successfully completed......................................
2023-05-12 14:55:23,549:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:23,549:INFO:Creating metrics dataframe
2023-05-12 14:55:23,574:INFO:Initializing Bayesian Ridge
2023-05-12 14:55:23,575:INFO:Total runtime is 0.06299696365992229 minutes
2023-05-12 14:55:23,581:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:23,581:INFO:Initializing create_model()
2023-05-12 14:55:23,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:23,582:INFO:Checking exceptions
2023-05-12 14:55:23,582:INFO:Importing libraries
2023-05-12 14:55:23,582:INFO:Copying training dataset
2023-05-12 14:55:23,588:INFO:Defining folds
2023-05-12 14:55:23,589:INFO:Declaring metric variables
2023-05-12 14:55:23,595:INFO:Importing untrained model
2023-05-12 14:55:23,607:INFO:Bayesian Ridge Imported successfully
2023-05-12 14:55:23,623:INFO:Starting cross validation
2023-05-12 14:55:23,624:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:24,024:INFO:Calculating mean and std
2023-05-12 14:55:24,025:INFO:Creating metrics dataframe
2023-05-12 14:55:24,029:INFO:Uploading results into container
2023-05-12 14:55:24,030:INFO:Uploading model into container now
2023-05-12 14:55:24,031:INFO:_master_model_container: 8
2023-05-12 14:55:24,031:INFO:_display_container: 2
2023-05-12 14:55:24,032:INFO:BayesianRidge()
2023-05-12 14:55:24,032:INFO:create_model() successfully completed......................................
2023-05-12 14:55:24,131:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:24,131:INFO:Creating metrics dataframe
2023-05-12 14:55:24,149:INFO:Initializing Passive Aggressive Regressor
2023-05-12 14:55:24,149:INFO:Total runtime is 0.07256452242533366 minutes
2023-05-12 14:55:24,157:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:24,157:INFO:Initializing create_model()
2023-05-12 14:55:24,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:24,157:INFO:Checking exceptions
2023-05-12 14:55:24,158:INFO:Importing libraries
2023-05-12 14:55:24,158:INFO:Copying training dataset
2023-05-12 14:55:24,162:INFO:Defining folds
2023-05-12 14:55:24,162:INFO:Declaring metric variables
2023-05-12 14:55:24,171:INFO:Importing untrained model
2023-05-12 14:55:24,177:INFO:Passive Aggressive Regressor Imported successfully
2023-05-12 14:55:24,193:INFO:Starting cross validation
2023-05-12 14:55:24,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:24,523:INFO:Calculating mean and std
2023-05-12 14:55:24,526:INFO:Creating metrics dataframe
2023-05-12 14:55:24,530:INFO:Uploading results into container
2023-05-12 14:55:24,531:INFO:Uploading model into container now
2023-05-12 14:55:24,533:INFO:_master_model_container: 9
2023-05-12 14:55:24,534:INFO:_display_container: 2
2023-05-12 14:55:24,535:INFO:PassiveAggressiveRegressor(random_state=123)
2023-05-12 14:55:24,536:INFO:create_model() successfully completed......................................
2023-05-12 14:55:24,632:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:24,633:INFO:Creating metrics dataframe
2023-05-12 14:55:24,654:INFO:Initializing Huber Regressor
2023-05-12 14:55:24,654:INFO:Total runtime is 0.08098121881484986 minutes
2023-05-12 14:55:24,661:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:24,661:INFO:Initializing create_model()
2023-05-12 14:55:24,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:24,661:INFO:Checking exceptions
2023-05-12 14:55:24,662:INFO:Importing libraries
2023-05-12 14:55:24,662:INFO:Copying training dataset
2023-05-12 14:55:24,665:INFO:Defining folds
2023-05-12 14:55:24,665:INFO:Declaring metric variables
2023-05-12 14:55:24,672:INFO:Importing untrained model
2023-05-12 14:55:24,679:INFO:Huber Regressor Imported successfully
2023-05-12 14:55:24,691:INFO:Starting cross validation
2023-05-12 14:55:24,692:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:25,075:INFO:Calculating mean and std
2023-05-12 14:55:25,077:INFO:Creating metrics dataframe
2023-05-12 14:55:25,081:INFO:Uploading results into container
2023-05-12 14:55:25,082:INFO:Uploading model into container now
2023-05-12 14:55:25,084:INFO:_master_model_container: 10
2023-05-12 14:55:25,085:INFO:_display_container: 2
2023-05-12 14:55:25,086:INFO:HuberRegressor()
2023-05-12 14:55:25,087:INFO:create_model() successfully completed......................................
2023-05-12 14:55:25,180:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:25,180:INFO:Creating metrics dataframe
2023-05-12 14:55:25,196:INFO:Initializing K Neighbors Regressor
2023-05-12 14:55:25,197:INFO:Total runtime is 0.09002394676208497 minutes
2023-05-12 14:55:25,204:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:25,205:INFO:Initializing create_model()
2023-05-12 14:55:25,205:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:25,205:INFO:Checking exceptions
2023-05-12 14:55:25,205:INFO:Importing libraries
2023-05-12 14:55:25,205:INFO:Copying training dataset
2023-05-12 14:55:25,209:INFO:Defining folds
2023-05-12 14:55:25,209:INFO:Declaring metric variables
2023-05-12 14:55:25,216:INFO:Importing untrained model
2023-05-12 14:55:25,226:INFO:K Neighbors Regressor Imported successfully
2023-05-12 14:55:25,237:INFO:Starting cross validation
2023-05-12 14:55:25,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:32,367:INFO:Calculating mean and std
2023-05-12 14:55:32,368:INFO:Creating metrics dataframe
2023-05-12 14:55:32,372:INFO:Uploading results into container
2023-05-12 14:55:32,373:INFO:Uploading model into container now
2023-05-12 14:55:32,373:INFO:_master_model_container: 11
2023-05-12 14:55:32,373:INFO:_display_container: 2
2023-05-12 14:55:32,374:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-12 14:55:32,374:INFO:create_model() successfully completed......................................
2023-05-12 14:55:32,456:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:32,456:INFO:Creating metrics dataframe
2023-05-12 14:55:32,479:INFO:Initializing Decision Tree Regressor
2023-05-12 14:55:32,480:INFO:Total runtime is 0.2113990902900696 minutes
2023-05-12 14:55:32,487:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:32,488:INFO:Initializing create_model()
2023-05-12 14:55:32,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:32,488:INFO:Checking exceptions
2023-05-12 14:55:32,488:INFO:Importing libraries
2023-05-12 14:55:32,488:INFO:Copying training dataset
2023-05-12 14:55:32,493:INFO:Defining folds
2023-05-12 14:55:32,494:INFO:Declaring metric variables
2023-05-12 14:55:32,502:INFO:Importing untrained model
2023-05-12 14:55:32,511:INFO:Decision Tree Regressor Imported successfully
2023-05-12 14:55:32,528:INFO:Starting cross validation
2023-05-12 14:55:32,529:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:32,785:INFO:Calculating mean and std
2023-05-12 14:55:32,786:INFO:Creating metrics dataframe
2023-05-12 14:55:32,791:INFO:Uploading results into container
2023-05-12 14:55:32,792:INFO:Uploading model into container now
2023-05-12 14:55:32,793:INFO:_master_model_container: 12
2023-05-12 14:55:32,793:INFO:_display_container: 2
2023-05-12 14:55:32,794:INFO:DecisionTreeRegressor(random_state=123)
2023-05-12 14:55:32,794:INFO:create_model() successfully completed......................................
2023-05-12 14:55:32,886:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:32,887:INFO:Creating metrics dataframe
2023-05-12 14:55:32,904:INFO:Initializing Random Forest Regressor
2023-05-12 14:55:32,904:INFO:Total runtime is 0.21848249435424805 minutes
2023-05-12 14:55:32,911:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:32,912:INFO:Initializing create_model()
2023-05-12 14:55:32,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:32,912:INFO:Checking exceptions
2023-05-12 14:55:32,912:INFO:Importing libraries
2023-05-12 14:55:32,912:INFO:Copying training dataset
2023-05-12 14:55:32,918:INFO:Defining folds
2023-05-12 14:55:32,919:INFO:Declaring metric variables
2023-05-12 14:55:32,925:INFO:Importing untrained model
2023-05-12 14:55:32,932:INFO:Random Forest Regressor Imported successfully
2023-05-12 14:55:32,945:INFO:Starting cross validation
2023-05-12 14:55:32,946:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:35,023:INFO:Calculating mean and std
2023-05-12 14:55:35,027:INFO:Creating metrics dataframe
2023-05-12 14:55:35,036:INFO:Uploading results into container
2023-05-12 14:55:35,038:INFO:Uploading model into container now
2023-05-12 14:55:35,038:INFO:_master_model_container: 13
2023-05-12 14:55:35,039:INFO:_display_container: 2
2023-05-12 14:55:35,040:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-05-12 14:55:35,040:INFO:create_model() successfully completed......................................
2023-05-12 14:55:35,156:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:35,156:INFO:Creating metrics dataframe
2023-05-12 14:55:35,179:INFO:Initializing Extra Trees Regressor
2023-05-12 14:55:35,179:INFO:Total runtime is 0.2563991109530131 minutes
2023-05-12 14:55:35,189:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:35,189:INFO:Initializing create_model()
2023-05-12 14:55:35,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:35,190:INFO:Checking exceptions
2023-05-12 14:55:35,190:INFO:Importing libraries
2023-05-12 14:55:35,190:INFO:Copying training dataset
2023-05-12 14:55:35,195:INFO:Defining folds
2023-05-12 14:55:35,196:INFO:Declaring metric variables
2023-05-12 14:55:35,202:INFO:Importing untrained model
2023-05-12 14:55:35,210:INFO:Extra Trees Regressor Imported successfully
2023-05-12 14:55:35,227:INFO:Starting cross validation
2023-05-12 14:55:35,229:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:37,263:INFO:Calculating mean and std
2023-05-12 14:55:37,265:INFO:Creating metrics dataframe
2023-05-12 14:55:37,271:INFO:Uploading results into container
2023-05-12 14:55:37,272:INFO:Uploading model into container now
2023-05-12 14:55:37,273:INFO:_master_model_container: 14
2023-05-12 14:55:37,273:INFO:_display_container: 2
2023-05-12 14:55:37,274:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-05-12 14:55:37,274:INFO:create_model() successfully completed......................................
2023-05-12 14:55:37,358:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:37,358:INFO:Creating metrics dataframe
2023-05-12 14:55:37,375:INFO:Initializing AdaBoost Regressor
2023-05-12 14:55:37,375:INFO:Total runtime is 0.2929990847905477 minutes
2023-05-12 14:55:37,380:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:37,380:INFO:Initializing create_model()
2023-05-12 14:55:37,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:37,381:INFO:Checking exceptions
2023-05-12 14:55:37,381:INFO:Importing libraries
2023-05-12 14:55:37,381:INFO:Copying training dataset
2023-05-12 14:55:37,387:INFO:Defining folds
2023-05-12 14:55:37,387:INFO:Declaring metric variables
2023-05-12 14:55:37,393:INFO:Importing untrained model
2023-05-12 14:55:37,401:INFO:AdaBoost Regressor Imported successfully
2023-05-12 14:55:37,413:INFO:Starting cross validation
2023-05-12 14:55:37,414:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:37,923:INFO:Calculating mean and std
2023-05-12 14:55:37,924:INFO:Creating metrics dataframe
2023-05-12 14:55:37,928:INFO:Uploading results into container
2023-05-12 14:55:37,929:INFO:Uploading model into container now
2023-05-12 14:55:37,930:INFO:_master_model_container: 15
2023-05-12 14:55:37,930:INFO:_display_container: 2
2023-05-12 14:55:37,931:INFO:AdaBoostRegressor(random_state=123)
2023-05-12 14:55:37,931:INFO:create_model() successfully completed......................................
2023-05-12 14:55:38,037:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:38,038:INFO:Creating metrics dataframe
2023-05-12 14:55:38,060:INFO:Initializing Gradient Boosting Regressor
2023-05-12 14:55:38,061:INFO:Total runtime is 0.3044326980908712 minutes
2023-05-12 14:55:38,068:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:38,069:INFO:Initializing create_model()
2023-05-12 14:55:38,069:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:38,070:INFO:Checking exceptions
2023-05-12 14:55:38,070:INFO:Importing libraries
2023-05-12 14:55:38,070:INFO:Copying training dataset
2023-05-12 14:55:38,076:INFO:Defining folds
2023-05-12 14:55:38,076:INFO:Declaring metric variables
2023-05-12 14:55:38,085:INFO:Importing untrained model
2023-05-12 14:55:38,094:INFO:Gradient Boosting Regressor Imported successfully
2023-05-12 14:55:38,111:INFO:Starting cross validation
2023-05-12 14:55:38,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:38,737:INFO:Calculating mean and std
2023-05-12 14:55:38,739:INFO:Creating metrics dataframe
2023-05-12 14:55:38,743:INFO:Uploading results into container
2023-05-12 14:55:38,744:INFO:Uploading model into container now
2023-05-12 14:55:38,744:INFO:_master_model_container: 16
2023-05-12 14:55:38,745:INFO:_display_container: 2
2023-05-12 14:55:38,745:INFO:GradientBoostingRegressor(random_state=123)
2023-05-12 14:55:38,745:INFO:create_model() successfully completed......................................
2023-05-12 14:55:38,826:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:38,826:INFO:Creating metrics dataframe
2023-05-12 14:55:38,843:INFO:Initializing Extreme Gradient Boosting
2023-05-12 14:55:38,843:INFO:Total runtime is 0.31746578216552734 minutes
2023-05-12 14:55:38,848:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:38,849:INFO:Initializing create_model()
2023-05-12 14:55:38,849:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:38,849:INFO:Checking exceptions
2023-05-12 14:55:38,849:INFO:Importing libraries
2023-05-12 14:55:38,850:INFO:Copying training dataset
2023-05-12 14:55:38,856:INFO:Defining folds
2023-05-12 14:55:38,856:INFO:Declaring metric variables
2023-05-12 14:55:38,861:INFO:Importing untrained model
2023-05-12 14:55:38,870:INFO:Extreme Gradient Boosting Imported successfully
2023-05-12 14:55:38,882:INFO:Starting cross validation
2023-05-12 14:55:38,883:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:44,459:INFO:Calculating mean and std
2023-05-12 14:55:44,462:INFO:Creating metrics dataframe
2023-05-12 14:55:44,469:INFO:Uploading results into container
2023-05-12 14:55:44,470:INFO:Uploading model into container now
2023-05-12 14:55:44,471:INFO:_master_model_container: 17
2023-05-12 14:55:44,472:INFO:_display_container: 2
2023-05-12 14:55:44,474:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-05-12 14:55:44,474:INFO:create_model() successfully completed......................................
2023-05-12 14:55:44,587:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:44,587:INFO:Creating metrics dataframe
2023-05-12 14:55:44,609:INFO:Initializing Light Gradient Boosting Machine
2023-05-12 14:55:44,610:INFO:Total runtime is 0.4135751247406006 minutes
2023-05-12 14:55:44,617:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:44,618:INFO:Initializing create_model()
2023-05-12 14:55:44,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:44,618:INFO:Checking exceptions
2023-05-12 14:55:44,618:INFO:Importing libraries
2023-05-12 14:55:44,618:INFO:Copying training dataset
2023-05-12 14:55:44,622:INFO:Defining folds
2023-05-12 14:55:44,622:INFO:Declaring metric variables
2023-05-12 14:55:44,632:INFO:Importing untrained model
2023-05-12 14:55:44,656:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-12 14:55:44,673:INFO:Starting cross validation
2023-05-12 14:55:44,675:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:51,924:INFO:Calculating mean and std
2023-05-12 14:55:51,927:INFO:Creating metrics dataframe
2023-05-12 14:55:51,935:INFO:Uploading results into container
2023-05-12 14:55:51,936:INFO:Uploading model into container now
2023-05-12 14:55:51,937:INFO:_master_model_container: 18
2023-05-12 14:55:51,937:INFO:_display_container: 2
2023-05-12 14:55:51,938:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-05-12 14:55:51,938:INFO:create_model() successfully completed......................................
2023-05-12 14:55:52,074:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:52,074:INFO:Creating metrics dataframe
2023-05-12 14:55:52,092:INFO:Initializing Dummy Regressor
2023-05-12 14:55:52,092:INFO:Total runtime is 0.5382695674896241 minutes
2023-05-12 14:55:52,097:INFO:SubProcess create_model() called ==================================
2023-05-12 14:55:52,098:INFO:Initializing create_model()
2023-05-12 14:55:52,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A11C2440>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:52,098:INFO:Checking exceptions
2023-05-12 14:55:52,098:INFO:Importing libraries
2023-05-12 14:55:52,098:INFO:Copying training dataset
2023-05-12 14:55:52,103:INFO:Defining folds
2023-05-12 14:55:52,103:INFO:Declaring metric variables
2023-05-12 14:55:52,109:INFO:Importing untrained model
2023-05-12 14:55:52,115:INFO:Dummy Regressor Imported successfully
2023-05-12 14:55:52,125:INFO:Starting cross validation
2023-05-12 14:55:52,126:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:52,346:INFO:Calculating mean and std
2023-05-12 14:55:52,347:INFO:Creating metrics dataframe
2023-05-12 14:55:52,352:INFO:Uploading results into container
2023-05-12 14:55:52,352:INFO:Uploading model into container now
2023-05-12 14:55:52,353:INFO:_master_model_container: 19
2023-05-12 14:55:52,353:INFO:_display_container: 2
2023-05-12 14:55:52,353:INFO:DummyRegressor()
2023-05-12 14:55:52,354:INFO:create_model() successfully completed......................................
2023-05-12 14:55:52,434:INFO:SubProcess create_model() end ==================================
2023-05-12 14:55:52,434:INFO:Creating metrics dataframe
2023-05-12 14:55:52,467:INFO:Initializing create_model()
2023-05-12 14:55:52,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:52,467:INFO:Checking exceptions
2023-05-12 14:55:52,470:INFO:Importing libraries
2023-05-12 14:55:52,470:INFO:Copying training dataset
2023-05-12 14:55:52,473:INFO:Defining folds
2023-05-12 14:55:52,473:INFO:Declaring metric variables
2023-05-12 14:55:52,473:INFO:Importing untrained model
2023-05-12 14:55:52,473:INFO:Declaring custom model
2023-05-12 14:55:52,474:INFO:Huber Regressor Imported successfully
2023-05-12 14:55:52,475:INFO:Cross validation set to False
2023-05-12 14:55:52,475:INFO:Fitting Model
2023-05-12 14:55:52,514:INFO:HuberRegressor()
2023-05-12 14:55:52,514:INFO:create_model() successfully completed......................................
2023-05-12 14:55:52,653:INFO:_master_model_container: 19
2023-05-12 14:55:52,653:INFO:_display_container: 2
2023-05-12 14:55:52,654:INFO:HuberRegressor()
2023-05-12 14:55:52,654:INFO:compare_models() successfully completed......................................
2023-05-12 14:55:52,814:INFO:Initializing create_model()
2023-05-12 14:55:52,814:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 14:55:52,814:INFO:Checking exceptions
2023-05-12 14:55:52,858:INFO:Importing libraries
2023-05-12 14:55:52,858:INFO:Copying training dataset
2023-05-12 14:55:52,865:INFO:Defining folds
2023-05-12 14:55:52,865:INFO:Declaring metric variables
2023-05-12 14:55:52,870:INFO:Importing untrained model
2023-05-12 14:55:52,875:INFO:Huber Regressor Imported successfully
2023-05-12 14:55:52,893:INFO:Starting cross validation
2023-05-12 14:55:52,897:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 14:55:53,282:INFO:Calculating mean and std
2023-05-12 14:55:53,283:INFO:Creating metrics dataframe
2023-05-12 14:55:53,289:INFO:Finalizing model
2023-05-12 14:55:53,330:INFO:Uploading results into container
2023-05-12 14:55:53,331:INFO:Uploading model into container now
2023-05-12 14:55:53,346:INFO:_master_model_container: 20
2023-05-12 14:55:53,346:INFO:_display_container: 3
2023-05-12 14:55:53,346:INFO:HuberRegressor()
2023-05-12 14:55:53,347:INFO:create_model() successfully completed......................................
2023-05-12 14:55:53,601:INFO:Initializing evaluate_model()
2023-05-12 14:55:53,601:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-05-12 14:55:53,645:INFO:Initializing plot_model()
2023-05-12 14:55:53,646:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, system=True)
2023-05-12 14:55:53,646:INFO:Checking exceptions
2023-05-12 14:55:53,649:INFO:Preloading libraries
2023-05-12 14:55:53,650:INFO:Copying training dataset
2023-05-12 14:55:53,650:INFO:Plot type: pipeline
2023-05-12 14:55:53,880:INFO:Visual Rendered Successfully
2023-05-12 14:55:53,989:INFO:plot_model() successfully completed......................................
2023-05-12 14:55:54,104:INFO:Initializing predict_model()
2023-05-12 14:55:54,105:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A49DA17190>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A4A16EFC70>)
2023-05-12 14:55:54,105:INFO:Checking exceptions
2023-05-12 14:55:54,106:INFO:Preloading libraries
2023-05-12 14:55:54,110:INFO:Set up data.
2023-05-12 14:55:54,116:INFO:Set up index.
2023-05-12 15:18:40,287:INFO:PyCaret RegressionExperiment
2023-05-12 15:18:40,289:INFO:Logging name: reg-default-name
2023-05-12 15:18:40,290:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-12 15:18:40,290:INFO:version 3.0.0.rc8
2023-05-12 15:18:40,291:INFO:Initializing setup()
2023-05-12 15:18:40,291:INFO:self.USI: 5d53
2023-05-12 15:18:40,292:INFO:self._variable_keys: {'html_param', 'memory', '_available_plots', 'seed', 'idx', 'fold_groups_param', 'X', 'data', 'y_test', 'gpu_param', 'exp_name_log', 'exp_id', 'X_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'logging_param', 'USI', 'log_plots_param', 'y', 'n_jobs_param', '_ml_usecase', 'y_train', 'fold_generator', 'transform_target_param', 'pipeline', 'X_train', 'target_param'}
2023-05-12 15:18:40,293:INFO:Checking environment
2023-05-12 15:18:40,293:INFO:python_version: 3.10.9
2023-05-12 15:18:40,293:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-05-12 15:18:40,294:INFO:machine: AMD64
2023-05-12 15:18:40,294:INFO:platform: Windows-10-10.0.19045-SP0
2023-05-12 15:18:40,294:INFO:Memory: svmem(total=17090879488, available=3406737408, percent=80.1, used=13684142080, free=3406737408)
2023-05-12 15:18:40,295:INFO:Physical Core: 4
2023-05-12 15:18:40,295:INFO:Logical Core: 8
2023-05-12 15:18:40,295:INFO:Checking libraries
2023-05-12 15:18:40,295:INFO:System:
2023-05-12 15:18:40,296:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-05-12 15:18:40,296:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-05-12 15:18:40,296:INFO:   machine: Windows-10-10.0.19045-SP0
2023-05-12 15:18:40,296:INFO:PyCaret required dependencies:
2023-05-12 15:18:40,297:INFO:                 pip: 23.0
2023-05-12 15:18:40,297:INFO:          setuptools: 67.1.0
2023-05-12 15:18:40,297:INFO:             pycaret: 3.0.0rc8
2023-05-12 15:18:40,297:INFO:             IPython: 8.8.0
2023-05-12 15:18:40,297:INFO:          ipywidgets: 8.0.4
2023-05-12 15:18:40,297:INFO:                tqdm: 4.64.1
2023-05-12 15:18:40,297:INFO:               numpy: 1.23.5
2023-05-12 15:18:40,297:INFO:              pandas: 1.5.3
2023-05-12 15:18:40,298:INFO:              jinja2: 3.1.2
2023-05-12 15:18:40,298:INFO:               scipy: 1.10.0
2023-05-12 15:18:40,298:INFO:              joblib: 1.2.0
2023-05-12 15:18:40,298:INFO:             sklearn: 1.1.3
2023-05-12 15:18:40,298:INFO:                pyod: 1.0.7
2023-05-12 15:18:40,298:INFO:            imblearn: 0.10.1
2023-05-12 15:18:40,299:INFO:   category_encoders: 2.6.0
2023-05-12 15:18:40,299:INFO:            lightgbm: 3.3.5
2023-05-12 15:18:40,299:INFO:               numba: 0.56.4
2023-05-12 15:18:40,299:INFO:            requests: 2.28.2
2023-05-12 15:18:40,299:INFO:          matplotlib: 3.6.3
2023-05-12 15:18:40,300:INFO:          scikitplot: 0.3.7
2023-05-12 15:18:40,300:INFO:         yellowbrick: 1.5
2023-05-12 15:18:40,300:INFO:              plotly: 5.13.0
2023-05-12 15:18:40,300:INFO:             kaleido: 0.2.1
2023-05-12 15:18:40,301:INFO:         statsmodels: 0.13.5
2023-05-12 15:18:40,301:INFO:              sktime: 0.16.0
2023-05-12 15:18:40,301:INFO:               tbats: 1.1.2
2023-05-12 15:18:40,301:INFO:            pmdarima: 2.0.2
2023-05-12 15:18:40,301:INFO:              psutil: 5.9.0
2023-05-12 15:18:40,302:INFO:PyCaret optional dependencies:
2023-05-12 15:18:40,302:INFO:                shap: Not installed
2023-05-12 15:18:40,302:INFO:           interpret: Not installed
2023-05-12 15:18:40,303:INFO:                umap: Not installed
2023-05-12 15:18:40,303:INFO:    pandas_profiling: Not installed
2023-05-12 15:18:40,303:INFO:  explainerdashboard: Not installed
2023-05-12 15:18:40,303:INFO:             autoviz: Not installed
2023-05-12 15:18:40,303:INFO:           fairlearn: Not installed
2023-05-12 15:18:40,304:INFO:             xgboost: 1.7.3
2023-05-12 15:18:40,304:INFO:            catboost: Not installed
2023-05-12 15:18:40,304:INFO:              kmodes: Not installed
2023-05-12 15:18:40,305:INFO:             mlxtend: Not installed
2023-05-12 15:18:40,305:INFO:       statsforecast: Not installed
2023-05-12 15:18:40,305:INFO:        tune_sklearn: Not installed
2023-05-12 15:18:40,305:INFO:                 ray: Not installed
2023-05-12 15:18:40,305:INFO:            hyperopt: Not installed
2023-05-12 15:18:40,305:INFO:              optuna: Not installed
2023-05-12 15:18:40,306:INFO:               skopt: Not installed
2023-05-12 15:18:40,306:INFO:              mlflow: Not installed
2023-05-12 15:18:40,306:INFO:              gradio: Not installed
2023-05-12 15:18:40,306:INFO:             fastapi: Not installed
2023-05-12 15:18:40,306:INFO:             uvicorn: Not installed
2023-05-12 15:18:40,307:INFO:              m2cgen: Not installed
2023-05-12 15:18:40,307:INFO:           evidently: Not installed
2023-05-12 15:18:40,307:INFO:                nltk: Not installed
2023-05-12 15:18:40,307:INFO:            pyLDAvis: Not installed
2023-05-12 15:18:40,307:INFO:              gensim: Not installed
2023-05-12 15:18:40,307:INFO:               spacy: Not installed
2023-05-12 15:18:40,308:INFO:           wordcloud: Not installed
2023-05-12 15:18:40,308:INFO:            textblob: Not installed
2023-05-12 15:18:40,308:INFO:               fugue: Not installed
2023-05-12 15:18:40,308:INFO:           streamlit: Not installed
2023-05-12 15:18:40,308:INFO:             prophet: Not installed
2023-05-12 15:18:40,308:INFO:None
2023-05-12 15:18:40,308:INFO:Set up GPU usage.
2023-05-12 15:18:40,308:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:40,309:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-05-12 15:18:40,309:INFO:Set up data.
2023-05-12 15:18:40,314:INFO:Set up train/test split.
2023-05-12 15:18:40,324:INFO:Set up index.
2023-05-12 15:18:40,324:INFO:Set up folding strategy.
2023-05-12 15:18:40,324:INFO:Assigning column types.
2023-05-12 15:18:40,328:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-12 15:18:40,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:40,329:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 15:18:40,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:40,335:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:18:40,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:40,341:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:18:40,341:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:40,429:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:18:40,429:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:40,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:18:40,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:40,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:40,488:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:18:41,193:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:18:41,194:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,195:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 15:18:41,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,208:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:18:41,208:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,222:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:18:41,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,331:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:18:41,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,383:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:18:41,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,384:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:18:41,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:18:41,567:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-12 15:18:41,568:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,568:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,581:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:18:41,581:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,595:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:18:41,595:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,705:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:18:41,706:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:18:41,763:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,763:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,763:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:18:41,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:18:41,959:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,959:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,974:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:18:41,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:41,987:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:18:41,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,112:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:18:42,112:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:18:42,171:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,172:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,172:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:18:42,372:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:18:42,373:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-12 15:18:42,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,388:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,398:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:18:42,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,511:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:18:42,511:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,568:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:18:42,568:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,568:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,569:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:18:42,729:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:18:42,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,742:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,756:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:18:42,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,862:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:18:42,862:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,916:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:18:42,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:42,917:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:18:43,100:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:18:43,101:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-12 15:18:43,102:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,102:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,114:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,128:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,239:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:18:43,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,297:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:18:43,297:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,298:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:18:43,473:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:18:43,474:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,474:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,614:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:18:43,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,665:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:18:43,665:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,666:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,666:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:18:43,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:18:43,850:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-12 15:18:43,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,864:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,877:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:43,990:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:18:43,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,049:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:18:44,221:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:18:44,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,235:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,249:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,361:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:18:44,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,414:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:18:44,593:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:18:44,594:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-12 15:18:44,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,595:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,620:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,724:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,777:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,777:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,778:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:18:44,960:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:18:44,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:44,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,098:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,154:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,162:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,163:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:18:45,334:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:18:45,336:INFO:Preparing preprocessing pipeline...
2023-05-12 15:18:45,338:INFO:Set up simple imputation.
2023-05-12 15:18:45,353:INFO:Finished creating preprocessing pipeline.
2023-05-12 15:18:45,364:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-05-12 15:18:45,364:INFO:Creating final display dataframe.
2023-05-12 15:18:45,479:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape          (731, 2)
4        Transformed data shape          (731, 2)
5   Transformed train set shape          (511, 2)
6    Transformed test set shape          (220, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              5d53
2023-05-12 15:18:45,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,495:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,502:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,568:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,631:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:18:45,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:18:45,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,833:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,939:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,991:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:18:45,992:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:18:46,161:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:18:46,163:INFO:setup() successfully completed in 5.88s...............
2023-05-12 15:18:46,243:INFO:Initializing compare_models()
2023-05-12 15:18:46,244:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-12 15:18:46,244:INFO:Checking exceptions
2023-05-12 15:18:46,247:INFO:Preparing display monitor
2023-05-12 15:18:46,297:INFO:Initializing Linear Regression
2023-05-12 15:18:46,297:INFO:Total runtime is 0.0 minutes
2023-05-12 15:18:46,303:INFO:SubProcess create_model() called ==================================
2023-05-12 15:18:46,304:INFO:Initializing create_model()
2023-05-12 15:18:46,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:18:46,304:INFO:Checking exceptions
2023-05-12 15:18:46,305:INFO:Importing libraries
2023-05-12 15:18:46,305:INFO:Copying training dataset
2023-05-12 15:18:46,313:INFO:Defining folds
2023-05-12 15:18:46,313:INFO:Declaring metric variables
2023-05-12 15:18:46,321:INFO:Importing untrained model
2023-05-12 15:18:46,327:INFO:Linear Regression Imported successfully
2023-05-12 15:18:46,341:INFO:Starting cross validation
2023-05-12 15:18:46,343:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:18:46,587:INFO:Calculating mean and std
2023-05-12 15:18:46,587:INFO:Creating metrics dataframe
2023-05-12 15:18:46,591:INFO:Uploading results into container
2023-05-12 15:18:46,592:INFO:Uploading model into container now
2023-05-12 15:18:46,592:INFO:_master_model_container: 1
2023-05-12 15:18:46,592:INFO:_display_container: 2
2023-05-12 15:18:46,592:INFO:LinearRegression(n_jobs=-1)
2023-05-12 15:18:46,592:INFO:create_model() successfully completed......................................
2023-05-12 15:18:46,690:INFO:SubProcess create_model() end ==================================
2023-05-12 15:18:46,690:INFO:Creating metrics dataframe
2023-05-12 15:18:46,703:INFO:Initializing Lasso Regression
2023-05-12 15:18:46,704:INFO:Total runtime is 0.006758753458658854 minutes
2023-05-12 15:18:46,711:INFO:SubProcess create_model() called ==================================
2023-05-12 15:18:46,712:INFO:Initializing create_model()
2023-05-12 15:18:46,712:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:18:46,713:INFO:Checking exceptions
2023-05-12 15:18:46,713:INFO:Importing libraries
2023-05-12 15:18:46,713:INFO:Copying training dataset
2023-05-12 15:18:46,720:INFO:Defining folds
2023-05-12 15:18:46,720:INFO:Declaring metric variables
2023-05-12 15:18:46,738:INFO:Importing untrained model
2023-05-12 15:18:46,746:INFO:Lasso Regression Imported successfully
2023-05-12 15:18:46,769:INFO:Starting cross validation
2023-05-12 15:18:46,770:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:18:46,825:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.814e+08, tolerance: 9.007e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:46,849:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.327e+08, tolerance: 9.082e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:46,872:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.914e+08, tolerance: 9.031e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:46,898:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.116e+08, tolerance: 9.143e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:46,922:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.606e+08, tolerance: 9.165e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:46,946:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.105e+08, tolerance: 8.948e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:46,970:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.059e+08, tolerance: 8.970e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:46,993:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.385e+08, tolerance: 9.263e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:47,017:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.838e+08, tolerance: 9.056e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:47,028:INFO:Calculating mean and std
2023-05-12 15:18:47,029:INFO:Creating metrics dataframe
2023-05-12 15:18:47,033:INFO:Uploading results into container
2023-05-12 15:18:47,033:INFO:Uploading model into container now
2023-05-12 15:18:47,034:INFO:_master_model_container: 2
2023-05-12 15:18:47,034:INFO:_display_container: 2
2023-05-12 15:18:47,034:INFO:Lasso(random_state=123)
2023-05-12 15:18:47,034:INFO:create_model() successfully completed......................................
2023-05-12 15:18:47,118:INFO:SubProcess create_model() end ==================================
2023-05-12 15:18:47,118:INFO:Creating metrics dataframe
2023-05-12 15:18:47,129:INFO:Initializing Ridge Regression
2023-05-12 15:18:47,130:INFO:Total runtime is 0.013875925540924072 minutes
2023-05-12 15:18:47,135:INFO:SubProcess create_model() called ==================================
2023-05-12 15:18:47,135:INFO:Initializing create_model()
2023-05-12 15:18:47,136:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:18:47,136:INFO:Checking exceptions
2023-05-12 15:18:47,136:INFO:Importing libraries
2023-05-12 15:18:47,136:INFO:Copying training dataset
2023-05-12 15:18:47,139:INFO:Defining folds
2023-05-12 15:18:47,139:INFO:Declaring metric variables
2023-05-12 15:18:47,143:INFO:Importing untrained model
2023-05-12 15:18:47,147:INFO:Ridge Regression Imported successfully
2023-05-12 15:18:47,157:INFO:Starting cross validation
2023-05-12 15:18:47,158:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:18:47,383:INFO:Calculating mean and std
2023-05-12 15:18:47,384:INFO:Creating metrics dataframe
2023-05-12 15:18:47,388:INFO:Uploading results into container
2023-05-12 15:18:47,389:INFO:Uploading model into container now
2023-05-12 15:18:47,390:INFO:_master_model_container: 3
2023-05-12 15:18:47,390:INFO:_display_container: 2
2023-05-12 15:18:47,391:INFO:Ridge(random_state=123)
2023-05-12 15:18:47,392:INFO:create_model() successfully completed......................................
2023-05-12 15:18:47,471:INFO:SubProcess create_model() end ==================================
2023-05-12 15:18:47,471:INFO:Creating metrics dataframe
2023-05-12 15:18:47,483:INFO:Initializing Elastic Net
2023-05-12 15:18:47,483:INFO:Total runtime is 0.019758991400400796 minutes
2023-05-12 15:18:47,488:INFO:SubProcess create_model() called ==================================
2023-05-12 15:18:47,489:INFO:Initializing create_model()
2023-05-12 15:18:47,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:18:47,489:INFO:Checking exceptions
2023-05-12 15:18:47,489:INFO:Importing libraries
2023-05-12 15:18:47,490:INFO:Copying training dataset
2023-05-12 15:18:47,493:INFO:Defining folds
2023-05-12 15:18:47,493:INFO:Declaring metric variables
2023-05-12 15:18:47,498:INFO:Importing untrained model
2023-05-12 15:18:47,504:INFO:Elastic Net Imported successfully
2023-05-12 15:18:47,513:INFO:Starting cross validation
2023-05-12 15:18:47,515:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:18:47,558:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.236e+08, tolerance: 9.007e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:47,582:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.542e+08, tolerance: 9.082e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:47,613:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.170e+08, tolerance: 9.031e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:47,637:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.308e+08, tolerance: 9.143e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:47,679:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.676e+08, tolerance: 9.165e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:47,704:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.372e+08, tolerance: 8.948e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:47,729:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.400e+08, tolerance: 8.970e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:47,755:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.545e+08, tolerance: 9.263e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:47,779:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.233e+08, tolerance: 9.056e+06
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:18:47,789:INFO:Calculating mean and std
2023-05-12 15:18:47,791:INFO:Creating metrics dataframe
2023-05-12 15:18:47,795:INFO:Uploading results into container
2023-05-12 15:18:47,796:INFO:Uploading model into container now
2023-05-12 15:18:47,796:INFO:_master_model_container: 4
2023-05-12 15:18:47,796:INFO:_display_container: 2
2023-05-12 15:18:47,797:INFO:ElasticNet(random_state=123)
2023-05-12 15:18:47,797:INFO:create_model() successfully completed......................................
2023-05-12 15:18:47,877:INFO:SubProcess create_model() end ==================================
2023-05-12 15:18:47,877:INFO:Creating metrics dataframe
2023-05-12 15:18:47,891:INFO:Initializing Least Angle Regression
2023-05-12 15:18:47,891:INFO:Total runtime is 0.026558804512023925 minutes
2023-05-12 15:18:47,896:INFO:SubProcess create_model() called ==================================
2023-05-12 15:18:47,896:INFO:Initializing create_model()
2023-05-12 15:18:47,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:18:47,897:INFO:Checking exceptions
2023-05-12 15:18:47,897:INFO:Importing libraries
2023-05-12 15:18:47,897:INFO:Copying training dataset
2023-05-12 15:18:47,901:INFO:Defining folds
2023-05-12 15:18:47,901:INFO:Declaring metric variables
2023-05-12 15:18:47,907:INFO:Importing untrained model
2023-05-12 15:18:47,912:INFO:Least Angle Regression Imported successfully
2023-05-12 15:18:47,922:INFO:Starting cross validation
2023-05-12 15:18:47,923:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:18:47,938:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:47,961:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:47,984:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,008:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,030:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,056:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,078:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,101:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,123:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,146:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,156:INFO:Calculating mean and std
2023-05-12 15:18:48,157:INFO:Creating metrics dataframe
2023-05-12 15:18:48,161:INFO:Uploading results into container
2023-05-12 15:18:48,162:INFO:Uploading model into container now
2023-05-12 15:18:48,162:INFO:_master_model_container: 5
2023-05-12 15:18:48,162:INFO:_display_container: 2
2023-05-12 15:18:48,163:INFO:Lars(random_state=123)
2023-05-12 15:18:48,163:INFO:create_model() successfully completed......................................
2023-05-12 15:18:48,247:INFO:SubProcess create_model() end ==================================
2023-05-12 15:18:48,248:INFO:Creating metrics dataframe
2023-05-12 15:18:48,263:INFO:Initializing Lasso Least Angle Regression
2023-05-12 15:18:48,263:INFO:Total runtime is 0.0327596108118693 minutes
2023-05-12 15:18:48,269:INFO:SubProcess create_model() called ==================================
2023-05-12 15:18:48,269:INFO:Initializing create_model()
2023-05-12 15:18:48,270:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:18:48,270:INFO:Checking exceptions
2023-05-12 15:18:48,270:INFO:Importing libraries
2023-05-12 15:18:48,270:INFO:Copying training dataset
2023-05-12 15:18:48,274:INFO:Defining folds
2023-05-12 15:18:48,274:INFO:Declaring metric variables
2023-05-12 15:18:48,283:INFO:Importing untrained model
2023-05-12 15:18:48,290:INFO:Lasso Least Angle Regression Imported successfully
2023-05-12 15:18:48,301:INFO:Starting cross validation
2023-05-12 15:18:48,303:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:18:48,318:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:18:48,345:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:18:48,371:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:18:48,396:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:18:48,422:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:18:48,447:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:18:48,472:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:18:48,495:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:18:48,519:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:18:48,542:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:18:48,553:INFO:Calculating mean and std
2023-05-12 15:18:48,554:INFO:Creating metrics dataframe
2023-05-12 15:18:48,558:INFO:Uploading results into container
2023-05-12 15:18:48,559:INFO:Uploading model into container now
2023-05-12 15:18:48,559:INFO:_master_model_container: 6
2023-05-12 15:18:48,559:INFO:_display_container: 2
2023-05-12 15:18:48,560:INFO:LassoLars(random_state=123)
2023-05-12 15:18:48,560:INFO:create_model() successfully completed......................................
2023-05-12 15:18:48,645:INFO:SubProcess create_model() end ==================================
2023-05-12 15:18:48,645:INFO:Creating metrics dataframe
2023-05-12 15:18:48,660:INFO:Initializing Orthogonal Matching Pursuit
2023-05-12 15:18:48,661:INFO:Total runtime is 0.03939295212427775 minutes
2023-05-12 15:18:48,667:INFO:SubProcess create_model() called ==================================
2023-05-12 15:18:48,667:INFO:Initializing create_model()
2023-05-12 15:18:48,668:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:18:48,668:INFO:Checking exceptions
2023-05-12 15:18:48,668:INFO:Importing libraries
2023-05-12 15:18:48,668:INFO:Copying training dataset
2023-05-12 15:18:48,672:INFO:Defining folds
2023-05-12 15:18:48,672:INFO:Declaring metric variables
2023-05-12 15:18:48,677:INFO:Importing untrained model
2023-05-12 15:18:48,683:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-12 15:18:48,693:INFO:Starting cross validation
2023-05-12 15:18:48,694:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:18:48,707:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,729:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,751:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,773:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,795:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,817:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,841:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,864:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,887:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,910:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:18:48,923:INFO:Calculating mean and std
2023-05-12 15:18:48,925:INFO:Creating metrics dataframe
2023-05-12 15:18:48,929:INFO:Uploading results into container
2023-05-12 15:18:48,930:INFO:Uploading model into container now
2023-05-12 15:18:48,930:INFO:_master_model_container: 7
2023-05-12 15:18:48,930:INFO:_display_container: 2
2023-05-12 15:18:48,931:INFO:OrthogonalMatchingPursuit()
2023-05-12 15:18:48,932:INFO:create_model() successfully completed......................................
2023-05-12 15:18:49,011:INFO:SubProcess create_model() end ==================================
2023-05-12 15:18:49,012:INFO:Creating metrics dataframe
2023-05-12 15:18:49,026:INFO:Initializing Bayesian Ridge
2023-05-12 15:18:49,026:INFO:Total runtime is 0.04547627766927083 minutes
2023-05-12 15:18:49,031:INFO:SubProcess create_model() called ==================================
2023-05-12 15:18:49,032:INFO:Initializing create_model()
2023-05-12 15:18:49,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:18:49,032:INFO:Checking exceptions
2023-05-12 15:18:49,032:INFO:Importing libraries
2023-05-12 15:18:49,032:INFO:Copying training dataset
2023-05-12 15:18:49,038:INFO:Defining folds
2023-05-12 15:18:49,038:INFO:Declaring metric variables
2023-05-12 15:18:49,043:INFO:Importing untrained model
2023-05-12 15:18:49,048:INFO:Bayesian Ridge Imported successfully
2023-05-12 15:18:49,059:INFO:Starting cross validation
2023-05-12 15:18:49,060:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:18:49,289:INFO:Calculating mean and std
2023-05-12 15:18:49,290:INFO:Creating metrics dataframe
2023-05-12 15:18:49,295:INFO:Uploading results into container
2023-05-12 15:18:49,296:INFO:Uploading model into container now
2023-05-12 15:18:49,296:INFO:_master_model_container: 8
2023-05-12 15:18:49,297:INFO:_display_container: 2
2023-05-12 15:18:49,297:INFO:BayesianRidge()
2023-05-12 15:18:49,298:INFO:create_model() successfully completed......................................
2023-05-12 15:18:49,378:INFO:SubProcess create_model() end ==================================
2023-05-12 15:18:49,379:INFO:Creating metrics dataframe
2023-05-12 15:18:49,394:INFO:Initializing Passive Aggressive Regressor
2023-05-12 15:18:49,395:INFO:Total runtime is 0.051626296838124586 minutes
2023-05-12 15:18:49,399:INFO:SubProcess create_model() called ==================================
2023-05-12 15:18:49,400:INFO:Initializing create_model()
2023-05-12 15:18:49,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:18:49,400:INFO:Checking exceptions
2023-05-12 15:18:49,400:INFO:Importing libraries
2023-05-12 15:18:49,400:INFO:Copying training dataset
2023-05-12 15:18:49,405:INFO:Defining folds
2023-05-12 15:18:49,405:INFO:Declaring metric variables
2023-05-12 15:18:49,411:INFO:Importing untrained model
2023-05-12 15:18:49,416:INFO:Passive Aggressive Regressor Imported successfully
2023-05-12 15:18:49,426:INFO:Starting cross validation
2023-05-12 15:18:49,427:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:18:49,659:INFO:Calculating mean and std
2023-05-12 15:18:49,660:INFO:Creating metrics dataframe
2023-05-12 15:18:49,664:INFO:Uploading results into container
2023-05-12 15:18:49,665:INFO:Uploading model into container now
2023-05-12 15:18:49,666:INFO:_master_model_container: 9
2023-05-12 15:18:49,666:INFO:_display_container: 2
2023-05-12 15:18:49,667:INFO:PassiveAggressiveRegressor(random_state=123)
2023-05-12 15:18:49,667:INFO:create_model() successfully completed......................................
2023-05-12 15:18:49,747:INFO:SubProcess create_model() end ==================================
2023-05-12 15:18:49,747:INFO:Creating metrics dataframe
2023-05-12 15:18:49,764:INFO:Initializing Huber Regressor
2023-05-12 15:18:49,764:INFO:Total runtime is 0.05777626832326253 minutes
2023-05-12 15:18:49,769:INFO:SubProcess create_model() called ==================================
2023-05-12 15:18:49,769:INFO:Initializing create_model()
2023-05-12 15:18:49,769:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:18:49,770:INFO:Checking exceptions
2023-05-12 15:18:49,770:INFO:Importing libraries
2023-05-12 15:18:49,770:INFO:Copying training dataset
2023-05-12 15:18:49,773:INFO:Defining folds
2023-05-12 15:18:49,774:INFO:Declaring metric variables
2023-05-12 15:18:49,779:INFO:Importing untrained model
2023-05-12 15:18:49,785:INFO:Huber Regressor Imported successfully
2023-05-12 15:18:49,794:INFO:Starting cross validation
2023-05-12 15:18:49,795:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:18:50,083:INFO:Calculating mean and std
2023-05-12 15:18:50,085:INFO:Creating metrics dataframe
2023-05-12 15:18:50,089:INFO:Uploading results into container
2023-05-12 15:18:50,090:INFO:Uploading model into container now
2023-05-12 15:18:50,091:INFO:_master_model_container: 10
2023-05-12 15:18:50,092:INFO:_display_container: 2
2023-05-12 15:18:50,092:INFO:HuberRegressor()
2023-05-12 15:18:50,092:INFO:create_model() successfully completed......................................
2023-05-12 15:18:50,173:INFO:SubProcess create_model() end ==================================
2023-05-12 15:18:50,173:INFO:Creating metrics dataframe
2023-05-12 15:18:50,187:INFO:Initializing K Neighbors Regressor
2023-05-12 15:18:50,187:INFO:Total runtime is 0.06482646862665811 minutes
2023-05-12 15:18:50,192:INFO:SubProcess create_model() called ==================================
2023-05-12 15:18:50,193:INFO:Initializing create_model()
2023-05-12 15:18:50,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:18:50,193:INFO:Checking exceptions
2023-05-12 15:18:50,193:INFO:Importing libraries
2023-05-12 15:18:50,193:INFO:Copying training dataset
2023-05-12 15:18:50,197:INFO:Defining folds
2023-05-12 15:18:50,197:INFO:Declaring metric variables
2023-05-12 15:18:50,203:INFO:Importing untrained model
2023-05-12 15:18:50,208:INFO:K Neighbors Regressor Imported successfully
2023-05-12 15:18:50,219:INFO:Starting cross validation
2023-05-12 15:18:50,221:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:18:54,756:INFO:Calculating mean and std
2023-05-12 15:18:54,757:INFO:Creating metrics dataframe
2023-05-12 15:18:54,761:INFO:Uploading results into container
2023-05-12 15:18:54,762:INFO:Uploading model into container now
2023-05-12 15:18:54,762:INFO:_master_model_container: 11
2023-05-12 15:18:54,762:INFO:_display_container: 2
2023-05-12 15:18:54,763:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-12 15:18:54,763:INFO:create_model() successfully completed......................................
2023-05-12 15:18:54,844:INFO:SubProcess create_model() end ==================================
2023-05-12 15:18:54,844:INFO:Creating metrics dataframe
2023-05-12 15:18:54,875:INFO:Initializing Decision Tree Regressor
2023-05-12 15:18:54,876:INFO:Total runtime is 0.1429842154184977 minutes
2023-05-12 15:18:54,892:INFO:SubProcess create_model() called ==================================
2023-05-12 15:18:54,893:INFO:Initializing create_model()
2023-05-12 15:18:54,893:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:18:54,893:INFO:Checking exceptions
2023-05-12 15:18:54,893:INFO:Importing libraries
2023-05-12 15:18:54,893:INFO:Copying training dataset
2023-05-12 15:18:54,905:INFO:Defining folds
2023-05-12 15:18:54,906:INFO:Declaring metric variables
2023-05-12 15:18:54,914:INFO:Importing untrained model
2023-05-12 15:18:54,922:INFO:Decision Tree Regressor Imported successfully
2023-05-12 15:18:54,941:INFO:Starting cross validation
2023-05-12 15:18:54,943:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:18:55,189:INFO:Calculating mean and std
2023-05-12 15:18:55,190:INFO:Creating metrics dataframe
2023-05-12 15:18:55,194:INFO:Uploading results into container
2023-05-12 15:18:55,195:INFO:Uploading model into container now
2023-05-12 15:18:55,195:INFO:_master_model_container: 12
2023-05-12 15:18:55,195:INFO:_display_container: 2
2023-05-12 15:18:55,196:INFO:DecisionTreeRegressor(random_state=123)
2023-05-12 15:18:55,196:INFO:create_model() successfully completed......................................
2023-05-12 15:18:55,276:INFO:SubProcess create_model() end ==================================
2023-05-12 15:18:55,276:INFO:Creating metrics dataframe
2023-05-12 15:18:55,293:INFO:Initializing Random Forest Regressor
2023-05-12 15:18:55,293:INFO:Total runtime is 0.14993446667989094 minutes
2023-05-12 15:18:55,297:INFO:SubProcess create_model() called ==================================
2023-05-12 15:18:55,298:INFO:Initializing create_model()
2023-05-12 15:18:55,298:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:18:55,298:INFO:Checking exceptions
2023-05-12 15:18:55,298:INFO:Importing libraries
2023-05-12 15:18:55,298:INFO:Copying training dataset
2023-05-12 15:18:55,303:INFO:Defining folds
2023-05-12 15:18:55,303:INFO:Declaring metric variables
2023-05-12 15:18:55,310:INFO:Importing untrained model
2023-05-12 15:18:55,315:INFO:Random Forest Regressor Imported successfully
2023-05-12 15:18:55,324:INFO:Starting cross validation
2023-05-12 15:18:55,326:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:18:57,264:INFO:Calculating mean and std
2023-05-12 15:18:57,265:INFO:Creating metrics dataframe
2023-05-12 15:18:57,269:INFO:Uploading results into container
2023-05-12 15:18:57,270:INFO:Uploading model into container now
2023-05-12 15:18:57,271:INFO:_master_model_container: 13
2023-05-12 15:18:57,271:INFO:_display_container: 2
2023-05-12 15:18:57,271:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-05-12 15:18:57,272:INFO:create_model() successfully completed......................................
2023-05-12 15:18:57,354:INFO:SubProcess create_model() end ==================================
2023-05-12 15:18:57,354:INFO:Creating metrics dataframe
2023-05-12 15:18:57,370:INFO:Initializing Extra Trees Regressor
2023-05-12 15:18:57,370:INFO:Total runtime is 0.18454304933547971 minutes
2023-05-12 15:18:57,375:INFO:SubProcess create_model() called ==================================
2023-05-12 15:18:57,376:INFO:Initializing create_model()
2023-05-12 15:18:57,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:18:57,376:INFO:Checking exceptions
2023-05-12 15:18:57,376:INFO:Importing libraries
2023-05-12 15:18:57,377:INFO:Copying training dataset
2023-05-12 15:18:57,380:INFO:Defining folds
2023-05-12 15:18:57,380:INFO:Declaring metric variables
2023-05-12 15:18:57,386:INFO:Importing untrained model
2023-05-12 15:18:57,391:INFO:Extra Trees Regressor Imported successfully
2023-05-12 15:18:57,401:INFO:Starting cross validation
2023-05-12 15:18:57,403:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:18:59,182:INFO:Calculating mean and std
2023-05-12 15:18:59,183:INFO:Creating metrics dataframe
2023-05-12 15:18:59,187:INFO:Uploading results into container
2023-05-12 15:18:59,188:INFO:Uploading model into container now
2023-05-12 15:18:59,189:INFO:_master_model_container: 14
2023-05-12 15:18:59,189:INFO:_display_container: 2
2023-05-12 15:18:59,189:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-05-12 15:18:59,190:INFO:create_model() successfully completed......................................
2023-05-12 15:18:59,273:INFO:SubProcess create_model() end ==================================
2023-05-12 15:18:59,273:INFO:Creating metrics dataframe
2023-05-12 15:18:59,290:INFO:Initializing AdaBoost Regressor
2023-05-12 15:18:59,290:INFO:Total runtime is 0.21654268900553383 minutes
2023-05-12 15:18:59,294:INFO:SubProcess create_model() called ==================================
2023-05-12 15:18:59,295:INFO:Initializing create_model()
2023-05-12 15:18:59,295:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:18:59,295:INFO:Checking exceptions
2023-05-12 15:18:59,295:INFO:Importing libraries
2023-05-12 15:18:59,295:INFO:Copying training dataset
2023-05-12 15:18:59,299:INFO:Defining folds
2023-05-12 15:18:59,299:INFO:Declaring metric variables
2023-05-12 15:18:59,305:INFO:Importing untrained model
2023-05-12 15:18:59,310:INFO:AdaBoost Regressor Imported successfully
2023-05-12 15:18:59,320:INFO:Starting cross validation
2023-05-12 15:18:59,322:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:18:59,781:INFO:Calculating mean and std
2023-05-12 15:18:59,782:INFO:Creating metrics dataframe
2023-05-12 15:18:59,786:INFO:Uploading results into container
2023-05-12 15:18:59,787:INFO:Uploading model into container now
2023-05-12 15:18:59,788:INFO:_master_model_container: 15
2023-05-12 15:18:59,788:INFO:_display_container: 2
2023-05-12 15:18:59,788:INFO:AdaBoostRegressor(random_state=123)
2023-05-12 15:18:59,788:INFO:create_model() successfully completed......................................
2023-05-12 15:18:59,869:INFO:SubProcess create_model() end ==================================
2023-05-12 15:18:59,869:INFO:Creating metrics dataframe
2023-05-12 15:18:59,886:INFO:Initializing Gradient Boosting Regressor
2023-05-12 15:18:59,886:INFO:Total runtime is 0.22647629578908282 minutes
2023-05-12 15:18:59,891:INFO:SubProcess create_model() called ==================================
2023-05-12 15:18:59,891:INFO:Initializing create_model()
2023-05-12 15:18:59,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:18:59,891:INFO:Checking exceptions
2023-05-12 15:18:59,892:INFO:Importing libraries
2023-05-12 15:18:59,892:INFO:Copying training dataset
2023-05-12 15:18:59,895:INFO:Defining folds
2023-05-12 15:18:59,896:INFO:Declaring metric variables
2023-05-12 15:18:59,902:INFO:Importing untrained model
2023-05-12 15:18:59,907:INFO:Gradient Boosting Regressor Imported successfully
2023-05-12 15:18:59,917:INFO:Starting cross validation
2023-05-12 15:18:59,918:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:19:00,512:INFO:Calculating mean and std
2023-05-12 15:19:00,514:INFO:Creating metrics dataframe
2023-05-12 15:19:00,518:INFO:Uploading results into container
2023-05-12 15:19:00,519:INFO:Uploading model into container now
2023-05-12 15:19:00,519:INFO:_master_model_container: 16
2023-05-12 15:19:00,519:INFO:_display_container: 2
2023-05-12 15:19:00,520:INFO:GradientBoostingRegressor(random_state=123)
2023-05-12 15:19:00,520:INFO:create_model() successfully completed......................................
2023-05-12 15:19:00,602:INFO:SubProcess create_model() end ==================================
2023-05-12 15:19:00,602:INFO:Creating metrics dataframe
2023-05-12 15:19:00,620:INFO:Initializing Extreme Gradient Boosting
2023-05-12 15:19:00,621:INFO:Total runtime is 0.23872606356938678 minutes
2023-05-12 15:19:00,625:INFO:SubProcess create_model() called ==================================
2023-05-12 15:19:00,626:INFO:Initializing create_model()
2023-05-12 15:19:00,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:19:00,626:INFO:Checking exceptions
2023-05-12 15:19:00,626:INFO:Importing libraries
2023-05-12 15:19:00,627:INFO:Copying training dataset
2023-05-12 15:19:00,630:INFO:Defining folds
2023-05-12 15:19:00,630:INFO:Declaring metric variables
2023-05-12 15:19:00,636:INFO:Importing untrained model
2023-05-12 15:19:00,642:INFO:Extreme Gradient Boosting Imported successfully
2023-05-12 15:19:00,652:INFO:Starting cross validation
2023-05-12 15:19:00,653:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:19:07,244:INFO:Calculating mean and std
2023-05-12 15:19:07,246:INFO:Creating metrics dataframe
2023-05-12 15:19:07,255:INFO:Uploading results into container
2023-05-12 15:19:07,256:INFO:Uploading model into container now
2023-05-12 15:19:07,257:INFO:_master_model_container: 17
2023-05-12 15:19:07,258:INFO:_display_container: 2
2023-05-12 15:19:07,260:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-05-12 15:19:07,260:INFO:create_model() successfully completed......................................
2023-05-12 15:19:07,383:INFO:SubProcess create_model() end ==================================
2023-05-12 15:19:07,383:INFO:Creating metrics dataframe
2023-05-12 15:19:07,398:INFO:Initializing Light Gradient Boosting Machine
2023-05-12 15:19:07,399:INFO:Total runtime is 0.35170546372731526 minutes
2023-05-12 15:19:07,403:INFO:SubProcess create_model() called ==================================
2023-05-12 15:19:07,403:INFO:Initializing create_model()
2023-05-12 15:19:07,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:19:07,404:INFO:Checking exceptions
2023-05-12 15:19:07,404:INFO:Importing libraries
2023-05-12 15:19:07,404:INFO:Copying training dataset
2023-05-12 15:19:07,408:INFO:Defining folds
2023-05-12 15:19:07,408:INFO:Declaring metric variables
2023-05-12 15:19:07,414:INFO:Importing untrained model
2023-05-12 15:19:07,419:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-12 15:19:07,427:INFO:Starting cross validation
2023-05-12 15:19:07,428:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:19:14,099:INFO:Calculating mean and std
2023-05-12 15:19:14,102:INFO:Creating metrics dataframe
2023-05-12 15:19:14,112:INFO:Uploading results into container
2023-05-12 15:19:14,113:INFO:Uploading model into container now
2023-05-12 15:19:14,114:INFO:_master_model_container: 18
2023-05-12 15:19:14,115:INFO:_display_container: 2
2023-05-12 15:19:14,115:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-05-12 15:19:14,115:INFO:create_model() successfully completed......................................
2023-05-12 15:19:14,231:INFO:SubProcess create_model() end ==================================
2023-05-12 15:19:14,231:INFO:Creating metrics dataframe
2023-05-12 15:19:14,248:INFO:Initializing Dummy Regressor
2023-05-12 15:19:14,249:INFO:Total runtime is 0.46585515737533567 minutes
2023-05-12 15:19:14,253:INFO:SubProcess create_model() called ==================================
2023-05-12 15:19:14,254:INFO:Initializing create_model()
2023-05-12 15:19:14,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A1768FD0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:19:14,254:INFO:Checking exceptions
2023-05-12 15:19:14,254:INFO:Importing libraries
2023-05-12 15:19:14,254:INFO:Copying training dataset
2023-05-12 15:19:14,258:INFO:Defining folds
2023-05-12 15:19:14,258:INFO:Declaring metric variables
2023-05-12 15:19:14,264:INFO:Importing untrained model
2023-05-12 15:19:14,269:INFO:Dummy Regressor Imported successfully
2023-05-12 15:19:14,279:INFO:Starting cross validation
2023-05-12 15:19:14,280:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:19:14,480:INFO:Calculating mean and std
2023-05-12 15:19:14,481:INFO:Creating metrics dataframe
2023-05-12 15:19:14,485:INFO:Uploading results into container
2023-05-12 15:19:14,486:INFO:Uploading model into container now
2023-05-12 15:19:14,487:INFO:_master_model_container: 19
2023-05-12 15:19:14,487:INFO:_display_container: 2
2023-05-12 15:19:14,487:INFO:DummyRegressor()
2023-05-12 15:19:14,488:INFO:create_model() successfully completed......................................
2023-05-12 15:19:14,567:INFO:SubProcess create_model() end ==================================
2023-05-12 15:19:14,567:INFO:Creating metrics dataframe
2023-05-12 15:19:14,604:INFO:Initializing create_model()
2023-05-12 15:19:14,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:19:14,604:INFO:Checking exceptions
2023-05-12 15:19:14,607:INFO:Importing libraries
2023-05-12 15:19:14,607:INFO:Copying training dataset
2023-05-12 15:19:14,609:INFO:Defining folds
2023-05-12 15:19:14,609:INFO:Declaring metric variables
2023-05-12 15:19:14,610:INFO:Importing untrained model
2023-05-12 15:19:14,610:INFO:Declaring custom model
2023-05-12 15:19:14,610:INFO:Huber Regressor Imported successfully
2023-05-12 15:19:14,611:INFO:Cross validation set to False
2023-05-12 15:19:14,611:INFO:Fitting Model
2023-05-12 15:19:14,630:INFO:HuberRegressor()
2023-05-12 15:19:14,630:INFO:create_model() successfully completed......................................
2023-05-12 15:19:14,754:INFO:_master_model_container: 19
2023-05-12 15:19:14,755:INFO:_display_container: 2
2023-05-12 15:19:14,755:INFO:HuberRegressor()
2023-05-12 15:19:14,755:INFO:compare_models() successfully completed......................................
2023-05-12 15:19:15,054:INFO:Initializing create_model()
2023-05-12 15:19:15,054:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:19:15,054:INFO:Checking exceptions
2023-05-12 15:19:15,084:INFO:Importing libraries
2023-05-12 15:19:15,084:INFO:Copying training dataset
2023-05-12 15:19:15,091:INFO:Defining folds
2023-05-12 15:19:15,091:INFO:Declaring metric variables
2023-05-12 15:19:15,100:INFO:Importing untrained model
2023-05-12 15:19:15,109:INFO:Huber Regressor Imported successfully
2023-05-12 15:19:15,121:INFO:Starting cross validation
2023-05-12 15:19:15,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:19:15,498:INFO:Calculating mean and std
2023-05-12 15:19:15,498:INFO:Creating metrics dataframe
2023-05-12 15:19:15,504:INFO:Finalizing model
2023-05-12 15:19:15,531:INFO:Uploading results into container
2023-05-12 15:19:15,532:INFO:Uploading model into container now
2023-05-12 15:19:15,544:INFO:_master_model_container: 20
2023-05-12 15:19:15,544:INFO:_display_container: 3
2023-05-12 15:19:15,545:INFO:HuberRegressor()
2023-05-12 15:19:15,546:INFO:create_model() successfully completed......................................
2023-05-12 15:19:15,807:INFO:Initializing evaluate_model()
2023-05-12 15:19:15,807:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-05-12 15:19:15,828:INFO:Initializing plot_model()
2023-05-12 15:19:15,828:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, system=True)
2023-05-12 15:19:15,829:INFO:Checking exceptions
2023-05-12 15:19:15,832:INFO:Preloading libraries
2023-05-12 15:19:15,832:INFO:Copying training dataset
2023-05-12 15:19:15,832:INFO:Plot type: pipeline
2023-05-12 15:19:15,948:INFO:Visual Rendered Successfully
2023-05-12 15:19:16,029:INFO:plot_model() successfully completed......................................
2023-05-12 15:19:16,192:INFO:Initializing predict_model()
2023-05-12 15:19:16,192:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A1768BE0>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A49DF2C1F0>)
2023-05-12 15:19:16,193:INFO:Checking exceptions
2023-05-12 15:19:16,193:INFO:Preloading libraries
2023-05-12 15:19:16,196:INFO:Set up data.
2023-05-12 15:19:16,201:INFO:Set up index.
2023-05-12 15:23:54,553:INFO:PyCaret RegressionExperiment
2023-05-12 15:23:54,553:INFO:Logging name: reg-default-name
2023-05-12 15:23:54,554:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-12 15:23:54,554:INFO:version 3.0.0.rc8
2023-05-12 15:23:54,554:INFO:Initializing setup()
2023-05-12 15:23:54,554:INFO:self.USI: a39f
2023-05-12 15:23:54,554:INFO:self._variable_keys: {'html_param', 'memory', '_available_plots', 'seed', 'idx', 'fold_groups_param', 'X', 'data', 'y_test', 'gpu_param', 'exp_name_log', 'exp_id', 'X_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'logging_param', 'USI', 'log_plots_param', 'y', 'n_jobs_param', '_ml_usecase', 'y_train', 'fold_generator', 'transform_target_param', 'pipeline', 'X_train', 'target_param'}
2023-05-12 15:23:54,555:INFO:Checking environment
2023-05-12 15:23:54,555:INFO:python_version: 3.10.9
2023-05-12 15:23:54,555:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-05-12 15:23:54,555:INFO:machine: AMD64
2023-05-12 15:23:54,555:INFO:platform: Windows-10-10.0.19045-SP0
2023-05-12 15:23:54,556:INFO:Memory: svmem(total=17090879488, available=2709766144, percent=84.1, used=14381113344, free=2709766144)
2023-05-12 15:23:54,556:INFO:Physical Core: 4
2023-05-12 15:23:54,556:INFO:Logical Core: 8
2023-05-12 15:23:54,556:INFO:Checking libraries
2023-05-12 15:23:54,557:INFO:System:
2023-05-12 15:23:54,557:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-05-12 15:23:54,557:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-05-12 15:23:54,557:INFO:   machine: Windows-10-10.0.19045-SP0
2023-05-12 15:23:54,558:INFO:PyCaret required dependencies:
2023-05-12 15:23:54,558:INFO:                 pip: 23.0
2023-05-12 15:23:54,558:INFO:          setuptools: 67.1.0
2023-05-12 15:23:54,558:INFO:             pycaret: 3.0.0rc8
2023-05-12 15:23:54,559:INFO:             IPython: 8.8.0
2023-05-12 15:23:54,559:INFO:          ipywidgets: 8.0.4
2023-05-12 15:23:54,559:INFO:                tqdm: 4.64.1
2023-05-12 15:23:54,559:INFO:               numpy: 1.23.5
2023-05-12 15:23:54,559:INFO:              pandas: 1.5.3
2023-05-12 15:23:54,560:INFO:              jinja2: 3.1.2
2023-05-12 15:23:54,560:INFO:               scipy: 1.10.0
2023-05-12 15:23:54,560:INFO:              joblib: 1.2.0
2023-05-12 15:23:54,560:INFO:             sklearn: 1.1.3
2023-05-12 15:23:54,560:INFO:                pyod: 1.0.7
2023-05-12 15:23:54,560:INFO:            imblearn: 0.10.1
2023-05-12 15:23:54,560:INFO:   category_encoders: 2.6.0
2023-05-12 15:23:54,561:INFO:            lightgbm: 3.3.5
2023-05-12 15:23:54,561:INFO:               numba: 0.56.4
2023-05-12 15:23:54,561:INFO:            requests: 2.28.2
2023-05-12 15:23:54,561:INFO:          matplotlib: 3.6.3
2023-05-12 15:23:54,561:INFO:          scikitplot: 0.3.7
2023-05-12 15:23:54,562:INFO:         yellowbrick: 1.5
2023-05-12 15:23:54,563:INFO:              plotly: 5.13.0
2023-05-12 15:23:54,563:INFO:             kaleido: 0.2.1
2023-05-12 15:23:54,563:INFO:         statsmodels: 0.13.5
2023-05-12 15:23:54,564:INFO:              sktime: 0.16.0
2023-05-12 15:23:54,564:INFO:               tbats: 1.1.2
2023-05-12 15:23:54,564:INFO:            pmdarima: 2.0.2
2023-05-12 15:23:54,565:INFO:              psutil: 5.9.0
2023-05-12 15:23:54,565:INFO:PyCaret optional dependencies:
2023-05-12 15:23:54,566:INFO:                shap: Not installed
2023-05-12 15:23:54,566:INFO:           interpret: Not installed
2023-05-12 15:23:54,566:INFO:                umap: Not installed
2023-05-12 15:23:54,566:INFO:    pandas_profiling: Not installed
2023-05-12 15:23:54,567:INFO:  explainerdashboard: Not installed
2023-05-12 15:23:54,567:INFO:             autoviz: Not installed
2023-05-12 15:23:54,567:INFO:           fairlearn: Not installed
2023-05-12 15:23:54,567:INFO:             xgboost: 1.7.3
2023-05-12 15:23:54,567:INFO:            catboost: Not installed
2023-05-12 15:23:54,568:INFO:              kmodes: Not installed
2023-05-12 15:23:54,568:INFO:             mlxtend: Not installed
2023-05-12 15:23:54,568:INFO:       statsforecast: Not installed
2023-05-12 15:23:54,568:INFO:        tune_sklearn: Not installed
2023-05-12 15:23:54,568:INFO:                 ray: Not installed
2023-05-12 15:23:54,569:INFO:            hyperopt: Not installed
2023-05-12 15:23:54,569:INFO:              optuna: Not installed
2023-05-12 15:23:54,569:INFO:               skopt: Not installed
2023-05-12 15:23:54,569:INFO:              mlflow: Not installed
2023-05-12 15:23:54,569:INFO:              gradio: Not installed
2023-05-12 15:23:54,569:INFO:             fastapi: Not installed
2023-05-12 15:23:54,570:INFO:             uvicorn: Not installed
2023-05-12 15:23:54,570:INFO:              m2cgen: Not installed
2023-05-12 15:23:54,570:INFO:           evidently: Not installed
2023-05-12 15:23:54,570:INFO:                nltk: Not installed
2023-05-12 15:23:54,570:INFO:            pyLDAvis: Not installed
2023-05-12 15:23:54,571:INFO:              gensim: Not installed
2023-05-12 15:23:54,571:INFO:               spacy: Not installed
2023-05-12 15:23:54,571:INFO:           wordcloud: Not installed
2023-05-12 15:23:54,571:INFO:            textblob: Not installed
2023-05-12 15:23:54,571:INFO:               fugue: Not installed
2023-05-12 15:23:54,572:INFO:           streamlit: Not installed
2023-05-12 15:23:54,572:INFO:             prophet: Not installed
2023-05-12 15:23:54,572:INFO:None
2023-05-12 15:23:54,572:INFO:Set up GPU usage.
2023-05-12 15:23:54,572:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:54,573:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-05-12 15:23:54,573:INFO:Set up data.
2023-05-12 15:23:54,582:INFO:Set up train/test split.
2023-05-12 15:23:54,617:INFO:Set up index.
2023-05-12 15:23:54,617:INFO:Set up folding strategy.
2023-05-12 15:23:54,617:INFO:Assigning column types.
2023-05-12 15:23:54,627:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-12 15:23:54,627:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:54,628:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 15:23:54,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:54,639:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:23:54,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:54,655:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:23:54,655:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:54,748:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:23:54,749:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:54,802:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:23:54,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:54,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:54,803:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:23:55,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:23:55,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:55,446:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 15:23:55,446:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:55,460:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:23:55,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:55,475:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:23:55,475:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:55,584:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:23:55,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:55,650:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:23:55,651:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:55,651:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:55,651:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:23:55,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:23:55,838:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-12 15:23:55,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:55,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:55,851:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:23:55,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:55,865:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:23:55,865:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:55,987:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:23:55,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,074:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:23:56,074:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,074:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,075:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:23:56,269:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:23:56,270:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,270:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,285:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:23:56,285:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,300:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:23:56,300:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,412:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:23:56,412:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,473:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:23:56,473:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,473:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,474:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:23:56,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:23:56,646:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-12 15:23:56,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,660:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,676:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:23:56,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,799:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:23:56,800:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,856:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:23:56,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:56,857:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:23:57,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:23:57,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,059:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,072:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:23:57,072:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,189:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:23:57,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,243:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:23:57,243:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,244:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,245:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:23:57,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:23:57,429:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-12 15:23:57,429:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,430:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,455:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,568:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:23:57,568:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,628:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:23:57,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,629:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:23:57,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:23:57,816:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,816:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,830:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:57,956:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:23:57,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,011:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:23:58,012:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,012:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,013:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:23:58,211:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:23:58,212:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-12 15:23:58,212:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,226:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,346:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:23:58,346:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,398:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:23:58,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:23:58,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,702:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:23:58,702:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,754:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,755:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,755:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:23:58,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:23:58,947:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-12 15:23:58,948:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,948:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:58,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,084:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,137:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,137:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,137:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:23:59,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:23:59,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,322:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,333:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,344:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,463:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,521:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,521:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:23:59,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:23:59,695:INFO:Preparing preprocessing pipeline...
2023-05-12 15:23:59,697:INFO:Set up simple imputation.
2023-05-12 15:23:59,713:INFO:Finished creating preprocessing pipeline.
2023-05-12 15:23:59,721:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-05-12 15:23:59,721:INFO:Creating final display dataframe.
2023-05-12 15:23:59,841:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape         (1042, 2)
4        Transformed data shape         (1042, 2)
5   Transformed train set shape          (729, 2)
6    Transformed test set shape          (313, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              a39f
2023-05-12 15:23:59,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,857:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:23:59,995:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:24:00,166:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:24:00,167:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:24:00,168:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:24:00,178:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:24:00,188:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:24:00,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:24:00,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:24:00,363:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:24:00,363:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:24:00,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:24:00,548:INFO:setup() successfully completed in 6.0s...............
2023-05-12 15:24:00,618:INFO:Initializing compare_models()
2023-05-12 15:24:00,618:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-12 15:24:00,618:INFO:Checking exceptions
2023-05-12 15:24:00,623:INFO:Preparing display monitor
2023-05-12 15:24:00,688:INFO:Initializing Linear Regression
2023-05-12 15:24:00,688:INFO:Total runtime is 0.0 minutes
2023-05-12 15:24:00,696:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:00,697:INFO:Initializing create_model()
2023-05-12 15:24:00,697:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:00,698:INFO:Checking exceptions
2023-05-12 15:24:00,699:INFO:Importing libraries
2023-05-12 15:24:00,700:INFO:Copying training dataset
2023-05-12 15:24:00,706:INFO:Defining folds
2023-05-12 15:24:00,706:INFO:Declaring metric variables
2023-05-12 15:24:00,712:INFO:Importing untrained model
2023-05-12 15:24:00,719:INFO:Linear Regression Imported successfully
2023-05-12 15:24:00,732:INFO:Starting cross validation
2023-05-12 15:24:00,734:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:01,016:INFO:Calculating mean and std
2023-05-12 15:24:01,017:INFO:Creating metrics dataframe
2023-05-12 15:24:01,020:INFO:Uploading results into container
2023-05-12 15:24:01,021:INFO:Uploading model into container now
2023-05-12 15:24:01,022:INFO:_master_model_container: 1
2023-05-12 15:24:01,022:INFO:_display_container: 2
2023-05-12 15:24:01,022:INFO:LinearRegression(n_jobs=-1)
2023-05-12 15:24:01,022:INFO:create_model() successfully completed......................................
2023-05-12 15:24:01,134:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:01,134:INFO:Creating metrics dataframe
2023-05-12 15:24:01,148:INFO:Initializing Lasso Regression
2023-05-12 15:24:01,148:INFO:Total runtime is 0.00766754945119222 minutes
2023-05-12 15:24:01,154:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:01,154:INFO:Initializing create_model()
2023-05-12 15:24:01,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:01,155:INFO:Checking exceptions
2023-05-12 15:24:01,155:INFO:Importing libraries
2023-05-12 15:24:01,155:INFO:Copying training dataset
2023-05-12 15:24:01,158:INFO:Defining folds
2023-05-12 15:24:01,158:INFO:Declaring metric variables
2023-05-12 15:24:01,164:INFO:Importing untrained model
2023-05-12 15:24:01,171:INFO:Lasso Regression Imported successfully
2023-05-12 15:24:01,184:INFO:Starting cross validation
2023-05-12 15:24:01,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:01,208:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.228e+08, tolerance: 1.948e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:01,236:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.926e+08, tolerance: 1.970e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:01,264:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.543e+08, tolerance: 1.940e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:01,294:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.701e+08, tolerance: 1.938e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:01,322:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.060e+08, tolerance: 1.941e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:01,350:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.280e+08, tolerance: 1.951e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:01,379:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.429e+08, tolerance: 1.974e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:01,409:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.178e+08, tolerance: 1.907e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:01,437:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.602e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:01,465:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.286e+08, tolerance: 1.982e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:01,475:INFO:Calculating mean and std
2023-05-12 15:24:01,476:INFO:Creating metrics dataframe
2023-05-12 15:24:01,480:INFO:Uploading results into container
2023-05-12 15:24:01,481:INFO:Uploading model into container now
2023-05-12 15:24:01,481:INFO:_master_model_container: 2
2023-05-12 15:24:01,482:INFO:_display_container: 2
2023-05-12 15:24:01,482:INFO:Lasso(random_state=123)
2023-05-12 15:24:01,482:INFO:create_model() successfully completed......................................
2023-05-12 15:24:01,573:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:01,573:INFO:Creating metrics dataframe
2023-05-12 15:24:01,586:INFO:Initializing Ridge Regression
2023-05-12 15:24:01,586:INFO:Total runtime is 0.014967552820841471 minutes
2023-05-12 15:24:01,591:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:01,592:INFO:Initializing create_model()
2023-05-12 15:24:01,592:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:01,592:INFO:Checking exceptions
2023-05-12 15:24:01,592:INFO:Importing libraries
2023-05-12 15:24:01,592:INFO:Copying training dataset
2023-05-12 15:24:01,598:INFO:Defining folds
2023-05-12 15:24:01,598:INFO:Declaring metric variables
2023-05-12 15:24:01,606:INFO:Importing untrained model
2023-05-12 15:24:01,623:INFO:Ridge Regression Imported successfully
2023-05-12 15:24:01,642:INFO:Starting cross validation
2023-05-12 15:24:01,645:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:01,903:INFO:Calculating mean and std
2023-05-12 15:24:01,904:INFO:Creating metrics dataframe
2023-05-12 15:24:01,909:INFO:Uploading results into container
2023-05-12 15:24:01,911:INFO:Uploading model into container now
2023-05-12 15:24:01,912:INFO:_master_model_container: 3
2023-05-12 15:24:01,912:INFO:_display_container: 2
2023-05-12 15:24:01,912:INFO:Ridge(random_state=123)
2023-05-12 15:24:01,913:INFO:create_model() successfully completed......................................
2023-05-12 15:24:01,996:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:01,996:INFO:Creating metrics dataframe
2023-05-12 15:24:02,007:INFO:Initializing Elastic Net
2023-05-12 15:24:02,008:INFO:Total runtime is 0.022000877062479655 minutes
2023-05-12 15:24:02,014:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:02,014:INFO:Initializing create_model()
2023-05-12 15:24:02,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:02,015:INFO:Checking exceptions
2023-05-12 15:24:02,015:INFO:Importing libraries
2023-05-12 15:24:02,015:INFO:Copying training dataset
2023-05-12 15:24:02,018:INFO:Defining folds
2023-05-12 15:24:02,019:INFO:Declaring metric variables
2023-05-12 15:24:02,024:INFO:Importing untrained model
2023-05-12 15:24:02,031:INFO:Elastic Net Imported successfully
2023-05-12 15:24:02,039:INFO:Starting cross validation
2023-05-12 15:24:02,040:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:02,059:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.219e+08, tolerance: 1.948e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:02,082:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.152e+08, tolerance: 1.970e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:02,106:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.940e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:02,129:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.927e+08, tolerance: 1.938e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:02,154:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.434e+08, tolerance: 1.941e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:02,177:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.622e+08, tolerance: 1.951e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:02,200:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.840e+08, tolerance: 1.974e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:02,223:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.019e+08, tolerance: 1.907e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:02,247:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.858e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:02,270:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.022e+08, tolerance: 1.982e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:24:02,280:INFO:Calculating mean and std
2023-05-12 15:24:02,282:INFO:Creating metrics dataframe
2023-05-12 15:24:02,287:INFO:Uploading results into container
2023-05-12 15:24:02,288:INFO:Uploading model into container now
2023-05-12 15:24:02,289:INFO:_master_model_container: 4
2023-05-12 15:24:02,289:INFO:_display_container: 2
2023-05-12 15:24:02,289:INFO:ElasticNet(random_state=123)
2023-05-12 15:24:02,290:INFO:create_model() successfully completed......................................
2023-05-12 15:24:02,371:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:02,371:INFO:Creating metrics dataframe
2023-05-12 15:24:02,384:INFO:Initializing Least Angle Regression
2023-05-12 15:24:02,385:INFO:Total runtime is 0.028284223874409993 minutes
2023-05-12 15:24:02,389:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:02,389:INFO:Initializing create_model()
2023-05-12 15:24:02,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:02,390:INFO:Checking exceptions
2023-05-12 15:24:02,390:INFO:Importing libraries
2023-05-12 15:24:02,390:INFO:Copying training dataset
2023-05-12 15:24:02,394:INFO:Defining folds
2023-05-12 15:24:02,394:INFO:Declaring metric variables
2023-05-12 15:24:02,400:INFO:Importing untrained model
2023-05-12 15:24:02,405:INFO:Least Angle Regression Imported successfully
2023-05-12 15:24:02,416:INFO:Starting cross validation
2023-05-12 15:24:02,417:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:02,431:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:02,455:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:02,479:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:02,501:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:02,524:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:02,546:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:02,569:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:02,592:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:02,617:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:02,639:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:02,650:INFO:Calculating mean and std
2023-05-12 15:24:02,651:INFO:Creating metrics dataframe
2023-05-12 15:24:02,655:INFO:Uploading results into container
2023-05-12 15:24:02,656:INFO:Uploading model into container now
2023-05-12 15:24:02,656:INFO:_master_model_container: 5
2023-05-12 15:24:02,656:INFO:_display_container: 2
2023-05-12 15:24:02,657:INFO:Lars(random_state=123)
2023-05-12 15:24:02,657:INFO:create_model() successfully completed......................................
2023-05-12 15:24:02,741:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:02,741:INFO:Creating metrics dataframe
2023-05-12 15:24:02,754:INFO:Initializing Lasso Least Angle Regression
2023-05-12 15:24:02,754:INFO:Total runtime is 0.03443482319513957 minutes
2023-05-12 15:24:02,758:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:02,759:INFO:Initializing create_model()
2023-05-12 15:24:02,760:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:02,760:INFO:Checking exceptions
2023-05-12 15:24:02,761:INFO:Importing libraries
2023-05-12 15:24:02,761:INFO:Copying training dataset
2023-05-12 15:24:02,765:INFO:Defining folds
2023-05-12 15:24:02,766:INFO:Declaring metric variables
2023-05-12 15:24:02,774:INFO:Importing untrained model
2023-05-12 15:24:02,780:INFO:Lasso Least Angle Regression Imported successfully
2023-05-12 15:24:02,789:INFO:Starting cross validation
2023-05-12 15:24:02,790:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:02,806:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:24:02,840:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:24:02,875:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:24:02,906:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:24:02,937:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:24:02,962:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:24:02,987:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:24:03,014:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:24:03,041:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:24:03,064:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:24:03,075:INFO:Calculating mean and std
2023-05-12 15:24:03,076:INFO:Creating metrics dataframe
2023-05-12 15:24:03,080:INFO:Uploading results into container
2023-05-12 15:24:03,081:INFO:Uploading model into container now
2023-05-12 15:24:03,081:INFO:_master_model_container: 6
2023-05-12 15:24:03,081:INFO:_display_container: 2
2023-05-12 15:24:03,082:INFO:LassoLars(random_state=123)
2023-05-12 15:24:03,082:INFO:create_model() successfully completed......................................
2023-05-12 15:24:03,162:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:03,162:INFO:Creating metrics dataframe
2023-05-12 15:24:03,177:INFO:Initializing Orthogonal Matching Pursuit
2023-05-12 15:24:03,177:INFO:Total runtime is 0.04147910674413045 minutes
2023-05-12 15:24:03,182:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:03,182:INFO:Initializing create_model()
2023-05-12 15:24:03,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:03,183:INFO:Checking exceptions
2023-05-12 15:24:03,183:INFO:Importing libraries
2023-05-12 15:24:03,183:INFO:Copying training dataset
2023-05-12 15:24:03,186:INFO:Defining folds
2023-05-12 15:24:03,187:INFO:Declaring metric variables
2023-05-12 15:24:03,192:INFO:Importing untrained model
2023-05-12 15:24:03,198:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-12 15:24:03,207:INFO:Starting cross validation
2023-05-12 15:24:03,208:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:03,222:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:03,246:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:03,267:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:03,290:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:03,313:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:03,334:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:03,358:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:03,381:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:03,404:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:03,432:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:24:03,448:INFO:Calculating mean and std
2023-05-12 15:24:03,449:INFO:Creating metrics dataframe
2023-05-12 15:24:03,453:INFO:Uploading results into container
2023-05-12 15:24:03,454:INFO:Uploading model into container now
2023-05-12 15:24:03,455:INFO:_master_model_container: 7
2023-05-12 15:24:03,455:INFO:_display_container: 2
2023-05-12 15:24:03,455:INFO:OrthogonalMatchingPursuit()
2023-05-12 15:24:03,455:INFO:create_model() successfully completed......................................
2023-05-12 15:24:03,565:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:03,566:INFO:Creating metrics dataframe
2023-05-12 15:24:03,579:INFO:Initializing Bayesian Ridge
2023-05-12 15:24:03,579:INFO:Total runtime is 0.04818347692489624 minutes
2023-05-12 15:24:03,584:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:03,584:INFO:Initializing create_model()
2023-05-12 15:24:03,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:03,585:INFO:Checking exceptions
2023-05-12 15:24:03,585:INFO:Importing libraries
2023-05-12 15:24:03,585:INFO:Copying training dataset
2023-05-12 15:24:03,589:INFO:Defining folds
2023-05-12 15:24:03,589:INFO:Declaring metric variables
2023-05-12 15:24:03,595:INFO:Importing untrained model
2023-05-12 15:24:03,603:INFO:Bayesian Ridge Imported successfully
2023-05-12 15:24:03,615:INFO:Starting cross validation
2023-05-12 15:24:03,616:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:03,845:INFO:Calculating mean and std
2023-05-12 15:24:03,847:INFO:Creating metrics dataframe
2023-05-12 15:24:03,850:INFO:Uploading results into container
2023-05-12 15:24:03,851:INFO:Uploading model into container now
2023-05-12 15:24:03,852:INFO:_master_model_container: 8
2023-05-12 15:24:03,852:INFO:_display_container: 2
2023-05-12 15:24:03,852:INFO:BayesianRidge()
2023-05-12 15:24:03,852:INFO:create_model() successfully completed......................................
2023-05-12 15:24:03,935:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:03,935:INFO:Creating metrics dataframe
2023-05-12 15:24:03,951:INFO:Initializing Passive Aggressive Regressor
2023-05-12 15:24:03,951:INFO:Total runtime is 0.05438414414723714 minutes
2023-05-12 15:24:03,955:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:03,956:INFO:Initializing create_model()
2023-05-12 15:24:03,956:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:03,957:INFO:Checking exceptions
2023-05-12 15:24:03,957:INFO:Importing libraries
2023-05-12 15:24:03,957:INFO:Copying training dataset
2023-05-12 15:24:03,963:INFO:Defining folds
2023-05-12 15:24:03,964:INFO:Declaring metric variables
2023-05-12 15:24:03,971:INFO:Importing untrained model
2023-05-12 15:24:03,979:INFO:Passive Aggressive Regressor Imported successfully
2023-05-12 15:24:03,990:INFO:Starting cross validation
2023-05-12 15:24:03,991:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:04,247:INFO:Calculating mean and std
2023-05-12 15:24:04,248:INFO:Creating metrics dataframe
2023-05-12 15:24:04,252:INFO:Uploading results into container
2023-05-12 15:24:04,252:INFO:Uploading model into container now
2023-05-12 15:24:04,253:INFO:_master_model_container: 9
2023-05-12 15:24:04,253:INFO:_display_container: 2
2023-05-12 15:24:04,254:INFO:PassiveAggressiveRegressor(random_state=123)
2023-05-12 15:24:04,254:INFO:create_model() successfully completed......................................
2023-05-12 15:24:04,391:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:04,391:INFO:Creating metrics dataframe
2023-05-12 15:24:04,405:INFO:Initializing Huber Regressor
2023-05-12 15:24:04,405:INFO:Total runtime is 0.061940550804138184 minutes
2023-05-12 15:24:04,410:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:04,411:INFO:Initializing create_model()
2023-05-12 15:24:04,411:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:04,411:INFO:Checking exceptions
2023-05-12 15:24:04,411:INFO:Importing libraries
2023-05-12 15:24:04,411:INFO:Copying training dataset
2023-05-12 15:24:04,415:INFO:Defining folds
2023-05-12 15:24:04,416:INFO:Declaring metric variables
2023-05-12 15:24:04,421:INFO:Importing untrained model
2023-05-12 15:24:04,426:INFO:Huber Regressor Imported successfully
2023-05-12 15:24:04,436:INFO:Starting cross validation
2023-05-12 15:24:04,437:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:04,714:INFO:Calculating mean and std
2023-05-12 15:24:04,716:INFO:Creating metrics dataframe
2023-05-12 15:24:04,719:INFO:Uploading results into container
2023-05-12 15:24:04,720:INFO:Uploading model into container now
2023-05-12 15:24:04,721:INFO:_master_model_container: 10
2023-05-12 15:24:04,722:INFO:_display_container: 2
2023-05-12 15:24:04,722:INFO:HuberRegressor()
2023-05-12 15:24:04,723:INFO:create_model() successfully completed......................................
2023-05-12 15:24:04,818:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:04,819:INFO:Creating metrics dataframe
2023-05-12 15:24:04,834:INFO:Initializing K Neighbors Regressor
2023-05-12 15:24:04,834:INFO:Total runtime is 0.06909053325653076 minutes
2023-05-12 15:24:04,839:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:04,840:INFO:Initializing create_model()
2023-05-12 15:24:04,840:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:04,840:INFO:Checking exceptions
2023-05-12 15:24:04,840:INFO:Importing libraries
2023-05-12 15:24:04,840:INFO:Copying training dataset
2023-05-12 15:24:04,845:INFO:Defining folds
2023-05-12 15:24:04,845:INFO:Declaring metric variables
2023-05-12 15:24:04,852:INFO:Importing untrained model
2023-05-12 15:24:04,857:INFO:K Neighbors Regressor Imported successfully
2023-05-12 15:24:04,872:INFO:Starting cross validation
2023-05-12 15:24:04,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:05,737:INFO:Calculating mean and std
2023-05-12 15:24:05,739:INFO:Creating metrics dataframe
2023-05-12 15:24:05,753:INFO:Uploading results into container
2023-05-12 15:24:05,755:INFO:Uploading model into container now
2023-05-12 15:24:05,756:INFO:_master_model_container: 11
2023-05-12 15:24:05,756:INFO:_display_container: 2
2023-05-12 15:24:05,757:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-12 15:24:05,757:INFO:create_model() successfully completed......................................
2023-05-12 15:24:05,921:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:05,921:INFO:Creating metrics dataframe
2023-05-12 15:24:05,967:INFO:Initializing Decision Tree Regressor
2023-05-12 15:24:05,968:INFO:Total runtime is 0.08797385692596435 minutes
2023-05-12 15:24:05,978:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:05,979:INFO:Initializing create_model()
2023-05-12 15:24:05,980:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:05,980:INFO:Checking exceptions
2023-05-12 15:24:05,980:INFO:Importing libraries
2023-05-12 15:24:05,980:INFO:Copying training dataset
2023-05-12 15:24:05,990:INFO:Defining folds
2023-05-12 15:24:05,990:INFO:Declaring metric variables
2023-05-12 15:24:06,001:INFO:Importing untrained model
2023-05-12 15:24:06,026:INFO:Decision Tree Regressor Imported successfully
2023-05-12 15:24:06,052:INFO:Starting cross validation
2023-05-12 15:24:06,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:06,683:INFO:Calculating mean and std
2023-05-12 15:24:06,686:INFO:Creating metrics dataframe
2023-05-12 15:24:06,698:INFO:Uploading results into container
2023-05-12 15:24:06,700:INFO:Uploading model into container now
2023-05-12 15:24:06,701:INFO:_master_model_container: 12
2023-05-12 15:24:06,701:INFO:_display_container: 2
2023-05-12 15:24:06,702:INFO:DecisionTreeRegressor(random_state=123)
2023-05-12 15:24:06,702:INFO:create_model() successfully completed......................................
2023-05-12 15:24:06,956:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:06,956:INFO:Creating metrics dataframe
2023-05-12 15:24:07,003:INFO:Initializing Random Forest Regressor
2023-05-12 15:24:07,003:INFO:Total runtime is 0.10524052381515503 minutes
2023-05-12 15:24:07,017:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:07,018:INFO:Initializing create_model()
2023-05-12 15:24:07,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:07,019:INFO:Checking exceptions
2023-05-12 15:24:07,019:INFO:Importing libraries
2023-05-12 15:24:07,019:INFO:Copying training dataset
2023-05-12 15:24:07,032:INFO:Defining folds
2023-05-12 15:24:07,032:INFO:Declaring metric variables
2023-05-12 15:24:07,045:INFO:Importing untrained model
2023-05-12 15:24:07,056:INFO:Random Forest Regressor Imported successfully
2023-05-12 15:24:07,082:INFO:Starting cross validation
2023-05-12 15:24:07,084:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:11,165:INFO:Calculating mean and std
2023-05-12 15:24:11,167:INFO:Creating metrics dataframe
2023-05-12 15:24:11,172:INFO:Uploading results into container
2023-05-12 15:24:11,172:INFO:Uploading model into container now
2023-05-12 15:24:11,173:INFO:_master_model_container: 13
2023-05-12 15:24:11,173:INFO:_display_container: 2
2023-05-12 15:24:11,174:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-05-12 15:24:11,175:INFO:create_model() successfully completed......................................
2023-05-12 15:24:11,275:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:11,275:INFO:Creating metrics dataframe
2023-05-12 15:24:11,295:INFO:Initializing Extra Trees Regressor
2023-05-12 15:24:11,295:INFO:Total runtime is 0.17677388985951742 minutes
2023-05-12 15:24:11,299:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:11,300:INFO:Initializing create_model()
2023-05-12 15:24:11,300:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:11,300:INFO:Checking exceptions
2023-05-12 15:24:11,300:INFO:Importing libraries
2023-05-12 15:24:11,301:INFO:Copying training dataset
2023-05-12 15:24:11,304:INFO:Defining folds
2023-05-12 15:24:11,305:INFO:Declaring metric variables
2023-05-12 15:24:11,311:INFO:Importing untrained model
2023-05-12 15:24:11,319:INFO:Extra Trees Regressor Imported successfully
2023-05-12 15:24:11,330:INFO:Starting cross validation
2023-05-12 15:24:11,331:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:13,222:INFO:Calculating mean and std
2023-05-12 15:24:13,223:INFO:Creating metrics dataframe
2023-05-12 15:24:13,228:INFO:Uploading results into container
2023-05-12 15:24:13,229:INFO:Uploading model into container now
2023-05-12 15:24:13,230:INFO:_master_model_container: 14
2023-05-12 15:24:13,230:INFO:_display_container: 2
2023-05-12 15:24:13,230:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-05-12 15:24:13,231:INFO:create_model() successfully completed......................................
2023-05-12 15:24:13,318:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:13,318:INFO:Creating metrics dataframe
2023-05-12 15:24:13,334:INFO:Initializing AdaBoost Regressor
2023-05-12 15:24:13,334:INFO:Total runtime is 0.2107572078704834 minutes
2023-05-12 15:24:13,339:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:13,339:INFO:Initializing create_model()
2023-05-12 15:24:13,340:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:13,340:INFO:Checking exceptions
2023-05-12 15:24:13,340:INFO:Importing libraries
2023-05-12 15:24:13,340:INFO:Copying training dataset
2023-05-12 15:24:13,345:INFO:Defining folds
2023-05-12 15:24:13,345:INFO:Declaring metric variables
2023-05-12 15:24:13,350:INFO:Importing untrained model
2023-05-12 15:24:13,356:INFO:AdaBoost Regressor Imported successfully
2023-05-12 15:24:13,365:INFO:Starting cross validation
2023-05-12 15:24:13,366:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:13,970:INFO:Calculating mean and std
2023-05-12 15:24:13,972:INFO:Creating metrics dataframe
2023-05-12 15:24:13,976:INFO:Uploading results into container
2023-05-12 15:24:13,977:INFO:Uploading model into container now
2023-05-12 15:24:13,977:INFO:_master_model_container: 15
2023-05-12 15:24:13,978:INFO:_display_container: 2
2023-05-12 15:24:13,978:INFO:AdaBoostRegressor(random_state=123)
2023-05-12 15:24:13,979:INFO:create_model() successfully completed......................................
2023-05-12 15:24:14,062:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:14,062:INFO:Creating metrics dataframe
2023-05-12 15:24:14,078:INFO:Initializing Gradient Boosting Regressor
2023-05-12 15:24:14,078:INFO:Total runtime is 0.22315746943155926 minutes
2023-05-12 15:24:14,083:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:14,084:INFO:Initializing create_model()
2023-05-12 15:24:14,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:14,084:INFO:Checking exceptions
2023-05-12 15:24:14,084:INFO:Importing libraries
2023-05-12 15:24:14,084:INFO:Copying training dataset
2023-05-12 15:24:14,088:INFO:Defining folds
2023-05-12 15:24:14,088:INFO:Declaring metric variables
2023-05-12 15:24:14,093:INFO:Importing untrained model
2023-05-12 15:24:14,099:INFO:Gradient Boosting Regressor Imported successfully
2023-05-12 15:24:14,109:INFO:Starting cross validation
2023-05-12 15:24:14,110:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:14,754:INFO:Calculating mean and std
2023-05-12 15:24:14,755:INFO:Creating metrics dataframe
2023-05-12 15:24:14,761:INFO:Uploading results into container
2023-05-12 15:24:14,761:INFO:Uploading model into container now
2023-05-12 15:24:14,762:INFO:_master_model_container: 16
2023-05-12 15:24:14,762:INFO:_display_container: 2
2023-05-12 15:24:14,763:INFO:GradientBoostingRegressor(random_state=123)
2023-05-12 15:24:14,764:INFO:create_model() successfully completed......................................
2023-05-12 15:24:14,844:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:14,845:INFO:Creating metrics dataframe
2023-05-12 15:24:14,861:INFO:Initializing Extreme Gradient Boosting
2023-05-12 15:24:14,861:INFO:Total runtime is 0.23620744943618777 minutes
2023-05-12 15:24:14,866:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:14,866:INFO:Initializing create_model()
2023-05-12 15:24:14,866:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:14,867:INFO:Checking exceptions
2023-05-12 15:24:14,867:INFO:Importing libraries
2023-05-12 15:24:14,867:INFO:Copying training dataset
2023-05-12 15:24:14,870:INFO:Defining folds
2023-05-12 15:24:14,871:INFO:Declaring metric variables
2023-05-12 15:24:14,877:INFO:Importing untrained model
2023-05-12 15:24:14,883:INFO:Extreme Gradient Boosting Imported successfully
2023-05-12 15:24:14,893:INFO:Starting cross validation
2023-05-12 15:24:14,894:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:21,570:INFO:Calculating mean and std
2023-05-12 15:24:21,573:INFO:Creating metrics dataframe
2023-05-12 15:24:21,582:INFO:Uploading results into container
2023-05-12 15:24:21,583:INFO:Uploading model into container now
2023-05-12 15:24:21,584:INFO:_master_model_container: 17
2023-05-12 15:24:21,584:INFO:_display_container: 2
2023-05-12 15:24:21,586:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-05-12 15:24:21,586:INFO:create_model() successfully completed......................................
2023-05-12 15:24:21,707:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:21,707:INFO:Creating metrics dataframe
2023-05-12 15:24:21,725:INFO:Initializing Light Gradient Boosting Machine
2023-05-12 15:24:21,725:INFO:Total runtime is 0.3506121595700582 minutes
2023-05-12 15:24:21,765:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:21,766:INFO:Initializing create_model()
2023-05-12 15:24:21,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:21,766:INFO:Checking exceptions
2023-05-12 15:24:21,767:INFO:Importing libraries
2023-05-12 15:24:21,767:INFO:Copying training dataset
2023-05-12 15:24:21,775:INFO:Defining folds
2023-05-12 15:24:21,776:INFO:Declaring metric variables
2023-05-12 15:24:21,787:INFO:Importing untrained model
2023-05-12 15:24:21,796:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-12 15:24:21,807:INFO:Starting cross validation
2023-05-12 15:24:21,809:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:30,357:INFO:Calculating mean and std
2023-05-12 15:24:30,360:INFO:Creating metrics dataframe
2023-05-12 15:24:30,370:INFO:Uploading results into container
2023-05-12 15:24:30,371:INFO:Uploading model into container now
2023-05-12 15:24:30,372:INFO:_master_model_container: 18
2023-05-12 15:24:30,372:INFO:_display_container: 2
2023-05-12 15:24:30,373:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-05-12 15:24:30,373:INFO:create_model() successfully completed......................................
2023-05-12 15:24:30,491:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:30,491:INFO:Creating metrics dataframe
2023-05-12 15:24:30,508:INFO:Initializing Dummy Regressor
2023-05-12 15:24:30,508:INFO:Total runtime is 0.4969955603281657 minutes
2023-05-12 15:24:30,514:INFO:SubProcess create_model() called ==================================
2023-05-12 15:24:30,514:INFO:Initializing create_model()
2023-05-12 15:24:30,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4F93065C0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:30,514:INFO:Checking exceptions
2023-05-12 15:24:30,515:INFO:Importing libraries
2023-05-12 15:24:30,515:INFO:Copying training dataset
2023-05-12 15:24:30,519:INFO:Defining folds
2023-05-12 15:24:30,519:INFO:Declaring metric variables
2023-05-12 15:24:30,524:INFO:Importing untrained model
2023-05-12 15:24:30,530:INFO:Dummy Regressor Imported successfully
2023-05-12 15:24:30,540:INFO:Starting cross validation
2023-05-12 15:24:30,542:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:30,755:INFO:Calculating mean and std
2023-05-12 15:24:30,757:INFO:Creating metrics dataframe
2023-05-12 15:24:30,761:INFO:Uploading results into container
2023-05-12 15:24:30,762:INFO:Uploading model into container now
2023-05-12 15:24:30,762:INFO:_master_model_container: 19
2023-05-12 15:24:30,762:INFO:_display_container: 2
2023-05-12 15:24:30,763:INFO:DummyRegressor()
2023-05-12 15:24:30,763:INFO:create_model() successfully completed......................................
2023-05-12 15:24:30,843:INFO:SubProcess create_model() end ==================================
2023-05-12 15:24:30,843:INFO:Creating metrics dataframe
2023-05-12 15:24:30,874:INFO:Initializing create_model()
2023-05-12 15:24:30,874:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:30,874:INFO:Checking exceptions
2023-05-12 15:24:30,877:INFO:Importing libraries
2023-05-12 15:24:30,877:INFO:Copying training dataset
2023-05-12 15:24:30,880:INFO:Defining folds
2023-05-12 15:24:30,880:INFO:Declaring metric variables
2023-05-12 15:24:30,880:INFO:Importing untrained model
2023-05-12 15:24:30,880:INFO:Declaring custom model
2023-05-12 15:24:30,881:INFO:Linear Regression Imported successfully
2023-05-12 15:24:30,881:INFO:Cross validation set to False
2023-05-12 15:24:30,881:INFO:Fitting Model
2023-05-12 15:24:30,896:INFO:LinearRegression(n_jobs=-1)
2023-05-12 15:24:30,896:INFO:create_model() successfully completed......................................
2023-05-12 15:24:31,024:INFO:_master_model_container: 19
2023-05-12 15:24:31,025:INFO:_display_container: 2
2023-05-12 15:24:31,025:INFO:LinearRegression(n_jobs=-1)
2023-05-12 15:24:31,025:INFO:compare_models() successfully completed......................................
2023-05-12 15:24:31,260:INFO:Initializing create_model()
2023-05-12 15:24:31,260:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:24:31,260:INFO:Checking exceptions
2023-05-12 15:24:31,294:INFO:Importing libraries
2023-05-12 15:24:31,298:INFO:Copying training dataset
2023-05-12 15:24:31,303:INFO:Defining folds
2023-05-12 15:24:31,303:INFO:Declaring metric variables
2023-05-12 15:24:31,311:INFO:Importing untrained model
2023-05-12 15:24:31,318:INFO:Huber Regressor Imported successfully
2023-05-12 15:24:31,356:INFO:Starting cross validation
2023-05-12 15:24:31,361:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:24:31,706:INFO:Calculating mean and std
2023-05-12 15:24:31,707:INFO:Creating metrics dataframe
2023-05-12 15:24:31,713:INFO:Finalizing model
2023-05-12 15:24:31,738:INFO:Uploading results into container
2023-05-12 15:24:31,740:INFO:Uploading model into container now
2023-05-12 15:24:31,756:INFO:_master_model_container: 20
2023-05-12 15:24:31,756:INFO:_display_container: 3
2023-05-12 15:24:31,757:INFO:HuberRegressor()
2023-05-12 15:24:31,757:INFO:create_model() successfully completed......................................
2023-05-12 15:24:32,025:INFO:Initializing evaluate_model()
2023-05-12 15:24:32,026:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-05-12 15:24:32,047:INFO:Initializing plot_model()
2023-05-12 15:24:32,047:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, system=True)
2023-05-12 15:24:32,047:INFO:Checking exceptions
2023-05-12 15:24:32,051:INFO:Preloading libraries
2023-05-12 15:24:32,051:INFO:Copying training dataset
2023-05-12 15:24:32,051:INFO:Plot type: pipeline
2023-05-12 15:24:32,176:INFO:Visual Rendered Successfully
2023-05-12 15:24:32,259:INFO:plot_model() successfully completed......................................
2023-05-12 15:24:32,413:INFO:Initializing predict_model()
2023-05-12 15:24:32,413:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A15FE9B0>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A4A16EC8B0>)
2023-05-12 15:24:32,413:INFO:Checking exceptions
2023-05-12 15:24:32,414:INFO:Preloading libraries
2023-05-12 15:24:32,417:INFO:Set up data.
2023-05-12 15:24:32,425:INFO:Set up index.
2023-05-12 15:26:43,378:INFO:PyCaret RegressionExperiment
2023-05-12 15:26:43,378:INFO:Logging name: reg-default-name
2023-05-12 15:26:43,378:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-12 15:26:43,378:INFO:version 3.0.0.rc8
2023-05-12 15:26:43,378:INFO:Initializing setup()
2023-05-12 15:26:43,379:INFO:self.USI: 956a
2023-05-12 15:26:43,379:INFO:self._variable_keys: {'html_param', 'memory', '_available_plots', 'seed', 'idx', 'fold_groups_param', 'X', 'data', 'y_test', 'gpu_param', 'exp_name_log', 'exp_id', 'X_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'logging_param', 'USI', 'log_plots_param', 'y', 'n_jobs_param', '_ml_usecase', 'y_train', 'fold_generator', 'transform_target_param', 'pipeline', 'X_train', 'target_param'}
2023-05-12 15:26:43,379:INFO:Checking environment
2023-05-12 15:26:43,380:INFO:python_version: 3.10.9
2023-05-12 15:26:43,380:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-05-12 15:26:43,380:INFO:machine: AMD64
2023-05-12 15:26:43,380:INFO:platform: Windows-10-10.0.19045-SP0
2023-05-12 15:26:43,380:INFO:Memory: svmem(total=17090879488, available=2783264768, percent=83.7, used=14307614720, free=2783264768)
2023-05-12 15:26:43,381:INFO:Physical Core: 4
2023-05-12 15:26:43,381:INFO:Logical Core: 8
2023-05-12 15:26:43,381:INFO:Checking libraries
2023-05-12 15:26:43,382:INFO:System:
2023-05-12 15:26:43,382:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-05-12 15:26:43,382:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-05-12 15:26:43,382:INFO:   machine: Windows-10-10.0.19045-SP0
2023-05-12 15:26:43,382:INFO:PyCaret required dependencies:
2023-05-12 15:26:43,382:INFO:                 pip: 23.0
2023-05-12 15:26:43,382:INFO:          setuptools: 67.1.0
2023-05-12 15:26:43,382:INFO:             pycaret: 3.0.0rc8
2023-05-12 15:26:43,383:INFO:             IPython: 8.8.0
2023-05-12 15:26:43,383:INFO:          ipywidgets: 8.0.4
2023-05-12 15:26:43,383:INFO:                tqdm: 4.64.1
2023-05-12 15:26:43,383:INFO:               numpy: 1.23.5
2023-05-12 15:26:43,383:INFO:              pandas: 1.5.3
2023-05-12 15:26:43,383:INFO:              jinja2: 3.1.2
2023-05-12 15:26:43,383:INFO:               scipy: 1.10.0
2023-05-12 15:26:43,384:INFO:              joblib: 1.2.0
2023-05-12 15:26:43,384:INFO:             sklearn: 1.1.3
2023-05-12 15:26:43,384:INFO:                pyod: 1.0.7
2023-05-12 15:26:43,384:INFO:            imblearn: 0.10.1
2023-05-12 15:26:43,384:INFO:   category_encoders: 2.6.0
2023-05-12 15:26:43,385:INFO:            lightgbm: 3.3.5
2023-05-12 15:26:43,385:INFO:               numba: 0.56.4
2023-05-12 15:26:43,385:INFO:            requests: 2.28.2
2023-05-12 15:26:43,385:INFO:          matplotlib: 3.6.3
2023-05-12 15:26:43,385:INFO:          scikitplot: 0.3.7
2023-05-12 15:26:43,386:INFO:         yellowbrick: 1.5
2023-05-12 15:26:43,386:INFO:              plotly: 5.13.0
2023-05-12 15:26:43,386:INFO:             kaleido: 0.2.1
2023-05-12 15:26:43,386:INFO:         statsmodels: 0.13.5
2023-05-12 15:26:43,386:INFO:              sktime: 0.16.0
2023-05-12 15:26:43,387:INFO:               tbats: 1.1.2
2023-05-12 15:26:43,387:INFO:            pmdarima: 2.0.2
2023-05-12 15:26:43,387:INFO:              psutil: 5.9.0
2023-05-12 15:26:43,387:INFO:PyCaret optional dependencies:
2023-05-12 15:26:43,387:INFO:                shap: Not installed
2023-05-12 15:26:43,387:INFO:           interpret: Not installed
2023-05-12 15:26:43,388:INFO:                umap: Not installed
2023-05-12 15:26:43,388:INFO:    pandas_profiling: Not installed
2023-05-12 15:26:43,388:INFO:  explainerdashboard: Not installed
2023-05-12 15:26:43,388:INFO:             autoviz: Not installed
2023-05-12 15:26:43,388:INFO:           fairlearn: Not installed
2023-05-12 15:26:43,389:INFO:             xgboost: 1.7.3
2023-05-12 15:26:43,389:INFO:            catboost: Not installed
2023-05-12 15:26:43,389:INFO:              kmodes: Not installed
2023-05-12 15:26:43,389:INFO:             mlxtend: Not installed
2023-05-12 15:26:43,390:INFO:       statsforecast: Not installed
2023-05-12 15:26:43,390:INFO:        tune_sklearn: Not installed
2023-05-12 15:26:43,391:INFO:                 ray: Not installed
2023-05-12 15:26:43,391:INFO:            hyperopt: Not installed
2023-05-12 15:26:43,391:INFO:              optuna: Not installed
2023-05-12 15:26:43,392:INFO:               skopt: Not installed
2023-05-12 15:26:43,393:INFO:              mlflow: Not installed
2023-05-12 15:26:43,393:INFO:              gradio: Not installed
2023-05-12 15:26:43,393:INFO:             fastapi: Not installed
2023-05-12 15:26:43,393:INFO:             uvicorn: Not installed
2023-05-12 15:26:43,394:INFO:              m2cgen: Not installed
2023-05-12 15:26:43,395:INFO:           evidently: Not installed
2023-05-12 15:26:43,395:INFO:                nltk: Not installed
2023-05-12 15:26:43,395:INFO:            pyLDAvis: Not installed
2023-05-12 15:26:43,395:INFO:              gensim: Not installed
2023-05-12 15:26:43,395:INFO:               spacy: Not installed
2023-05-12 15:26:43,396:INFO:           wordcloud: Not installed
2023-05-12 15:26:43,396:INFO:            textblob: Not installed
2023-05-12 15:26:43,396:INFO:               fugue: Not installed
2023-05-12 15:26:43,397:INFO:           streamlit: Not installed
2023-05-12 15:26:43,397:INFO:             prophet: Not installed
2023-05-12 15:26:43,398:INFO:None
2023-05-12 15:26:43,398:INFO:Set up GPU usage.
2023-05-12 15:26:43,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:43,398:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-05-12 15:26:43,399:INFO:Set up data.
2023-05-12 15:26:43,410:INFO:Set up train/test split.
2023-05-12 15:26:43,414:INFO:Set up index.
2023-05-12 15:26:43,414:INFO:Set up folding strategy.
2023-05-12 15:26:43,415:INFO:Assigning column types.
2023-05-12 15:26:43,423:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-12 15:26:43,424:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:43,424:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 15:26:43,424:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:43,432:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:26:43,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:43,438:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:26:43,438:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:43,531:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:26:43,531:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:43,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:26:43,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:43,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:43,585:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:26:44,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:26:44,234:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:44,235:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 15:26:44,235:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:44,247:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:26:44,248:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:44,261:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:26:44,261:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:44,382:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:26:44,382:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:44,444:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:26:44,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:44,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:44,445:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:26:44,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:26:44,644:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-12 15:26:44,644:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:44,644:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:44,658:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:26:44,658:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:44,671:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:26:44,671:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:44,791:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:26:44,791:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:44,845:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:26:44,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:44,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:44,846:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:26:45,002:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:26:45,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,016:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:26:45,017:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,031:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:26:45,031:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,143:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:26:45,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,198:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:26:45,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,199:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,199:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:26:45,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:26:45,399:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-12 15:26:45,399:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,400:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,412:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,425:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:26:45,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,535:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:26:45,535:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,587:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:26:45,587:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,587:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,588:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:26:45,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:26:45,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,800:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:26:45,800:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,912:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:26:45,912:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,969:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:26:45,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:45,970:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:26:46,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:26:46,174:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-12 15:26:46,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,175:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,188:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,202:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,312:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:26:46,312:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,364:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:26:46,364:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,364:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,364:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:26:46,556:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:26:46,557:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,557:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,570:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,583:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,691:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:26:46,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,747:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:26:46,747:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,748:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,748:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:26:46,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:26:46,907:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-12 15:26:46,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,908:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:46,935:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,048:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:26:47,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,131:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:26:47,324:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:26:47,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,349:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,462:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:26:47,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,522:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,522:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,522:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:26:47,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:26:47,741:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-12 15:26:47,742:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,742:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,759:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,955:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:47,956:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:26:48,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:26:48,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:48,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:48,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:48,157:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:48,275:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:48,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:48,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:48,330:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:26:48,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:26:48,527:INFO:Preparing preprocessing pipeline...
2023-05-12 15:26:48,529:INFO:Set up simple imputation.
2023-05-12 15:26:48,545:INFO:Finished creating preprocessing pipeline.
2023-05-12 15:26:48,556:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-05-12 15:26:48,556:INFO:Creating final display dataframe.
2023-05-12 15:26:48,669:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape         (1042, 2)
4        Transformed data shape         (1042, 2)
5   Transformed train set shape          (729, 2)
6    Transformed test set shape          (313, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              956a
2023-05-12 15:26:48,677:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:48,678:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:48,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:48,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:48,758:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:48,810:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:48,810:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:48,811:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:26:48,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:26:48,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:48,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:48,996:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:49,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:49,113:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:49,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:49,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:26:49,165:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:26:49,359:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:26:49,361:INFO:setup() successfully completed in 5.99s...............
2023-05-12 15:26:49,426:INFO:Initializing compare_models()
2023-05-12 15:26:49,427:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-12 15:26:49,427:INFO:Checking exceptions
2023-05-12 15:26:49,431:INFO:Preparing display monitor
2023-05-12 15:26:49,486:INFO:Initializing Linear Regression
2023-05-12 15:26:49,486:INFO:Total runtime is 0.0 minutes
2023-05-12 15:26:49,494:INFO:SubProcess create_model() called ==================================
2023-05-12 15:26:49,494:INFO:Initializing create_model()
2023-05-12 15:26:49,494:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:26:49,495:INFO:Checking exceptions
2023-05-12 15:26:49,495:INFO:Importing libraries
2023-05-12 15:26:49,496:INFO:Copying training dataset
2023-05-12 15:26:49,502:INFO:Defining folds
2023-05-12 15:26:49,503:INFO:Declaring metric variables
2023-05-12 15:26:49,516:INFO:Importing untrained model
2023-05-12 15:26:49,531:INFO:Linear Regression Imported successfully
2023-05-12 15:26:49,548:INFO:Starting cross validation
2023-05-12 15:26:49,549:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:26:49,864:INFO:Calculating mean and std
2023-05-12 15:26:49,865:INFO:Creating metrics dataframe
2023-05-12 15:26:49,869:INFO:Uploading results into container
2023-05-12 15:26:49,871:INFO:Uploading model into container now
2023-05-12 15:26:49,872:INFO:_master_model_container: 1
2023-05-12 15:26:49,872:INFO:_display_container: 2
2023-05-12 15:26:49,872:INFO:LinearRegression(n_jobs=-1)
2023-05-12 15:26:49,872:INFO:create_model() successfully completed......................................
2023-05-12 15:26:49,981:INFO:SubProcess create_model() end ==================================
2023-05-12 15:26:49,981:INFO:Creating metrics dataframe
2023-05-12 15:26:49,994:INFO:Initializing Lasso Regression
2023-05-12 15:26:49,994:INFO:Total runtime is 0.008466931184132893 minutes
2023-05-12 15:26:49,999:INFO:SubProcess create_model() called ==================================
2023-05-12 15:26:49,999:INFO:Initializing create_model()
2023-05-12 15:26:50,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:26:50,000:INFO:Checking exceptions
2023-05-12 15:26:50,000:INFO:Importing libraries
2023-05-12 15:26:50,000:INFO:Copying training dataset
2023-05-12 15:26:50,004:INFO:Defining folds
2023-05-12 15:26:50,004:INFO:Declaring metric variables
2023-05-12 15:26:50,009:INFO:Importing untrained model
2023-05-12 15:26:50,014:INFO:Lasso Regression Imported successfully
2023-05-12 15:26:50,025:INFO:Starting cross validation
2023-05-12 15:26:50,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:26:50,041:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.228e+08, tolerance: 1.948e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:50,067:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.926e+08, tolerance: 1.970e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:50,093:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.543e+08, tolerance: 1.940e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:50,126:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.701e+08, tolerance: 1.938e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:50,152:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.060e+08, tolerance: 1.941e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:50,179:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.280e+08, tolerance: 1.951e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:50,204:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.429e+08, tolerance: 1.974e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:50,228:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.178e+08, tolerance: 1.907e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:50,253:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.602e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:50,279:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.286e+08, tolerance: 1.982e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:50,291:INFO:Calculating mean and std
2023-05-12 15:26:50,291:INFO:Creating metrics dataframe
2023-05-12 15:26:50,295:INFO:Uploading results into container
2023-05-12 15:26:50,295:INFO:Uploading model into container now
2023-05-12 15:26:50,296:INFO:_master_model_container: 2
2023-05-12 15:26:50,296:INFO:_display_container: 2
2023-05-12 15:26:50,296:INFO:Lasso(random_state=123)
2023-05-12 15:26:50,296:INFO:create_model() successfully completed......................................
2023-05-12 15:26:50,395:INFO:SubProcess create_model() end ==================================
2023-05-12 15:26:50,395:INFO:Creating metrics dataframe
2023-05-12 15:26:50,407:INFO:Initializing Ridge Regression
2023-05-12 15:26:50,408:INFO:Total runtime is 0.015366705258687337 minutes
2023-05-12 15:26:50,412:INFO:SubProcess create_model() called ==================================
2023-05-12 15:26:50,413:INFO:Initializing create_model()
2023-05-12 15:26:50,413:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:26:50,413:INFO:Checking exceptions
2023-05-12 15:26:50,413:INFO:Importing libraries
2023-05-12 15:26:50,413:INFO:Copying training dataset
2023-05-12 15:26:50,416:INFO:Defining folds
2023-05-12 15:26:50,416:INFO:Declaring metric variables
2023-05-12 15:26:50,421:INFO:Importing untrained model
2023-05-12 15:26:50,426:INFO:Ridge Regression Imported successfully
2023-05-12 15:26:50,436:INFO:Starting cross validation
2023-05-12 15:26:50,438:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:26:50,710:INFO:Calculating mean and std
2023-05-12 15:26:50,712:INFO:Creating metrics dataframe
2023-05-12 15:26:50,717:INFO:Uploading results into container
2023-05-12 15:26:50,717:INFO:Uploading model into container now
2023-05-12 15:26:50,718:INFO:_master_model_container: 3
2023-05-12 15:26:50,718:INFO:_display_container: 2
2023-05-12 15:26:50,719:INFO:Ridge(random_state=123)
2023-05-12 15:26:50,720:INFO:create_model() successfully completed......................................
2023-05-12 15:26:50,818:INFO:SubProcess create_model() end ==================================
2023-05-12 15:26:50,818:INFO:Creating metrics dataframe
2023-05-12 15:26:50,834:INFO:Initializing Elastic Net
2023-05-12 15:26:50,834:INFO:Total runtime is 0.02246667941411336 minutes
2023-05-12 15:26:50,841:INFO:SubProcess create_model() called ==================================
2023-05-12 15:26:50,842:INFO:Initializing create_model()
2023-05-12 15:26:50,842:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:26:50,842:INFO:Checking exceptions
2023-05-12 15:26:50,842:INFO:Importing libraries
2023-05-12 15:26:50,842:INFO:Copying training dataset
2023-05-12 15:26:50,847:INFO:Defining folds
2023-05-12 15:26:50,847:INFO:Declaring metric variables
2023-05-12 15:26:50,853:INFO:Importing untrained model
2023-05-12 15:26:50,858:INFO:Elastic Net Imported successfully
2023-05-12 15:26:50,869:INFO:Starting cross validation
2023-05-12 15:26:50,871:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:26:50,889:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.219e+08, tolerance: 1.948e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:50,913:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.152e+08, tolerance: 1.970e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:50,937:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.940e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:50,960:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.927e+08, tolerance: 1.938e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:50,983:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.434e+08, tolerance: 1.941e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:51,008:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.622e+08, tolerance: 1.951e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:51,032:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.840e+08, tolerance: 1.974e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:51,057:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.019e+08, tolerance: 1.907e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:51,082:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.858e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:51,108:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.022e+08, tolerance: 1.982e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:26:51,119:INFO:Calculating mean and std
2023-05-12 15:26:51,121:INFO:Creating metrics dataframe
2023-05-12 15:26:51,125:INFO:Uploading results into container
2023-05-12 15:26:51,126:INFO:Uploading model into container now
2023-05-12 15:26:51,127:INFO:_master_model_container: 4
2023-05-12 15:26:51,127:INFO:_display_container: 2
2023-05-12 15:26:51,128:INFO:ElasticNet(random_state=123)
2023-05-12 15:26:51,129:INFO:create_model() successfully completed......................................
2023-05-12 15:26:51,212:INFO:SubProcess create_model() end ==================================
2023-05-12 15:26:51,212:INFO:Creating metrics dataframe
2023-05-12 15:26:51,225:INFO:Initializing Least Angle Regression
2023-05-12 15:26:51,225:INFO:Total runtime is 0.028983624776204427 minutes
2023-05-12 15:26:51,230:INFO:SubProcess create_model() called ==================================
2023-05-12 15:26:51,230:INFO:Initializing create_model()
2023-05-12 15:26:51,230:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:26:51,230:INFO:Checking exceptions
2023-05-12 15:26:51,230:INFO:Importing libraries
2023-05-12 15:26:51,231:INFO:Copying training dataset
2023-05-12 15:26:51,234:INFO:Defining folds
2023-05-12 15:26:51,234:INFO:Declaring metric variables
2023-05-12 15:26:51,241:INFO:Importing untrained model
2023-05-12 15:26:51,246:INFO:Least Angle Regression Imported successfully
2023-05-12 15:26:51,256:INFO:Starting cross validation
2023-05-12 15:26:51,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:26:51,271:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:51,295:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:51,318:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:51,341:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:51,363:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:51,387:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:51,410:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:51,432:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:51,454:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:51,477:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:51,487:INFO:Calculating mean and std
2023-05-12 15:26:51,489:INFO:Creating metrics dataframe
2023-05-12 15:26:51,493:INFO:Uploading results into container
2023-05-12 15:26:51,493:INFO:Uploading model into container now
2023-05-12 15:26:51,494:INFO:_master_model_container: 5
2023-05-12 15:26:51,494:INFO:_display_container: 2
2023-05-12 15:26:51,494:INFO:Lars(random_state=123)
2023-05-12 15:26:51,495:INFO:create_model() successfully completed......................................
2023-05-12 15:26:51,583:INFO:SubProcess create_model() end ==================================
2023-05-12 15:26:51,583:INFO:Creating metrics dataframe
2023-05-12 15:26:51,596:INFO:Initializing Lasso Least Angle Regression
2023-05-12 15:26:51,596:INFO:Total runtime is 0.03516665697097778 minutes
2023-05-12 15:26:51,602:INFO:SubProcess create_model() called ==================================
2023-05-12 15:26:51,602:INFO:Initializing create_model()
2023-05-12 15:26:51,603:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:26:51,603:INFO:Checking exceptions
2023-05-12 15:26:51,604:INFO:Importing libraries
2023-05-12 15:26:51,604:INFO:Copying training dataset
2023-05-12 15:26:51,610:INFO:Defining folds
2023-05-12 15:26:51,610:INFO:Declaring metric variables
2023-05-12 15:26:51,617:INFO:Importing untrained model
2023-05-12 15:26:51,624:INFO:Lasso Least Angle Regression Imported successfully
2023-05-12 15:26:51,635:INFO:Starting cross validation
2023-05-12 15:26:51,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:26:51,653:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:26:51,678:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:26:51,702:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:26:51,726:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:26:51,748:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:26:51,773:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:26:51,796:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:26:51,820:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:26:51,842:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:26:51,867:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:26:51,878:INFO:Calculating mean and std
2023-05-12 15:26:51,879:INFO:Creating metrics dataframe
2023-05-12 15:26:51,884:INFO:Uploading results into container
2023-05-12 15:26:51,885:INFO:Uploading model into container now
2023-05-12 15:26:51,886:INFO:_master_model_container: 6
2023-05-12 15:26:51,886:INFO:_display_container: 2
2023-05-12 15:26:51,887:INFO:LassoLars(random_state=123)
2023-05-12 15:26:51,887:INFO:create_model() successfully completed......................................
2023-05-12 15:26:51,971:INFO:SubProcess create_model() end ==================================
2023-05-12 15:26:51,971:INFO:Creating metrics dataframe
2023-05-12 15:26:51,984:INFO:Initializing Orthogonal Matching Pursuit
2023-05-12 15:26:51,984:INFO:Total runtime is 0.041633609930674234 minutes
2023-05-12 15:26:51,990:INFO:SubProcess create_model() called ==================================
2023-05-12 15:26:51,990:INFO:Initializing create_model()
2023-05-12 15:26:51,991:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:26:51,991:INFO:Checking exceptions
2023-05-12 15:26:51,991:INFO:Importing libraries
2023-05-12 15:26:51,991:INFO:Copying training dataset
2023-05-12 15:26:51,995:INFO:Defining folds
2023-05-12 15:26:51,995:INFO:Declaring metric variables
2023-05-12 15:26:52,001:INFO:Importing untrained model
2023-05-12 15:26:52,007:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-12 15:26:52,015:INFO:Starting cross validation
2023-05-12 15:26:52,016:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:26:52,030:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:52,053:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:52,075:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:52,098:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:52,121:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:52,145:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:52,168:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:52,192:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:52,214:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:52,238:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:26:52,250:INFO:Calculating mean and std
2023-05-12 15:26:52,251:INFO:Creating metrics dataframe
2023-05-12 15:26:52,256:INFO:Uploading results into container
2023-05-12 15:26:52,257:INFO:Uploading model into container now
2023-05-12 15:26:52,258:INFO:_master_model_container: 7
2023-05-12 15:26:52,258:INFO:_display_container: 2
2023-05-12 15:26:52,259:INFO:OrthogonalMatchingPursuit()
2023-05-12 15:26:52,259:INFO:create_model() successfully completed......................................
2023-05-12 15:26:52,341:INFO:SubProcess create_model() end ==================================
2023-05-12 15:26:52,342:INFO:Creating metrics dataframe
2023-05-12 15:26:52,355:INFO:Initializing Bayesian Ridge
2023-05-12 15:26:52,355:INFO:Total runtime is 0.04781662623087565 minutes
2023-05-12 15:26:52,361:INFO:SubProcess create_model() called ==================================
2023-05-12 15:26:52,361:INFO:Initializing create_model()
2023-05-12 15:26:52,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:26:52,362:INFO:Checking exceptions
2023-05-12 15:26:52,362:INFO:Importing libraries
2023-05-12 15:26:52,362:INFO:Copying training dataset
2023-05-12 15:26:52,366:INFO:Defining folds
2023-05-12 15:26:52,366:INFO:Declaring metric variables
2023-05-12 15:26:52,372:INFO:Importing untrained model
2023-05-12 15:26:52,378:INFO:Bayesian Ridge Imported successfully
2023-05-12 15:26:52,388:INFO:Starting cross validation
2023-05-12 15:26:52,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:26:52,630:INFO:Calculating mean and std
2023-05-12 15:26:52,631:INFO:Creating metrics dataframe
2023-05-12 15:26:52,635:INFO:Uploading results into container
2023-05-12 15:26:52,636:INFO:Uploading model into container now
2023-05-12 15:26:52,637:INFO:_master_model_container: 8
2023-05-12 15:26:52,637:INFO:_display_container: 2
2023-05-12 15:26:52,638:INFO:BayesianRidge()
2023-05-12 15:26:52,638:INFO:create_model() successfully completed......................................
2023-05-12 15:26:52,722:INFO:SubProcess create_model() end ==================================
2023-05-12 15:26:52,722:INFO:Creating metrics dataframe
2023-05-12 15:26:52,735:INFO:Initializing Passive Aggressive Regressor
2023-05-12 15:26:52,736:INFO:Total runtime is 0.05416676998138428 minutes
2023-05-12 15:26:52,741:INFO:SubProcess create_model() called ==================================
2023-05-12 15:26:52,742:INFO:Initializing create_model()
2023-05-12 15:26:52,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:26:52,742:INFO:Checking exceptions
2023-05-12 15:26:52,742:INFO:Importing libraries
2023-05-12 15:26:52,742:INFO:Copying training dataset
2023-05-12 15:26:52,747:INFO:Defining folds
2023-05-12 15:26:52,747:INFO:Declaring metric variables
2023-05-12 15:26:52,755:INFO:Importing untrained model
2023-05-12 15:26:52,760:INFO:Passive Aggressive Regressor Imported successfully
2023-05-12 15:26:52,770:INFO:Starting cross validation
2023-05-12 15:26:52,771:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:26:53,005:INFO:Calculating mean and std
2023-05-12 15:26:53,006:INFO:Creating metrics dataframe
2023-05-12 15:26:53,010:INFO:Uploading results into container
2023-05-12 15:26:53,011:INFO:Uploading model into container now
2023-05-12 15:26:53,011:INFO:_master_model_container: 9
2023-05-12 15:26:53,012:INFO:_display_container: 2
2023-05-12 15:26:53,012:INFO:PassiveAggressiveRegressor(random_state=123)
2023-05-12 15:26:53,013:INFO:create_model() successfully completed......................................
2023-05-12 15:26:53,095:INFO:SubProcess create_model() end ==================================
2023-05-12 15:26:53,095:INFO:Creating metrics dataframe
2023-05-12 15:26:53,108:INFO:Initializing Huber Regressor
2023-05-12 15:26:53,109:INFO:Total runtime is 0.06037760178248088 minutes
2023-05-12 15:26:53,114:INFO:SubProcess create_model() called ==================================
2023-05-12 15:26:53,115:INFO:Initializing create_model()
2023-05-12 15:26:53,115:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:26:53,115:INFO:Checking exceptions
2023-05-12 15:26:53,115:INFO:Importing libraries
2023-05-12 15:26:53,115:INFO:Copying training dataset
2023-05-12 15:26:53,119:INFO:Defining folds
2023-05-12 15:26:53,120:INFO:Declaring metric variables
2023-05-12 15:26:53,126:INFO:Importing untrained model
2023-05-12 15:26:53,131:INFO:Huber Regressor Imported successfully
2023-05-12 15:26:53,142:INFO:Starting cross validation
2023-05-12 15:26:53,143:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:26:53,469:INFO:Calculating mean and std
2023-05-12 15:26:53,471:INFO:Creating metrics dataframe
2023-05-12 15:26:53,477:INFO:Uploading results into container
2023-05-12 15:26:53,478:INFO:Uploading model into container now
2023-05-12 15:26:53,479:INFO:_master_model_container: 10
2023-05-12 15:26:53,479:INFO:_display_container: 2
2023-05-12 15:26:53,480:INFO:HuberRegressor()
2023-05-12 15:26:53,480:INFO:create_model() successfully completed......................................
2023-05-12 15:26:53,576:INFO:SubProcess create_model() end ==================================
2023-05-12 15:26:53,576:INFO:Creating metrics dataframe
2023-05-12 15:26:53,599:INFO:Initializing K Neighbors Regressor
2023-05-12 15:26:53,600:INFO:Total runtime is 0.06856094201405843 minutes
2023-05-12 15:26:53,606:INFO:SubProcess create_model() called ==================================
2023-05-12 15:26:53,607:INFO:Initializing create_model()
2023-05-12 15:26:53,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:26:53,607:INFO:Checking exceptions
2023-05-12 15:26:53,607:INFO:Importing libraries
2023-05-12 15:26:53,607:INFO:Copying training dataset
2023-05-12 15:26:53,612:INFO:Defining folds
2023-05-12 15:26:53,612:INFO:Declaring metric variables
2023-05-12 15:26:53,618:INFO:Importing untrained model
2023-05-12 15:26:53,624:INFO:K Neighbors Regressor Imported successfully
2023-05-12 15:26:53,633:INFO:Starting cross validation
2023-05-12 15:26:53,634:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:26:53,996:INFO:Calculating mean and std
2023-05-12 15:26:53,998:INFO:Creating metrics dataframe
2023-05-12 15:26:54,001:INFO:Uploading results into container
2023-05-12 15:26:54,002:INFO:Uploading model into container now
2023-05-12 15:26:54,003:INFO:_master_model_container: 11
2023-05-12 15:26:54,004:INFO:_display_container: 2
2023-05-12 15:26:54,004:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-12 15:26:54,004:INFO:create_model() successfully completed......................................
2023-05-12 15:26:54,086:INFO:SubProcess create_model() end ==================================
2023-05-12 15:26:54,086:INFO:Creating metrics dataframe
2023-05-12 15:26:54,101:INFO:Initializing Decision Tree Regressor
2023-05-12 15:26:54,102:INFO:Total runtime is 0.07693310976028443 minutes
2023-05-12 15:26:54,107:INFO:SubProcess create_model() called ==================================
2023-05-12 15:26:54,108:INFO:Initializing create_model()
2023-05-12 15:26:54,108:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:26:54,108:INFO:Checking exceptions
2023-05-12 15:26:54,108:INFO:Importing libraries
2023-05-12 15:26:54,108:INFO:Copying training dataset
2023-05-12 15:26:54,112:INFO:Defining folds
2023-05-12 15:26:54,112:INFO:Declaring metric variables
2023-05-12 15:26:54,117:INFO:Importing untrained model
2023-05-12 15:26:54,124:INFO:Decision Tree Regressor Imported successfully
2023-05-12 15:26:54,134:INFO:Starting cross validation
2023-05-12 15:26:54,136:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:26:54,374:INFO:Calculating mean and std
2023-05-12 15:26:54,375:INFO:Creating metrics dataframe
2023-05-12 15:26:54,379:INFO:Uploading results into container
2023-05-12 15:26:54,380:INFO:Uploading model into container now
2023-05-12 15:26:54,380:INFO:_master_model_container: 12
2023-05-12 15:26:54,380:INFO:_display_container: 2
2023-05-12 15:26:54,380:INFO:DecisionTreeRegressor(random_state=123)
2023-05-12 15:26:54,381:INFO:create_model() successfully completed......................................
2023-05-12 15:26:54,464:INFO:SubProcess create_model() end ==================================
2023-05-12 15:26:54,465:INFO:Creating metrics dataframe
2023-05-12 15:26:54,480:INFO:Initializing Random Forest Regressor
2023-05-12 15:26:54,480:INFO:Total runtime is 0.08323309421539307 minutes
2023-05-12 15:26:54,484:INFO:SubProcess create_model() called ==================================
2023-05-12 15:26:54,485:INFO:Initializing create_model()
2023-05-12 15:26:54,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:26:54,486:INFO:Checking exceptions
2023-05-12 15:26:54,486:INFO:Importing libraries
2023-05-12 15:26:54,486:INFO:Copying training dataset
2023-05-12 15:26:54,490:INFO:Defining folds
2023-05-12 15:26:54,490:INFO:Declaring metric variables
2023-05-12 15:26:54,495:INFO:Importing untrained model
2023-05-12 15:26:54,500:INFO:Random Forest Regressor Imported successfully
2023-05-12 15:26:54,512:INFO:Starting cross validation
2023-05-12 15:26:54,513:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:26:56,581:INFO:Calculating mean and std
2023-05-12 15:26:56,582:INFO:Creating metrics dataframe
2023-05-12 15:26:56,592:INFO:Uploading results into container
2023-05-12 15:26:56,593:INFO:Uploading model into container now
2023-05-12 15:26:56,594:INFO:_master_model_container: 13
2023-05-12 15:26:56,594:INFO:_display_container: 2
2023-05-12 15:26:56,595:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-05-12 15:26:56,595:INFO:create_model() successfully completed......................................
2023-05-12 15:26:56,730:INFO:SubProcess create_model() end ==================================
2023-05-12 15:26:56,730:INFO:Creating metrics dataframe
2023-05-12 15:26:56,747:INFO:Initializing Extra Trees Regressor
2023-05-12 15:26:56,747:INFO:Total runtime is 0.12101647853851319 minutes
2023-05-12 15:26:56,755:INFO:SubProcess create_model() called ==================================
2023-05-12 15:26:56,755:INFO:Initializing create_model()
2023-05-12 15:26:56,755:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:26:56,755:INFO:Checking exceptions
2023-05-12 15:26:56,755:INFO:Importing libraries
2023-05-12 15:26:56,756:INFO:Copying training dataset
2023-05-12 15:26:56,762:INFO:Defining folds
2023-05-12 15:26:56,762:INFO:Declaring metric variables
2023-05-12 15:26:56,770:INFO:Importing untrained model
2023-05-12 15:26:56,779:INFO:Extra Trees Regressor Imported successfully
2023-05-12 15:26:56,792:INFO:Starting cross validation
2023-05-12 15:26:56,793:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:26:58,856:INFO:Calculating mean and std
2023-05-12 15:26:58,857:INFO:Creating metrics dataframe
2023-05-12 15:26:58,861:INFO:Uploading results into container
2023-05-12 15:26:58,862:INFO:Uploading model into container now
2023-05-12 15:26:58,862:INFO:_master_model_container: 14
2023-05-12 15:26:58,862:INFO:_display_container: 2
2023-05-12 15:26:58,863:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-05-12 15:26:58,863:INFO:create_model() successfully completed......................................
2023-05-12 15:26:58,949:INFO:SubProcess create_model() end ==================================
2023-05-12 15:26:58,949:INFO:Creating metrics dataframe
2023-05-12 15:26:58,964:INFO:Initializing AdaBoost Regressor
2023-05-12 15:26:58,965:INFO:Total runtime is 0.15798336664835613 minutes
2023-05-12 15:26:58,969:INFO:SubProcess create_model() called ==================================
2023-05-12 15:26:58,970:INFO:Initializing create_model()
2023-05-12 15:26:58,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:26:58,971:INFO:Checking exceptions
2023-05-12 15:26:58,971:INFO:Importing libraries
2023-05-12 15:26:58,971:INFO:Copying training dataset
2023-05-12 15:26:58,974:INFO:Defining folds
2023-05-12 15:26:58,974:INFO:Declaring metric variables
2023-05-12 15:26:58,979:INFO:Importing untrained model
2023-05-12 15:26:58,984:INFO:AdaBoost Regressor Imported successfully
2023-05-12 15:26:58,994:INFO:Starting cross validation
2023-05-12 15:26:58,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:26:59,599:INFO:Calculating mean and std
2023-05-12 15:26:59,600:INFO:Creating metrics dataframe
2023-05-12 15:26:59,607:INFO:Uploading results into container
2023-05-12 15:26:59,608:INFO:Uploading model into container now
2023-05-12 15:26:59,609:INFO:_master_model_container: 15
2023-05-12 15:26:59,609:INFO:_display_container: 2
2023-05-12 15:26:59,609:INFO:AdaBoostRegressor(random_state=123)
2023-05-12 15:26:59,610:INFO:create_model() successfully completed......................................
2023-05-12 15:26:59,698:INFO:SubProcess create_model() end ==================================
2023-05-12 15:26:59,698:INFO:Creating metrics dataframe
2023-05-12 15:26:59,719:INFO:Initializing Gradient Boosting Regressor
2023-05-12 15:26:59,719:INFO:Total runtime is 0.1705498774846395 minutes
2023-05-12 15:26:59,724:INFO:SubProcess create_model() called ==================================
2023-05-12 15:26:59,725:INFO:Initializing create_model()
2023-05-12 15:26:59,725:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:26:59,725:INFO:Checking exceptions
2023-05-12 15:26:59,725:INFO:Importing libraries
2023-05-12 15:26:59,725:INFO:Copying training dataset
2023-05-12 15:26:59,729:INFO:Defining folds
2023-05-12 15:26:59,730:INFO:Declaring metric variables
2023-05-12 15:26:59,735:INFO:Importing untrained model
2023-05-12 15:26:59,741:INFO:Gradient Boosting Regressor Imported successfully
2023-05-12 15:26:59,752:INFO:Starting cross validation
2023-05-12 15:26:59,753:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:27:00,455:INFO:Calculating mean and std
2023-05-12 15:27:00,456:INFO:Creating metrics dataframe
2023-05-12 15:27:00,460:INFO:Uploading results into container
2023-05-12 15:27:00,461:INFO:Uploading model into container now
2023-05-12 15:27:00,461:INFO:_master_model_container: 16
2023-05-12 15:27:00,462:INFO:_display_container: 2
2023-05-12 15:27:00,462:INFO:GradientBoostingRegressor(random_state=123)
2023-05-12 15:27:00,462:INFO:create_model() successfully completed......................................
2023-05-12 15:27:00,552:INFO:SubProcess create_model() end ==================================
2023-05-12 15:27:00,552:INFO:Creating metrics dataframe
2023-05-12 15:27:00,569:INFO:Initializing Extreme Gradient Boosting
2023-05-12 15:27:00,569:INFO:Total runtime is 0.1847167253494263 minutes
2023-05-12 15:27:00,574:INFO:SubProcess create_model() called ==================================
2023-05-12 15:27:00,575:INFO:Initializing create_model()
2023-05-12 15:27:00,575:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:27:00,575:INFO:Checking exceptions
2023-05-12 15:27:00,575:INFO:Importing libraries
2023-05-12 15:27:00,575:INFO:Copying training dataset
2023-05-12 15:27:00,579:INFO:Defining folds
2023-05-12 15:27:00,579:INFO:Declaring metric variables
2023-05-12 15:27:00,585:INFO:Importing untrained model
2023-05-12 15:27:00,590:INFO:Extreme Gradient Boosting Imported successfully
2023-05-12 15:27:00,599:INFO:Starting cross validation
2023-05-12 15:27:00,602:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:27:07,454:INFO:Calculating mean and std
2023-05-12 15:27:07,457:INFO:Creating metrics dataframe
2023-05-12 15:27:07,466:INFO:Uploading results into container
2023-05-12 15:27:07,467:INFO:Uploading model into container now
2023-05-12 15:27:07,468:INFO:_master_model_container: 17
2023-05-12 15:27:07,469:INFO:_display_container: 2
2023-05-12 15:27:07,471:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-05-12 15:27:07,472:INFO:create_model() successfully completed......................................
2023-05-12 15:27:07,596:INFO:SubProcess create_model() end ==================================
2023-05-12 15:27:07,597:INFO:Creating metrics dataframe
2023-05-12 15:27:07,619:INFO:Initializing Light Gradient Boosting Machine
2023-05-12 15:27:07,619:INFO:Total runtime is 0.30220843950907395 minutes
2023-05-12 15:27:07,624:INFO:SubProcess create_model() called ==================================
2023-05-12 15:27:07,625:INFO:Initializing create_model()
2023-05-12 15:27:07,625:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:27:07,625:INFO:Checking exceptions
2023-05-12 15:27:07,625:INFO:Importing libraries
2023-05-12 15:27:07,625:INFO:Copying training dataset
2023-05-12 15:27:07,629:INFO:Defining folds
2023-05-12 15:27:07,629:INFO:Declaring metric variables
2023-05-12 15:27:07,635:INFO:Importing untrained model
2023-05-12 15:27:07,640:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-12 15:27:07,651:INFO:Starting cross validation
2023-05-12 15:27:07,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:27:16,402:INFO:Calculating mean and std
2023-05-12 15:27:16,405:INFO:Creating metrics dataframe
2023-05-12 15:27:16,414:INFO:Uploading results into container
2023-05-12 15:27:16,416:INFO:Uploading model into container now
2023-05-12 15:27:16,417:INFO:_master_model_container: 18
2023-05-12 15:27:16,417:INFO:_display_container: 2
2023-05-12 15:27:16,418:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-05-12 15:27:16,418:INFO:create_model() successfully completed......................................
2023-05-12 15:27:16,544:INFO:SubProcess create_model() end ==================================
2023-05-12 15:27:16,544:INFO:Creating metrics dataframe
2023-05-12 15:27:16,562:INFO:Initializing Dummy Regressor
2023-05-12 15:27:16,562:INFO:Total runtime is 0.4512584805488587 minutes
2023-05-12 15:27:16,568:INFO:SubProcess create_model() called ==================================
2023-05-12 15:27:16,568:INFO:Initializing create_model()
2023-05-12 15:27:16,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4ADE334F0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:27:16,569:INFO:Checking exceptions
2023-05-12 15:27:16,569:INFO:Importing libraries
2023-05-12 15:27:16,569:INFO:Copying training dataset
2023-05-12 15:27:16,572:INFO:Defining folds
2023-05-12 15:27:16,573:INFO:Declaring metric variables
2023-05-12 15:27:16,577:INFO:Importing untrained model
2023-05-12 15:27:16,584:INFO:Dummy Regressor Imported successfully
2023-05-12 15:27:16,593:INFO:Starting cross validation
2023-05-12 15:27:16,596:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:27:16,800:INFO:Calculating mean and std
2023-05-12 15:27:16,802:INFO:Creating metrics dataframe
2023-05-12 15:27:16,805:INFO:Uploading results into container
2023-05-12 15:27:16,806:INFO:Uploading model into container now
2023-05-12 15:27:16,807:INFO:_master_model_container: 19
2023-05-12 15:27:16,807:INFO:_display_container: 2
2023-05-12 15:27:16,808:INFO:DummyRegressor()
2023-05-12 15:27:16,808:INFO:create_model() successfully completed......................................
2023-05-12 15:27:16,893:INFO:SubProcess create_model() end ==================================
2023-05-12 15:27:16,893:INFO:Creating metrics dataframe
2023-05-12 15:27:16,927:INFO:Initializing create_model()
2023-05-12 15:27:16,927:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:27:16,928:INFO:Checking exceptions
2023-05-12 15:27:16,931:INFO:Importing libraries
2023-05-12 15:27:16,931:INFO:Copying training dataset
2023-05-12 15:27:16,934:INFO:Defining folds
2023-05-12 15:27:16,934:INFO:Declaring metric variables
2023-05-12 15:27:16,934:INFO:Importing untrained model
2023-05-12 15:27:16,934:INFO:Declaring custom model
2023-05-12 15:27:16,934:INFO:Linear Regression Imported successfully
2023-05-12 15:27:16,935:INFO:Cross validation set to False
2023-05-12 15:27:16,935:INFO:Fitting Model
2023-05-12 15:27:16,946:INFO:LinearRegression(n_jobs=-1)
2023-05-12 15:27:16,946:INFO:create_model() successfully completed......................................
2023-05-12 15:27:17,071:INFO:_master_model_container: 19
2023-05-12 15:27:17,071:INFO:_display_container: 2
2023-05-12 15:27:17,072:INFO:LinearRegression(n_jobs=-1)
2023-05-12 15:27:17,072:INFO:compare_models() successfully completed......................................
2023-05-12 15:27:17,249:INFO:Initializing create_model()
2023-05-12 15:27:17,249:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:27:17,249:INFO:Checking exceptions
2023-05-12 15:27:17,289:INFO:Importing libraries
2023-05-12 15:27:17,289:INFO:Copying training dataset
2023-05-12 15:27:17,295:INFO:Defining folds
2023-05-12 15:27:17,295:INFO:Declaring metric variables
2023-05-12 15:27:17,304:INFO:Importing untrained model
2023-05-12 15:27:17,312:INFO:Huber Regressor Imported successfully
2023-05-12 15:27:17,336:INFO:Starting cross validation
2023-05-12 15:27:17,337:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:27:17,646:INFO:Calculating mean and std
2023-05-12 15:27:17,646:INFO:Creating metrics dataframe
2023-05-12 15:27:17,654:INFO:Finalizing model
2023-05-12 15:27:17,679:INFO:Uploading results into container
2023-05-12 15:27:17,680:INFO:Uploading model into container now
2023-05-12 15:27:17,694:INFO:_master_model_container: 20
2023-05-12 15:27:17,694:INFO:_display_container: 3
2023-05-12 15:27:17,695:INFO:HuberRegressor()
2023-05-12 15:27:17,695:INFO:create_model() successfully completed......................................
2023-05-12 15:27:17,956:INFO:Initializing evaluate_model()
2023-05-12 15:27:17,957:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-05-12 15:27:17,978:INFO:Initializing plot_model()
2023-05-12 15:27:17,978:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, system=True)
2023-05-12 15:27:17,978:INFO:Checking exceptions
2023-05-12 15:27:17,981:INFO:Preloading libraries
2023-05-12 15:27:17,981:INFO:Copying training dataset
2023-05-12 15:27:17,982:INFO:Plot type: pipeline
2023-05-12 15:27:18,094:INFO:Visual Rendered Successfully
2023-05-12 15:27:18,178:INFO:plot_model() successfully completed......................................
2023-05-12 15:27:18,304:INFO:Initializing predict_model()
2023-05-12 15:27:18,304:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A11B03A0>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A49DA09360>)
2023-05-12 15:27:18,304:INFO:Checking exceptions
2023-05-12 15:27:18,304:INFO:Preloading libraries
2023-05-12 15:27:18,307:INFO:Set up data.
2023-05-12 15:27:18,312:INFO:Set up index.
2023-05-12 15:29:41,176:INFO:PyCaret RegressionExperiment
2023-05-12 15:29:41,176:INFO:Logging name: reg-default-name
2023-05-12 15:29:41,176:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-12 15:29:41,176:INFO:version 3.0.0.rc8
2023-05-12 15:29:41,176:INFO:Initializing setup()
2023-05-12 15:29:41,177:INFO:self.USI: 5039
2023-05-12 15:29:41,177:INFO:self._variable_keys: {'html_param', 'memory', '_available_plots', 'seed', 'idx', 'fold_groups_param', 'X', 'data', 'y_test', 'gpu_param', 'exp_name_log', 'exp_id', 'X_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'logging_param', 'USI', 'log_plots_param', 'y', 'n_jobs_param', '_ml_usecase', 'y_train', 'fold_generator', 'transform_target_param', 'pipeline', 'X_train', 'target_param'}
2023-05-12 15:29:41,177:INFO:Checking environment
2023-05-12 15:29:41,177:INFO:python_version: 3.10.9
2023-05-12 15:29:41,177:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-05-12 15:29:41,177:INFO:machine: AMD64
2023-05-12 15:29:41,178:INFO:platform: Windows-10-10.0.19045-SP0
2023-05-12 15:29:41,178:INFO:Memory: svmem(total=17090879488, available=2760818688, percent=83.8, used=14330060800, free=2760818688)
2023-05-12 15:29:41,178:INFO:Physical Core: 4
2023-05-12 15:29:41,178:INFO:Logical Core: 8
2023-05-12 15:29:41,178:INFO:Checking libraries
2023-05-12 15:29:41,179:INFO:System:
2023-05-12 15:29:41,179:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-05-12 15:29:41,179:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-05-12 15:29:41,179:INFO:   machine: Windows-10-10.0.19045-SP0
2023-05-12 15:29:41,181:INFO:PyCaret required dependencies:
2023-05-12 15:29:41,182:INFO:                 pip: 23.0
2023-05-12 15:29:41,183:INFO:          setuptools: 67.1.0
2023-05-12 15:29:41,183:INFO:             pycaret: 3.0.0rc8
2023-05-12 15:29:41,184:INFO:             IPython: 8.8.0
2023-05-12 15:29:41,184:INFO:          ipywidgets: 8.0.4
2023-05-12 15:29:41,184:INFO:                tqdm: 4.64.1
2023-05-12 15:29:41,184:INFO:               numpy: 1.23.5
2023-05-12 15:29:41,184:INFO:              pandas: 1.5.3
2023-05-12 15:29:41,185:INFO:              jinja2: 3.1.2
2023-05-12 15:29:41,185:INFO:               scipy: 1.10.0
2023-05-12 15:29:41,185:INFO:              joblib: 1.2.0
2023-05-12 15:29:41,185:INFO:             sklearn: 1.1.3
2023-05-12 15:29:41,185:INFO:                pyod: 1.0.7
2023-05-12 15:29:41,185:INFO:            imblearn: 0.10.1
2023-05-12 15:29:41,186:INFO:   category_encoders: 2.6.0
2023-05-12 15:29:41,186:INFO:            lightgbm: 3.3.5
2023-05-12 15:29:41,186:INFO:               numba: 0.56.4
2023-05-12 15:29:41,186:INFO:            requests: 2.28.2
2023-05-12 15:29:41,186:INFO:          matplotlib: 3.6.3
2023-05-12 15:29:41,187:INFO:          scikitplot: 0.3.7
2023-05-12 15:29:41,187:INFO:         yellowbrick: 1.5
2023-05-12 15:29:41,187:INFO:              plotly: 5.13.0
2023-05-12 15:29:41,187:INFO:             kaleido: 0.2.1
2023-05-12 15:29:41,187:INFO:         statsmodels: 0.13.5
2023-05-12 15:29:41,188:INFO:              sktime: 0.16.0
2023-05-12 15:29:41,188:INFO:               tbats: 1.1.2
2023-05-12 15:29:41,188:INFO:            pmdarima: 2.0.2
2023-05-12 15:29:41,188:INFO:              psutil: 5.9.0
2023-05-12 15:29:41,188:INFO:PyCaret optional dependencies:
2023-05-12 15:29:41,188:INFO:                shap: Not installed
2023-05-12 15:29:41,189:INFO:           interpret: Not installed
2023-05-12 15:29:41,189:INFO:                umap: Not installed
2023-05-12 15:29:41,189:INFO:    pandas_profiling: Not installed
2023-05-12 15:29:41,189:INFO:  explainerdashboard: Not installed
2023-05-12 15:29:41,189:INFO:             autoviz: Not installed
2023-05-12 15:29:41,189:INFO:           fairlearn: Not installed
2023-05-12 15:29:41,190:INFO:             xgboost: 1.7.3
2023-05-12 15:29:41,190:INFO:            catboost: Not installed
2023-05-12 15:29:41,190:INFO:              kmodes: Not installed
2023-05-12 15:29:41,190:INFO:             mlxtend: Not installed
2023-05-12 15:29:41,190:INFO:       statsforecast: Not installed
2023-05-12 15:29:41,191:INFO:        tune_sklearn: Not installed
2023-05-12 15:29:41,191:INFO:                 ray: Not installed
2023-05-12 15:29:41,191:INFO:            hyperopt: Not installed
2023-05-12 15:29:41,191:INFO:              optuna: Not installed
2023-05-12 15:29:41,192:INFO:               skopt: Not installed
2023-05-12 15:29:41,192:INFO:              mlflow: Not installed
2023-05-12 15:29:41,192:INFO:              gradio: Not installed
2023-05-12 15:29:41,192:INFO:             fastapi: Not installed
2023-05-12 15:29:41,192:INFO:             uvicorn: Not installed
2023-05-12 15:29:41,193:INFO:              m2cgen: Not installed
2023-05-12 15:29:41,193:INFO:           evidently: Not installed
2023-05-12 15:29:41,193:INFO:                nltk: Not installed
2023-05-12 15:29:41,193:INFO:            pyLDAvis: Not installed
2023-05-12 15:29:41,193:INFO:              gensim: Not installed
2023-05-12 15:29:41,193:INFO:               spacy: Not installed
2023-05-12 15:29:41,193:INFO:           wordcloud: Not installed
2023-05-12 15:29:41,193:INFO:            textblob: Not installed
2023-05-12 15:29:41,193:INFO:               fugue: Not installed
2023-05-12 15:29:41,194:INFO:           streamlit: Not installed
2023-05-12 15:29:41,194:INFO:             prophet: Not installed
2023-05-12 15:29:41,194:INFO:None
2023-05-12 15:29:41,194:INFO:Set up GPU usage.
2023-05-12 15:29:41,194:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:41,195:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-05-12 15:29:41,195:INFO:Set up data.
2023-05-12 15:29:41,204:INFO:Set up train/test split.
2023-05-12 15:29:41,208:INFO:Set up index.
2023-05-12 15:29:41,209:INFO:Set up folding strategy.
2023-05-12 15:29:41,209:INFO:Assigning column types.
2023-05-12 15:29:41,213:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-12 15:29:41,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:41,214:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 15:29:41,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:41,221:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:29:41,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:41,227:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:29:41,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:41,299:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:29:41,299:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:41,361:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:29:41,361:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:41,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:41,362:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:29:42,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:29:42,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,009:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 15:29:42,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,022:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:29:42,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,037:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:29:42,037:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,174:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:29:42,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,233:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:29:42,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,233:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:29:42,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:29:42,435:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-12 15:29:42,435:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,435:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,448:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:29:42,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,461:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:29:42,461:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,575:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:29:42,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,632:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:29:42,632:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,632:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,632:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:29:42,828:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:29:42,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,844:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:29:42,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,857:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:29:42,858:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:42,962:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:29:42,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:29:43,015:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,015:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,015:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:29:43,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:29:43,214:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-12 15:29:43,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,242:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:29:43,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:29:43,348:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,399:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:29:43,399:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,399:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,399:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:29:43,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:29:43,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,604:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:29:43,604:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,708:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:29:43,708:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,760:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:29:43,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,761:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:29:43,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:29:43,960:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-12 15:29:43,960:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,960:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:43,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,097:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:29:44,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,148:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:29:44,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,149:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:29:44,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:29:44,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,351:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:29:44,472:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,526:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:29:44,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,526:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:29:44,704:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:29:44,705:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-12 15:29:44,705:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,706:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,718:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,844:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:29:44,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,897:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,897:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:44,898:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:29:45,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:29:45,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,110:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,222:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:29:45,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,274:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:29:45,462:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:29:45,463:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-12 15:29:45,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,477:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,664:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,664:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,665:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:29:45,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:29:45,846:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,846:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,859:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,872:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:45,998:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,059:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:29:46,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:29:46,247:INFO:Preparing preprocessing pipeline...
2023-05-12 15:29:46,248:INFO:Set up simple imputation.
2023-05-12 15:29:46,265:INFO:Finished creating preprocessing pipeline.
2023-05-12 15:29:46,275:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-05-12 15:29:46,275:INFO:Creating final display dataframe.
2023-05-12 15:29:46,393:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape         (1042, 2)
4        Transformed data shape         (1042, 2)
5   Transformed train set shape          (729, 2)
6    Transformed test set shape          (313, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              5039
2023-05-12 15:29:46,402:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,402:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,408:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,413:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,479:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,529:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,530:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,530:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:29:46,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:29:46,701:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,701:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,712:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,725:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:29:46,928:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:29:47,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:29:47,121:INFO:setup() successfully completed in 5.95s...............
2023-05-12 15:29:47,233:INFO:Initializing compare_models()
2023-05-12 15:29:47,233:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-12 15:29:47,233:INFO:Checking exceptions
2023-05-12 15:29:47,236:INFO:Preparing display monitor
2023-05-12 15:29:47,293:INFO:Initializing Linear Regression
2023-05-12 15:29:47,294:INFO:Total runtime is 1.6629695892333984e-05 minutes
2023-05-12 15:29:47,303:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:47,304:INFO:Initializing create_model()
2023-05-12 15:29:47,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:47,304:INFO:Checking exceptions
2023-05-12 15:29:47,305:INFO:Importing libraries
2023-05-12 15:29:47,305:INFO:Copying training dataset
2023-05-12 15:29:47,312:INFO:Defining folds
2023-05-12 15:29:47,313:INFO:Declaring metric variables
2023-05-12 15:29:47,320:INFO:Importing untrained model
2023-05-12 15:29:47,326:INFO:Linear Regression Imported successfully
2023-05-12 15:29:47,340:INFO:Starting cross validation
2023-05-12 15:29:47,343:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:29:47,587:INFO:Calculating mean and std
2023-05-12 15:29:47,588:INFO:Creating metrics dataframe
2023-05-12 15:29:47,591:INFO:Uploading results into container
2023-05-12 15:29:47,592:INFO:Uploading model into container now
2023-05-12 15:29:47,592:INFO:_master_model_container: 1
2023-05-12 15:29:47,592:INFO:_display_container: 2
2023-05-12 15:29:47,592:INFO:LinearRegression(n_jobs=-1)
2023-05-12 15:29:47,593:INFO:create_model() successfully completed......................................
2023-05-12 15:29:47,684:INFO:SubProcess create_model() end ==================================
2023-05-12 15:29:47,684:INFO:Creating metrics dataframe
2023-05-12 15:29:47,694:INFO:Initializing Lasso Regression
2023-05-12 15:29:47,694:INFO:Total runtime is 0.006683282057444255 minutes
2023-05-12 15:29:47,699:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:47,700:INFO:Initializing create_model()
2023-05-12 15:29:47,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:47,700:INFO:Checking exceptions
2023-05-12 15:29:47,700:INFO:Importing libraries
2023-05-12 15:29:47,700:INFO:Copying training dataset
2023-05-12 15:29:47,703:INFO:Defining folds
2023-05-12 15:29:47,703:INFO:Declaring metric variables
2023-05-12 15:29:47,707:INFO:Importing untrained model
2023-05-12 15:29:47,713:INFO:Lasso Regression Imported successfully
2023-05-12 15:29:47,723:INFO:Starting cross validation
2023-05-12 15:29:47,724:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:29:47,741:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.228e+08, tolerance: 1.948e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:47,767:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.926e+08, tolerance: 1.970e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:47,789:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.543e+08, tolerance: 1.940e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:47,813:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.701e+08, tolerance: 1.938e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:47,835:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.060e+08, tolerance: 1.941e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:47,859:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.280e+08, tolerance: 1.951e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:47,883:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.429e+08, tolerance: 1.974e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:47,911:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.178e+08, tolerance: 1.907e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:47,935:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.602e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:47,959:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.286e+08, tolerance: 1.982e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:47,970:INFO:Calculating mean and std
2023-05-12 15:29:47,971:INFO:Creating metrics dataframe
2023-05-12 15:29:47,974:INFO:Uploading results into container
2023-05-12 15:29:47,975:INFO:Uploading model into container now
2023-05-12 15:29:47,975:INFO:_master_model_container: 2
2023-05-12 15:29:47,975:INFO:_display_container: 2
2023-05-12 15:29:47,976:INFO:Lasso(random_state=123)
2023-05-12 15:29:47,976:INFO:create_model() successfully completed......................................
2023-05-12 15:29:48,062:INFO:SubProcess create_model() end ==================================
2023-05-12 15:29:48,063:INFO:Creating metrics dataframe
2023-05-12 15:29:48,074:INFO:Initializing Ridge Regression
2023-05-12 15:29:48,075:INFO:Total runtime is 0.013033294677734376 minutes
2023-05-12 15:29:48,080:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:48,080:INFO:Initializing create_model()
2023-05-12 15:29:48,081:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:48,081:INFO:Checking exceptions
2023-05-12 15:29:48,081:INFO:Importing libraries
2023-05-12 15:29:48,081:INFO:Copying training dataset
2023-05-12 15:29:48,083:INFO:Defining folds
2023-05-12 15:29:48,084:INFO:Declaring metric variables
2023-05-12 15:29:48,088:INFO:Importing untrained model
2023-05-12 15:29:48,093:INFO:Ridge Regression Imported successfully
2023-05-12 15:29:48,103:INFO:Starting cross validation
2023-05-12 15:29:48,104:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:29:48,332:INFO:Calculating mean and std
2023-05-12 15:29:48,333:INFO:Creating metrics dataframe
2023-05-12 15:29:48,338:INFO:Uploading results into container
2023-05-12 15:29:48,338:INFO:Uploading model into container now
2023-05-12 15:29:48,339:INFO:_master_model_container: 3
2023-05-12 15:29:48,339:INFO:_display_container: 2
2023-05-12 15:29:48,340:INFO:Ridge(random_state=123)
2023-05-12 15:29:48,340:INFO:create_model() successfully completed......................................
2023-05-12 15:29:48,426:INFO:SubProcess create_model() end ==================================
2023-05-12 15:29:48,426:INFO:Creating metrics dataframe
2023-05-12 15:29:48,438:INFO:Initializing Elastic Net
2023-05-12 15:29:48,438:INFO:Total runtime is 0.019083269437154136 minutes
2023-05-12 15:29:48,444:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:48,445:INFO:Initializing create_model()
2023-05-12 15:29:48,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:48,445:INFO:Checking exceptions
2023-05-12 15:29:48,446:INFO:Importing libraries
2023-05-12 15:29:48,446:INFO:Copying training dataset
2023-05-12 15:29:48,449:INFO:Defining folds
2023-05-12 15:29:48,450:INFO:Declaring metric variables
2023-05-12 15:29:48,456:INFO:Importing untrained model
2023-05-12 15:29:48,466:INFO:Elastic Net Imported successfully
2023-05-12 15:29:48,483:INFO:Starting cross validation
2023-05-12 15:29:48,484:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:29:48,513:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.219e+08, tolerance: 1.948e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:48,550:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.152e+08, tolerance: 1.970e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:48,573:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.940e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:48,597:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.927e+08, tolerance: 1.938e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:48,622:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.434e+08, tolerance: 1.941e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:48,646:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.622e+08, tolerance: 1.951e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:48,669:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.840e+08, tolerance: 1.974e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:48,692:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.019e+08, tolerance: 1.907e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:48,717:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.858e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:48,741:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.022e+08, tolerance: 1.982e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:29:48,753:INFO:Calculating mean and std
2023-05-12 15:29:48,754:INFO:Creating metrics dataframe
2023-05-12 15:29:48,759:INFO:Uploading results into container
2023-05-12 15:29:48,759:INFO:Uploading model into container now
2023-05-12 15:29:48,760:INFO:_master_model_container: 4
2023-05-12 15:29:48,760:INFO:_display_container: 2
2023-05-12 15:29:48,761:INFO:ElasticNet(random_state=123)
2023-05-12 15:29:48,761:INFO:create_model() successfully completed......................................
2023-05-12 15:29:48,853:INFO:SubProcess create_model() end ==================================
2023-05-12 15:29:48,853:INFO:Creating metrics dataframe
2023-05-12 15:29:48,867:INFO:Initializing Least Angle Regression
2023-05-12 15:29:48,867:INFO:Total runtime is 0.02623327175776164 minutes
2023-05-12 15:29:48,872:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:48,872:INFO:Initializing create_model()
2023-05-12 15:29:48,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:48,873:INFO:Checking exceptions
2023-05-12 15:29:48,873:INFO:Importing libraries
2023-05-12 15:29:48,873:INFO:Copying training dataset
2023-05-12 15:29:48,877:INFO:Defining folds
2023-05-12 15:29:48,878:INFO:Declaring metric variables
2023-05-12 15:29:48,883:INFO:Importing untrained model
2023-05-12 15:29:48,889:INFO:Least Angle Regression Imported successfully
2023-05-12 15:29:48,899:INFO:Starting cross validation
2023-05-12 15:29:48,901:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:29:48,916:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:48,938:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:48,964:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:48,988:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,012:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,034:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,056:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,079:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,104:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,126:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,138:INFO:Calculating mean and std
2023-05-12 15:29:49,139:INFO:Creating metrics dataframe
2023-05-12 15:29:49,144:INFO:Uploading results into container
2023-05-12 15:29:49,145:INFO:Uploading model into container now
2023-05-12 15:29:49,146:INFO:_master_model_container: 5
2023-05-12 15:29:49,146:INFO:_display_container: 2
2023-05-12 15:29:49,147:INFO:Lars(random_state=123)
2023-05-12 15:29:49,147:INFO:create_model() successfully completed......................................
2023-05-12 15:29:49,230:INFO:SubProcess create_model() end ==================================
2023-05-12 15:29:49,231:INFO:Creating metrics dataframe
2023-05-12 15:29:49,243:INFO:Initializing Lasso Least Angle Regression
2023-05-12 15:29:49,243:INFO:Total runtime is 0.032499957084655764 minutes
2023-05-12 15:29:49,249:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:49,250:INFO:Initializing create_model()
2023-05-12 15:29:49,250:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:49,250:INFO:Checking exceptions
2023-05-12 15:29:49,250:INFO:Importing libraries
2023-05-12 15:29:49,251:INFO:Copying training dataset
2023-05-12 15:29:49,254:INFO:Defining folds
2023-05-12 15:29:49,255:INFO:Declaring metric variables
2023-05-12 15:29:49,260:INFO:Importing untrained model
2023-05-12 15:29:49,266:INFO:Lasso Least Angle Regression Imported successfully
2023-05-12 15:29:49,276:INFO:Starting cross validation
2023-05-12 15:29:49,277:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:29:49,292:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:29:49,316:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:29:49,340:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:29:49,364:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:29:49,387:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:29:49,410:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:29:49,434:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:29:49,456:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:29:49,482:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:29:49,505:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:29:49,516:INFO:Calculating mean and std
2023-05-12 15:29:49,517:INFO:Creating metrics dataframe
2023-05-12 15:29:49,521:INFO:Uploading results into container
2023-05-12 15:29:49,522:INFO:Uploading model into container now
2023-05-12 15:29:49,522:INFO:_master_model_container: 6
2023-05-12 15:29:49,522:INFO:_display_container: 2
2023-05-12 15:29:49,523:INFO:LassoLars(random_state=123)
2023-05-12 15:29:49,523:INFO:create_model() successfully completed......................................
2023-05-12 15:29:49,610:INFO:SubProcess create_model() end ==================================
2023-05-12 15:29:49,610:INFO:Creating metrics dataframe
2023-05-12 15:29:49,626:INFO:Initializing Orthogonal Matching Pursuit
2023-05-12 15:29:49,626:INFO:Total runtime is 0.03888328870137533 minutes
2023-05-12 15:29:49,632:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:49,632:INFO:Initializing create_model()
2023-05-12 15:29:49,632:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:49,633:INFO:Checking exceptions
2023-05-12 15:29:49,633:INFO:Importing libraries
2023-05-12 15:29:49,633:INFO:Copying training dataset
2023-05-12 15:29:49,638:INFO:Defining folds
2023-05-12 15:29:49,639:INFO:Declaring metric variables
2023-05-12 15:29:49,645:INFO:Importing untrained model
2023-05-12 15:29:49,651:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-12 15:29:49,662:INFO:Starting cross validation
2023-05-12 15:29:49,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:29:49,675:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,698:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,722:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,747:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,770:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,794:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,817:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,839:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,862:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,884:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:29:49,897:INFO:Calculating mean and std
2023-05-12 15:29:49,899:INFO:Creating metrics dataframe
2023-05-12 15:29:49,903:INFO:Uploading results into container
2023-05-12 15:29:49,903:INFO:Uploading model into container now
2023-05-12 15:29:49,904:INFO:_master_model_container: 7
2023-05-12 15:29:49,904:INFO:_display_container: 2
2023-05-12 15:29:49,904:INFO:OrthogonalMatchingPursuit()
2023-05-12 15:29:49,904:INFO:create_model() successfully completed......................................
2023-05-12 15:29:49,990:INFO:SubProcess create_model() end ==================================
2023-05-12 15:29:49,991:INFO:Creating metrics dataframe
2023-05-12 15:29:50,004:INFO:Initializing Bayesian Ridge
2023-05-12 15:29:50,004:INFO:Total runtime is 0.04518331289291382 minutes
2023-05-12 15:29:50,008:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:50,009:INFO:Initializing create_model()
2023-05-12 15:29:50,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:50,009:INFO:Checking exceptions
2023-05-12 15:29:50,009:INFO:Importing libraries
2023-05-12 15:29:50,009:INFO:Copying training dataset
2023-05-12 15:29:50,014:INFO:Defining folds
2023-05-12 15:29:50,014:INFO:Declaring metric variables
2023-05-12 15:29:50,019:INFO:Importing untrained model
2023-05-12 15:29:50,024:INFO:Bayesian Ridge Imported successfully
2023-05-12 15:29:50,035:INFO:Starting cross validation
2023-05-12 15:29:50,037:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:29:50,266:INFO:Calculating mean and std
2023-05-12 15:29:50,267:INFO:Creating metrics dataframe
2023-05-12 15:29:50,271:INFO:Uploading results into container
2023-05-12 15:29:50,272:INFO:Uploading model into container now
2023-05-12 15:29:50,273:INFO:_master_model_container: 8
2023-05-12 15:29:50,273:INFO:_display_container: 2
2023-05-12 15:29:50,274:INFO:BayesianRidge()
2023-05-12 15:29:50,274:INFO:create_model() successfully completed......................................
2023-05-12 15:29:50,359:INFO:SubProcess create_model() end ==================================
2023-05-12 15:29:50,359:INFO:Creating metrics dataframe
2023-05-12 15:29:50,372:INFO:Initializing Passive Aggressive Regressor
2023-05-12 15:29:50,373:INFO:Total runtime is 0.05133995612462362 minutes
2023-05-12 15:29:50,378:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:50,378:INFO:Initializing create_model()
2023-05-12 15:29:50,378:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:50,379:INFO:Checking exceptions
2023-05-12 15:29:50,379:INFO:Importing libraries
2023-05-12 15:29:50,379:INFO:Copying training dataset
2023-05-12 15:29:50,382:INFO:Defining folds
2023-05-12 15:29:50,383:INFO:Declaring metric variables
2023-05-12 15:29:50,388:INFO:Importing untrained model
2023-05-12 15:29:50,393:INFO:Passive Aggressive Regressor Imported successfully
2023-05-12 15:29:50,404:INFO:Starting cross validation
2023-05-12 15:29:50,405:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:29:50,640:INFO:Calculating mean and std
2023-05-12 15:29:50,641:INFO:Creating metrics dataframe
2023-05-12 15:29:50,645:INFO:Uploading results into container
2023-05-12 15:29:50,646:INFO:Uploading model into container now
2023-05-12 15:29:50,646:INFO:_master_model_container: 9
2023-05-12 15:29:50,646:INFO:_display_container: 2
2023-05-12 15:29:50,647:INFO:PassiveAggressiveRegressor(random_state=123)
2023-05-12 15:29:50,648:INFO:create_model() successfully completed......................................
2023-05-12 15:29:50,732:INFO:SubProcess create_model() end ==================================
2023-05-12 15:29:50,732:INFO:Creating metrics dataframe
2023-05-12 15:29:50,745:INFO:Initializing Huber Regressor
2023-05-12 15:29:50,746:INFO:Total runtime is 0.05755507151285808 minutes
2023-05-12 15:29:50,750:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:50,751:INFO:Initializing create_model()
2023-05-12 15:29:50,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:50,751:INFO:Checking exceptions
2023-05-12 15:29:50,751:INFO:Importing libraries
2023-05-12 15:29:50,751:INFO:Copying training dataset
2023-05-12 15:29:50,755:INFO:Defining folds
2023-05-12 15:29:50,755:INFO:Declaring metric variables
2023-05-12 15:29:50,761:INFO:Importing untrained model
2023-05-12 15:29:50,766:INFO:Huber Regressor Imported successfully
2023-05-12 15:29:50,775:INFO:Starting cross validation
2023-05-12 15:29:50,776:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:29:51,060:INFO:Calculating mean and std
2023-05-12 15:29:51,061:INFO:Creating metrics dataframe
2023-05-12 15:29:51,066:INFO:Uploading results into container
2023-05-12 15:29:51,067:INFO:Uploading model into container now
2023-05-12 15:29:51,067:INFO:_master_model_container: 10
2023-05-12 15:29:51,067:INFO:_display_container: 2
2023-05-12 15:29:51,067:INFO:HuberRegressor()
2023-05-12 15:29:51,068:INFO:create_model() successfully completed......................................
2023-05-12 15:29:51,151:INFO:SubProcess create_model() end ==================================
2023-05-12 15:29:51,152:INFO:Creating metrics dataframe
2023-05-12 15:29:51,166:INFO:Initializing K Neighbors Regressor
2023-05-12 15:29:51,166:INFO:Total runtime is 0.06455506086349488 minutes
2023-05-12 15:29:51,171:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:51,171:INFO:Initializing create_model()
2023-05-12 15:29:51,172:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:51,172:INFO:Checking exceptions
2023-05-12 15:29:51,172:INFO:Importing libraries
2023-05-12 15:29:51,172:INFO:Copying training dataset
2023-05-12 15:29:51,175:INFO:Defining folds
2023-05-12 15:29:51,176:INFO:Declaring metric variables
2023-05-12 15:29:51,182:INFO:Importing untrained model
2023-05-12 15:29:51,187:INFO:K Neighbors Regressor Imported successfully
2023-05-12 15:29:51,197:INFO:Starting cross validation
2023-05-12 15:29:51,199:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:29:51,571:INFO:Calculating mean and std
2023-05-12 15:29:51,573:INFO:Creating metrics dataframe
2023-05-12 15:29:51,577:INFO:Uploading results into container
2023-05-12 15:29:51,578:INFO:Uploading model into container now
2023-05-12 15:29:51,579:INFO:_master_model_container: 11
2023-05-12 15:29:51,579:INFO:_display_container: 2
2023-05-12 15:29:51,580:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-12 15:29:51,580:INFO:create_model() successfully completed......................................
2023-05-12 15:29:51,672:INFO:SubProcess create_model() end ==================================
2023-05-12 15:29:51,672:INFO:Creating metrics dataframe
2023-05-12 15:29:51,686:INFO:Initializing Decision Tree Regressor
2023-05-12 15:29:51,687:INFO:Total runtime is 0.0732330878575643 minutes
2023-05-12 15:29:51,691:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:51,692:INFO:Initializing create_model()
2023-05-12 15:29:51,692:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:51,692:INFO:Checking exceptions
2023-05-12 15:29:51,692:INFO:Importing libraries
2023-05-12 15:29:51,692:INFO:Copying training dataset
2023-05-12 15:29:51,697:INFO:Defining folds
2023-05-12 15:29:51,698:INFO:Declaring metric variables
2023-05-12 15:29:51,703:INFO:Importing untrained model
2023-05-12 15:29:51,711:INFO:Decision Tree Regressor Imported successfully
2023-05-12 15:29:51,735:INFO:Starting cross validation
2023-05-12 15:29:51,738:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:29:52,022:INFO:Calculating mean and std
2023-05-12 15:29:52,023:INFO:Creating metrics dataframe
2023-05-12 15:29:52,028:INFO:Uploading results into container
2023-05-12 15:29:52,029:INFO:Uploading model into container now
2023-05-12 15:29:52,030:INFO:_master_model_container: 12
2023-05-12 15:29:52,030:INFO:_display_container: 2
2023-05-12 15:29:52,030:INFO:DecisionTreeRegressor(random_state=123)
2023-05-12 15:29:52,031:INFO:create_model() successfully completed......................................
2023-05-12 15:29:52,116:INFO:SubProcess create_model() end ==================================
2023-05-12 15:29:52,116:INFO:Creating metrics dataframe
2023-05-12 15:29:52,131:INFO:Initializing Random Forest Regressor
2023-05-12 15:29:52,131:INFO:Total runtime is 0.0806333382924398 minutes
2023-05-12 15:29:52,137:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:52,137:INFO:Initializing create_model()
2023-05-12 15:29:52,137:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:52,137:INFO:Checking exceptions
2023-05-12 15:29:52,138:INFO:Importing libraries
2023-05-12 15:29:52,138:INFO:Copying training dataset
2023-05-12 15:29:52,141:INFO:Defining folds
2023-05-12 15:29:52,141:INFO:Declaring metric variables
2023-05-12 15:29:52,147:INFO:Importing untrained model
2023-05-12 15:29:52,153:INFO:Random Forest Regressor Imported successfully
2023-05-12 15:29:52,163:INFO:Starting cross validation
2023-05-12 15:29:52,164:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:29:54,376:INFO:Calculating mean and std
2023-05-12 15:29:54,380:INFO:Creating metrics dataframe
2023-05-12 15:29:54,388:INFO:Uploading results into container
2023-05-12 15:29:54,390:INFO:Uploading model into container now
2023-05-12 15:29:54,391:INFO:_master_model_container: 13
2023-05-12 15:29:54,391:INFO:_display_container: 2
2023-05-12 15:29:54,392:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-05-12 15:29:54,392:INFO:create_model() successfully completed......................................
2023-05-12 15:29:54,579:INFO:SubProcess create_model() end ==================================
2023-05-12 15:29:54,579:INFO:Creating metrics dataframe
2023-05-12 15:29:54,609:INFO:Initializing Extra Trees Regressor
2023-05-12 15:29:54,610:INFO:Total runtime is 0.12195246219635011 minutes
2023-05-12 15:29:54,618:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:54,619:INFO:Initializing create_model()
2023-05-12 15:29:54,619:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:54,619:INFO:Checking exceptions
2023-05-12 15:29:54,620:INFO:Importing libraries
2023-05-12 15:29:54,620:INFO:Copying training dataset
2023-05-12 15:29:54,626:INFO:Defining folds
2023-05-12 15:29:54,626:INFO:Declaring metric variables
2023-05-12 15:29:54,635:INFO:Importing untrained model
2023-05-12 15:29:54,641:INFO:Extra Trees Regressor Imported successfully
2023-05-12 15:29:54,654:INFO:Starting cross validation
2023-05-12 15:29:54,656:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:29:57,052:INFO:Calculating mean and std
2023-05-12 15:29:57,054:INFO:Creating metrics dataframe
2023-05-12 15:29:57,058:INFO:Uploading results into container
2023-05-12 15:29:57,059:INFO:Uploading model into container now
2023-05-12 15:29:57,061:INFO:_master_model_container: 14
2023-05-12 15:29:57,062:INFO:_display_container: 2
2023-05-12 15:29:57,063:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-05-12 15:29:57,063:INFO:create_model() successfully completed......................................
2023-05-12 15:29:57,169:INFO:SubProcess create_model() end ==================================
2023-05-12 15:29:57,169:INFO:Creating metrics dataframe
2023-05-12 15:29:57,187:INFO:Initializing AdaBoost Regressor
2023-05-12 15:29:57,187:INFO:Total runtime is 0.16489458084106445 minutes
2023-05-12 15:29:57,192:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:57,193:INFO:Initializing create_model()
2023-05-12 15:29:57,195:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:57,195:INFO:Checking exceptions
2023-05-12 15:29:57,195:INFO:Importing libraries
2023-05-12 15:29:57,195:INFO:Copying training dataset
2023-05-12 15:29:57,200:INFO:Defining folds
2023-05-12 15:29:57,200:INFO:Declaring metric variables
2023-05-12 15:29:57,207:INFO:Importing untrained model
2023-05-12 15:29:57,216:INFO:AdaBoost Regressor Imported successfully
2023-05-12 15:29:57,228:INFO:Starting cross validation
2023-05-12 15:29:57,230:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:29:57,921:INFO:Calculating mean and std
2023-05-12 15:29:57,922:INFO:Creating metrics dataframe
2023-05-12 15:29:57,926:INFO:Uploading results into container
2023-05-12 15:29:57,927:INFO:Uploading model into container now
2023-05-12 15:29:57,928:INFO:_master_model_container: 15
2023-05-12 15:29:57,928:INFO:_display_container: 2
2023-05-12 15:29:57,929:INFO:AdaBoostRegressor(random_state=123)
2023-05-12 15:29:57,930:INFO:create_model() successfully completed......................................
2023-05-12 15:29:58,018:INFO:SubProcess create_model() end ==================================
2023-05-12 15:29:58,018:INFO:Creating metrics dataframe
2023-05-12 15:29:58,036:INFO:Initializing Gradient Boosting Regressor
2023-05-12 15:29:58,036:INFO:Total runtime is 0.17904455661773683 minutes
2023-05-12 15:29:58,041:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:58,042:INFO:Initializing create_model()
2023-05-12 15:29:58,042:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:58,042:INFO:Checking exceptions
2023-05-12 15:29:58,042:INFO:Importing libraries
2023-05-12 15:29:58,042:INFO:Copying training dataset
2023-05-12 15:29:58,047:INFO:Defining folds
2023-05-12 15:29:58,047:INFO:Declaring metric variables
2023-05-12 15:29:58,053:INFO:Importing untrained model
2023-05-12 15:29:58,061:INFO:Gradient Boosting Regressor Imported successfully
2023-05-12 15:29:58,071:INFO:Starting cross validation
2023-05-12 15:29:58,072:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:29:58,731:INFO:Calculating mean and std
2023-05-12 15:29:58,732:INFO:Creating metrics dataframe
2023-05-12 15:29:58,736:INFO:Uploading results into container
2023-05-12 15:29:58,737:INFO:Uploading model into container now
2023-05-12 15:29:58,737:INFO:_master_model_container: 16
2023-05-12 15:29:58,738:INFO:_display_container: 2
2023-05-12 15:29:58,738:INFO:GradientBoostingRegressor(random_state=123)
2023-05-12 15:29:58,738:INFO:create_model() successfully completed......................................
2023-05-12 15:29:58,823:INFO:SubProcess create_model() end ==================================
2023-05-12 15:29:58,824:INFO:Creating metrics dataframe
2023-05-12 15:29:58,839:INFO:Initializing Extreme Gradient Boosting
2023-05-12 15:29:58,839:INFO:Total runtime is 0.1924279014269511 minutes
2023-05-12 15:29:58,844:INFO:SubProcess create_model() called ==================================
2023-05-12 15:29:58,845:INFO:Initializing create_model()
2023-05-12 15:29:58,845:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:29:58,845:INFO:Checking exceptions
2023-05-12 15:29:58,845:INFO:Importing libraries
2023-05-12 15:29:58,845:INFO:Copying training dataset
2023-05-12 15:29:58,849:INFO:Defining folds
2023-05-12 15:29:58,849:INFO:Declaring metric variables
2023-05-12 15:29:58,854:INFO:Importing untrained model
2023-05-12 15:29:58,860:INFO:Extreme Gradient Boosting Imported successfully
2023-05-12 15:29:58,869:INFO:Starting cross validation
2023-05-12 15:29:58,871:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:08,081:INFO:Calculating mean and std
2023-05-12 15:30:08,084:INFO:Creating metrics dataframe
2023-05-12 15:30:08,092:INFO:Uploading results into container
2023-05-12 15:30:08,094:INFO:Uploading model into container now
2023-05-12 15:30:08,095:INFO:_master_model_container: 17
2023-05-12 15:30:08,095:INFO:_display_container: 2
2023-05-12 15:30:08,097:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-05-12 15:30:08,098:INFO:create_model() successfully completed......................................
2023-05-12 15:30:08,218:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:08,218:INFO:Creating metrics dataframe
2023-05-12 15:30:08,235:INFO:Initializing Light Gradient Boosting Machine
2023-05-12 15:30:08,236:INFO:Total runtime is 0.3490473866462708 minutes
2023-05-12 15:30:08,241:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:08,242:INFO:Initializing create_model()
2023-05-12 15:30:08,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:08,243:INFO:Checking exceptions
2023-05-12 15:30:08,243:INFO:Importing libraries
2023-05-12 15:30:08,243:INFO:Copying training dataset
2023-05-12 15:30:08,247:INFO:Defining folds
2023-05-12 15:30:08,247:INFO:Declaring metric variables
2023-05-12 15:30:08,252:INFO:Importing untrained model
2023-05-12 15:30:08,258:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-12 15:30:08,268:INFO:Starting cross validation
2023-05-12 15:30:08,269:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:17,041:INFO:Calculating mean and std
2023-05-12 15:30:17,044:INFO:Creating metrics dataframe
2023-05-12 15:30:17,053:INFO:Uploading results into container
2023-05-12 15:30:17,054:INFO:Uploading model into container now
2023-05-12 15:30:17,055:INFO:_master_model_container: 18
2023-05-12 15:30:17,056:INFO:_display_container: 2
2023-05-12 15:30:17,057:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-05-12 15:30:17,058:INFO:create_model() successfully completed......................................
2023-05-12 15:30:17,184:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:17,184:INFO:Creating metrics dataframe
2023-05-12 15:30:17,203:INFO:Initializing Dummy Regressor
2023-05-12 15:30:17,203:INFO:Total runtime is 0.4984973470369975 minutes
2023-05-12 15:30:17,209:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:17,209:INFO:Initializing create_model()
2023-05-12 15:30:17,210:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0672920>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:17,210:INFO:Checking exceptions
2023-05-12 15:30:17,210:INFO:Importing libraries
2023-05-12 15:30:17,210:INFO:Copying training dataset
2023-05-12 15:30:17,214:INFO:Defining folds
2023-05-12 15:30:17,214:INFO:Declaring metric variables
2023-05-12 15:30:17,219:INFO:Importing untrained model
2023-05-12 15:30:17,226:INFO:Dummy Regressor Imported successfully
2023-05-12 15:30:17,237:INFO:Starting cross validation
2023-05-12 15:30:17,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:17,456:INFO:Calculating mean and std
2023-05-12 15:30:17,457:INFO:Creating metrics dataframe
2023-05-12 15:30:17,461:INFO:Uploading results into container
2023-05-12 15:30:17,462:INFO:Uploading model into container now
2023-05-12 15:30:17,462:INFO:_master_model_container: 19
2023-05-12 15:30:17,462:INFO:_display_container: 2
2023-05-12 15:30:17,463:INFO:DummyRegressor()
2023-05-12 15:30:17,463:INFO:create_model() successfully completed......................................
2023-05-12 15:30:17,549:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:17,549:INFO:Creating metrics dataframe
2023-05-12 15:30:17,581:INFO:Initializing create_model()
2023-05-12 15:30:17,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:17,581:INFO:Checking exceptions
2023-05-12 15:30:17,584:INFO:Importing libraries
2023-05-12 15:30:17,584:INFO:Copying training dataset
2023-05-12 15:30:17,586:INFO:Defining folds
2023-05-12 15:30:17,587:INFO:Declaring metric variables
2023-05-12 15:30:17,587:INFO:Importing untrained model
2023-05-12 15:30:17,587:INFO:Declaring custom model
2023-05-12 15:30:17,587:INFO:Linear Regression Imported successfully
2023-05-12 15:30:17,589:INFO:Cross validation set to False
2023-05-12 15:30:17,589:INFO:Fitting Model
2023-05-12 15:30:17,604:INFO:LinearRegression(n_jobs=-1)
2023-05-12 15:30:17,604:INFO:create_model() successfully completed......................................
2023-05-12 15:30:17,797:INFO:_master_model_container: 19
2023-05-12 15:30:17,797:INFO:_display_container: 2
2023-05-12 15:30:17,798:INFO:LinearRegression(n_jobs=-1)
2023-05-12 15:30:17,798:INFO:compare_models() successfully completed......................................
2023-05-12 15:30:17,997:INFO:Initializing create_model()
2023-05-12 15:30:17,998:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:17,998:INFO:Checking exceptions
2023-05-12 15:30:18,028:INFO:Importing libraries
2023-05-12 15:30:18,029:INFO:Copying training dataset
2023-05-12 15:30:18,033:INFO:Defining folds
2023-05-12 15:30:18,033:INFO:Declaring metric variables
2023-05-12 15:30:18,039:INFO:Importing untrained model
2023-05-12 15:30:18,046:INFO:Huber Regressor Imported successfully
2023-05-12 15:30:18,056:INFO:Starting cross validation
2023-05-12 15:30:18,057:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:18,435:INFO:Calculating mean and std
2023-05-12 15:30:18,436:INFO:Creating metrics dataframe
2023-05-12 15:30:18,443:INFO:Finalizing model
2023-05-12 15:30:18,467:INFO:Uploading results into container
2023-05-12 15:30:18,468:INFO:Uploading model into container now
2023-05-12 15:30:18,480:INFO:_master_model_container: 20
2023-05-12 15:30:18,481:INFO:_display_container: 3
2023-05-12 15:30:18,481:INFO:HuberRegressor()
2023-05-12 15:30:18,481:INFO:create_model() successfully completed......................................
2023-05-12 15:30:18,823:INFO:Initializing evaluate_model()
2023-05-12 15:30:18,823:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-05-12 15:30:18,844:INFO:Initializing plot_model()
2023-05-12 15:30:18,844:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, system=True)
2023-05-12 15:30:18,845:INFO:Checking exceptions
2023-05-12 15:30:18,848:INFO:Preloading libraries
2023-05-12 15:30:18,848:INFO:Copying training dataset
2023-05-12 15:30:18,848:INFO:Plot type: pipeline
2023-05-12 15:30:19,028:INFO:Visual Rendered Successfully
2023-05-12 15:30:19,129:INFO:plot_model() successfully completed......................................
2023-05-12 15:30:19,315:INFO:Initializing predict_model()
2023-05-12 15:30:19,315:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4A9016320>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A4A12FCD30>)
2023-05-12 15:30:19,316:INFO:Checking exceptions
2023-05-12 15:30:19,316:INFO:Preloading libraries
2023-05-12 15:30:19,319:INFO:Set up data.
2023-05-12 15:30:19,324:INFO:Set up index.
2023-05-12 15:30:28,061:INFO:PyCaret RegressionExperiment
2023-05-12 15:30:28,062:INFO:Logging name: reg-default-name
2023-05-12 15:30:28,062:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-12 15:30:28,062:INFO:version 3.0.0.rc8
2023-05-12 15:30:28,062:INFO:Initializing setup()
2023-05-12 15:30:28,062:INFO:self.USI: 9986
2023-05-12 15:30:28,063:INFO:self._variable_keys: {'html_param', 'memory', '_available_plots', 'seed', 'idx', 'fold_groups_param', 'X', 'data', 'y_test', 'gpu_param', 'exp_name_log', 'exp_id', 'X_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'logging_param', 'USI', 'log_plots_param', 'y', 'n_jobs_param', '_ml_usecase', 'y_train', 'fold_generator', 'transform_target_param', 'pipeline', 'X_train', 'target_param'}
2023-05-12 15:30:28,063:INFO:Checking environment
2023-05-12 15:30:28,063:INFO:python_version: 3.10.9
2023-05-12 15:30:28,063:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-05-12 15:30:28,064:INFO:machine: AMD64
2023-05-12 15:30:28,064:INFO:platform: Windows-10-10.0.19045-SP0
2023-05-12 15:30:28,064:INFO:Memory: svmem(total=17090879488, available=2793320448, percent=83.7, used=14297559040, free=2793320448)
2023-05-12 15:30:28,064:INFO:Physical Core: 4
2023-05-12 15:30:28,065:INFO:Logical Core: 8
2023-05-12 15:30:28,065:INFO:Checking libraries
2023-05-12 15:30:28,065:INFO:System:
2023-05-12 15:30:28,065:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-05-12 15:30:28,066:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-05-12 15:30:28,066:INFO:   machine: Windows-10-10.0.19045-SP0
2023-05-12 15:30:28,066:INFO:PyCaret required dependencies:
2023-05-12 15:30:28,067:INFO:                 pip: 23.0
2023-05-12 15:30:28,067:INFO:          setuptools: 67.1.0
2023-05-12 15:30:28,067:INFO:             pycaret: 3.0.0rc8
2023-05-12 15:30:28,068:INFO:             IPython: 8.8.0
2023-05-12 15:30:28,068:INFO:          ipywidgets: 8.0.4
2023-05-12 15:30:28,068:INFO:                tqdm: 4.64.1
2023-05-12 15:30:28,068:INFO:               numpy: 1.23.5
2023-05-12 15:30:28,069:INFO:              pandas: 1.5.3
2023-05-12 15:30:28,069:INFO:              jinja2: 3.1.2
2023-05-12 15:30:28,070:INFO:               scipy: 1.10.0
2023-05-12 15:30:28,071:INFO:              joblib: 1.2.0
2023-05-12 15:30:28,072:INFO:             sklearn: 1.1.3
2023-05-12 15:30:28,072:INFO:                pyod: 1.0.7
2023-05-12 15:30:28,072:INFO:            imblearn: 0.10.1
2023-05-12 15:30:28,072:INFO:   category_encoders: 2.6.0
2023-05-12 15:30:28,073:INFO:            lightgbm: 3.3.5
2023-05-12 15:30:28,073:INFO:               numba: 0.56.4
2023-05-12 15:30:28,073:INFO:            requests: 2.28.2
2023-05-12 15:30:28,073:INFO:          matplotlib: 3.6.3
2023-05-12 15:30:28,074:INFO:          scikitplot: 0.3.7
2023-05-12 15:30:28,074:INFO:         yellowbrick: 1.5
2023-05-12 15:30:28,074:INFO:              plotly: 5.13.0
2023-05-12 15:30:28,074:INFO:             kaleido: 0.2.1
2023-05-12 15:30:28,074:INFO:         statsmodels: 0.13.5
2023-05-12 15:30:28,074:INFO:              sktime: 0.16.0
2023-05-12 15:30:28,075:INFO:               tbats: 1.1.2
2023-05-12 15:30:28,075:INFO:            pmdarima: 2.0.2
2023-05-12 15:30:28,075:INFO:              psutil: 5.9.0
2023-05-12 15:30:28,075:INFO:PyCaret optional dependencies:
2023-05-12 15:30:28,075:INFO:                shap: Not installed
2023-05-12 15:30:28,076:INFO:           interpret: Not installed
2023-05-12 15:30:28,076:INFO:                umap: Not installed
2023-05-12 15:30:28,076:INFO:    pandas_profiling: Not installed
2023-05-12 15:30:28,076:INFO:  explainerdashboard: Not installed
2023-05-12 15:30:28,076:INFO:             autoviz: Not installed
2023-05-12 15:30:28,077:INFO:           fairlearn: Not installed
2023-05-12 15:30:28,077:INFO:             xgboost: 1.7.3
2023-05-12 15:30:28,077:INFO:            catboost: Not installed
2023-05-12 15:30:28,077:INFO:              kmodes: Not installed
2023-05-12 15:30:28,078:INFO:             mlxtend: Not installed
2023-05-12 15:30:28,078:INFO:       statsforecast: Not installed
2023-05-12 15:30:28,078:INFO:        tune_sklearn: Not installed
2023-05-12 15:30:28,078:INFO:                 ray: Not installed
2023-05-12 15:30:28,078:INFO:            hyperopt: Not installed
2023-05-12 15:30:28,078:INFO:              optuna: Not installed
2023-05-12 15:30:28,079:INFO:               skopt: Not installed
2023-05-12 15:30:28,079:INFO:              mlflow: Not installed
2023-05-12 15:30:28,079:INFO:              gradio: Not installed
2023-05-12 15:30:28,079:INFO:             fastapi: Not installed
2023-05-12 15:30:28,079:INFO:             uvicorn: Not installed
2023-05-12 15:30:28,079:INFO:              m2cgen: Not installed
2023-05-12 15:30:28,080:INFO:           evidently: Not installed
2023-05-12 15:30:28,080:INFO:                nltk: Not installed
2023-05-12 15:30:28,080:INFO:            pyLDAvis: Not installed
2023-05-12 15:30:28,080:INFO:              gensim: Not installed
2023-05-12 15:30:28,080:INFO:               spacy: Not installed
2023-05-12 15:30:28,080:INFO:           wordcloud: Not installed
2023-05-12 15:30:28,080:INFO:            textblob: Not installed
2023-05-12 15:30:28,080:INFO:               fugue: Not installed
2023-05-12 15:30:28,080:INFO:           streamlit: Not installed
2023-05-12 15:30:28,080:INFO:             prophet: Not installed
2023-05-12 15:30:28,081:INFO:None
2023-05-12 15:30:28,081:INFO:Set up GPU usage.
2023-05-12 15:30:28,081:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:28,081:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-05-12 15:30:28,081:INFO:Set up data.
2023-05-12 15:30:28,088:INFO:Set up train/test split.
2023-05-12 15:30:28,093:INFO:Set up index.
2023-05-12 15:30:28,094:INFO:Set up folding strategy.
2023-05-12 15:30:28,094:INFO:Assigning column types.
2023-05-12 15:30:28,102:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-12 15:30:28,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:28,104:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 15:30:28,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:28,116:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:30:28,116:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:28,137:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:30:28,138:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:28,274:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:30:28,275:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:28,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:30:28,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:28,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:28,346:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:30:28,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:30:28,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:28,845:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 15:30:28,846:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:28,859:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:30:28,859:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:28,873:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:30:28,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:28,996:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:30:28,996:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,048:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:30:29,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,049:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:30:29,221:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:30:29,222:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-12 15:30:29,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,235:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:30:29,236:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,249:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:30:29,249:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,361:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:30:29,361:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,416:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:30:29,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,418:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:30:29,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:30:29,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,624:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:30:29,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,637:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:30:29,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,751:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:30:29,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,807:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:30:29,808:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,808:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:29,809:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:30:30,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:30:30,009:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-12 15:30:30,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,041:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:30:30,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,169:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:30:30,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,233:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:30:30,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,234:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:30:30,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:30:30,423:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,423:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,438:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,450:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:30:30,450:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,571:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:30:30,571:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,629:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:30:30,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,630:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:30:30,824:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:30:30,825:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-12 15:30:30,825:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,825:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,852:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:30,956:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:30:30,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,010:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:30:31,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,011:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:30:31,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:30:31,196:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,208:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,332:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:30:31,333:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,385:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:30:31,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,386:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:30:31,582:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:30:31,583:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-12 15:30:31,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,597:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,722:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:30:31,722:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,776:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:30:31,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:30:31,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,976:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:31,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,099:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:30:32,099:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,151:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,153:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:30:32,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:30:32,329:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-12 15:30:32,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,470:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,534:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,534:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,536:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:30:32,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:30:32,764:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,789:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,909:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,961:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:32,962:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:30:33,139:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:30:33,141:INFO:Preparing preprocessing pipeline...
2023-05-12 15:30:33,143:INFO:Set up simple imputation.
2023-05-12 15:30:33,160:INFO:Finished creating preprocessing pipeline.
2023-05-12 15:30:33,170:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-05-12 15:30:33,170:INFO:Creating final display dataframe.
2023-05-12 15:30:33,289:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape         (1042, 2)
4        Transformed data shape         (1042, 2)
5   Transformed train set shape          (729, 2)
6    Transformed test set shape          (313, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              9986
2023-05-12 15:30:33,297:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:33,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:33,310:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:33,319:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:33,402:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:33,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:33,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:33,457:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:30:33,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:30:33,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:33,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:33,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:33,665:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:33,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:33,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:33,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:30:33,828:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:30:34,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:30:34,017:INFO:setup() successfully completed in 5.96s...............
2023-05-12 15:30:34,139:INFO:Initializing compare_models()
2023-05-12 15:30:34,139:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-12 15:30:34,140:INFO:Checking exceptions
2023-05-12 15:30:34,142:INFO:Preparing display monitor
2023-05-12 15:30:34,197:INFO:Initializing Linear Regression
2023-05-12 15:30:34,197:INFO:Total runtime is 0.0 minutes
2023-05-12 15:30:34,206:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:34,206:INFO:Initializing create_model()
2023-05-12 15:30:34,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:34,207:INFO:Checking exceptions
2023-05-12 15:30:34,207:INFO:Importing libraries
2023-05-12 15:30:34,207:INFO:Copying training dataset
2023-05-12 15:30:34,212:INFO:Defining folds
2023-05-12 15:30:34,212:INFO:Declaring metric variables
2023-05-12 15:30:34,222:INFO:Importing untrained model
2023-05-12 15:30:34,231:INFO:Linear Regression Imported successfully
2023-05-12 15:30:34,248:INFO:Starting cross validation
2023-05-12 15:30:34,249:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:34,531:INFO:Calculating mean and std
2023-05-12 15:30:34,531:INFO:Creating metrics dataframe
2023-05-12 15:30:34,535:INFO:Uploading results into container
2023-05-12 15:30:34,536:INFO:Uploading model into container now
2023-05-12 15:30:34,536:INFO:_master_model_container: 1
2023-05-12 15:30:34,536:INFO:_display_container: 2
2023-05-12 15:30:34,536:INFO:LinearRegression(n_jobs=-1)
2023-05-12 15:30:34,536:INFO:create_model() successfully completed......................................
2023-05-12 15:30:34,626:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:34,626:INFO:Creating metrics dataframe
2023-05-12 15:30:34,637:INFO:Initializing Lasso Regression
2023-05-12 15:30:34,637:INFO:Total runtime is 0.007333294550577799 minutes
2023-05-12 15:30:34,641:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:34,641:INFO:Initializing create_model()
2023-05-12 15:30:34,642:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:34,642:INFO:Checking exceptions
2023-05-12 15:30:34,642:INFO:Importing libraries
2023-05-12 15:30:34,642:INFO:Copying training dataset
2023-05-12 15:30:34,645:INFO:Defining folds
2023-05-12 15:30:34,645:INFO:Declaring metric variables
2023-05-12 15:30:34,649:INFO:Importing untrained model
2023-05-12 15:30:34,654:INFO:Lasso Regression Imported successfully
2023-05-12 15:30:34,669:INFO:Starting cross validation
2023-05-12 15:30:34,670:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:34,684:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.228e+08, tolerance: 1.948e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:34,707:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.926e+08, tolerance: 1.970e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:34,730:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.543e+08, tolerance: 1.940e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:34,752:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.701e+08, tolerance: 1.938e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:34,775:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.060e+08, tolerance: 1.941e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:34,798:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.280e+08, tolerance: 1.951e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:34,822:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.429e+08, tolerance: 1.974e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:34,846:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.178e+08, tolerance: 1.907e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:34,870:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.602e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:34,895:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.286e+08, tolerance: 1.982e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:34,906:INFO:Calculating mean and std
2023-05-12 15:30:34,907:INFO:Creating metrics dataframe
2023-05-12 15:30:34,910:INFO:Uploading results into container
2023-05-12 15:30:34,911:INFO:Uploading model into container now
2023-05-12 15:30:34,911:INFO:_master_model_container: 2
2023-05-12 15:30:34,911:INFO:_display_container: 2
2023-05-12 15:30:34,911:INFO:Lasso(random_state=123)
2023-05-12 15:30:34,911:INFO:create_model() successfully completed......................................
2023-05-12 15:30:35,001:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:35,002:INFO:Creating metrics dataframe
2023-05-12 15:30:35,013:INFO:Initializing Ridge Regression
2023-05-12 15:30:35,013:INFO:Total runtime is 0.013608853022257486 minutes
2023-05-12 15:30:35,019:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:35,019:INFO:Initializing create_model()
2023-05-12 15:30:35,019:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:35,019:INFO:Checking exceptions
2023-05-12 15:30:35,019:INFO:Importing libraries
2023-05-12 15:30:35,019:INFO:Copying training dataset
2023-05-12 15:30:35,023:INFO:Defining folds
2023-05-12 15:30:35,023:INFO:Declaring metric variables
2023-05-12 15:30:35,027:INFO:Importing untrained model
2023-05-12 15:30:35,032:INFO:Ridge Regression Imported successfully
2023-05-12 15:30:35,045:INFO:Starting cross validation
2023-05-12 15:30:35,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:35,274:INFO:Calculating mean and std
2023-05-12 15:30:35,275:INFO:Creating metrics dataframe
2023-05-12 15:30:35,279:INFO:Uploading results into container
2023-05-12 15:30:35,280:INFO:Uploading model into container now
2023-05-12 15:30:35,281:INFO:_master_model_container: 3
2023-05-12 15:30:35,281:INFO:_display_container: 2
2023-05-12 15:30:35,282:INFO:Ridge(random_state=123)
2023-05-12 15:30:35,282:INFO:create_model() successfully completed......................................
2023-05-12 15:30:35,369:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:35,369:INFO:Creating metrics dataframe
2023-05-12 15:30:35,380:INFO:Initializing Elastic Net
2023-05-12 15:30:35,381:INFO:Total runtime is 0.019742147127787272 minutes
2023-05-12 15:30:35,386:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:35,386:INFO:Initializing create_model()
2023-05-12 15:30:35,387:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:35,387:INFO:Checking exceptions
2023-05-12 15:30:35,387:INFO:Importing libraries
2023-05-12 15:30:35,387:INFO:Copying training dataset
2023-05-12 15:30:35,391:INFO:Defining folds
2023-05-12 15:30:35,391:INFO:Declaring metric variables
2023-05-12 15:30:35,396:INFO:Importing untrained model
2023-05-12 15:30:35,402:INFO:Elastic Net Imported successfully
2023-05-12 15:30:35,411:INFO:Starting cross validation
2023-05-12 15:30:35,413:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:35,427:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.219e+08, tolerance: 1.948e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:35,454:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.152e+08, tolerance: 1.970e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:35,478:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.940e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:35,502:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.927e+08, tolerance: 1.938e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:35,525:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.434e+08, tolerance: 1.941e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:35,549:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.622e+08, tolerance: 1.951e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:35,575:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.840e+08, tolerance: 1.974e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:35,599:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.019e+08, tolerance: 1.907e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:35,627:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.858e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:35,652:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.022e+08, tolerance: 1.982e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:30:35,662:INFO:Calculating mean and std
2023-05-12 15:30:35,663:INFO:Creating metrics dataframe
2023-05-12 15:30:35,668:INFO:Uploading results into container
2023-05-12 15:30:35,668:INFO:Uploading model into container now
2023-05-12 15:30:35,669:INFO:_master_model_container: 4
2023-05-12 15:30:35,669:INFO:_display_container: 2
2023-05-12 15:30:35,669:INFO:ElasticNet(random_state=123)
2023-05-12 15:30:35,670:INFO:create_model() successfully completed......................................
2023-05-12 15:30:35,759:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:35,759:INFO:Creating metrics dataframe
2023-05-12 15:30:35,775:INFO:Initializing Least Angle Regression
2023-05-12 15:30:35,775:INFO:Total runtime is 0.026308814684549965 minutes
2023-05-12 15:30:35,780:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:35,781:INFO:Initializing create_model()
2023-05-12 15:30:35,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:35,781:INFO:Checking exceptions
2023-05-12 15:30:35,781:INFO:Importing libraries
2023-05-12 15:30:35,781:INFO:Copying training dataset
2023-05-12 15:30:35,785:INFO:Defining folds
2023-05-12 15:30:35,785:INFO:Declaring metric variables
2023-05-12 15:30:35,791:INFO:Importing untrained model
2023-05-12 15:30:35,796:INFO:Least Angle Regression Imported successfully
2023-05-12 15:30:35,807:INFO:Starting cross validation
2023-05-12 15:30:35,808:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:35,821:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:35,846:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:35,869:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:35,892:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:35,915:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:35,939:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:35,961:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:36,000:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:36,025:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:36,054:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:36,065:INFO:Calculating mean and std
2023-05-12 15:30:36,067:INFO:Creating metrics dataframe
2023-05-12 15:30:36,072:INFO:Uploading results into container
2023-05-12 15:30:36,072:INFO:Uploading model into container now
2023-05-12 15:30:36,074:INFO:_master_model_container: 5
2023-05-12 15:30:36,074:INFO:_display_container: 2
2023-05-12 15:30:36,074:INFO:Lars(random_state=123)
2023-05-12 15:30:36,075:INFO:create_model() successfully completed......................................
2023-05-12 15:30:36,163:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:36,164:INFO:Creating metrics dataframe
2023-05-12 15:30:36,176:INFO:Initializing Lasso Least Angle Regression
2023-05-12 15:30:36,177:INFO:Total runtime is 0.033008821805318195 minutes
2023-05-12 15:30:36,181:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:36,182:INFO:Initializing create_model()
2023-05-12 15:30:36,182:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:36,182:INFO:Checking exceptions
2023-05-12 15:30:36,182:INFO:Importing libraries
2023-05-12 15:30:36,182:INFO:Copying training dataset
2023-05-12 15:30:36,187:INFO:Defining folds
2023-05-12 15:30:36,187:INFO:Declaring metric variables
2023-05-12 15:30:36,193:INFO:Importing untrained model
2023-05-12 15:30:36,198:INFO:Lasso Least Angle Regression Imported successfully
2023-05-12 15:30:36,209:INFO:Starting cross validation
2023-05-12 15:30:36,210:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:36,227:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:30:36,250:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:30:36,273:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:30:36,295:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:30:36,319:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:30:36,341:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:30:36,365:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:30:36,387:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:30:36,410:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:30:36,433:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:30:36,443:INFO:Calculating mean and std
2023-05-12 15:30:36,444:INFO:Creating metrics dataframe
2023-05-12 15:30:36,448:INFO:Uploading results into container
2023-05-12 15:30:36,449:INFO:Uploading model into container now
2023-05-12 15:30:36,449:INFO:_master_model_container: 6
2023-05-12 15:30:36,450:INFO:_display_container: 2
2023-05-12 15:30:36,451:INFO:LassoLars(random_state=123)
2023-05-12 15:30:36,451:INFO:create_model() successfully completed......................................
2023-05-12 15:30:36,538:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:36,538:INFO:Creating metrics dataframe
2023-05-12 15:30:36,552:INFO:Initializing Orthogonal Matching Pursuit
2023-05-12 15:30:36,553:INFO:Total runtime is 0.03927554289499918 minutes
2023-05-12 15:30:36,558:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:36,558:INFO:Initializing create_model()
2023-05-12 15:30:36,558:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:36,559:INFO:Checking exceptions
2023-05-12 15:30:36,559:INFO:Importing libraries
2023-05-12 15:30:36,559:INFO:Copying training dataset
2023-05-12 15:30:36,562:INFO:Defining folds
2023-05-12 15:30:36,563:INFO:Declaring metric variables
2023-05-12 15:30:36,570:INFO:Importing untrained model
2023-05-12 15:30:36,576:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-12 15:30:36,588:INFO:Starting cross validation
2023-05-12 15:30:36,589:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:36,645:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:36,684:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:36,711:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:36,737:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:36,760:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:36,783:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:36,806:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:36,828:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:36,860:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:36,887:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:30:36,899:INFO:Calculating mean and std
2023-05-12 15:30:36,901:INFO:Creating metrics dataframe
2023-05-12 15:30:36,905:INFO:Uploading results into container
2023-05-12 15:30:36,906:INFO:Uploading model into container now
2023-05-12 15:30:36,906:INFO:_master_model_container: 7
2023-05-12 15:30:36,907:INFO:_display_container: 2
2023-05-12 15:30:36,907:INFO:OrthogonalMatchingPursuit()
2023-05-12 15:30:36,907:INFO:create_model() successfully completed......................................
2023-05-12 15:30:37,007:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:37,007:INFO:Creating metrics dataframe
2023-05-12 15:30:37,024:INFO:Initializing Bayesian Ridge
2023-05-12 15:30:37,024:INFO:Total runtime is 0.04712549845377604 minutes
2023-05-12 15:30:37,029:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:37,030:INFO:Initializing create_model()
2023-05-12 15:30:37,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:37,030:INFO:Checking exceptions
2023-05-12 15:30:37,030:INFO:Importing libraries
2023-05-12 15:30:37,030:INFO:Copying training dataset
2023-05-12 15:30:37,034:INFO:Defining folds
2023-05-12 15:30:37,034:INFO:Declaring metric variables
2023-05-12 15:30:37,039:INFO:Importing untrained model
2023-05-12 15:30:37,045:INFO:Bayesian Ridge Imported successfully
2023-05-12 15:30:37,057:INFO:Starting cross validation
2023-05-12 15:30:37,058:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:37,294:INFO:Calculating mean and std
2023-05-12 15:30:37,295:INFO:Creating metrics dataframe
2023-05-12 15:30:37,299:INFO:Uploading results into container
2023-05-12 15:30:37,300:INFO:Uploading model into container now
2023-05-12 15:30:37,302:INFO:_master_model_container: 8
2023-05-12 15:30:37,302:INFO:_display_container: 2
2023-05-12 15:30:37,303:INFO:BayesianRidge()
2023-05-12 15:30:37,303:INFO:create_model() successfully completed......................................
2023-05-12 15:30:37,390:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:37,391:INFO:Creating metrics dataframe
2023-05-12 15:30:37,405:INFO:Initializing Passive Aggressive Regressor
2023-05-12 15:30:37,405:INFO:Total runtime is 0.05347551107406616 minutes
2023-05-12 15:30:37,410:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:37,411:INFO:Initializing create_model()
2023-05-12 15:30:37,412:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:37,412:INFO:Checking exceptions
2023-05-12 15:30:37,413:INFO:Importing libraries
2023-05-12 15:30:37,413:INFO:Copying training dataset
2023-05-12 15:30:37,422:INFO:Defining folds
2023-05-12 15:30:37,423:INFO:Declaring metric variables
2023-05-12 15:30:37,435:INFO:Importing untrained model
2023-05-12 15:30:37,443:INFO:Passive Aggressive Regressor Imported successfully
2023-05-12 15:30:37,458:INFO:Starting cross validation
2023-05-12 15:30:37,459:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:37,707:INFO:Calculating mean and std
2023-05-12 15:30:37,709:INFO:Creating metrics dataframe
2023-05-12 15:30:37,713:INFO:Uploading results into container
2023-05-12 15:30:37,714:INFO:Uploading model into container now
2023-05-12 15:30:37,714:INFO:_master_model_container: 9
2023-05-12 15:30:37,715:INFO:_display_container: 2
2023-05-12 15:30:37,715:INFO:PassiveAggressiveRegressor(random_state=123)
2023-05-12 15:30:37,716:INFO:create_model() successfully completed......................................
2023-05-12 15:30:37,806:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:37,806:INFO:Creating metrics dataframe
2023-05-12 15:30:37,821:INFO:Initializing Huber Regressor
2023-05-12 15:30:37,821:INFO:Total runtime is 0.06040881474812825 minutes
2023-05-12 15:30:37,827:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:37,828:INFO:Initializing create_model()
2023-05-12 15:30:37,828:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:37,828:INFO:Checking exceptions
2023-05-12 15:30:37,828:INFO:Importing libraries
2023-05-12 15:30:37,829:INFO:Copying training dataset
2023-05-12 15:30:37,833:INFO:Defining folds
2023-05-12 15:30:37,834:INFO:Declaring metric variables
2023-05-12 15:30:37,839:INFO:Importing untrained model
2023-05-12 15:30:37,844:INFO:Huber Regressor Imported successfully
2023-05-12 15:30:37,854:INFO:Starting cross validation
2023-05-12 15:30:37,855:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:38,135:INFO:Calculating mean and std
2023-05-12 15:30:38,137:INFO:Creating metrics dataframe
2023-05-12 15:30:38,141:INFO:Uploading results into container
2023-05-12 15:30:38,143:INFO:Uploading model into container now
2023-05-12 15:30:38,143:INFO:_master_model_container: 10
2023-05-12 15:30:38,144:INFO:_display_container: 2
2023-05-12 15:30:38,144:INFO:HuberRegressor()
2023-05-12 15:30:38,144:INFO:create_model() successfully completed......................................
2023-05-12 15:30:38,232:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:38,232:INFO:Creating metrics dataframe
2023-05-12 15:30:38,248:INFO:Initializing K Neighbors Regressor
2023-05-12 15:30:38,248:INFO:Total runtime is 0.06752547820409138 minutes
2023-05-12 15:30:38,255:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:38,255:INFO:Initializing create_model()
2023-05-12 15:30:38,256:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:38,256:INFO:Checking exceptions
2023-05-12 15:30:38,256:INFO:Importing libraries
2023-05-12 15:30:38,256:INFO:Copying training dataset
2023-05-12 15:30:38,260:INFO:Defining folds
2023-05-12 15:30:38,261:INFO:Declaring metric variables
2023-05-12 15:30:38,267:INFO:Importing untrained model
2023-05-12 15:30:38,274:INFO:K Neighbors Regressor Imported successfully
2023-05-12 15:30:38,285:INFO:Starting cross validation
2023-05-12 15:30:38,287:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:38,649:INFO:Calculating mean and std
2023-05-12 15:30:38,651:INFO:Creating metrics dataframe
2023-05-12 15:30:38,656:INFO:Uploading results into container
2023-05-12 15:30:38,656:INFO:Uploading model into container now
2023-05-12 15:30:38,657:INFO:_master_model_container: 11
2023-05-12 15:30:38,657:INFO:_display_container: 2
2023-05-12 15:30:38,657:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-12 15:30:38,658:INFO:create_model() successfully completed......................................
2023-05-12 15:30:38,746:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:38,746:INFO:Creating metrics dataframe
2023-05-12 15:30:38,761:INFO:Initializing Decision Tree Regressor
2023-05-12 15:30:38,761:INFO:Total runtime is 0.07607144117355347 minutes
2023-05-12 15:30:38,765:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:38,766:INFO:Initializing create_model()
2023-05-12 15:30:38,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:38,766:INFO:Checking exceptions
2023-05-12 15:30:38,767:INFO:Importing libraries
2023-05-12 15:30:38,767:INFO:Copying training dataset
2023-05-12 15:30:38,771:INFO:Defining folds
2023-05-12 15:30:38,772:INFO:Declaring metric variables
2023-05-12 15:30:38,777:INFO:Importing untrained model
2023-05-12 15:30:38,783:INFO:Decision Tree Regressor Imported successfully
2023-05-12 15:30:38,794:INFO:Starting cross validation
2023-05-12 15:30:38,796:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:39,042:INFO:Calculating mean and std
2023-05-12 15:30:39,043:INFO:Creating metrics dataframe
2023-05-12 15:30:39,049:INFO:Uploading results into container
2023-05-12 15:30:39,050:INFO:Uploading model into container now
2023-05-12 15:30:39,051:INFO:_master_model_container: 12
2023-05-12 15:30:39,051:INFO:_display_container: 2
2023-05-12 15:30:39,052:INFO:DecisionTreeRegressor(random_state=123)
2023-05-12 15:30:39,053:INFO:create_model() successfully completed......................................
2023-05-12 15:30:39,138:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:39,139:INFO:Creating metrics dataframe
2023-05-12 15:30:39,154:INFO:Initializing Random Forest Regressor
2023-05-12 15:30:39,154:INFO:Total runtime is 0.08262998263041178 minutes
2023-05-12 15:30:39,158:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:39,159:INFO:Initializing create_model()
2023-05-12 15:30:39,159:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:39,159:INFO:Checking exceptions
2023-05-12 15:30:39,159:INFO:Importing libraries
2023-05-12 15:30:39,159:INFO:Copying training dataset
2023-05-12 15:30:39,163:INFO:Defining folds
2023-05-12 15:30:39,164:INFO:Declaring metric variables
2023-05-12 15:30:39,170:INFO:Importing untrained model
2023-05-12 15:30:39,176:INFO:Random Forest Regressor Imported successfully
2023-05-12 15:30:39,185:INFO:Starting cross validation
2023-05-12 15:30:39,187:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:41,204:INFO:Calculating mean and std
2023-05-12 15:30:41,206:INFO:Creating metrics dataframe
2023-05-12 15:30:41,209:INFO:Uploading results into container
2023-05-12 15:30:41,210:INFO:Uploading model into container now
2023-05-12 15:30:41,210:INFO:_master_model_container: 13
2023-05-12 15:30:41,211:INFO:_display_container: 2
2023-05-12 15:30:41,211:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-05-12 15:30:41,212:INFO:create_model() successfully completed......................................
2023-05-12 15:30:41,308:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:41,308:INFO:Creating metrics dataframe
2023-05-12 15:30:41,324:INFO:Initializing Extra Trees Regressor
2023-05-12 15:30:41,324:INFO:Total runtime is 0.11879639228185018 minutes
2023-05-12 15:30:41,329:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:41,329:INFO:Initializing create_model()
2023-05-12 15:30:41,329:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:41,330:INFO:Checking exceptions
2023-05-12 15:30:41,330:INFO:Importing libraries
2023-05-12 15:30:41,330:INFO:Copying training dataset
2023-05-12 15:30:41,334:INFO:Defining folds
2023-05-12 15:30:41,335:INFO:Declaring metric variables
2023-05-12 15:30:41,340:INFO:Importing untrained model
2023-05-12 15:30:41,347:INFO:Extra Trees Regressor Imported successfully
2023-05-12 15:30:41,358:INFO:Starting cross validation
2023-05-12 15:30:41,359:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:43,294:INFO:Calculating mean and std
2023-05-12 15:30:43,296:INFO:Creating metrics dataframe
2023-05-12 15:30:43,300:INFO:Uploading results into container
2023-05-12 15:30:43,301:INFO:Uploading model into container now
2023-05-12 15:30:43,301:INFO:_master_model_container: 14
2023-05-12 15:30:43,302:INFO:_display_container: 2
2023-05-12 15:30:43,302:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-05-12 15:30:43,302:INFO:create_model() successfully completed......................................
2023-05-12 15:30:43,392:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:43,392:INFO:Creating metrics dataframe
2023-05-12 15:30:43,410:INFO:Initializing AdaBoost Regressor
2023-05-12 15:30:43,411:INFO:Total runtime is 0.15357982714970908 minutes
2023-05-12 15:30:43,417:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:43,418:INFO:Initializing create_model()
2023-05-12 15:30:43,418:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:43,418:INFO:Checking exceptions
2023-05-12 15:30:43,419:INFO:Importing libraries
2023-05-12 15:30:43,419:INFO:Copying training dataset
2023-05-12 15:30:43,423:INFO:Defining folds
2023-05-12 15:30:43,423:INFO:Declaring metric variables
2023-05-12 15:30:43,431:INFO:Importing untrained model
2023-05-12 15:30:43,439:INFO:AdaBoost Regressor Imported successfully
2023-05-12 15:30:43,454:INFO:Starting cross validation
2023-05-12 15:30:43,455:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:44,468:INFO:Calculating mean and std
2023-05-12 15:30:44,472:INFO:Creating metrics dataframe
2023-05-12 15:30:44,486:INFO:Uploading results into container
2023-05-12 15:30:44,488:INFO:Uploading model into container now
2023-05-12 15:30:44,488:INFO:_master_model_container: 15
2023-05-12 15:30:44,488:INFO:_display_container: 2
2023-05-12 15:30:44,489:INFO:AdaBoostRegressor(random_state=123)
2023-05-12 15:30:44,489:INFO:create_model() successfully completed......................................
2023-05-12 15:30:44,598:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:44,598:INFO:Creating metrics dataframe
2023-05-12 15:30:44,623:INFO:Initializing Gradient Boosting Regressor
2023-05-12 15:30:44,623:INFO:Total runtime is 0.17377968629201254 minutes
2023-05-12 15:30:44,629:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:44,630:INFO:Initializing create_model()
2023-05-12 15:30:44,630:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:44,630:INFO:Checking exceptions
2023-05-12 15:30:44,630:INFO:Importing libraries
2023-05-12 15:30:44,630:INFO:Copying training dataset
2023-05-12 15:30:44,635:INFO:Defining folds
2023-05-12 15:30:44,635:INFO:Declaring metric variables
2023-05-12 15:30:44,645:INFO:Importing untrained model
2023-05-12 15:30:44,652:INFO:Gradient Boosting Regressor Imported successfully
2023-05-12 15:30:44,663:INFO:Starting cross validation
2023-05-12 15:30:44,665:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:45,376:INFO:Calculating mean and std
2023-05-12 15:30:45,378:INFO:Creating metrics dataframe
2023-05-12 15:30:45,385:INFO:Uploading results into container
2023-05-12 15:30:45,386:INFO:Uploading model into container now
2023-05-12 15:30:45,386:INFO:_master_model_container: 16
2023-05-12 15:30:45,387:INFO:_display_container: 2
2023-05-12 15:30:45,388:INFO:GradientBoostingRegressor(random_state=123)
2023-05-12 15:30:45,388:INFO:create_model() successfully completed......................................
2023-05-12 15:30:45,487:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:45,488:INFO:Creating metrics dataframe
2023-05-12 15:30:45,505:INFO:Initializing Extreme Gradient Boosting
2023-05-12 15:30:45,506:INFO:Total runtime is 0.18849643468856814 minutes
2023-05-12 15:30:45,516:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:45,517:INFO:Initializing create_model()
2023-05-12 15:30:45,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:45,517:INFO:Checking exceptions
2023-05-12 15:30:45,518:INFO:Importing libraries
2023-05-12 15:30:45,518:INFO:Copying training dataset
2023-05-12 15:30:45,524:INFO:Defining folds
2023-05-12 15:30:45,524:INFO:Declaring metric variables
2023-05-12 15:30:45,531:INFO:Importing untrained model
2023-05-12 15:30:45,539:INFO:Extreme Gradient Boosting Imported successfully
2023-05-12 15:30:45,551:INFO:Starting cross validation
2023-05-12 15:30:45,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:30:52,824:INFO:Calculating mean and std
2023-05-12 15:30:52,827:INFO:Creating metrics dataframe
2023-05-12 15:30:52,836:INFO:Uploading results into container
2023-05-12 15:30:52,837:INFO:Uploading model into container now
2023-05-12 15:30:52,838:INFO:_master_model_container: 17
2023-05-12 15:30:52,838:INFO:_display_container: 2
2023-05-12 15:30:52,841:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-05-12 15:30:52,841:INFO:create_model() successfully completed......................................
2023-05-12 15:30:52,973:INFO:SubProcess create_model() end ==================================
2023-05-12 15:30:52,973:INFO:Creating metrics dataframe
2023-05-12 15:30:52,991:INFO:Initializing Light Gradient Boosting Machine
2023-05-12 15:30:52,991:INFO:Total runtime is 0.31324653625488286 minutes
2023-05-12 15:30:52,996:INFO:SubProcess create_model() called ==================================
2023-05-12 15:30:52,998:INFO:Initializing create_model()
2023-05-12 15:30:52,998:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:30:52,998:INFO:Checking exceptions
2023-05-12 15:30:52,998:INFO:Importing libraries
2023-05-12 15:30:52,998:INFO:Copying training dataset
2023-05-12 15:30:53,003:INFO:Defining folds
2023-05-12 15:30:53,003:INFO:Declaring metric variables
2023-05-12 15:30:53,007:INFO:Importing untrained model
2023-05-12 15:30:53,012:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-12 15:30:53,024:INFO:Starting cross validation
2023-05-12 15:30:53,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:02,140:INFO:Calculating mean and std
2023-05-12 15:31:02,143:INFO:Creating metrics dataframe
2023-05-12 15:31:02,152:INFO:Uploading results into container
2023-05-12 15:31:02,153:INFO:Uploading model into container now
2023-05-12 15:31:02,154:INFO:_master_model_container: 18
2023-05-12 15:31:02,154:INFO:_display_container: 2
2023-05-12 15:31:02,155:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-05-12 15:31:02,155:INFO:create_model() successfully completed......................................
2023-05-12 15:31:02,279:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:02,280:INFO:Creating metrics dataframe
2023-05-12 15:31:02,297:INFO:Initializing Dummy Regressor
2023-05-12 15:31:02,297:INFO:Total runtime is 0.46834694941838584 minutes
2023-05-12 15:31:02,301:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:02,302:INFO:Initializing create_model()
2023-05-12 15:31:02,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A4A0640EB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:02,302:INFO:Checking exceptions
2023-05-12 15:31:02,302:INFO:Importing libraries
2023-05-12 15:31:02,302:INFO:Copying training dataset
2023-05-12 15:31:02,306:INFO:Defining folds
2023-05-12 15:31:02,306:INFO:Declaring metric variables
2023-05-12 15:31:02,312:INFO:Importing untrained model
2023-05-12 15:31:02,318:INFO:Dummy Regressor Imported successfully
2023-05-12 15:31:02,328:INFO:Starting cross validation
2023-05-12 15:31:02,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:02,537:INFO:Calculating mean and std
2023-05-12 15:31:02,538:INFO:Creating metrics dataframe
2023-05-12 15:31:02,542:INFO:Uploading results into container
2023-05-12 15:31:02,543:INFO:Uploading model into container now
2023-05-12 15:31:02,544:INFO:_master_model_container: 19
2023-05-12 15:31:02,544:INFO:_display_container: 2
2023-05-12 15:31:02,545:INFO:DummyRegressor()
2023-05-12 15:31:02,545:INFO:create_model() successfully completed......................................
2023-05-12 15:31:02,637:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:02,637:INFO:Creating metrics dataframe
2023-05-12 15:31:02,671:INFO:Initializing create_model()
2023-05-12 15:31:02,672:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:02,672:INFO:Checking exceptions
2023-05-12 15:31:02,674:INFO:Importing libraries
2023-05-12 15:31:02,674:INFO:Copying training dataset
2023-05-12 15:31:02,677:INFO:Defining folds
2023-05-12 15:31:02,677:INFO:Declaring metric variables
2023-05-12 15:31:02,677:INFO:Importing untrained model
2023-05-12 15:31:02,677:INFO:Declaring custom model
2023-05-12 15:31:02,678:INFO:Linear Regression Imported successfully
2023-05-12 15:31:02,679:INFO:Cross validation set to False
2023-05-12 15:31:02,679:INFO:Fitting Model
2023-05-12 15:31:02,689:INFO:LinearRegression(n_jobs=-1)
2023-05-12 15:31:02,689:INFO:create_model() successfully completed......................................
2023-05-12 15:31:02,826:INFO:_master_model_container: 19
2023-05-12 15:31:02,827:INFO:_display_container: 2
2023-05-12 15:31:02,828:INFO:LinearRegression(n_jobs=-1)
2023-05-12 15:31:02,828:INFO:compare_models() successfully completed......................................
2023-05-12 15:31:02,999:INFO:Initializing create_model()
2023-05-12 15:31:03,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:03,000:INFO:Checking exceptions
2023-05-12 15:31:03,032:INFO:Importing libraries
2023-05-12 15:31:03,033:INFO:Copying training dataset
2023-05-12 15:31:03,040:INFO:Defining folds
2023-05-12 15:31:03,040:INFO:Declaring metric variables
2023-05-12 15:31:03,053:INFO:Importing untrained model
2023-05-12 15:31:03,064:INFO:Huber Regressor Imported successfully
2023-05-12 15:31:03,074:INFO:Starting cross validation
2023-05-12 15:31:03,076:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:03,464:INFO:Calculating mean and std
2023-05-12 15:31:03,465:INFO:Creating metrics dataframe
2023-05-12 15:31:03,472:INFO:Finalizing model
2023-05-12 15:31:03,501:INFO:Uploading results into container
2023-05-12 15:31:03,502:INFO:Uploading model into container now
2023-05-12 15:31:03,516:INFO:_master_model_container: 20
2023-05-12 15:31:03,516:INFO:_display_container: 3
2023-05-12 15:31:03,517:INFO:HuberRegressor()
2023-05-12 15:31:03,517:INFO:create_model() successfully completed......................................
2023-05-12 15:31:03,850:INFO:Initializing evaluate_model()
2023-05-12 15:31:03,850:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-05-12 15:31:03,882:INFO:Initializing plot_model()
2023-05-12 15:31:03,883:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, system=True)
2023-05-12 15:31:03,883:INFO:Checking exceptions
2023-05-12 15:31:03,889:INFO:Preloading libraries
2023-05-12 15:31:03,890:INFO:Copying training dataset
2023-05-12 15:31:03,890:INFO:Plot type: pipeline
2023-05-12 15:31:04,031:INFO:Visual Rendered Successfully
2023-05-12 15:31:04,138:INFO:plot_model() successfully completed......................................
2023-05-12 15:31:04,396:INFO:Initializing predict_model()
2023-05-12 15:31:04,396:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001A4ADF91570>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001A4A141FB50>)
2023-05-12 15:31:04,396:INFO:Checking exceptions
2023-05-12 15:31:04,397:INFO:Preloading libraries
2023-05-12 15:31:04,402:INFO:Set up data.
2023-05-12 15:31:04,408:INFO:Set up index.
2023-05-12 15:31:28,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:28,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:28,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:28,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:29,964:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-12 15:31:33,369:INFO:PyCaret RegressionExperiment
2023-05-12 15:31:33,370:INFO:Logging name: reg-default-name
2023-05-12 15:31:33,370:INFO:ML Usecase: MLUsecase.REGRESSION
2023-05-12 15:31:33,370:INFO:version 3.0.0.rc8
2023-05-12 15:31:33,370:INFO:Initializing setup()
2023-05-12 15:31:33,371:INFO:self.USI: e257
2023-05-12 15:31:33,371:INFO:self._variable_keys: {'fold_generator', 'X_train', 'y_test', 'transform_target_param', 'html_param', 'exp_name_log', '_available_plots', 'y', 'idx', 'exp_id', 'logging_param', 'pipeline', 'data', 'target_param', 'fold_shuffle_param', 'n_jobs_param', 'memory', 'log_plots_param', 'X', 'seed', 'X_test', '_ml_usecase', 'fold_groups_param', 'y_train', 'gpu_param', 'gpu_n_jobs_param', 'USI'}
2023-05-12 15:31:33,371:INFO:Checking environment
2023-05-12 15:31:33,371:INFO:python_version: 3.10.9
2023-05-12 15:31:33,371:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2023-05-12 15:31:33,371:INFO:machine: AMD64
2023-05-12 15:31:33,372:INFO:platform: Windows-10-10.0.19045-SP0
2023-05-12 15:31:33,372:INFO:Memory: svmem(total=17090879488, available=3697025024, percent=78.4, used=13393854464, free=3697025024)
2023-05-12 15:31:33,373:INFO:Physical Core: 4
2023-05-12 15:31:33,373:INFO:Logical Core: 8
2023-05-12 15:31:33,373:INFO:Checking libraries
2023-05-12 15:31:33,375:INFO:System:
2023-05-12 15:31:33,378:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2023-05-12 15:31:33,380:INFO:executable: c:\Users\Feras\anaconda3\envs\Crypto\python.exe
2023-05-12 15:31:33,381:INFO:   machine: Windows-10-10.0.19045-SP0
2023-05-12 15:31:33,381:INFO:PyCaret required dependencies:
2023-05-12 15:31:33,385:INFO:                 pip: 23.0
2023-05-12 15:31:33,385:INFO:          setuptools: 67.1.0
2023-05-12 15:31:33,387:INFO:             pycaret: 3.0.0rc8
2023-05-12 15:31:33,389:INFO:             IPython: 8.8.0
2023-05-12 15:31:33,389:INFO:          ipywidgets: 8.0.4
2023-05-12 15:31:33,390:INFO:                tqdm: 4.64.1
2023-05-12 15:31:33,390:INFO:               numpy: 1.23.5
2023-05-12 15:31:33,390:INFO:              pandas: 1.5.3
2023-05-12 15:31:33,390:INFO:              jinja2: 3.1.2
2023-05-12 15:31:33,391:INFO:               scipy: 1.10.0
2023-05-12 15:31:33,391:INFO:              joblib: 1.2.0
2023-05-12 15:31:33,391:INFO:             sklearn: 1.1.3
2023-05-12 15:31:33,391:INFO:                pyod: 1.0.7
2023-05-12 15:31:33,391:INFO:            imblearn: 0.10.1
2023-05-12 15:31:33,392:INFO:   category_encoders: 2.6.0
2023-05-12 15:31:33,392:INFO:            lightgbm: 3.3.5
2023-05-12 15:31:33,392:INFO:               numba: 0.56.4
2023-05-12 15:31:33,392:INFO:            requests: 2.28.2
2023-05-12 15:31:33,393:INFO:          matplotlib: 3.6.3
2023-05-12 15:31:33,393:INFO:          scikitplot: 0.3.7
2023-05-12 15:31:33,393:INFO:         yellowbrick: 1.5
2023-05-12 15:31:33,393:INFO:              plotly: 5.13.0
2023-05-12 15:31:33,394:INFO:             kaleido: 0.2.1
2023-05-12 15:31:33,394:INFO:         statsmodels: 0.13.5
2023-05-12 15:31:33,394:INFO:              sktime: 0.16.0
2023-05-12 15:31:33,394:INFO:               tbats: 1.1.2
2023-05-12 15:31:33,394:INFO:            pmdarima: 2.0.2
2023-05-12 15:31:33,395:INFO:              psutil: 5.9.0
2023-05-12 15:31:33,396:INFO:PyCaret optional dependencies:
2023-05-12 15:31:33,474:INFO:                shap: Not installed
2023-05-12 15:31:33,474:INFO:           interpret: Not installed
2023-05-12 15:31:33,474:INFO:                umap: Not installed
2023-05-12 15:31:33,474:INFO:    pandas_profiling: Not installed
2023-05-12 15:31:33,474:INFO:  explainerdashboard: Not installed
2023-05-12 15:31:33,474:INFO:             autoviz: Not installed
2023-05-12 15:31:33,474:INFO:           fairlearn: Not installed
2023-05-12 15:31:33,474:INFO:             xgboost: 1.7.3
2023-05-12 15:31:33,475:INFO:            catboost: Not installed
2023-05-12 15:31:33,475:INFO:              kmodes: Not installed
2023-05-12 15:31:33,475:INFO:             mlxtend: Not installed
2023-05-12 15:31:33,475:INFO:       statsforecast: Not installed
2023-05-12 15:31:33,475:INFO:        tune_sklearn: Not installed
2023-05-12 15:31:33,475:INFO:                 ray: Not installed
2023-05-12 15:31:33,475:INFO:            hyperopt: Not installed
2023-05-12 15:31:33,475:INFO:              optuna: Not installed
2023-05-12 15:31:33,475:INFO:               skopt: Not installed
2023-05-12 15:31:33,475:INFO:              mlflow: Not installed
2023-05-12 15:31:33,475:INFO:              gradio: Not installed
2023-05-12 15:31:33,475:INFO:             fastapi: Not installed
2023-05-12 15:31:33,475:INFO:             uvicorn: Not installed
2023-05-12 15:31:33,475:INFO:              m2cgen: Not installed
2023-05-12 15:31:33,475:INFO:           evidently: Not installed
2023-05-12 15:31:33,476:INFO:                nltk: Not installed
2023-05-12 15:31:33,476:INFO:            pyLDAvis: Not installed
2023-05-12 15:31:33,476:INFO:              gensim: Not installed
2023-05-12 15:31:33,476:INFO:               spacy: Not installed
2023-05-12 15:31:33,476:INFO:           wordcloud: Not installed
2023-05-12 15:31:33,476:INFO:            textblob: Not installed
2023-05-12 15:31:33,476:INFO:               fugue: Not installed
2023-05-12 15:31:33,476:INFO:           streamlit: Not installed
2023-05-12 15:31:33,476:INFO:             prophet: Not installed
2023-05-12 15:31:33,476:INFO:None
2023-05-12 15:31:33,476:INFO:Set up GPU usage.
2023-05-12 15:31:33,476:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:33,476:WARNING:cuML is outdated or not found. Required version is >=22.10, got 3.0.0.rc8
2023-05-12 15:31:33,477:INFO:Set up data.
2023-05-12 15:31:33,481:INFO:Set up train/test split.
2023-05-12 15:31:33,485:INFO:Set up index.
2023-05-12 15:31:33,485:INFO:Set up folding strategy.
2023-05-12 15:31:33,485:INFO:Assigning column types.
2023-05-12 15:31:33,493:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-12 15:31:33,493:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:33,493:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 15:31:33,493:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:33,506:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:31:33,506:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:33,512:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:31:33,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:33,595:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:31:33,595:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:33,657:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:31:33,657:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:33,658:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:33,660:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:31:34,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:31:34,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,053:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-05-12 15:31:34,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,066:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:31:34,066:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,080:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:31:34,081:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,195:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:31:34,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,257:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:31:34,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,258:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:31:34,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:31:34,423:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-05-12 15:31:34,424:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,424:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,437:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:31:34,438:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,450:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:31:34,450:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,569:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:31:34,570:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,631:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:31:34,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,632:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,632:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:31:34,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:31:34,816:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,830:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-05-12 15:31:34,830:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,843:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:31:34,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:34,955:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:31:34,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,011:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:31:35,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,012:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:31:35,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:31:35,198:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-05-12 15:31:35,199:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,199:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,226:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:31:35,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,342:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:31:35,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,394:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:31:35,394:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,394:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,395:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:31:35,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:31:35,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,589:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-05-12 15:31:35,589:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,694:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:31:35,694:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,745:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:31:35,746:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,746:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,747:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:31:35,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:31:35,906:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-05-12 15:31:35,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:35,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,041:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:31:36,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,095:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:31:36,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,099:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:31:36,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:31:36,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,293:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,407:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:31:36,407:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,463:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-12 15:31:36,463:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,463:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,464:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:31:36,629:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:31:36,630:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-12 15:31:36,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,631:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,644:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,658:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:31:36,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,825:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,825:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,826:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:31:36,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:31:36,996:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:36,996:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,009:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,130:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-05-12 15:31:37,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,185:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:31:37,370:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:31:37,371:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-05-12 15:31:37,372:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,372:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,508:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,561:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,561:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,561:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:31:37,730:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:31:37,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,732:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,746:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,926:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:37,927:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:31:38,087:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:31:38,090:INFO:Preparing preprocessing pipeline...
2023-05-12 15:31:38,091:INFO:Set up simple imputation.
2023-05-12 15:31:38,110:INFO:Finished creating preprocessing pipeline.
2023-05-12 15:31:38,123:INFO:Pipeline: Pipeline(memory=Memory(location=C:\Users\Feras\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Close'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-05-12 15:31:38,123:INFO:Creating final display dataframe.
2023-05-12 15:31:38,241:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      Future_Price
2                   Target type        Regression
3           Original data shape         (1042, 2)
4        Transformed data shape         (1042, 2)
5   Transformed train set shape          (729, 2)
6    Transformed test set shape          (313, 2)
7              Numeric features                 1
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              e257
2023-05-12 15:31:38,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:38,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:38,256:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:38,262:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:38,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:38,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:38,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:38,384:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:31:38,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:31:38,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:38,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:38,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:38,590:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:38,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:38,752:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:38,752:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-12 15:31:38,753:INFO:Soft dependency imported: xgboost: 1.7.3
2023-05-12 15:31:38,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-12 15:31:38,936:INFO:setup() successfully completed in 5.57s...............
2023-05-12 15:31:38,996:INFO:Initializing compare_models()
2023-05-12 15:31:38,996:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-05-12 15:31:38,996:INFO:Checking exceptions
2023-05-12 15:31:38,999:INFO:Preparing display monitor
2023-05-12 15:31:39,064:INFO:Initializing Linear Regression
2023-05-12 15:31:39,064:INFO:Total runtime is 0.0 minutes
2023-05-12 15:31:39,073:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:39,074:INFO:Initializing create_model()
2023-05-12 15:31:39,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:39,075:INFO:Checking exceptions
2023-05-12 15:31:39,075:INFO:Importing libraries
2023-05-12 15:31:39,076:INFO:Copying training dataset
2023-05-12 15:31:39,080:INFO:Defining folds
2023-05-12 15:31:39,081:INFO:Declaring metric variables
2023-05-12 15:31:39,089:INFO:Importing untrained model
2023-05-12 15:31:39,096:INFO:Linear Regression Imported successfully
2023-05-12 15:31:39,108:INFO:Starting cross validation
2023-05-12 15:31:39,118:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:39,357:INFO:Calculating mean and std
2023-05-12 15:31:39,357:INFO:Creating metrics dataframe
2023-05-12 15:31:39,361:INFO:Uploading results into container
2023-05-12 15:31:39,361:INFO:Uploading model into container now
2023-05-12 15:31:39,362:INFO:_master_model_container: 1
2023-05-12 15:31:39,362:INFO:_display_container: 2
2023-05-12 15:31:39,362:INFO:LinearRegression(n_jobs=-1)
2023-05-12 15:31:39,362:INFO:create_model() successfully completed......................................
2023-05-12 15:31:39,444:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:39,445:INFO:Creating metrics dataframe
2023-05-12 15:31:39,455:INFO:Initializing Lasso Regression
2023-05-12 15:31:39,456:INFO:Total runtime is 0.006533344586690267 minutes
2023-05-12 15:31:39,461:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:39,461:INFO:Initializing create_model()
2023-05-12 15:31:39,461:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:39,462:INFO:Checking exceptions
2023-05-12 15:31:39,462:INFO:Importing libraries
2023-05-12 15:31:39,462:INFO:Copying training dataset
2023-05-12 15:31:39,465:INFO:Defining folds
2023-05-12 15:31:39,465:INFO:Declaring metric variables
2023-05-12 15:31:39,470:INFO:Importing untrained model
2023-05-12 15:31:39,476:INFO:Lasso Regression Imported successfully
2023-05-12 15:31:39,486:INFO:Starting cross validation
2023-05-12 15:31:39,487:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:39,511:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.228e+08, tolerance: 1.948e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:39,535:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.926e+08, tolerance: 1.970e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:39,560:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.543e+08, tolerance: 1.940e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:39,587:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.701e+08, tolerance: 1.938e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:39,615:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.060e+08, tolerance: 1.941e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:39,639:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.280e+08, tolerance: 1.951e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:39,662:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.429e+08, tolerance: 1.974e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:39,686:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.178e+08, tolerance: 1.907e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:39,710:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.602e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:39,734:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.286e+08, tolerance: 1.982e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:39,744:INFO:Calculating mean and std
2023-05-12 15:31:39,745:INFO:Creating metrics dataframe
2023-05-12 15:31:39,748:INFO:Uploading results into container
2023-05-12 15:31:39,749:INFO:Uploading model into container now
2023-05-12 15:31:39,749:INFO:_master_model_container: 2
2023-05-12 15:31:39,749:INFO:_display_container: 2
2023-05-12 15:31:39,750:INFO:Lasso(random_state=123)
2023-05-12 15:31:39,750:INFO:create_model() successfully completed......................................
2023-05-12 15:31:39,829:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:39,829:INFO:Creating metrics dataframe
2023-05-12 15:31:39,844:INFO:Initializing Ridge Regression
2023-05-12 15:31:39,844:INFO:Total runtime is 0.012998819351196289 minutes
2023-05-12 15:31:39,848:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:39,849:INFO:Initializing create_model()
2023-05-12 15:31:39,849:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:39,849:INFO:Checking exceptions
2023-05-12 15:31:39,850:INFO:Importing libraries
2023-05-12 15:31:39,850:INFO:Copying training dataset
2023-05-12 15:31:39,853:INFO:Defining folds
2023-05-12 15:31:39,853:INFO:Declaring metric variables
2023-05-12 15:31:39,857:INFO:Importing untrained model
2023-05-12 15:31:39,862:INFO:Ridge Regression Imported successfully
2023-05-12 15:31:39,872:INFO:Starting cross validation
2023-05-12 15:31:39,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:40,139:INFO:Calculating mean and std
2023-05-12 15:31:40,143:INFO:Creating metrics dataframe
2023-05-12 15:31:40,167:INFO:Uploading results into container
2023-05-12 15:31:40,168:INFO:Uploading model into container now
2023-05-12 15:31:40,169:INFO:_master_model_container: 3
2023-05-12 15:31:40,169:INFO:_display_container: 2
2023-05-12 15:31:40,170:INFO:Ridge(random_state=123)
2023-05-12 15:31:40,170:INFO:create_model() successfully completed......................................
2023-05-12 15:31:40,258:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:40,258:INFO:Creating metrics dataframe
2023-05-12 15:31:40,271:INFO:Initializing Elastic Net
2023-05-12 15:31:40,271:INFO:Total runtime is 0.020115482807159423 minutes
2023-05-12 15:31:40,276:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:40,277:INFO:Initializing create_model()
2023-05-12 15:31:40,277:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:40,277:INFO:Checking exceptions
2023-05-12 15:31:40,277:INFO:Importing libraries
2023-05-12 15:31:40,277:INFO:Copying training dataset
2023-05-12 15:31:40,281:INFO:Defining folds
2023-05-12 15:31:40,281:INFO:Declaring metric variables
2023-05-12 15:31:40,287:INFO:Importing untrained model
2023-05-12 15:31:40,293:INFO:Elastic Net Imported successfully
2023-05-12 15:31:40,303:INFO:Starting cross validation
2023-05-12 15:31:40,304:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:40,320:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.219e+08, tolerance: 1.948e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:40,344:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.152e+08, tolerance: 1.970e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:40,368:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+08, tolerance: 1.940e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:40,393:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.927e+08, tolerance: 1.938e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:40,417:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.434e+08, tolerance: 1.941e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:40,441:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.622e+08, tolerance: 1.951e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:40,465:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.840e+08, tolerance: 1.974e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:40,490:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.019e+08, tolerance: 1.907e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:40,514:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.858e+08, tolerance: 1.939e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:40,538:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.022e+08, tolerance: 1.982e+07
  model = cd_fast.enet_coordinate_descent(

2023-05-12 15:31:40,549:INFO:Calculating mean and std
2023-05-12 15:31:40,550:INFO:Creating metrics dataframe
2023-05-12 15:31:40,555:INFO:Uploading results into container
2023-05-12 15:31:40,556:INFO:Uploading model into container now
2023-05-12 15:31:40,557:INFO:_master_model_container: 4
2023-05-12 15:31:40,557:INFO:_display_container: 2
2023-05-12 15:31:40,558:INFO:ElasticNet(random_state=123)
2023-05-12 15:31:40,558:INFO:create_model() successfully completed......................................
2023-05-12 15:31:40,639:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:40,639:INFO:Creating metrics dataframe
2023-05-12 15:31:40,653:INFO:Initializing Least Angle Regression
2023-05-12 15:31:40,654:INFO:Total runtime is 0.0264873743057251 minutes
2023-05-12 15:31:40,658:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:40,659:INFO:Initializing create_model()
2023-05-12 15:31:40,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:40,659:INFO:Checking exceptions
2023-05-12 15:31:40,659:INFO:Importing libraries
2023-05-12 15:31:40,659:INFO:Copying training dataset
2023-05-12 15:31:40,663:INFO:Defining folds
2023-05-12 15:31:40,663:INFO:Declaring metric variables
2023-05-12 15:31:40,668:INFO:Importing untrained model
2023-05-12 15:31:40,674:INFO:Least Angle Regression Imported successfully
2023-05-12 15:31:40,683:INFO:Starting cross validation
2023-05-12 15:31:40,685:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:40,709:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:40,731:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:40,754:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:40,786:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:40,810:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:40,834:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:40,858:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:40,885:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:40,908:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:40,932:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:40,943:INFO:Calculating mean and std
2023-05-12 15:31:40,945:INFO:Creating metrics dataframe
2023-05-12 15:31:40,948:INFO:Uploading results into container
2023-05-12 15:31:40,949:INFO:Uploading model into container now
2023-05-12 15:31:40,950:INFO:_master_model_container: 5
2023-05-12 15:31:40,950:INFO:_display_container: 2
2023-05-12 15:31:40,950:INFO:Lars(random_state=123)
2023-05-12 15:31:40,951:INFO:create_model() successfully completed......................................
2023-05-12 15:31:41,027:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:41,028:INFO:Creating metrics dataframe
2023-05-12 15:31:41,041:INFO:Initializing Lasso Least Angle Regression
2023-05-12 15:31:41,041:INFO:Total runtime is 0.03295421600341797 minutes
2023-05-12 15:31:41,047:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:41,048:INFO:Initializing create_model()
2023-05-12 15:31:41,048:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:41,048:INFO:Checking exceptions
2023-05-12 15:31:41,048:INFO:Importing libraries
2023-05-12 15:31:41,048:INFO:Copying training dataset
2023-05-12 15:31:41,052:INFO:Defining folds
2023-05-12 15:31:41,053:INFO:Declaring metric variables
2023-05-12 15:31:41,058:INFO:Importing untrained model
2023-05-12 15:31:41,063:INFO:Lasso Least Angle Regression Imported successfully
2023-05-12 15:31:41,075:INFO:Starting cross validation
2023-05-12 15:31:41,077:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:41,090:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:31:41,113:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:31:41,136:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:31:41,161:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:31:41,187:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:31:41,211:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:31:41,237:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:31:41,261:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:31:41,283:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:31:41,307:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-05-12 15:31:41,318:INFO:Calculating mean and std
2023-05-12 15:31:41,319:INFO:Creating metrics dataframe
2023-05-12 15:31:41,323:INFO:Uploading results into container
2023-05-12 15:31:41,324:INFO:Uploading model into container now
2023-05-12 15:31:41,324:INFO:_master_model_container: 6
2023-05-12 15:31:41,325:INFO:_display_container: 2
2023-05-12 15:31:41,325:INFO:LassoLars(random_state=123)
2023-05-12 15:31:41,325:INFO:create_model() successfully completed......................................
2023-05-12 15:31:41,404:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:41,404:INFO:Creating metrics dataframe
2023-05-12 15:31:41,419:INFO:Initializing Orthogonal Matching Pursuit
2023-05-12 15:31:41,420:INFO:Total runtime is 0.039270909627278645 minutes
2023-05-12 15:31:41,427:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:41,428:INFO:Initializing create_model()
2023-05-12 15:31:41,428:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:41,429:INFO:Checking exceptions
2023-05-12 15:31:41,429:INFO:Importing libraries
2023-05-12 15:31:41,429:INFO:Copying training dataset
2023-05-12 15:31:41,436:INFO:Defining folds
2023-05-12 15:31:41,437:INFO:Declaring metric variables
2023-05-12 15:31:41,447:INFO:Importing untrained model
2023-05-12 15:31:41,453:INFO:Orthogonal Matching Pursuit Imported successfully
2023-05-12 15:31:41,463:INFO:Starting cross validation
2023-05-12 15:31:41,464:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:41,479:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:41,505:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:41,531:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:41,556:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:41,578:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:41,603:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:41,630:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:41,653:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:41,675:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:41,699:WARNING:c:\Users\Feras\anaconda3\envs\Crypto\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-05-12 15:31:41,710:INFO:Calculating mean and std
2023-05-12 15:31:41,712:INFO:Creating metrics dataframe
2023-05-12 15:31:41,715:INFO:Uploading results into container
2023-05-12 15:31:41,716:INFO:Uploading model into container now
2023-05-12 15:31:41,717:INFO:_master_model_container: 7
2023-05-12 15:31:41,717:INFO:_display_container: 2
2023-05-12 15:31:41,717:INFO:OrthogonalMatchingPursuit()
2023-05-12 15:31:41,717:INFO:create_model() successfully completed......................................
2023-05-12 15:31:41,796:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:41,796:INFO:Creating metrics dataframe
2023-05-12 15:31:41,811:INFO:Initializing Bayesian Ridge
2023-05-12 15:31:41,812:INFO:Total runtime is 0.045804222424825035 minutes
2023-05-12 15:31:41,816:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:41,816:INFO:Initializing create_model()
2023-05-12 15:31:41,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:41,817:INFO:Checking exceptions
2023-05-12 15:31:41,817:INFO:Importing libraries
2023-05-12 15:31:41,817:INFO:Copying training dataset
2023-05-12 15:31:41,822:INFO:Defining folds
2023-05-12 15:31:41,823:INFO:Declaring metric variables
2023-05-12 15:31:41,832:INFO:Importing untrained model
2023-05-12 15:31:41,839:INFO:Bayesian Ridge Imported successfully
2023-05-12 15:31:41,849:INFO:Starting cross validation
2023-05-12 15:31:41,850:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:42,083:INFO:Calculating mean and std
2023-05-12 15:31:42,084:INFO:Creating metrics dataframe
2023-05-12 15:31:42,089:INFO:Uploading results into container
2023-05-12 15:31:42,090:INFO:Uploading model into container now
2023-05-12 15:31:42,091:INFO:_master_model_container: 8
2023-05-12 15:31:42,091:INFO:_display_container: 2
2023-05-12 15:31:42,092:INFO:BayesianRidge()
2023-05-12 15:31:42,093:INFO:create_model() successfully completed......................................
2023-05-12 15:31:42,171:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:42,171:INFO:Creating metrics dataframe
2023-05-12 15:31:42,184:INFO:Initializing Passive Aggressive Regressor
2023-05-12 15:31:42,185:INFO:Total runtime is 0.052020943164825445 minutes
2023-05-12 15:31:42,190:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:42,190:INFO:Initializing create_model()
2023-05-12 15:31:42,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:42,190:INFO:Checking exceptions
2023-05-12 15:31:42,191:INFO:Importing libraries
2023-05-12 15:31:42,191:INFO:Copying training dataset
2023-05-12 15:31:42,195:INFO:Defining folds
2023-05-12 15:31:42,196:INFO:Declaring metric variables
2023-05-12 15:31:42,201:INFO:Importing untrained model
2023-05-12 15:31:42,207:INFO:Passive Aggressive Regressor Imported successfully
2023-05-12 15:31:42,218:INFO:Starting cross validation
2023-05-12 15:31:42,220:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:42,460:INFO:Calculating mean and std
2023-05-12 15:31:42,461:INFO:Creating metrics dataframe
2023-05-12 15:31:42,465:INFO:Uploading results into container
2023-05-12 15:31:42,466:INFO:Uploading model into container now
2023-05-12 15:31:42,466:INFO:_master_model_container: 9
2023-05-12 15:31:42,466:INFO:_display_container: 2
2023-05-12 15:31:42,467:INFO:PassiveAggressiveRegressor(random_state=123)
2023-05-12 15:31:42,467:INFO:create_model() successfully completed......................................
2023-05-12 15:31:42,545:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:42,545:INFO:Creating metrics dataframe
2023-05-12 15:31:42,560:INFO:Initializing Huber Regressor
2023-05-12 15:31:42,560:INFO:Total runtime is 0.05826749801635743 minutes
2023-05-12 15:31:42,565:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:42,566:INFO:Initializing create_model()
2023-05-12 15:31:42,566:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:42,566:INFO:Checking exceptions
2023-05-12 15:31:42,566:INFO:Importing libraries
2023-05-12 15:31:42,567:INFO:Copying training dataset
2023-05-12 15:31:42,571:INFO:Defining folds
2023-05-12 15:31:42,571:INFO:Declaring metric variables
2023-05-12 15:31:42,576:INFO:Importing untrained model
2023-05-12 15:31:42,581:INFO:Huber Regressor Imported successfully
2023-05-12 15:31:42,591:INFO:Starting cross validation
2023-05-12 15:31:42,592:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:42,870:INFO:Calculating mean and std
2023-05-12 15:31:42,872:INFO:Creating metrics dataframe
2023-05-12 15:31:42,876:INFO:Uploading results into container
2023-05-12 15:31:42,876:INFO:Uploading model into container now
2023-05-12 15:31:42,877:INFO:_master_model_container: 10
2023-05-12 15:31:42,877:INFO:_display_container: 2
2023-05-12 15:31:42,878:INFO:HuberRegressor()
2023-05-12 15:31:42,878:INFO:create_model() successfully completed......................................
2023-05-12 15:31:42,955:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:42,955:INFO:Creating metrics dataframe
2023-05-12 15:31:42,969:INFO:Initializing K Neighbors Regressor
2023-05-12 15:31:42,969:INFO:Total runtime is 0.06508449713389079 minutes
2023-05-12 15:31:42,974:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:42,974:INFO:Initializing create_model()
2023-05-12 15:31:42,975:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:42,975:INFO:Checking exceptions
2023-05-12 15:31:42,975:INFO:Importing libraries
2023-05-12 15:31:42,975:INFO:Copying training dataset
2023-05-12 15:31:42,979:INFO:Defining folds
2023-05-12 15:31:42,979:INFO:Declaring metric variables
2023-05-12 15:31:42,984:INFO:Importing untrained model
2023-05-12 15:31:42,993:INFO:K Neighbors Regressor Imported successfully
2023-05-12 15:31:43,016:INFO:Starting cross validation
2023-05-12 15:31:43,020:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:48,315:INFO:Calculating mean and std
2023-05-12 15:31:48,317:INFO:Creating metrics dataframe
2023-05-12 15:31:48,321:INFO:Uploading results into container
2023-05-12 15:31:48,322:INFO:Uploading model into container now
2023-05-12 15:31:48,322:INFO:_master_model_container: 11
2023-05-12 15:31:48,323:INFO:_display_container: 2
2023-05-12 15:31:48,323:INFO:KNeighborsRegressor(n_jobs=-1)
2023-05-12 15:31:48,323:INFO:create_model() successfully completed......................................
2023-05-12 15:31:48,403:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:48,403:INFO:Creating metrics dataframe
2023-05-12 15:31:48,419:INFO:Initializing Decision Tree Regressor
2023-05-12 15:31:48,420:INFO:Total runtime is 0.15594160159428916 minutes
2023-05-12 15:31:48,425:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:48,425:INFO:Initializing create_model()
2023-05-12 15:31:48,426:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:48,426:INFO:Checking exceptions
2023-05-12 15:31:48,426:INFO:Importing libraries
2023-05-12 15:31:48,426:INFO:Copying training dataset
2023-05-12 15:31:48,429:INFO:Defining folds
2023-05-12 15:31:48,430:INFO:Declaring metric variables
2023-05-12 15:31:48,436:INFO:Importing untrained model
2023-05-12 15:31:48,441:INFO:Decision Tree Regressor Imported successfully
2023-05-12 15:31:48,450:INFO:Starting cross validation
2023-05-12 15:31:48,452:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:48,703:INFO:Calculating mean and std
2023-05-12 15:31:48,705:INFO:Creating metrics dataframe
2023-05-12 15:31:48,708:INFO:Uploading results into container
2023-05-12 15:31:48,709:INFO:Uploading model into container now
2023-05-12 15:31:48,710:INFO:_master_model_container: 12
2023-05-12 15:31:48,710:INFO:_display_container: 2
2023-05-12 15:31:48,710:INFO:DecisionTreeRegressor(random_state=123)
2023-05-12 15:31:48,711:INFO:create_model() successfully completed......................................
2023-05-12 15:31:48,789:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:48,789:INFO:Creating metrics dataframe
2023-05-12 15:31:48,805:INFO:Initializing Random Forest Regressor
2023-05-12 15:31:48,806:INFO:Total runtime is 0.16236443916956586 minutes
2023-05-12 15:31:48,811:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:48,811:INFO:Initializing create_model()
2023-05-12 15:31:48,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:48,812:INFO:Checking exceptions
2023-05-12 15:31:48,812:INFO:Importing libraries
2023-05-12 15:31:48,812:INFO:Copying training dataset
2023-05-12 15:31:48,816:INFO:Defining folds
2023-05-12 15:31:48,817:INFO:Declaring metric variables
2023-05-12 15:31:48,822:INFO:Importing untrained model
2023-05-12 15:31:48,828:INFO:Random Forest Regressor Imported successfully
2023-05-12 15:31:48,839:INFO:Starting cross validation
2023-05-12 15:31:48,840:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:50,943:INFO:Calculating mean and std
2023-05-12 15:31:50,944:INFO:Creating metrics dataframe
2023-05-12 15:31:50,949:INFO:Uploading results into container
2023-05-12 15:31:50,950:INFO:Uploading model into container now
2023-05-12 15:31:50,951:INFO:_master_model_container: 13
2023-05-12 15:31:50,951:INFO:_display_container: 2
2023-05-12 15:31:50,951:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-05-12 15:31:50,952:INFO:create_model() successfully completed......................................
2023-05-12 15:31:51,033:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:51,034:INFO:Creating metrics dataframe
2023-05-12 15:31:51,049:INFO:Initializing Extra Trees Regressor
2023-05-12 15:31:51,050:INFO:Total runtime is 0.19976442654927573 minutes
2023-05-12 15:31:51,054:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:51,055:INFO:Initializing create_model()
2023-05-12 15:31:51,055:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:51,055:INFO:Checking exceptions
2023-05-12 15:31:51,055:INFO:Importing libraries
2023-05-12 15:31:51,056:INFO:Copying training dataset
2023-05-12 15:31:51,059:INFO:Defining folds
2023-05-12 15:31:51,059:INFO:Declaring metric variables
2023-05-12 15:31:51,064:INFO:Importing untrained model
2023-05-12 15:31:51,070:INFO:Extra Trees Regressor Imported successfully
2023-05-12 15:31:51,080:INFO:Starting cross validation
2023-05-12 15:31:51,081:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:52,938:INFO:Calculating mean and std
2023-05-12 15:31:52,940:INFO:Creating metrics dataframe
2023-05-12 15:31:52,944:INFO:Uploading results into container
2023-05-12 15:31:52,945:INFO:Uploading model into container now
2023-05-12 15:31:52,945:INFO:_master_model_container: 14
2023-05-12 15:31:52,945:INFO:_display_container: 2
2023-05-12 15:31:52,946:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-05-12 15:31:52,946:INFO:create_model() successfully completed......................................
2023-05-12 15:31:53,028:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:53,028:INFO:Creating metrics dataframe
2023-05-12 15:31:53,049:INFO:Initializing AdaBoost Regressor
2023-05-12 15:31:53,050:INFO:Total runtime is 0.23309770027796428 minutes
2023-05-12 15:31:53,055:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:53,056:INFO:Initializing create_model()
2023-05-12 15:31:53,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:53,056:INFO:Checking exceptions
2023-05-12 15:31:53,056:INFO:Importing libraries
2023-05-12 15:31:53,056:INFO:Copying training dataset
2023-05-12 15:31:53,060:INFO:Defining folds
2023-05-12 15:31:53,060:INFO:Declaring metric variables
2023-05-12 15:31:53,065:INFO:Importing untrained model
2023-05-12 15:31:53,070:INFO:AdaBoost Regressor Imported successfully
2023-05-12 15:31:53,080:INFO:Starting cross validation
2023-05-12 15:31:53,082:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:53,697:INFO:Calculating mean and std
2023-05-12 15:31:53,698:INFO:Creating metrics dataframe
2023-05-12 15:31:53,703:INFO:Uploading results into container
2023-05-12 15:31:53,704:INFO:Uploading model into container now
2023-05-12 15:31:53,704:INFO:_master_model_container: 15
2023-05-12 15:31:53,705:INFO:_display_container: 2
2023-05-12 15:31:53,705:INFO:AdaBoostRegressor(random_state=123)
2023-05-12 15:31:53,705:INFO:create_model() successfully completed......................................
2023-05-12 15:31:53,784:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:53,785:INFO:Creating metrics dataframe
2023-05-12 15:31:53,801:INFO:Initializing Gradient Boosting Regressor
2023-05-12 15:31:53,801:INFO:Total runtime is 0.24561439355214437 minutes
2023-05-12 15:31:53,807:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:53,807:INFO:Initializing create_model()
2023-05-12 15:31:53,808:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:53,808:INFO:Checking exceptions
2023-05-12 15:31:53,808:INFO:Importing libraries
2023-05-12 15:31:53,808:INFO:Copying training dataset
2023-05-12 15:31:53,812:INFO:Defining folds
2023-05-12 15:31:53,812:INFO:Declaring metric variables
2023-05-12 15:31:53,817:INFO:Importing untrained model
2023-05-12 15:31:53,822:INFO:Gradient Boosting Regressor Imported successfully
2023-05-12 15:31:53,833:INFO:Starting cross validation
2023-05-12 15:31:53,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:54,503:INFO:Calculating mean and std
2023-05-12 15:31:54,504:INFO:Creating metrics dataframe
2023-05-12 15:31:54,508:INFO:Uploading results into container
2023-05-12 15:31:54,509:INFO:Uploading model into container now
2023-05-12 15:31:54,510:INFO:_master_model_container: 16
2023-05-12 15:31:54,510:INFO:_display_container: 2
2023-05-12 15:31:54,511:INFO:GradientBoostingRegressor(random_state=123)
2023-05-12 15:31:54,511:INFO:create_model() successfully completed......................................
2023-05-12 15:31:54,587:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:54,587:INFO:Creating metrics dataframe
2023-05-12 15:31:54,604:INFO:Initializing Extreme Gradient Boosting
2023-05-12 15:31:54,604:INFO:Total runtime is 0.2589977780977885 minutes
2023-05-12 15:31:54,612:INFO:SubProcess create_model() called ==================================
2023-05-12 15:31:54,612:INFO:Initializing create_model()
2023-05-12 15:31:54,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:31:54,613:INFO:Checking exceptions
2023-05-12 15:31:54,613:INFO:Importing libraries
2023-05-12 15:31:54,613:INFO:Copying training dataset
2023-05-12 15:31:54,618:INFO:Defining folds
2023-05-12 15:31:54,618:INFO:Declaring metric variables
2023-05-12 15:31:54,625:INFO:Importing untrained model
2023-05-12 15:31:54,631:INFO:Extreme Gradient Boosting Imported successfully
2023-05-12 15:31:54,641:INFO:Starting cross validation
2023-05-12 15:31:54,643:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:31:59,859:INFO:Calculating mean and std
2023-05-12 15:31:59,862:INFO:Creating metrics dataframe
2023-05-12 15:31:59,872:INFO:Uploading results into container
2023-05-12 15:31:59,874:INFO:Uploading model into container now
2023-05-12 15:31:59,875:INFO:_master_model_container: 17
2023-05-12 15:31:59,875:INFO:_display_container: 2
2023-05-12 15:31:59,877:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-05-12 15:31:59,877:INFO:create_model() successfully completed......................................
2023-05-12 15:31:59,992:INFO:SubProcess create_model() end ==================================
2023-05-12 15:31:59,992:INFO:Creating metrics dataframe
2023-05-12 15:32:00,009:INFO:Initializing Light Gradient Boosting Machine
2023-05-12 15:32:00,009:INFO:Total runtime is 0.3490793546040853 minutes
2023-05-12 15:32:00,017:INFO:SubProcess create_model() called ==================================
2023-05-12 15:32:00,018:INFO:Initializing create_model()
2023-05-12 15:32:00,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:32:00,019:INFO:Checking exceptions
2023-05-12 15:32:00,019:INFO:Importing libraries
2023-05-12 15:32:00,019:INFO:Copying training dataset
2023-05-12 15:32:00,024:INFO:Defining folds
2023-05-12 15:32:00,024:INFO:Declaring metric variables
2023-05-12 15:32:00,031:INFO:Importing untrained model
2023-05-12 15:32:00,037:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-12 15:32:00,049:INFO:Starting cross validation
2023-05-12 15:32:00,051:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:32:08,689:INFO:Calculating mean and std
2023-05-12 15:32:08,692:INFO:Creating metrics dataframe
2023-05-12 15:32:08,700:INFO:Uploading results into container
2023-05-12 15:32:08,702:INFO:Uploading model into container now
2023-05-12 15:32:08,703:INFO:_master_model_container: 18
2023-05-12 15:32:08,703:INFO:_display_container: 2
2023-05-12 15:32:08,704:INFO:LGBMRegressor(device='gpu', random_state=123)
2023-05-12 15:32:08,704:INFO:create_model() successfully completed......................................
2023-05-12 15:32:08,823:INFO:SubProcess create_model() end ==================================
2023-05-12 15:32:08,823:INFO:Creating metrics dataframe
2023-05-12 15:32:08,840:INFO:Initializing Dummy Regressor
2023-05-12 15:32:08,840:INFO:Total runtime is 0.4962626894315084 minutes
2023-05-12 15:32:08,844:INFO:SubProcess create_model() called ==================================
2023-05-12 15:32:08,845:INFO:Initializing create_model()
2023-05-12 15:32:08,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208929FA350>, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:32:08,846:INFO:Checking exceptions
2023-05-12 15:32:08,846:INFO:Importing libraries
2023-05-12 15:32:08,846:INFO:Copying training dataset
2023-05-12 15:32:08,850:INFO:Defining folds
2023-05-12 15:32:08,850:INFO:Declaring metric variables
2023-05-12 15:32:08,855:INFO:Importing untrained model
2023-05-12 15:32:08,864:INFO:Dummy Regressor Imported successfully
2023-05-12 15:32:08,884:INFO:Starting cross validation
2023-05-12 15:32:08,885:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:32:09,127:INFO:Calculating mean and std
2023-05-12 15:32:09,129:INFO:Creating metrics dataframe
2023-05-12 15:32:09,134:INFO:Uploading results into container
2023-05-12 15:32:09,135:INFO:Uploading model into container now
2023-05-12 15:32:09,135:INFO:_master_model_container: 19
2023-05-12 15:32:09,136:INFO:_display_container: 2
2023-05-12 15:32:09,136:INFO:DummyRegressor()
2023-05-12 15:32:09,136:INFO:create_model() successfully completed......................................
2023-05-12 15:32:09,216:INFO:SubProcess create_model() end ==================================
2023-05-12 15:32:09,216:INFO:Creating metrics dataframe
2023-05-12 15:32:09,247:INFO:Initializing create_model()
2023-05-12 15:32:09,247:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:32:09,248:INFO:Checking exceptions
2023-05-12 15:32:09,250:INFO:Importing libraries
2023-05-12 15:32:09,250:INFO:Copying training dataset
2023-05-12 15:32:09,255:INFO:Defining folds
2023-05-12 15:32:09,255:INFO:Declaring metric variables
2023-05-12 15:32:09,255:INFO:Importing untrained model
2023-05-12 15:32:09,256:INFO:Declaring custom model
2023-05-12 15:32:09,256:INFO:Linear Regression Imported successfully
2023-05-12 15:32:09,258:INFO:Cross validation set to False
2023-05-12 15:32:09,258:INFO:Fitting Model
2023-05-12 15:32:09,269:INFO:LinearRegression(n_jobs=-1)
2023-05-12 15:32:09,269:INFO:create_model() successfully completed......................................
2023-05-12 15:32:09,399:INFO:_master_model_container: 19
2023-05-12 15:32:09,399:INFO:_display_container: 2
2023-05-12 15:32:09,399:INFO:LinearRegression(n_jobs=-1)
2023-05-12 15:32:09,399:INFO:compare_models() successfully completed......................................
2023-05-12 15:32:09,579:INFO:Initializing create_model()
2023-05-12 15:32:09,580:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-12 15:32:09,580:INFO:Checking exceptions
2023-05-12 15:32:09,617:INFO:Importing libraries
2023-05-12 15:32:09,617:INFO:Copying training dataset
2023-05-12 15:32:09,625:INFO:Defining folds
2023-05-12 15:32:09,625:INFO:Declaring metric variables
2023-05-12 15:32:09,634:INFO:Importing untrained model
2023-05-12 15:32:09,641:INFO:Huber Regressor Imported successfully
2023-05-12 15:32:09,652:INFO:Starting cross validation
2023-05-12 15:32:09,653:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2023-05-12 15:32:10,003:INFO:Calculating mean and std
2023-05-12 15:32:10,004:INFO:Creating metrics dataframe
2023-05-12 15:32:10,010:INFO:Finalizing model
2023-05-12 15:32:10,034:INFO:Uploading results into container
2023-05-12 15:32:10,035:INFO:Uploading model into container now
2023-05-12 15:32:10,049:INFO:_master_model_container: 20
2023-05-12 15:32:10,050:INFO:_display_container: 3
2023-05-12 15:32:10,050:INFO:HuberRegressor()
2023-05-12 15:32:10,050:INFO:create_model() successfully completed......................................
2023-05-12 15:32:10,287:INFO:Initializing evaluate_model()
2023-05-12 15:32:10,287:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-05-12 15:32:10,311:INFO:Initializing plot_model()
2023-05-12 15:32:10,311:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, system=True)
2023-05-12 15:32:10,312:INFO:Checking exceptions
2023-05-12 15:32:10,314:INFO:Preloading libraries
2023-05-12 15:32:10,314:INFO:Copying training dataset
2023-05-12 15:32:10,315:INFO:Plot type: pipeline
2023-05-12 15:32:10,491:INFO:Visual Rendered Successfully
2023-05-12 15:32:10,573:INFO:plot_model() successfully completed......................................
2023-05-12 15:32:10,716:INFO:Initializing predict_model()
2023-05-12 15:32:10,717:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000208B6DDFD90>, estimator=HuberRegressor(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000208BAD71630>)
2023-05-12 15:32:10,717:INFO:Checking exceptions
2023-05-12 15:32:10,717:INFO:Preloading libraries
2023-05-12 15:32:10,721:INFO:Set up data.
2023-05-12 15:32:10,726:INFO:Set up index.
